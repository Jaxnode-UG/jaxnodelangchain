Twitter/XLinkedInReddit   Listen to Post By David FekkeFebruary 9th, 2024I normally do not use my posts to rant about anything because I find that boring in most cases, but I have decided to speak up about something I have noticed about the way companies are treating applicants for technical roles.
I recently was laid off from the company I worked at for the last year and half. It is not my first rodeo, I have been through this before. I have the advantage of having a quarter century of work experience as a software engineer. I found another job, but it took longer than I thought it would, so I wanted to write about some of the things I noticed about tech hiring.
I had some runway from my old job, but I decided that I did not want to wait before starting to look for a new job. I live in North East Florida. While there are a lot of software engineering roles here in Jacksonville, there are not a lot of roles doing specifically what I had been doing, which was mobile development.
My previous company was based in Silicon Valley where I worked remotely. So I decided I was either going to pursue remote roles or local roles where I could work onsite.
One of the other things that became evident to me was despite having historically low unemployment in the United States, all of the tech layoffs has put a lot more potential candidates out into the marketplace competing for the same roles.
No one is hiring in December
I was notified about the workforce reduction in December. The first thing I noticed was that no one is hiring in December. Most companies that have employees involved in the hiring process are on leave for the holidays. I was able to interview with two companies in December, but no offers came from those first two interviews.
In the second week of January is when I finally started hearing from companies that were looking to hire.
Hiring in the past
In the past when I interviewed for roles, the interview process has generally been very short. Usually two interviews. Generally the first interview would be an interview with a recruiter or hiring manager. The second was usually a technical interview where the company offering the role could pick my brain about how much I knew about whatever technologies I had experience using as a software engineer. Occasionally I would be asked to do a third interview.
In the past when a company asked to do a third interview, this was a sign to me that they did not know what they were doing when it came to hiring. It should never take more than two interviews for a company to know if they want to make an offer to a candidate.
Hiring now
In the last year and a half this process has changed. What used to be a relatively short process has become a real slog. On average with the companies that were serious about interviewing me for a role, it took five interviews. Five!
The Coding Assessment
I am assuming because there are so many applicants looking for fewer roles, many companies will have applicants for programming roles do a timed test where they have to perform a coding assignment. Brian Rinaldi just did a post on this on linkedin that I think everyone should read. These assessments are actually costing companies good candidates.
Most of the assessments I did had a timed test where the candidate was supposed to transform some sort of data structure to another structure, and modify the code so it would pass a series of unit tests. The first flaw I found with these tests is that they have the code in a pseudo IDE that is in a browser window. I typically use real IDEs when I am writing code so I can use break points. One of the things these assessments do is record your keystrokes so they can detect if you are cheating, i.e. going to Google or ChatGPT to lookup answers. One of the other problems is that these are not a real world tests. The data structures I typically use are nothing like the ones I used in these assessments.
Some companies are doing the assessments correctly. A couple of the companies provided me a template or an example of what they wanted, and then had me either go and fix their example or write a new program that accomplished what they were looking for in their assessment.
The best coding test I had was one where I was given a Xcode project with a bug. They asked me to fix the bug and add some new features, and write unit tests to test the new features. I think this is the best way to do an assessment, and it is more realistic than the timed based browser assessments.
The Technical Interview
One of the companies I interviewed with had me do two different technical interviews and then another one with the manager I would have been working for. At the end of the first technical interview at this company, the interviewer had one hour to interview me before I had to do another interview with another company. Towards the end of the interview, about five minutes before I had to go to my next interview, he asked me to do a coding assessment. The assessment was to transform a flat array of objects with a parent child relationship into a hierarchical structure in TypeScript. I told the interviewer that I only had five minutes before my next call, but I verbally described how I would transform the array into the structure using a Map.
This same company preceded to interview me another two times after this first technical interview. At the end of the process I tried to find out if they were going to make me an offer because I had another offer at this point after interviewing with for four weeks. They came back and told me that they were going to pass on making me an offer because I had not done the coding test. The same one that I verbally described how I would do five minutes before my next call.
Hiring Timeline
One of the advantages that companies have right now is that there is are many great candidates to choose from because of all of the tech layoffs. One of the more perplexing things I noticed was the amount of time that companies are taking to get back to candidates, and once they do, how long the entire process takes. One of the Silicon Valley companies I did an interview with I asked how long they were planning on taking to do the entire process. The answer I got back was six to seven weeks. As bad as that sounds, there are companies that take longer. I interviewed one time with one of the big cloud companies, I asked them how long they were planning on taking before filling the role, and they told this time it would be around six months, which was much faster than the 18 months it usually takes them to fill a role.
The advice I would give to any company that is hiring is that when you have candidates that are currently unemployed, you should not have a long extended hiring process. It is not good for your organization, and it is extremely disrespectful for the people who want to work for your company. These candidates may or may not have a severance. Don't make someone wait who can start working for you tomorrow.
Conclusion
It took me less than two months to land a new role, so I can't complain how long it took me to land a new role. I have a friend where it took him seven months to land his next gig.
My advice to companies looking to fill roles is to not waste time on extra unneeded interviews, especially with candidates that are currently out work.
If you have multiple people that need to interview the same candidate, try to do a gang interview where everyone can do the interview on the same day. If you do have to split the interviews up, keep the time between interviews to minimum.Tags: Technical Interview,   Hiring   ‚Üê Previous Page 



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 27th, 2024I will be giving a presentation on Software Development and AI at the Jax Software and AI meetup group on this Wednesday. This presentation will go over the current trends in AI as it concerns software development in 2024, and what developers and software engineers will be expected to know.
AI, and more specifically generative AI has been getting a lot of attention over the last year or so. We are already starting to see software changing and using some of the new technologies that have evolved in just the last year. Some examples we have seen so far:

GPT styled ChatBots
Generative fills in web and desktop applications
Prompts added to our UIs
Image generation
Voice generation and voice copying

Are we all going to lose our jobs?
One of the concerns, especially for white collar workers, is the prospect we are all going to be losing our jobs. Even in Software Engineering there has been the concern that jobs will be eliminated.
If you look throughout history, as automation has been added, some jobs are lost, but many more are gained because of increased productivity. The first effect we are seeing is increased worker productivity.
Developer tools
Many developers have already been using Github Copilot for the last couple of years. Copilot uses code completion features to try to automate and complete code in most programming languages. Github recently added a chatbot and prompt that can be used in Visual Studio Code. There are other tools for developers such as Amazon's codewhisperer and Tabnine.
Processors
When writing software for computers, the primary target has been the CPU, or central processing unit. More recently other processors and cores have been showing up in our computers and devices. GPUs (Graphic Processing Units), NPUs (Neural Processing Units) and TPUs (Tensor Processing Units) have all been seen entering computers and servers over the last few years. Much of the AI software being developed today is written to take advantage of the features of these cores and chips. The algorithms for many of today's AI and machine learning models use linear algebra to provide inference for these models.
GPUs, NPUs and TPUs all handle linear algebra much quicker and more efficiently than traditional CPUs. Expect to see more specialized hardware designed specifically for this type of processing.
Programming Languages for AI
The default language for much of machine learning, math and data science is Python. There are other languages that are also popular for ML and AI tasks, but most of the development for creating and working directly with the models is done in Python.
Many of the tools and libraries for working with machine learning and AI are written in Python as well. Some of these tools include SciKit, TensorFlow, Keras, Pandas and PyTorch. The two most popular frameworks are TensorFlow and PyTorch. Both work with tensors, the basic object type for working with machine learning.
Mojo
Mojo is a new language developed by a startup called Modular. Modular was started by Chris Lattner, the same engineer behind LLVM, Clang, Objective-C 2.0 and Swift.
Mojo is a superset of Python. Think of TypeScript and JavaScript. Just like TypeScript, Mojo adds a type system to the language, but unlike TypeScript, Mojo has a compiler than converts Python/Mojo code into executables that will run as fast as C++ or Rust programs.
Modular has a couple of products that seek to address some of the scaling issues that ML and AI companies have been facing with their Python code. Check out this interview with Chris on the Lex Fridman podcast:

    
        
    

Generative AI
The real breakthrough in AI over the last year or so has been Generative AI. Generative AI focuses mostly on the transformation and generating of content based on a prompts or other inputs. Some examples of Generative AI are as follows:

Text -> Text
Text -> Images
Text -> Video
Image -> Text
Text -> Audio

Many companies including OpenAI, Microsoft, Google, Anthropic and Meta have created services, APIs, SDKs and frameworks we can use to use generative AI. Some of these services cost money, and some can be run on fast hardware running open source software.
APIs
OpenAI has made many of their APIs available to the general public. These API are pretty easy to use. They can be authenticated with a simple key, and use the OpenAI python or Node.js modules. They can also be accessed with a REST API. Here is a example of how their API works:
from openai import OpenAI
client = OpenAI()

response = client.images.generate(
  model="dall-e-3",
  prompt="a white siamese cat",
  size="1024x1024",
  quality="standard",
  n=1,
)

image_url = response.data[0].url
In the above example, the Dall-E API is used to generate an image of a siamese cat. Here is the resulting image.

      
    
  
  
    
Prompts
One of the terms you may have heard recently is called Prompt Engineering. There is a whole new set of jobs that have been created in designing prompts that can be used in conjunction with AI models.
Think of prompts as being the input for your AI function or application. If you look at ChatGPT, when you ask ChatGPT a question, it is a type of prompt.
Prompts can also be designed for the entire system and user prompts can be decorated with additional meta information that can help the AI be more precise in its outputs.
Large Language Models
ChatGPT and GPT 3.5 and 4 are all examples of large language models. OpenAI is not the only vendor of LLMs. Google provides access to LLMs through Bard and Gemini. Gemini is the latest version of Google's multi-model AI that will work with images, text, audio and video.
Anthropic is a company that was started by former OpenAI engineers that have an LLM called Claude. Other vendors include Cohere and Fal.ai.
One of the more interesting entrants in this space is the open source LLM. Meta, the parent company of Facebook, released their open source LLM called Llama 2. This gives developers the ability to run this LLM on their own hardware.
Custom GPTs
OpenAI now allows users to create their own GPTs. The user can design custom prompts for their GPT, and add data and functions that can be used by the GPT. These custom GPTs can also be placed on the GPT store.
Langchain
One of the frameworks that has become popular over the last year has been Langchain. Langchain allows developers to build context aware AI applications with either Python or JavaScript.
Langchain also allows you to chain prompts, data and functions together with LLMs.
One of the more powerful features of Langchain is the ability to take unstructured data and break it up in a way that it can be stored either in a database or memory, and then retrieved for building intelligent applications and agents.
Vector Databases
Being able to store and retrieve text data easily is important if you want to be able to use the data with an AI model. There are now multiple vendors that provide vector databases or vector extensions for existing databases like Postgres SQL.
The way vector databases work is that they can store data along with a vector. Think of a vector as a array of numbers. OpenAI as an example has an embedding service that will convert text into an embedding. Embeddings are nothing more than an array of floating point numbers.
These embeddings can be stored in a vector database, and can be used when fetching an answer from the LLM. Vectors can also be retrieved from the database using a cosine search algorithm.
RAG Apps
RAG stands for Retrieval Augmented Generation. RAG apps are a way of passing your data and functions to an AI application when prompting the application for output that you want to be tailored to your data.
Langchain is a framework that makes this relatively easy to do. Lanchain has functions that can be used to break up unstructured data into vectors, and then those vectors cab be used with prompts for more precise output from the LLM.
A good example of a RAG application built with Langchain is one where PDF or word processing documents are converted into vectors and stored for retrieval, and then these vectors can be recalled when a user is asking questions around that data.
Examples of AI in use of apps today
I mentioned the coding assistants earlier, but there are many other examples of AI showing up in applications we use everyday. If you use gmail or iMessage, you may have noticed that these applications are using autocomplete to correct spelling and even grammar.
Linkedin and Meetup both have AI generated fills when filling out forms in their web applications. Even Adobe Photoshop has added a prompt and object detection for selecting objects and extending backgrounds.

      
    
  
  
    
Conclusion
There are really unlimited possibilities of some of the software we can build using these existing Generative AI models. We are already starting to see many examples in commercial and open source software. I can't wait to see how developers will use this technology in the future.
And please do not forget to join us at the Jax Software and AI meetup group on this Wednesday.Tags: AI,   Python,   OpenAI,   Dall-E,   Photoshop   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 18th, 2024
    
        
    

Yesterday I gave a presentation on Bun 1.0. If you are not familiar with Bun, it is a JavaScript runtime, bundler, package installer and tester. Not only does it package multiple JavaScript tools into a single tool, it is also really fast. I did a previous post on Bun when it was first released, but I was able to do a deep dive on Bun for this presentation I gave at the JaxNode User Group.
There are now multiple JavaScript runtimes that work outside of the browser, including Node.js and Deno, both created by Ryan Dahl. Both Node and Deno use V8, the JavaScript engine that is part of Chrome, Edge and many other browsers. Node.js is written in C++, and Deno is written in Rust, but they both use V8. Currently V8 is being developed so that it not only has to be compatible with Chrome, it also can not break Node.
Bun is actually written in a language called Zig and it uses WebKit. One of the things that is interesting about webkit is that Apple has made a lot of investments in
webkit to try to make it the fastest browser and the JavaScript engine.
On top of having a very fast JavaScript engine, another thing that we use
quite a bit in the in this ecosystem is package managers. NPM was the
original package manager that shipped with Node.js, and there were a lot of complaints
about uh NPM over the years, but the the project itself hosts modules.
They have well over two million modules, I think it's approaching 3 million modules on on
NPM.
There are a couple of other competing package
managers that came out over the years. Both Yarn and PNPM are our alternative package managers,
and they did some things that NPM didn't do, like caching.
Over the years there's actually been a lot of improvement to NPM, and so I believe now that if you
did a speed comparison between NPM and Yarn, initially yarn was a faster tool. NPM is
actually now faster than Yarn, and now that whole project is
owned by by Microsoft, so if you go to npmjs.com, that's all owned by by
Microsoft.
Now Bun aims to be the fastest package manager.
Bun is written in Zig, and it uses JavaScriptCore for it's runtime, which is the same runtime in WebKit and Safari.
There are some pluses and minuses with that which I'll get into
later, and it's very very fast. It's faster than Deno or Node.js.
Who is Jarred Sumner
So who is this Jarred Sumner guy? Sumner was a Thiel fellow. The Thiel fellowship is a program where they pay college students to leave college, and start a company instead.
Sumner has started other companies, but in 2022 he formed a new startup called Oven.sh to be the parent company for the Bun project. At the end of last year Bun went 1.0.
One of the design goals for Bun is speed. Support for Typescript and JSX are also goals with trasnpilation built in into
the into the tool. Bun also supports ESM and Commonjs
module imports in the same file. Compatibility with other web standard APIs is another goal.
Why is speed so important?
V8 brought JavaScript out of the 90s performance
realm. This really allowed servers to be written in JavaScript. Previously it really wasn't fast enough to run on the server.
JavaScript is still not as fast or as efficient as native code, and so anything that we can try to do to improve the speed of JavaScript is something that we should take
seriously.
JavaScript is an extremely productive languages, and has a lower barrier to entry than some other languages like Rust or Go Lang.
The speed that JavaScript can be bundled is also a huge gain for developer experience. Anyone who has tried to bundle a large Gatsby.js project know how important.
Another reason speed is important is the Cloud. Whether you are using AWS, Azure, GCP, Heroku or Vercel, in the cloud you pay for everything.
You pay for storage, you pay for CPU cycles and you pay for memory.
Installing Bun
So how do you install Bun? Right now Bun is mostly a Mac and a Linux tool, but they do have a Windows beta.
If you are using Windows, I would highly suggest using WSL 2 for Windows. WSL is the subsystem for linux. Bun will install very easily using WSL.
On the Mac, you can install it using a curl command,
NPM, homebrew or even Docker. The easiest way to install is using the curl command.
$ curl -fsSL https://bun.sh/install | bash
Use the curl command that I'm sharing right here, and it'll install it
right there on your your machine.
Bun's built in modules
So there are a bunch of really cool built-in features and modules in Bun. They have modules for serving HTTP content, File I/O and even SQLite. They also have mirrored some of the Node APIs, do you can still use the fs module and the http module.
To create a really simple web server, here is a sample using Bun's server API:
Bun.serve({
    fetch(req: Request) {
      return new Response(`Echo: ${req.url}`);
    },
});
If you want to read the contents of a text file, you can use the Bun.file function:
// Bun file reader is a simple way to read files from the file system
const airports = Bun.file('airports.dat'); 
console.log(`Size: ${airports.size}, type: ${airports.type}`); // number of bytes and mimetype

// Bun.file returns a promise, so we need to use await
const airporttext = await airports
    .text();

const airportArray = airporttext
    .trim()
    .split('\n')
    .map(line => line.split(','));

const airportObjectArray = airportArray.map(line => {
    const airportObject = {
        id: line[0],
        name: line[1].replace(/"/g, ''),
        city: line[2].replace(/"/g, ''),
        country: line[3].replace(/"/g, ''),
        iata: line[4].replace(/"/g, ''),
        icao: line[5].replace(/"/g, ''),
        latitude: line[6].replace(/"/g, ''),
        longitude: line[7].replace(/"/g, ''),
        altitude: line[8].replace(/"/g, ''),
        timezone: line[9].replace(/"/g, ''),
        dst: line[10].replace(/"/g, ''),
        tzDatabase: line[11].replace(/"/g, ''),
        type: line[12].replace(/"/g, ''),
        source: line[13].replace(/"/g, '')
    };
    return airportObject;
});

const crgAirport = airportObjectArray.find(airport => airport.icao === 'KHBI');
console.log(crgAirport);
They also have ffi functionality, that's the foreign function interface. So if you have native code and you need to be able to
interact that code in your JavaScript, you can call that from within your JavaScript application. In the example below, we have a Rust function that adds two numbers together.
// add.rs
#[no_mangle]
pub extern "C" fn add(a: isize, b: isize) -> isize {
    a + b
}
We can can compile this into a dynamic library using following command if you have Cargo installed:
rustc --crate-type cdylib add.rs
This will create a library named libadd.dylib. If we want to use this library in Bun, we can use the following example:
import { dlopen, FFIType, suffix } from "bun:ffi";

const path = `libadd.${suffix}`;

const lib = dlopen(path, {
  add: {
    args: [FFIType.i32, FFIType.i32],
    returns: FFIType.i32,
  },
});

const result = lib.symbols.add(1, 2);
console.log(`The result would be ${result}`);
Bun also supports the fetch API and they have an implementation of the Node Crypto libraries, but they do not seem to be 100% compatible with the Crypto library in Node.js
Node compatibility
While the makers of Bun claim that it is a drop in replacement for Node.js, I did not find that to be the case. You can go to the Bun documentation, and they actually do a pretty good of showing which features are not fully compatible with Node.js.
Bundling
The bundler that comes with Bun is inspired by the esbuild tool and all you have to
do is simply point to an entry point, and any files that are included in that file
will automatically get rolled up into your into your output directory.
await Bun.build({
    entrypoints: ['./index.ts', './server.ts', './honoserver.ts', './filereader.ts'],
    outdir: './dist',
    target: 'node'
});
The following script will run through an array of different entry points, and transpile
these TypeScript files into JavaScript vsersion in the folder called dist. The build function
can build for different targets including browser, node and bun.
Test runner
They also have a test runner that's built into Bun as well, and it is a Jest compatible Runner.It looks for files that have a .test, .spec, _test or _spec. All you have
to do is run bun test, and it will run any test that you have in your in your project.
Is Bun a drop in replacement for Node.js?
Is Bun a drop in replacement for for node.js. What you're going to find is that
most apis will will work just fine with with node. Modules like like the file system,
the HTTP modules are supported, so while Bun has their own modules that are most likely faster than the node based modules, they do support those modules
because they're trying to make it as compatible as possible with the node ecosystem.
Most of the frameworks will just work. Express, Koa, Svelte Kit, Nest will work. Some of the modules they use may not work, so it is important to test.
Frameworks that use JSX server components like Next.js and Remix have partial support on Bun. The server components will not work on Bun.
I would test thoroughly for for compatibility. Bun actually does have pretty good documentation under their docs on all the different Node.js apis, and the current level of support.
Let's talk about V8
Let's talk a little bit about V8 and JavaScriptCore. Node
originally adopted V8, and V8 releases were not initially tied to node releases.
Node was a side project and V8 was tightly
coupled with uh with the Chrome browser, and then at some point, they decided that they were going to release V8 in parallel with Node.js.
Now when V8 does a new release of V8, not only does it have to work with chrome also has to work with Node. They do a pretty thorough
job of making sure that V8 works with both the browser as well as Node.
There is a new release of V8 every four weeks, and that's usually
incorporated into some version of Chrome as well as Nodejs.
Bun uses a JavaScriptCore, which is coming through a webkit fork.
Chrome initially was forked off of the the WebKit project, and Safari is a fork of
the WebKit project. They have diverged, and Apple's made a lot of
investments to make sure that WebKit is really, really fast. It is faster than
V8.
But Apple releases a lot less frequently for for WebKit open source repo, so that's
something else to keep in mind. If you actually go to the source, you can see how often Apple
releases changes to that repo. Apple will release updates to the source after a
year or two.
Over at Oven, they have forked the webkit JavaScriptCore, and they are
updating it and making changes to it on a regular basis, I'm not sure how far they've diverged
from what Apple is doing because Apple kind of works in their their own little bubble. That is something to keep in mind when you know that V8 is something that's always actively being worked on and supported by Google.
Frameworks for Bun
Bun not only will use existing
Node.js web application frameworks, but Bun also runs new frameworks that have been built with Bun in mind. There is one that is called Hono, and then there is one called Elysia.js.
Somebody even has come up with a term called the BETH stack similar to the MERN stack or the MEAN stack. BETH stands for Bun, Elysia.js, Turso and HTMx. Elysia.js is a framework similar to Express.

      
    
  
  
    
The Edge
Whe you hear vendors refer to The Edge, they are generally referring to edge services that run on a server close to the client browser. They work very similar to a CDN, but you can also host functions on these Edge servers. Vercel offers Edge hosting along with a lot of other cloud based hosting providers.
Basically on these Edge servers, the idea is that when somebody hits up your
application and it's deployed on Vercel for example,
there are functions that they can host and run as
close to the user as possible.
Bun and these other edge based services support and complies with the
WinterCG or the Web-interoperable Runtimes Community Group.
Basically what that means is that all these companies are providing hosting Services where they
allow you to run functions on the Edge, and the WinterCG is the governing body that decides what
JavaScript features they're going to support, and what JavaScript features they are not going to support.
Conclusion
While I think that Bun has lots of promise, I would not recommend using it in production as a server. One of the business goals for Oven.sh, the parent company overseeing Bun is to provide hosting. This would probably be the first place I tried running Bun since they have the most experience in running Bun, and understand all of the limitations.Tags: Bun,   Node.js,   Deno,   Elysia,   Hono   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 8th, 2024
    
        
    

OpenAI plans to launch a GPT Store this week. Back in November, OpenAI announced that they would allow anyone to create their own GPT. The way this works is that an OpenAI user can define their own GPT, upload their own information and make that GPT available to other users. The really cool thing about this feature is that you can define your own GPT without any programming.
One of the other cool things is if you do know how to program or have access to external HTTP services, you can add custom actions to your GPT. In order for OpenAI to be able to use an action, it has to conform to the openapi standard. Openapi allows developers to create a yaml or json file that defines the methods and endpoints that can be consumed by other applications. This is very similar to the old WSDL files that were used to define SOAP based web services.
How to create a openapi definition using Swagger and Fastify
Lately I have been using Fastify to create REST based services. In the Node.js ecosystem Fastify has become a popular framework for creating REST based services.
I used Swagger to generate the openapi definition for my joke service. There are many frameworks for different languages that support adding Swagger to their services.
I have created a GPT for telling jokes, but I will have it run an action to get new jokes. Here is a simple Fastify service that will serve up new jokes:
import Fastify from 'fastify';
import fs from 'fs';

const port = process.env.PORT || 3000;
const data = await fs.promises.readFile('jokes.json', 'utf8');
const jokesObj = JSON.parse(data);

const schemaConfig = {
    schema: {
        description: 'This returns jokes',
        tags: ['JOKE'],
        summary: 'This returns a different joke every time this is called',
        response: {
            200: {
                description: 'Successful Response',
                type: 'object',
                properties: {
                    joke: { type: 'string' }
                }
            }
        }
    }
};

const fastify = Fastify({
    logger: true
});

fastify.get('/', schemaConfig, async (req, reply) => {
    const randomInteger = Math.floor(Math.random() * 20);
    const joke = jokesObj.jokes[randomInteger];
    reply
        .code(200)
        .header('Content-Type', 'application/json; charset=utf-8')
        .send({ joke: joke });
});

const start = async () => {
    try {
        await fastify.listen({
            port: port,
            host: '0.0.0.0'
        });
    } catch (error) {
        fastify.log.error(error);
        process.exit(1);
    }
}
start();

If we examine this service, it has one route that returns a joke from a JSON file with about 20 jokes.
fastify.get('/', schemaConfig, async (req, reply) => {
    const randomInteger = Math.floor(Math.random() * 20);
    const joke = jokesObj.jokes[randomInteger];
    reply
        .code(200)
        .header('Content-Type', 'application/json; charset=utf-8')
        .send({ joke: joke });
});
The second parameter in the get method takes a schema object, which is how Fastify allows developers to define input and response types in our routes. This is used as a kind of meta information that can then be reused by tools like Swagger.
Adding Swagger to Fastify
To add Swagger to our joke service, we will need to import Swagger and Swagger-UI using a package manager like npm or Bun.
> npm i @fastify/swagger @fastify/swagger-ui
Once we have added swagger to our project, we will need to add imports to our Fastify app.
import Swagger from '@fastify/swagger';
import SwaggerUI from '@fastify/swagger-ui';
Before we can register Swagger to our fastify app, we will need to create a configuration. I am going to do that in another file, and import it into our main fastify file.
const swaggerConfig = {
    openapi: {
        info: {
          title: 'Joke Service',
          description: 'This is an API serving up jokes.',
          version: '0.1.0'
        },
        servers: [{
          url: 'https://joke.mydomain.com'
        }]
    },
    hideUntagged: true,
    exposeRoute: true
};

export default swaggerConfig;

Then we can import this config into our fastify file.
import swaggerConfig from './swaggerConfig.js'
Now that we have imported these two modules and added a configuration, we will need to register them as plugins using our fastify object before starting the service.
const fastify = Fastify({
    logger: true
});

await fastify.register(Swagger, swaggerConfig);
await fastify.register(SwaggerUI);
That is all we need to do to add Swagger to our Fastify app, but I am going to make one more change to the schema for my route to add an operationId. OpenAI's actions need that property in order to use it as an action in your GPT.
const schemaConfig = {
    schema: {
        description: 'This returns jokes',
        tags: ['JOKE'],
        summary: 'This returns a different joke every time this is called',
        operationId: 'get-joke',
        response: {
            200: {
                description: 'Successful Response',
                type: 'object',
                properties: {
                    joke: { type: 'string' }
                }
            }
        }
    }
};
If we look at the schema definition above, we can see that I added an operationId called get-joke. If we run this app, and call the root route using a curl command like the following:
> curl http://localhost:3000
"What is a sea monster‚Äôs favorite snack? Ships and dip."
Swagger adds a new route to view the documentation for the service. By default the route to view the documentation is /documentation.

      
    
  
  
    
Under the @fastify/swagger title, there is a url that should be http://localhost:3000/documentation/json. That endpoint is the openapi definition that we will need to add to our GPT.
To add the action to a GPT, either create or edit an existing action. Once you have the GPT editor open, the form on the left hand side has two tabs at the top: Create and Configure. Select the Configure tab, and click on the Create new action button. This will open a new form called Add new actions. You can either paste the definition in the schema text field or click on the Import from URL.
Testing the actions
Once you have successfully added the action to your GPT, OpenAI's GPT editor will give you the option to test the actions. Go ahead and verify that your actions are working.
Conclusion
It is important to add really good summaries and descriptions to your Fastify schema. This makes it easier for OpenAI's LLM to correctly process your actions. It is essentially prompt engineering to give the schema the best description possible.
The real power of GPTs will come from organization and domain specific information. You will essentially be training OpenAI how to consume and repurpose this information, so it is important to get the description correct so OpenAI can have the proper context.
Have fun creating you own GPTs!Tags: Fastify,   OpenAI,   GPT,   Node.js,   Actions   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeDecember 23rd, 2023For this holiday season I decided to upgrade my lighting for the exterior of my home. I purchased some Philips Hue lights for my home. One of the nice things about the Philips Hue lights is that you can control your lights and their mood and color from a hub. The Philips Hue hub connects to a ethernet port in your home. Once it is installed, you can register new lights to that hub, and control them from an app. But the really cool thing about the hub is that it has a REST based web service you can call from your local network to check on and control your bulbs.
Philips has good instructions on how to get a user key to call the hub. Once you have that {user} key, you can turn lights off and on as well as change the color and brightness of the bulb.
Address	https://<bridge ip address>/api/1028d66426293e821ecfd9ef1a0731df/lights/1/state
Body	{"on":false}
Method	PUT
The following PUT tells the first light on the hub to turn off.
For my home project I decided that I wanted to be able to control the lights from a program I was running on a Raspberry Pi. If you are not familiar with the Pi, it is a credit card sized computer that can connect to Wi-Fi, bluetooth and ethernet.
I also decided that I wanted to be able to remote control my lights from a smart phone. Since the program I was using on my Raspberry Pi only connected to my local network, I had no way to access from outside of my home network. To get around this problem, I decided to use a simple queue service that I could send messages to and receive those messages on my Raspberry Pi. To do this I decoded to use RabbitMQ. I found a RabbitMQ service that was running on the internet with a free tier. I then created a REST service that I could call from my mobile app to send messages to the queue.

      
    
  
  
    
On my Raspberry Pi I created a program to consume messages from the queue. I used this program to control a service I was running using PM2 on my Pi to run another program on my Pi to alternate the bulbs between green and red on the front of my home.
Programming the lights
The program that runs on my Pi runs as a service using PM2. If you are not familiar with PM2, it is a process manager that can manage services run in Node.js or other programs. It will also persist those services so if the Pi is restarted, it will return the service to the previous state it was running before the Pi was restarted.
My program for alternating the lights can be seen below:
import process from 'node:process';

const ip_address = process.env.IP_ADDRESS;
const user = process.env.USERTOKEN;

let toggle = true;

async function setLightStatus(bulb, state) {
    const endpoint = `http://${ip_address}/api/${user}/lights/${bulb}/state`;
    const options = {
        method: "PUT",
        body: JSON.stringify(state)
    };
    await fetch(endpoint, options);
}

async function setLightStatus2() {
    let state = {
        "on":true,
        "sat":254,
        "bri":254,
        "hue": toggle ? 25600 : 0
    };
    await setLightStatus(2, state);
}

async function setLightStatus3() {
    let state = {
        "on":true,
        "sat":254,
        "bri":254,
        "hue": toggle ? 0 : 25600
    };
    await setLightStatus(3, state);
}

async function masterSwitch() {
    await setLightStatus2();
    await setLightStatus3();
    toggle = !toggle;
}

let timer = setInterval(await masterSwitch, 15000);

process.on('exit', (code) => {
    clearTimeout(timer);
    console.log(`Program exited with code: ${code}`);
});
As you can see from the code above, it uses a toggle variable to switch between red and green colors on the lights. So when one bulb is green the other one will be red, and vice versa.
Writing events to the RabbitMQ service
In order to send messages to my Pi, I used the following REST based service to write messages to RabbitMQ.
import Fastify from 'fastify';
import fastifyCors from '@fastify/cors';
import amqp from 'amqplib';

let connection;
let channel;
const queue = "pi_messages";
const rabbitmqURL = process.env.RABBITMQ_URL;

const fastify = Fastify({ logger: true });

const port = process.env.PORT || '3000';

fastify.register(fastifyCors, {
    // put your options here
});

fastify.post('/', async (request, reply) => {
    const jsonMessage = request.body;

    const response = {
        status: 'success',
        message: 'Message sent to AMQP',
        data: jsonMessage // Optionally include the user data or some identifier
    };

    await produceMessage(jsonMessage);

    reply
        .code(200)
        .header('Content-Type', 'application/json; charset=utf-8')
        .send(response);
})

const start = async () => {
    try {
        console.log(`URL: ${rabbitmqURL}`);
        connection = await amqp.connect(rabbitmqURL);
        channel = await connection.createChannel();
        await channel.assertQueue(queue, { durable: false });

        process.once("SIGINT", async () => {
            await channel.close();
            await connection.close();
        });

        await fastify.listen({ port, host: '0.0.0.0' });
    } catch(err) {
        fastify.log.error(err);
        process.exit(1);
    }
}

start();

async function produceMessage(msgObject) {
    try {
        channel.sendToQueue(queue, Buffer.from(JSON.stringify(msgObject)));
        console.log(" [x] Sent '%s'", msgObject);
    } catch (err) {
        console.error(err);
    }
}
As you can see above, this service is written Fastify, and simply takes a JSON message and sends it to a queue called pi_messages. For turning my lights on with my xmas program, I made my message look like the following JSON:
{
    "type": "üéÑLights",
    "on": true
}
Yes, I sent a Christmas tree (üéÑ) emoji in my JSON message.
Consuming the RabbitMQ Queue
To consume the RabbitMQ queue, I created another service that I ran on my Raspberry Pi to listen for new messages sent from my phone. The consumer looks like the following example below.
import amqp from 'amqplib';
import { stopService, startService } from './pm2service.js';
import { setLightStatusOff } from './lightservice.js';

const queue = "pi_messages";
const rabbitmqURL = process.env.RABBITMQ_URL;

const messagHandler = (message) => {
  if (message) {
    console.log(
      " [x] Received '%s'",
      JSON.parse(message.content.toString())
    );
    const messageObj = JSON.parse(message.content.toString());
      if (messageObj.type === "üéÑLights" && messageObj.on) {
        startLights();
      } else if (messageObj.type === "off" && !messageObj.on) {
        stopLights();
      }
  }
};

try {
  const connection = await amqp.connect(rabbitmqURL);
  const channel = await connection.createChannel();

  process.once("SIGINT", async () => {
    await channel.close();
    await connection.close();
  });

  await channel.assertQueue(queue, { durable: false });
  await channel.consume(queue, messagHandler, { noAck: true });

  console.log(" [*] Waiting for messages. To exit press CTRL+C");
} catch (err) {
  console.warn(err);
}

async function stopLights() {
  await stopService('xmaslights');
  await setLightStatusOff();
}

async function startLights() {
  await startService('xmaslights');
}
As you can see from the consumer above, I listen to the pi_messages queue for any messages. From this consumer I can turn my lights on or off by either sending a REST request directly to my hub, or turning on the other service from PM2.
To turn the lights off, I use the following module to setLightStatusOff.
const ip_address = process.env.IP_ADDRESS;
const user = process.env.USERTOKEN;

async function setLightStatus(bulb, state) {
    const endpoint = `http://${ip_address}/api/${user}/lights/${bulb}/state`;
    const options = {
        method: "PUT",
        body: JSON.stringify(state)
    };
    await fetch(endpoint, options);
}

export async function setLightStatusOff() {
    let state = {
        "on":false,
    };
    await setLightStatus(2, state);
    await setLightStatus(3, state);
}
For turning the Xmas lights program on, I turn that on by programmatically using PM2 to turn the xmaslights service back to a started state.
import pm2 from 'pm2';

export async function stopService(serviceName) {
  try {
    // Connect to PM2
    await new Promise((resolve, reject) => {
      pm2.connect(err => {
        if (err) reject(err);
        else resolve();
      });
    });

    // Stop the specified service
    await new Promise((resolve, reject) => {
      pm2.stop(serviceName, (err, proc) => {
        if (err) reject(err);
        else resolve(proc);
      });
    });

    console.log('Service stopped successfully');
  } catch (err) {
    console.error('Error stopping service:', err);
  } finally {
    // Disconnect from PM2
    pm2.disconnect();
  }
}

export async function startService(serviceName) {
    try {
        // Connect to PM2
        await new Promise((resolve, reject) => {
            pm2.connect(err => {
                if (err) reject(err);
                else resolve();
            });
        });

        // Stop the specified service
        await new Promise((resolve, reject) => {
            pm2.start(serviceName, (err, proc) => {
                if (err) reject(err);
                else resolve(proc);
            });
        });

        console.log('Service started successfully');
    } catch (err) {
        console.error('Error starting service:', err);
    } finally {
        // Disconnect from PM2
        pm2.disconnect();
    }
}
If everything is running properly, I can run a pm2 ls from my terminal and I should see the following in my terminal:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ id ‚îÇ name             ‚îÇ namespace   ‚îÇ version ‚îÇ mode    ‚îÇ pid      ‚îÇ uptime ‚îÇ ‚Ü∫    ‚îÇ status    ‚îÇ cpu      ‚îÇ mem      ‚îÇ user     ‚îÇ watching ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 1  ‚îÇ rabbitconsume    ‚îÇ default     ‚îÇ 1.0.0   ‚îÇ fork    ‚îÇ 62428    ‚îÇ 63m    ‚îÇ 0    ‚îÇ online    ‚îÇ 0%       ‚îÇ 49.6mb   ‚îÇ dav‚Ä¶ ‚îÇ disabled ‚îÇ
‚îÇ 0  ‚îÇ xmaslights       ‚îÇ default     ‚îÇ 1.0.0   ‚îÇ fork    ‚îÇ 62514    ‚îÇ 63m    ‚îÇ 1    ‚îÇ online    ‚îÇ 0%       ‚îÇ 58.7mb   ‚îÇ dav‚Ä¶ ‚îÇ disabled ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
Installing and deploying services on my Raspberry Pi
To install these two services on my Pi, I used shell scripts to run every-time I deployed a new version of the services on PM2. Here is the shell script I used for installing the main xmaslights service.
#!/bin/bash
pm2 stop xmaslights
pm2 delete xmaslights
pm2 save
rm -rf ~/apps/xmaslights
mkdir ~/apps/xmaslights
cp -r ~/path/to/projects/xmaslightsservice/* ~/apps/xmaslights
cp ~/.env ~/apps/xmaslights/
cd ~/apps/xmaslights
pm2 start ecosystem.config.cjs
pm2 save
I then used the following ecosystem.config file to configure PM2 to start the service with an environment variable file called .env.
module.exports = {
    apps: [{
      name: 'xmaslights',
      script: 'xmasservice.js', // or whatever your main file is
      node_args: '--env-file .env'
    }]
};
Conclusion
This was a fun project, and is a good example of some of the neat things you can do with Hue lights and a Raspberry Pi. It is another example of using the Pi for an IoT type of project. I hope you can use this as an inspiration for a project you want to run on your Pi. Merry Christmas!Tags: Raspberry Pi,   RabbitMQ,   Hue,   Node.js   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeDecember 18th, 2023
    
        
    

Apple has added a lot of features for concurrency in the Apple ecosystem as well as in the Swift language. I had a colleague show me a neat way to load services in the background using Operation Queues. Operation Queues are an older API that have their origination from the older Objective-C frameworks, but they are still useful even with Grand Central Dispatch, Swift Concurrency features and Combine.
In most highly visible iOS apps there are services that are needed as part of the services that are used by the company producing the app. A lot of apps use logging services like LogRocket, Firebase or Datadog to track when users experience errors or exceptions in their applications. It is a good way to improve the quality of your software. There are also realtime databases like Firebase and Realm that need to be set up and run at application startup.
Starting services Application startup
Whether your app is a SwiftUI app or a UIKit app, these services usually need to be started on application startup. On UIKit based apps, this is generally handled with the AppDelegate::application:didFinishLaunchingWithOptions: function. If you do not have an AppDelegate class in your SwiftUI app, you can add one, or use the SwiftUI App file to launch your services. If you want to use the AppDelegate with your SwiftUI App struct, I have a post on how to add that to your SwiftUI App.
Defining an Operation
To create a Operation for doing some work on the operation queue, you just need to create a new class that inherits from Operation.
class FirebaseSetupOperation: Operation {

    override func main() {
        FirebaseApp.configure()
        print("Firebase Configured")
    }

}
Now in our AppDelegate, we can add an OperationQueue to our startup process that we have defined. We can add the FirebaseSetupOperation to our OperationQueue.
import Foundation
import UIKit

class AppDelegate: NSObject, UIApplicationDelegate {
    
    func application(_ application: UIApplication, didFinishLaunchingWithOptions launchOptions: [UIApplication.LaunchOptionsKey : Any]? = nil) -> Bool {
        runMyStartupOperations()
        return true
    }
    
    func runMyStartupOperations() {
        let firebaseSetupOperation = FirebaseSetupOperation()
        let operationQueue = OperationQueue()
        operationQueue.addOperation(firebaseSetupOperation)
    }
}
Your application will create an instance of your operation, and run it in a background thread until the operation is completed. This operation can now run without the fear of the main thread being blocked.
Handling Dependencies
There is a good chance that if you have more than one operation, one of the operations may have a dependency on another. If you have an operation that has a dependency that requires that another operation to run first, you can also configure this very easily before running any of the operations.
You can also chain operations together. These operations will run in their own thread.
let firebaseSetupOperation = FirebaseSetupOperation()
let iRequireLoggingOperation = IRequireLoggingOperation()
iRequireLoggingOperation.addDependency(firebaseSetupOperation)

operationQueue.addOperations([firebaseSetupOperation, iRequireLoggingOperation], waitUntilFinished: false)
This will guarantee that the logSetupOperation runs before the iRequireLoggingOperation.
Conclusion
Apple's SDks contain many different tools for handling concurrency. If you find this useful, please take a look at Grand Central Dispatch as well as Combine, Async/await and Swift Actors.Tags: iOS,   Concurrency   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeDecember 13th, 2023
    
        
    

It seems the only thing anyone has been talking about in tech over the last year has been generative AI. When OpenAI launched ChatGPT last year it sent the world into an AI frenzy. One of OpenAI's chief competitors is Google. Google has been hard at work adding their own generative AI features, and they recently launched Gemini.
Today Google launched their API's for Gemini developers. This comes with a number of libraries and frameworks that developers can use to incorporate into their applications. In order to use these tools, you will need to generate an API key, which you can do with Google's AI Studio.

      
    
  
  
    
Once you have a key created, you can test your prompts in AI Studio, but there is code button that will show how to execute that prompt with your language of choice. The options today are as follows:

JavaScript
Python
Android (Kotlin)
Swift

They even show examples just using the cURL command line tool.
Node.js example
To execute a prompt using Node.js, you will need to install the following NPM package into your Node project:
> npm i @google/generative-ai
Once you have the package installed, you can initiate a prompt and response with the following sample code.

import { GoogleGenerativeAI, HarmCategory, HarmBlockThreshold } from "@google/generative-ai";
  
const MODEL_NAME = "gemini-pro";
const API_KEY = process.env.GEMINI_API_KEY;
  
async function run() {
    const genAI = new GoogleGenerativeAI(API_KEY);
    const model = genAI.getGenerativeModel({ model: MODEL_NAME });

    const generationConfig = {
        temperature: 0.9,
        topK: 1,
        topP: 1,
        maxOutputTokens: 2048,
    };

    const safetySettings = [
        {
            category: HarmCategory.HARM_CATEGORY_HARASSMENT,
            threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
        },
        {
            category: HarmCategory.HARM_CATEGORY_HATE_SPEECH,
            threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
        },
        {
            category: HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,
            threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
        },
        {
            category: HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,
            threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
        },
    ];

    const parts = [
        {text: "What are some of the differences between cats and dogs?"},
    ];

    const result = await model.generateContent({
        contents: [{ role: "user", parts }],
        generationConfig,
        safetySettings,
    });

    const response = result.response;
    console.log(response.text());
}

run();
I received the following result from the prompt What are some of the differences between cats and dogs?.


Social Behavior:

Cats: Cats are typically more independent and solitary animals, content with spending time alone. They don't inherently possess the pack-like bonding instinct seen in dogs.
Dogs: Dogs, on the other hand, are pack animals that thrive on social interaction, including with humans. They often exhibit a stronger attachment to their owners and tend to be more sociable with other dogs.



Activity Level:

Cats: Cats have a more flexible and self-regulating sleep-wake cycle compared to dogs. Their activity patterns often center around bursts of play and exploration followed by periods of rest.
Dogs: Dogs tend to have a more consistent and predictable activity level. They have higher energy requirements and often require regular exercise, whether it's playing fetch, going for walks, or engaging in other physical activities.



Grooming Habits:

Cats: Cats are meticulous groomers. They spend a significant amount of time licking and cleaning themselves, which helps maintain their fur and skin.
Dogs: Dogs have less frequent grooming habits compared to cats. Although they still groom themselves, they may require additional grooming assistance from their owners, such as brushing or bathing.



Diet:

Cats: Cats are obligate carnivores, meaning their bodies are biologically designed to digest and utilize animal-based nutrients. They have a higher protein requirement compared to dogs.
Dogs: Dogs are omnivores, capable of consuming both plant-based and animal-based foods. While they have a higher tolerance for carbohydrates, their diet should still be primarily meat-based.



Communication:

Cats: Cats communicate through a variety of vocalizations, such as meows, purrs, chirps, and hisses, as well as body language and facial expressions.
Dogs: Dogs primarily communicate through barking, growling, whining, and howling. They also use body language, including tail wagging, ear positioning, and facial expressions, to convey their emotions and intentions.



Trainability:

Cats: Cats are often perceived as less trainable compared to dogs. While they can be taught basic commands and tricks, they tend to be less responsive to consistent training methods.
Dogs: Dogs are generally more receptive to training due to their innate pack mentality and desire to please their owners. They can be trained to perform various tasks and commands, such as retrieving items, sitting, staying, and heeling.




Terminal will be reused by tasks, press any key to close it.

Output
The Output comes back as an array called candidates. Each candidate contains
Safety
One of the neat features of Gemini is the ability to establish certain safety guardrails when making requests. Here is the enum that defines harm categories that you can throttle back with a specific HarmCategory.
export declare enum HarmCategory {
   HARM_CATEGORY_UNSPECIFIED = "HARM_CATEGORY_UNSPECIFIED",
   HARM_CATEGORY_HATE_SPEECH = "HARM_CATEGORY_HATE_SPEECH",
   HARM_CATEGORY_SEXUALLY_EXPLICIT = "HARM_CATEGORY_SEXUALLY_EXPLICIT",
   HARM_CATEGORY_HARASSMENT = "HARM_CATEGORY_HARASSMENT",
   HARM_CATEGORY_DANGEROUS_CONTENT = "HARM_CATEGORY_DANGEROUS_CONTENT"
}
These get passed into the request with a HarmThreshold.
export declare enum HarmBlockThreshold {
    HARM_BLOCK_THRESHOLD_UNSPECIFIED = "HARM_BLOCK_THRESHOLD_UNSPECIFIED",
    BLOCK_LOW_AND_ABOVE = "BLOCK_LOW_AND_ABOVE",
    BLOCK_MEDIUM_AND_ABOVE = "BLOCK_MEDIUM_AND_ABOVE",
    BLOCK_ONLY_HIGH = "BLOCK_ONLY_HIGH",
    BLOCK_NONE = "BLOCK_NONE"
}
Looking at the Node.js example above you can see that these get passed as an array in the following form:
const safetySettings = [
    {
        category: HarmCategory.HARM_CATEGORY_HARASSMENT,
        threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
    },
    {
        category: HarmCategory.HARM_CATEGORY_HATE_SPEECH,
        threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
    },
    {
        category: HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,
        threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
    },
    {
        category: HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,
        threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
    },
];
It is nice to see that Google has given developers such granular control of safety in their generative model.
Conclusion
It has been exciting to see all of the new tools that have been made available to developers for building AI applications on top of existing models. It should be interesting to watch how these continue to improve over the next couple of years as we make our way towards AGI.Tags: Google,   Gemini,   AI,   LLM,   Node.js   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeDecember 11th, 2023My current engagement has come to an end, and I am now available to work on new projects. I have spent the last seven and half years building native mobile applications, primarily for iOS devices, but also on Android.
At my last engagement I not only worked on a greenfield iOS application for a major Silicon Valley based fin-tech company, but I also built out the CI/CD systems we used to build, test and deploy our mobile apps. Part of this was moving our CI/CD process from a custom Fastlane Gitlab solution to Bitrise.io.
Whats next?
I have spent most of my career working on publicly facing web applications, mobile applications, and the back end systems that support those applications. I would like to continue to build this type of software, but with a new emphasis on AI. A lot of the attention this past year has been on the AI boom going on with companies like OpenAI, Microsoft and Google. Most of these companies allow developers to build applications on top of the AI models that they have already built. I have been building software that utilizes these AI services.
Work location
I currently reside in Jacksonville, Fl, and I have been working remotely for the last two years. I am open to either working in an office, hybrid work or continuing to work remotely. I can also travel for work. Relocation is not impossible, but highly unlikely.
About Me and My Experience
I have a copy of my resume on this website, and you can view my Linkedin profile here.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeDecember 6th, 2023
    
        
    

Whenever I need to build a CLI (command line interface) application, my goto framework is OCLIF. OCLIF is the CLI framework that was used by Heroku and Salesforce to build their CLI applications, which Salesforce has open sourced. It is a great framework, and I have used on a couple of different projects.
One of the issues I ran into recently had to do with getting the CLI installed on a user's OS of choice. With OCLIF, you can publish your app up to NPM, and anyone with Node.js installed can run the application. As an example, here is a CLI I built for getting aviation weather called avweather-cli. To install it from NPM, all you have to do is run the following npm command:
> npm install avweather-cli -g 
What if the user does not have Node installed.
One of the other great things about OCLIF is it has the ability to create installers that do not require Node.js be installed on the user's computer. OCLIF has a pack command that you can use to create an installer for Linux, MacOS and Windows. If I want to create a build for Windows, all I have to do is run the following command:
> npx oclif pack win .
This will generate installers for all the different CPU architectures supported by Windows.

avwx-v0.5.15-a01e51d-x64.exe
avwx-v0.5.15-a01e51d-x86.exe

The OCLIF framework also has good documentation on how to use the pack command to build for all three OSs. The one exception is the Mac. Apple requires a 3rd Party Installer certificate to create an installer for MacOS. There is also a bug in the OCLIF with the current version of Node.js for generating the pkg installer where you can not use NPM. I was able to get around this by using yarn to run the pack command. The first thing you have to do is add a configuration in your package.json file for OCLIF. Mine looked like this:
"oclif": {
    "bin": "avwx",
    "dirname": "avweather-cli",
    "commands": "./dist/commands",
    "plugins": [
      "@oclif/plugin-help",
      "@oclif/plugin-plugins"
    ],
    "macos": {
      "identifier": "com.fekke.avwx",
      "sign": "\"3rd Party Mac Developer Installer: David Fekke (<TEAM ID>)\""
    }
},
Creating the 3rd Party Mac Developer certificate
The hardest part of this was creating and using the 3rd Party Mac Developer certificate. In order to do this you have to have an Apple Developer account, and create a certificate. To do this on a Mac, here are the steps to follow:

Open the Keychain Access on a Mac.
Click on the Keychain Access menu, and select Certificate Assistant. Then select the sub menu for Request a Certificate from a Certificate Authority for <Username>. This is the tool that lets request a certificate from Apple.
You will be presented with a dialog below. Make sure to select save to disk. This will prompt you to save a CertificateSigningRequest.
Now that you have the request, you go to Apple's developer portal at https://developer.apple.com.
Select the Account tab, and then click on the Certificates link under Certificates, IDs & Profiles.
Click on the + button next to the Certificates header. You will be presented with the option of Creating a New Certificate. Select the radio button next to where it says Mac Installer Distribution, and click continue.
You will be presented with a Create a New Certificate page, and a link called Choose File. Use that link to select the CertificateSigningRequest file you saved in step 3, and then click on the Continue button.
Download the certificate from the Download Your Certificate page you are presented with after that last step. Once you have downloaded the certificate, you can double-click on the certificate, and it will install it into your Keychain.

I hope you were able to complete those steps. Once you have that certificate in your Keychain, you can use OCLIF's pack command on your Mac to create the Mac installers for Intel and M-Series ARM Macs.
Automating this with Github Actions
One of the wonderful features that Github added was Github Actions. With Github Actions you can automate your testing, deployment and create executables on certain Github actions. For this CLI I created a single Github action for creating installers for Linux, MacOS and Windows on the release creation event. To create this action, I borrowed some knowledge  from this post by Kevin Viglucci. In his post he shows how you can create a release for Windows. I modified his action to create installers for all three OSs.
on:
  release:
    types: [published]

jobs:
  release:
    name: release ${{ matrix.target }}
    strategy:
      fail-fast: false
      matrix:
        include:
          - target: win
            artifact_glob: "./dist/win32/*"
            runs-on: windows-latest
          - target: macos
            artifact_glob: "./dist/macos/*"
            runs-on: macos-latest
          - target: deb
            artifact_glob: "./dist/deb/*"
            runs-on: ubuntu-latest

    runs-on: ${{ matrix.runs-on }}

    steps:
    - run: sudo apt update
      if: runner.os == 'Linux'
    - run: sudo apt install nsis p7zip-full p7zip-rar -y
      if: runner.os == 'Linux'
    - name: Install the Apple certificate
      if: matrix.target == 'macos'
      env:
        BUILD_CERTIFICATE_BASE64: ${{ secrets.BUILD_CERTIFICATE_BASE64 }}
        P12_PASSWORD: ${{ secrets.P12_PASSWORD }}
        KEYCHAIN_PASSWORD: ${{ secrets.KEYCHAIN_PASSWORD }}
      run: |
        # Create variables
        CERTIFICATE_PATH=$RUNNER_TEMP/3rdpartyCertificates.p12
        KEYCHAIN_PATH=$RUNNER_TEMP/app-signing.keychain-db

        # import certificate
        echo "$BUILD_CERTIFICATE_BASE64" | base64 --decode > $CERTIFICATE_PATH
        
        # create temporary keychain
        security create-keychain -p "$P12_PASSWORD" $KEYCHAIN_PATH
        security set-keychain-settings -lut 21600 $KEYCHAIN_PATH
        security unlock-keychain -p "$P12_PASSWORD" $KEYCHAIN_PATH

        # import certificate to keychain
        security import $CERTIFICATE_PATH -P "$P12_PASSWORD" -A -t cert -f pkcs12 -k $KEYCHAIN_PATH
        security list-keychain -d user -s $KEYCHAIN_PATH

    - uses: actions/checkout@v2
    - uses: actions/setup-node@v2
      with:
        node-version: '20.10.0'
    - run: npm install -g yarn
    - run: yarn
    - run: yarn global add oclif
    - name: Install oclif
      run: npm i oclif -g
      if: matrix.target == 'win'
    - run: oclif pack ${{ matrix.target }} -r .
    - name: Attach artifacts to release
      uses: svenstaro/upload-release-action@v2
      with:
        repo_token: ${{ secrets.GITHUB_TOKEN }}
        file: ${{ matrix.artifact_glob }}
        file_glob: true
        overwrite: true
        tag: ${{ github.ref }}

While this works, there is some set up that goes along with using this action.
Creating the Github Action.
To create the action you will need to create a .github folder in the root of your project if it does not already exist, and then create a folder underneath that called workflows. Save the Github Action from above into a file called installers.yaml.
Inside the action there is a section called strategy. Underneath the strategy is where the matrix is defined. The matrix tells Github that this action has to be performed separately for each of the matrices.
strategy:
  fail-fast: false
  matrix:
    include:
      - target: win
      artifact_glob: "./dist/win32/*"
      runs-on: windows-latest
      - target: macos
      artifact_glob: "./dist/macos/*"
      runs-on: macos-latest
      - target: deb
      artifact_glob: "./dist/deb/*"
      runs-on: ubuntu-latest
This matrix will run three times concurrently for each OS.
If you look at the individual steps in the action you will see where some of the steps have a condition set where the script is only run for a particular runner or matric target, like the following example.
- run: sudo apt install nsis p7zip-full p7zip-rar -y
  if: runner.os == 'Linux'
In the previous example, this action will only run if the actions is being run on a runner using Linux.
Allowing Github actions to use your 3rd Party Installer certificate
Since Apple requires a certificate to create the installer for the Mac, we have have a way for the Github runner to access that certificate. This can be done by adding the certificate to your Github secrets. You do not want to store any certificate in your repo, especially if it is a public repo. Here are the steps you can take to make sure the certificate is used by the runner.

Open Keychain Access on your mac and select My Certificates under the login keychain. Expand the Certificate so you can select both the certificate and the private key. Once you have both selected, you can export them as a .p12 Personal Information Exchange file. Save it to your Documents or Desktop folder.
Open up a terminal, and cd into the folder you saved the .p12 file. Then run the following command in your terminal:

> base64 -i nameofyourp12file.p12 | pbcopy

This command copies the contents of you .p12 file into your clipboard with a base64 encoding. Now that it is in your clipboard, this can be copied to a Github secret in your repo called BUILD_CERTIFICATE_BASE64. If you used a password for exporting the .p12, you can create a secret for that called P12_PASSWORD.

One of the steps in the action above will use these secrets to install your certificate on the github runner.
    - name: Install the Apple certificate
      if: matrix.target == 'macos'
      env:
        BUILD_CERTIFICATE_BASE64: ${{ secrets.BUILD_CERTIFICATE_BASE64 }}
        P12_PASSWORD: ${{ secrets.P12_PASSWORD }}
        KEYCHAIN_PASSWORD: ${{ secrets.KEYCHAIN_PASSWORD }}
      run: |
        # Create variables
        CERTIFICATE_PATH=$RUNNER_TEMP/3rdpartyCertificates.p12
        KEYCHAIN_PATH=$RUNNER_TEMP/app-signing.keychain-db

        # import certificate
        echo "$BUILD_CERTIFICATE_BASE64" | base64 --decode > $CERTIFICATE_PATH
        
        # create temporary keychain
        security create-keychain -p "$P12_PASSWORD" $KEYCHAIN_PATH
        security set-keychain-settings -lut 21600 $KEYCHAIN_PATH
        security unlock-keychain -p "$P12_PASSWORD" $KEYCHAIN_PATH

        # import certificate to keychain
        security import $CERTIFICATE_PATH -P "$P12_PASSWORD" -A -t cert -f pkcs12 -k $KEYCHAIN_PATH
        security list-keychain -d user -s $KEYCHAIN_PATH
What this script does is copy the secrets into a physical key that can then be installed and used on the runner's keychain. This step is also set up to only run on the MacOS portion of the action.
Conclusion
When using OCLIF with Github Actions, you can automagically produce all of your installers so that your users do not need to have Node.js installed to use your tool. For extra credit, you can tie your workflow releases into a S3 bucket so that your users can upgrade to the latest version of your tool without having to install it again.Tags: OCLIF,   Github Actions,   Node.js   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeDecember 3rd, 2023


I just purchased a new MacBook laptop from Apple. One of the things I intend on using it for is Software Development. I use a lot of different tools and frameworks including Node.js, Xcode, Android Studio and VSCode. I decided to live stream the process of setting up my new MacBook.
The first thing I do is set up the finder and Dock the way I prefer. I like to see invisible files in the Finder. This can be achieved by running the following shell commands:
> defaults write com.apple.finder AppleShowAllFiles true
> killall Finder
Xcode
The process of installing Xcode is pretty simple. Many of the other tools I use depend on Xcode being installed in order to use clang and compilers. This is pretty simple. All you have to do is go to the App Store app on your Mac and search for Xcode. Click on the button that says install.
Visual Studio Code
I use VSCode for most of my web development and Node.js coding. Setting up VSCode probably requires its own blog post, but I am going to keep it short. When you go to https://code.visualstudio.com/, there is a button to Download the Mac Universal installer. Once you have it installed, you can use the command-shift-P to open up the command pallete, and type >Shell Command: Install 'code' command in PATH. This will let you launch VSCode from the terminal.
iTerm 2
I like to use iTerm 2 over the bundled Terminal application that comes with the Mac. You can download here. Once I have iTerm installed, I like to install the oh-my-zsh tool. There are instructions on how to install oh-my-zsh at this web page. Once I have that installed, I change the theme to use agnoster. This gist explains how to set it up.

      
    
  
  
    
Docker
Docker is one of the ways I test and use containers locally on my Mac. It is a great tool because you can spin up a server container without having to spin up a whole Virtual Machine. If I am working with database server like Postgres, I generally run that in a container rather installing on my machine.
Homebrew
Now that I have my terminal set up, I install Homebrew. Homebrew is like a package manager, similar to apt-get on Linux or Choclately on Windows. Installing Homebrew is pretty easy. Just run the following command:
> /bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"
You can now use Homebrew to install different programs and packages on your Mac. Here is an example of how to install Cocoapods:
> brew install cocoapods
ASDF
I like to use ASDF as a universal version manager for different runtimes on my Mac. I use to manage Node.js, Python and Ruby. You can install ASDF with the following command:
> git clone https://aur.archlinux.org/asdf-vm.git && cd asdf-vm && makepkg -si
Once ASDF is installed, follow the directions on how to add plugins for you runtime of choice. Here is the command for installing the Node.js plugin as an example:
> asdf plugin add nodejs https://github.com/asdf-vm/asdf-nodejs.git
Rust
I have started using Rust for some software projects. Rust and Cargo can both be install with the following command:
curl https://sh.rustup.rs -sSf | sh
Github
Setting up Github access can be tricky, but it can be simpliefied by using one of the applications provided by Github. Github has a desktop application that you can download, but they also have an awesome CLI which can be installed using Homebrew.
> brew install gh
Onec you have gh installed, you can authenticate you Mac using the following command:
> gh auth login
This will prompt you login into Github with a web page. Once you are logged in, you will be able to push and pull from your repos.
Android Studio
Android Studio is the standard IDE for Android development. This can be be done by downloading the Android Studio image from the following web page.
Conclusion
It took me a little over an hour today to install all of my apps on this MacBook. If you watch the video, I did run into some complications, but for the most part it was not hard.Tags: macos,   Software Development,   Setup   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeNovember 30th, 2023The Raspberry Pi is a credit card sized computer that runs Linux or Windows. It is a great way for playing around with IoT projects, making robots or even running a simple web server in your house.

      
    
  
  
    
One of the things I like using the Raspberry Pi for is running agents or bots. There is no reason I can find to pay for an external server when you can run simple software like this on a Raspberry Pi locally in your own home.
Now that I have a Raspberry Pi, and I am running software on it, I was looking for a way to create a pipeline and automatically deploy software to my Pi. The solution I came up with was running a Github Actions runner directly on my Pi. Once you have a runner on your Pi, it will deploy any code from your github repository that are configured to use Github actions.
Adding a runner to your Pi
To add a runner to your Pi, go to your Github page, and click on the Setting button. When you see the menu on the left hand side of the page, select Actions and then the submenu for runners. Select the New runner button, and then the option for a New self-hosted runner.
On the New self-hosted runner page, you should see three options for MacOS, Linux and Windows. Select Linux. There is a architecture option below the OS options that lets you choose between x64, ARM and ARM64. Depending on the Raspberry Pi model it could be ARM or ARM64. You will have to check the model to find out for sure. Plus you will need to make sure the version of the Raspberry Pi OS is 32 bit or 64 bit. If the OS is 64 bit, you will need ARM64.
There will be a set of scripts to run on your Pi to install the Github Action runner, one for downloading, and one for configuring.
Once you have the runner installed, you will need to set it up as a service. Github recommends the following commands:
> sudo ./svc.sh install
Once the service is installed, you can start it up with the following command:
> sudo ./svc.sh start
Installing PM2 for you Node application
You can run the following command to install PM2 on your Pi.
> npm i  pm2 -g
This will install PM2 globally. PM2 is a great application runner and manager.
To install PM2 so that it runs at startup, run the following command in the terminal:
pm2 startup
You then might get an instruction on how to install the PM2 service like the following example using systemd:
sudo env PATH=$PATH:/usr/bin /usr/lib/node_modules/pm2/bin/pm2 startup systemd -u user --hp /home/user
Add Github action to your App to deploy to your Pi
Create a Github action by creating a YAML file in the following location in your repo:

/.github/workflows/myactionfile.yml

Your action will need to have the following steps:
name: Node.js CI

on:
  push:
    branches: [ main ]

jobs:
  build:

    runs-on: self-hosted

    strategy:
      matrix:
        node-version: [20.x]
        # See supported Node.js release schedule

    steps:
    - uses: actions/checkout@v2
    - run: npm ci
If you look at the tenth line on that YAML file you will see the following command for the jobs: runs-on: self-hosted. This line will run the action on the Pi you have installed the Github runner on.
When you check in this action, you will see the action deployed to a path on your Pi that might look like the following:

~/actions-runner/_work/yourreponame/yourreponame

Running your app on the Pi
Now that your Github action has downloaded your app to your Pi, you can use PM2 to run your app. If you Pi looses power or has to restart, we can use PM2 to automatically restart your app. PM2 will essentially let you run your app as a service. We can use the following shell commands to copy our app, and start running it with PM2:
mkdir ~/apps/
mkdir ~/apps/yourapp
cp -r ~/actions-runner/_work/yourreponame/yourreponame/* ~/apps/yourapp
cd ~/apps/yourapp
pm2 start index.js --name yourappname
pm2 save
You may also want to create a shell script that you can use to reset your app in PM2 every time you push a change through Github. You could write a script that shuts down the service, and reinstalls it like the following example:
# resetservice.sh
#!/bin/bash
pm2 stop yourappname
pm2 delete yourappname
pm2 save
rm -rf ~/apps/yourapp
mkdir ~/apps/yourapp
cp -r ~/actions-runner/_work/yourreponame/yourreponame/* ~/apps/yourapp
cd ~/apps/yourapp
pm2 start index.js --name yourappname
pm2 save
Now that you have a script that can stop, delete and restart the service, you can add it to your Github action:
name: Node.js CI

on:
  push:
    branches: [ main ]

jobs:
  build:

    runs-on: self-hosted

    strategy:
      matrix:
        node-version: [20.x]
        # See supported Node.js release schedule

    steps:
    - uses: actions/checkout@v2
    - run: npm ci
    - shell: bash
      run: chmod +x resetservice.sh
    - shell: bash
      run: ./resetservice.sh
Conclusion
With very little effort, you can add an Github Action runner that can deploy your own code to your Raspberry Pi. This makes it very easy to iterate through changes in your code, and have it deploy to your Pi.
The Raspberry Pi and Ubuntu also make it fairly easy to set up a Kubernetes cluster, so you can simulate deploying your apps in a similar way that many cloud based services do. Have fun tinkering!Tags: Node.js,   Github Action,   Raspberry Pi   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeNovember 27th, 2023


I recently started using some TypeScript in some of the applications I have been working on over the past year or so. A lot of JavaScript frameworks have generators that give the developer the option of whether they want to use TypeScript or JavaScript.
What if you want to add TypeScript to an existing JavaScript application. The nice thing about TypeScript is that it is a superset of JavaScript. In theory any JavaScript file should work in a TypeScript application.
Adding TypeScript to your project
It is actually pretty easy to add TypeScript to an existing Node.js app, and there are a number of different ways to do it as well. Some of the options include the TypeScript module from Microsoft, Babel and a newer tool called SWC. TypeScript and Babel both run in the Node.js runtime, but SWC is actually written Rust.
SWC
SWC is a project from Vercel, the hosting company. Vercel sponsors a lot of different open source projects, including Next.js and Svelte. As part of their development, they have been looking at ways to improve the speed of their tools, and one of the ways they have been doing that is by re-writing some of the modules in Rust.
SWC stands for the Speedy Web Compiler. It compiles and bundles for JavaScript, TypeScript, JSX and TSX. It also has an extensible plugin architecture.
To install the SWC, you need to install the core and cli modules.
> npm i -D @swc/core @swc/cli
The next step will be to move your existing code into a source folder. For my project I will call the folder src. Then we can add a build step to the scripts section of our package.json file.
"scripts": {
    "build": "swc build ./src -d dist",
    ...
Now if we run the npm run build script, SWC will transpile our app into JavaScript into a folder called dist. With this set up, you can go through and start progressively adding or rewriting your JavaScript into TypeScript code.
Conclusion
Many tools in the Node/JavaScript ecosystem are being rewritten in Rust for speed improvements. Much of this software is open source. It is worth taking a look at some of the tools that have been built for other projects. There is a good chance those tools can also be used in your projects as well.Tags: Node.js,   TypeScript,   SWC,   JavaScript   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeNovember 26th, 2023


OpenAI has been in the news a lot lately for reasons that have nothing to do with AI. While those things have been getting a lot attention, many people might have missed a lot of the announcements that came out of OpenAI's DevDay event earlier this month.
OpenAI now allows anyone to create their own context aware GPTs on OpenAI's platform. This had previously been achievable using OpenAI with frameworks like Langchain. One of the cool things about Langchain was that you could take your own data, parse it into a vector database like Pinecone, and then use that data using OpenAI's API to create your own chatbot based on your own data.
OpenAI has simplified the whole process by allowing you to create your own GPT, uploading your data to OpenAI directly in the form of PDF files or text documents.
I decided to do an experiment by creating my own GPT just for my blog. My blog uses markdown files for all of my blog posts, but I did not want to upload hundreds of different markdown files to OpenAI. I just wanted to use a single text file without any formatting. To do this, I decided to create a spider that could traverse through all of my blog posts, and create a single file.
My blog is set up with the last ten posts on the home page of my blog. My spider needs to be able to find of the URLs for the ten blog posts on that page, and then navigate to the next page in my blog and find all of those posts until it has navigated through my entire blog.
There are a couple of different tools in the Node.js ecosystem that can help you create a spider. One of them is called Cheerio, and there is another one called Puppeteer. Puppeteer is great option for anyone looking for a tool that might have to navigate through content on a website that might be dynamically generated. Websites that are built with a single page framework like Angular or React can be dynamically generated. If you just have a statically generated site, it may not be necessary to use a tool like Puppeteer.
I decided to use Cheerio. Cheerio works like JQuery, allowing the developer to use a selector based syntax to query specific elements on a webpage. I also am using Node.js 20 which has native fetch support. I wound up creating a script that could traverse through my blog, which is a static website using Cheerio.
Building the spider
For building my spider I started with an endpoint that I could load using fetch. The pageLoader function then loads all of the html from that page into a text variable that I could then use cheerio to find all of my links.
const domain = 'https://fek.io/';
const initialPage = 'blog';
const firstPage = `${domain}/${initialPage}`;

let pagetext = await pageLoader(firstPage);

async function pageLoader(url) {
    const pagedata = await fetch(url);
    const pagetext = await pagedata.text();
    return pagetext;
}
I then used chrome's developer tools to help identify the selector I would need to read the blog URLs from that start page.

      
    
  
  
    
All of the anchors for my blog links where contained in a parent div with a class called bloglistitem-module--listitem--99998. I then was able to define a class selector for the anchor tag using that class. My selector looks like the following: div.bloglistitem-module--listitem--99998 > div > a.
Using cheerio to find my blog URLs
Now that I had my selector, I could use cheerio to look up all of the blog URLs on that page. I created a function that could add the URLs to an array in the main scope of my node script.
import * as cheerio from 'cheerio';

let contentLinkArray = [];

async function firstPageLoader(pagetext) {
   const aClassSelector = 'div.bloglistitem-module--listitem--99998 > div > a';
   const $ = cheerio.load(pagetext);
   
   const links = $(aClassSelector);
   
   for (let linkObj of links) {
       contentLinkArray.push(linkObj.attribs.href);
   }
}
Paging through my blog
The next thing I need to do was to make this function recursive. I needed it to go through every index page on my blog to find all of the blog posts on my blog. If you are not familiar with the term recursion, it refers to when a function or subroutine can call itself.
To do this I had to identify the next link on my blog page, and load the next pages until it had read all of my blog URLs. I refactored my firstPageLoader function into a recursivePageLoader. The next anchor on all of my blog index pages has a relative attribute set to next. So I create a selector that matched the following anchor tag: a[rel="next"].

async function recursivePageLoader(pagetext) {
   const aClassSelector = 'div.bloglistitem-module--listitem--99998 > div > a';
   const $ = cheerio.load(pagetext);
   
   const links = $(aClassSelector);
   
   for (let linkObj of links) {
       contentLinkArray.push(linkObj.attribs.href);
   }
   
   let nextLink = $('a[rel="next"]');

   if (nextLink[0]) {
       console.log(nextLink[0].attribs.href);
       const nextPage = `${domain}/${nextLink[0].attribs.href}`;
       const nextPageText = await pageLoader(nextPage);
       await recursivePageLoader(nextPageText);
   }
}
Reading all of the blog entries into a single text file
Now that I had an array of all of my posts I could read each entry, and save them to a single text file. To accomplish this, I used a file system write stream. One of the more powerful capabilities in Node is its ability to work with streams.
The text for all of my blog posts are embedded inside of a div with a class called article. Knowing this I was able to use cheerio to load the text from that div into my file stream.
import * as cheerio from 'cheerio';
const writeStream = fs.createWriteStream('output.txt');

await readAllURLsToFile(contentLinkArray);

async function readAllURLsToFile(links) {
   for (const url of links) {
       let blogPostURL = `${domain}${url}`;
       let posttext = await pageLoader(blogPostURL);

       let $ = cheerio.load(posttext);
       let blogText = $('article').text();
       writeStream.write(blogText + '\n\n\n\n');
   }
   writeStream.end(); 
}

The completed script wound up looking like the following script.
import * as cheerio from 'cheerio';
import fs from 'fs';

let contentLinkArray = [];
const domain = 'https://fek.io/';
const initialPage = 'blog';
const fisrtPage = `${domain}/${initialPage}`; 

let pagetext = await pageLoader(fisrtPage);

await recursivePageLoader(pagetext);

const writeStream = fs.createWriteStream('output.txt');

await readAllURLsToFile(contentLinkArray);

async function readAllURLsToFile(links) {
   for (const url of links) {
       let blogPostURL = `${domain}${url}`;
       let posttext = await pageLoader(blogPostURL);

       let $ = cheerio.load(posttext);
       let blogText = $('article').text();
       writeStream.write(blogText + '\n\n\n\n');
   }
   writeStream.end(); 
}

async function pageLoader(url) {
   const pagedata = await fetch(url);
   const pagetext = await pagedata.text();
   return pagetext;
}

async function recursivePageLoader(pagetext) {
   const aClassSelector = 'div.bloglistitem-module--listitem--99998 > div > a';
   const $ = cheerio.load(pagetext);
   
   const links = $(aClassSelector);
   
   for (let linkObj of links) {
       contentLinkArray.push(linkObj.attribs.href);
   }
   
   let nextLink = $('a[rel="next"]');
   
   if (nextLink[0]) {
       console.log(nextLink[0].attribs.href);
       const nextPage = `${domain}/${nextLink[0].attribs.href}`;
       const nextPageText = await pageLoader(nextPage);
       await recursivePageLoader(nextPageText);
   } 
}
Now that I have an output file of all of my blog posts, I can edit my GPT on OpenAI and upload my output file.

      
    
  
  
    
Conclusion
OpenAI has made it very easy to add our data to our GPTs. They are currently planning on allowing developers to sell or make you GPTs available on their own store later this month. Using simple tools like this makes it very easy to add data from your website into you own GPT chatbot.
I plan on making future posts on OpenAIs developer tooling. Another part of their dev day announcement were the beta availability of an assistants API. This API is available in both their Python and JavaScript libraries.Tags: ChatGPT,   OpenAI,   JavaScript,   Spider   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeOctober 19th, 2023I have been playing around with the new programming language Mojo by Modular. If you are not familiar with Mojo, it is a language that is a superset of Python, but with blazing fast performance.
For anyone else using asdf, I was getting the following error trying to install Mojo.
~ > modular install mojo                                                     ÓÇ≤ ‚úî
# Found release for https://packages.modular.com/mojo @ 0.4.0
# Installing to /Users/davidfekke/.modular/pkg/packages.modular.com_mojo
# Downloading artifacts. Please wait...
# Downloads complete, setting configs...
# Configs complete, running post-install hooks...
unknown command: python3. Perhaps you have to reshim?
modular: error: failed to run python:
I had to uninstall python from asdf, remove the reference from .tool-versions. I had to add the homebrew path to my ~/.zshrc file. I was able to look up the correct path using brew info python.
I also had to remove python3 from my asdf shims. Once I did all of those things, I was able to get Mojo installed on my M1 Mac.Tags: mojo,   asdf,   python   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJuly 30th, 2023A colleague recently showed me an article that showed that half of the repos on GitHub that had ChatGPT examples had their access key in their source code. GitHub actually does a pretty good job of policing when someone checks in a secure key or token, but if you want to avoid checking them in in the first place.
Many 3rd party APIs require the use of some sort of secret or configuration file that you do not want to share with the rest of the world.
It is considered a bad practice to keep secrets in your source code. Whether you are keeping you source code in a public repo or private repo, do not keep secrets in your source.
What is a secret?
A secret is any kind of information you do not want exposed to either external or internal resources. Even if you have a private repo through Github or Bitbucket, you have services that you might use that need to access your source code. That might be an external build system or even an internal employee who you do not want to access a service.
It is very common for a 3rd party service you consume in your application to provide secret keys to access that service. Having that key exposed could cause someone else to either run up charges on that service, or even worse, allow access to sensitive organizational information or customer data. I hope in this post I can show how to remove these secrets from your source code.
Finding secrets in your source code
The first thing you should do is identify anywhere in your application that you are using secrets. If you are using Github, it already will give you some warnings if it detects that you are storing. You also might be able to use a third party service if you are using a self hosted git server like GitLab.
Some places to look for secrets would be the Info.plist for your application. Some services like Firebase will provide their own plist files. Also look for anywhere in your code where a developer might have hard coded a password or secret.
// DO NOT DO THIS!!!
let servicePassword = "my_secret_1234"
The problem with plists
Plists are XML files that can be used for storing permanent values in your application in the file system. Apple on the iOS and iPadOS operating uses a system called secure enclave to encrypt any file that is used in your application. While that does provide a certain amount of security, it is not foolproof. Jamon Holmgren of Infinite Red recently tweeted about the problem with using these types of files in your application.
No way in any iOS app. Quoted tweet was Flutter, but my first exposure to this problem was in a native compiled app. A friend showed me how to extract the secret keys from my app and he took about 3 minutes. It blew my mind.‚Äî Jamon (@jamonholmgren) April 14, 2023 
The bottom line if someone can download your IPA file to a desktop computer, the IPA file is a zip format, and the contents of the IPA can be browsed quite easily.
Where can I store my secrets
There are a couple of different places you can store your secrets. If you use GitHub or GitLab, they both provide a place where you can store variables and secrets. It is important to make sure only the people who need access to these variables are able to view those variables. Generally in a larger org you will have engineers who have this level access. This is usually the Devops team that can set and view.
If you are using AWS, they have a feature called AWS secrets manager that can store these secrets as well. There are also third party vault tools that can be deployed that can be used as source for your secrets.
How to reference your secrets in Xcode
Depending on where you need your secrets in your code, there are a few different ways to make you secrets available in your application. Some of this will depend if you referencing them directly in your code or through an external file like a plist. The Info.plist is the most common plist used by Apple applications. In the current version of Xcode, part of this file has been moved internally inside of the xcodeproj bundle.
Apple actually provides and easy way to inject values into this plist using environment variables. Xcode can swap out these values out at build time inside of your Info.plist. If you look inside of your Info.plist file you will see values are contained inside of a $(). Anything side of those parenthesis are replaced by the value coming from the environment variable. The Executable file will be set to a string called $(EXECUTABLE_NAME). It should look like this inside of the plist.
<string>$(EXECUTABLE_NAME)</string>
You can add a new key for your secret to the Info.plist, and then reference that value in your code when you need to use the secret.
...
<key>YourSecretKey</key>
<string>$(YourSecretKeyFromEnvironmentVariable)</string>
...
To reference this value in your code, you can use the Bundle.main object like follows:
if let infoDict = Bundle.main.infoDictionary {
    // Access the value for your secret key in the Info.plist
    if let mySecret = infoDict["YourSecretKey"] as? String {
        print("mySecret value: \(mySecret)")
        // You can use the value here as needed
    } else {
        print("mySecret not found in Info.plist")
    }
} else {
    print("Info.plist not found.")
}
Replacing secrets in your code at build time
Another technique for using secrets in your code is to replace your secrets using a template at build time. This can be done very simply using a shell script. You can then just run this script on your build server.
An easy way to implement this is to create a constants file that can use dummy values in your source. Here is an example:
public struct Constants {
    let mySuperSecret = "DummyValue"
} 
This file can be replaced by file with the actual values at build time using a shell script. There is a command in Unix called envsubst that will substitute any environment variables in a template, and let you create a new file. The template can just be a text file like the following:
// mytemplate.txt
public struct Constants {
    let mySuperSecret = "${SUPER_SECRET_VALUE}"
} 
Then you can use the envsubst command in a shell script to create the file you want to use at build time.
#!/bin/bash

# Create the output file by substituting the environment variables in the template
echo "Create Constants.swift file for secret constants values"
envsubst < Scripts/mytemplate.txt > Shared/Constants.swift
This will create a new file or replace an existing file with the correct secrets.
public struct Constants {
    let mySuperSecret = "ActualSuperSecretValue123"
}
Then in the rest of you code you can reference this secret like this:
let password = Constants.mySuperSecret
Updating values in other plists
If you are using other plists or are required by an SDK to use a third party plist, you can set dummy values in this plist file, and then update the plist at build time using PlistBuddy. PlistBuddy is a command line tool build by Apple that come included on all Macs. If you are using a Mac as your build machine you can reference this tool in a shell script as follows:
/usr/libexec/PlistBuddy
PlistBuddy can read, set the value of a key, and delete or add keys. PlistBuddy takes two parameters for the command and the plist. An example for setting a key value might like like this:
/usr/libexec/PlistBuddy -c "Set :SecretString 123" ThirdParty.plist
Conclusion
As you can see there are multiple ways to store and reference secrets in your application with out storing them in your source code. If you work at a large enough organization, you can consult with your Information Security team or your Devops team to go over some of the different strategies for storing secrets for your application.
It is more important than ever that everyone do their part in making sure that we secure and lock down our apps. You do not want to be too late in making this change to how you store secrets.Tags: secrets,   iOS,   Xcode   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeApril 10th, 2023If you are using zscaler and are trying to run the iOS simulator with the React Native metro server, you may have run into the issue of not being able to pull in content from your metro server while zscaler is running. Turning off Internet Security might allow this to work, but the real reason the simulator cannot access the metro server is because the simulator does not have the zscaler certificate installed. Here is how you can fix this in your simulator.
Zscaler certificate
Zscaler has a security certificate that it installs on your computer to let you access resources on your zscaler network. You can download this certificate from zscaler on mobile devices by using the following URL: https://mobile.zscaler.net/downloads/zscaler2048_sha256.crt.
You can download this using your terminal using the following command:
$ curl https://mobile.zscaler.net/downloads/zscaler2048_sha256.crt --output ~/zscalerrootca.der
Selecting the correct iOS simulator
Xcode installs many simulators, but generally you only run one at a time. The following command will show all of your simulators that are installed.
$ xcrun simctl list devices
You should see a list that looks something like this:
== Devices ==
-- iOS 16.2 --
    iPhone SE (3rd generation) (1B53E6A9-522B-42FD-96CA-FECD651698F5) (Shutdown)
    iPhone 14 (04D2D6E0-A89E-4401-8809-FCE0982A4397) (Shutdown)
    iPhone 14 Plus (7860E3BC-8D14-47B1-B64F-41B405BF3054) (Shutdown)
    iPhone 14 Pro (6A686E6D-2A0A-4D2B-9B77-8517D97CCD4F) (Shutdown)
    iPhone 14 Pro Max (205ACFE7-18C2-4283-BE93-AB21CA1894F5) (Shutdown)
    iPad Air (5th generation) (EE9C9096-D588-4DF7-82AA-938119080A14) (Shutdown)
    iPad (10th generation) (08F02635-A08F-403C-828E-19527CB4BCBD) (Shutdown)
    iPad mini (6th generation) (2CF3CE52-A1F5-42BE-8BA3-1E65B68553F0) (Shutdown)
    iPad Pro (11-inch) (4th generation) (E0B10CB8-057E-49BF-9268-B1D3EA106CB7) (Shutdown)
    iPad Pro (12.9-inch) (6th generation) (00673013-72C8-4BE2-ACD9-83AD75841A1D) (Shutdown)
-- Unavailable: com.apple.CoreSimulator.SimRuntime.iOS-16-4 --
    iPhone 14 Pro (92DB7E6A-E7FB-4FE2-9859-B040A163B393) (Booted)
    iPhone SE (3rd generation) (D3120EBC-E125-46AC-830E-FC9D44144173) (Shutdown) (unavailable, runtime profile not found using "System" match policy)
    iPhone 14 (41EB4C16-3856-439D-9465-665B259D0911) (Shutdown) (unavailable, runtime profile not found using "System" match policy)
    iPhone 14 Plus (A0917104-9CDA-4084-9EDA-ED8E912DB3B4) (Shutdown) (unavailable, runtime profile not found using "System" match policy)
    iPhone 14 Pro Max (E1B79203-9C7A-4742-959B-A5A7A5CCC58C) (Shutdown) (unavailable, runtime profile not found using "System" match policy)
    iPad Air (5th generation) (D3933745-68D5-41BD-AE91-E12860254C5B) (Shutdown) (unavailable, runtime profile not found using "System" match policy)
    iPad (10th generation) (B9FCB2D1-5C12-418F-A0BB-7BB6B62F2FC4) (Shutdown) (unavailable, runtime profile not found using "System" match policy)
    iPad mini (6th generation) (2793C759-F546-4369-8783-B05A2F0B591E) (Shutdown) (unavailable, runtime profile not found using "System" match policy)
    iPad Pro (11-inch) (4th generation) (8242F1A3-D7EA-45FB-AEED-1B0313709788) (Shutdown) (unavailable, runtime profile not found using "System" match policy)
    iPad Pro (12.9-inch) (6th generation) (EF792F79-387D-461D-B780-94891A0EC2A2) (Shutdown) (unavailable, runtime profile not found using "System" match policy)
Look for a simulator that has (Booted) at the end of the line. This is the simulator that is running. You can now install that certificate into that simulator using the following command where the <sim_uuid> is the placeholder for the actual UUID of your simulator. In my case the UUID was 92DB7E6A-E7FB-4FE2-9859-B040A163B393:
xcrun simctl keychain <sim_uuid> add-root-cert ~/zscalerrootca.der
Putting it all together in a shell script
If you have the simulator that you want to install the certificate running, you can use the following script to install the certificate automatically.
#!/bin/bash

echo "** Downloading CA cert **"
curl https://mobile.zscaler.net/downloads/zscaler2048_sha256.crt --output ~/zscalerrootca.der

# Get the list of simulators
sim_list=$(xcrun simctl list devices)

# Regex to match the booted simulator
regex="([0-9A-Fa-f]{8}-[0-9A-Fa-f]{4}-[0-9A-Fa-f]{4}-[0-9A-Fa-f]{4}-[0-9A-Fa-f]{12}).*\((Booted)\)"

# Find the UUID of the booted simulator
sim_uuid=""

while IFS= read -r line; do
  if [[ $line =~ $regex ]]; then
    sim_uuid="${BASH_REMATCH[1]}"
    break
  fi
done <<< "$sim_list"

if [[ ! -z "$sim_uuid" ]]; then
  echo "Booted Simulator UUID: $sim_uuid"
  
  xcrun simctl keychain $sim_uuid add-root-cert ~/zscalerrootca.der
else
  echo "No booted simulator found."
fi
Conclusion
Zscaler is a great tool for improving corporate security. Understanding how to install certificates onto your iOS simulator can help you whenever this impacts your iOS development.Tags: zscaler,   iOS,   Simulator   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeApril 8th, 2023Make sure to add the following to this post
I have been researching using Mercurius and Fastify for a GraphQL backend for iOS. I think a lot of iOS developers are already familiar with using Apollo as a GraphQL backend, but I have a couple of Fastify services that I was already hosting as REST endpoints. In a previous post I wrote about adding a GraphQL endpoint to Fastify. In this post I wanted to write about how you can add iOS code generation to your existing iOS apps using Mercurius and Fastify as the backend.
Consuming GraphQL in iOS
The easiest way to consume GrapghQL on iOS is use the Apollo Client for iOS. This client library comes with a bunch of tools including code generation, and can be installed using CocoaPods, Swift Package Manager to your Xcode project or SPM with your Package.swift. For this post I am just going to use SPM with the Xcode project.
One of the problems I cam across in getting this working is that the Apollo docs do not show everything you need to get this working for your application. I hope to show how you can install and use these tools to make GraphQL queries.
Installing the Apollo-ios-cli
In the Apollo documentation, they suggest installing the command line tool using the right mouse click menu in the project explorer. As of Xcode 14.3, this option no longer works. I had to install the executable for the apollo-ios-cli directly in a path that my terminal could access. I installed the apollo-ios-cli directly in my '/usr/local/bin' directory on my Mac. You can download the executable from the releases link on the GitHub page for Apollo-ios.
Download the release of apollo-ios-cli.tar.qz for the version you plan on using of the library. At the time of writing this post, that was version 1.1.1. The library and cli have to be the same version.
You can confirm that the tool is installed and working by using the following command in the terminal:
$ apollo-ios-cli --version
Generating code for iOS using the Apollo-ios-cli tool
Once you have the cli tool installed and working on your machine, Apollo needs a couple of things in order to generate code. It will need configuration file called apollo-codegen-configuration.json, GraphQL files with the queries you want to use in files with the .grapghql extension and the schema for your GraphQL endpoint. Once you have all three, you will be able to generate code.
One of the challenges I came across with using Mercurius for hosting my GraphQL endpoint was there was not an easy way getting the schema definition or the SDL from the endpoint. You can always use an Introspection query to return the schema in a JSON format, but I wanted to be able to use the SDL since that is the example usually given in the Apollo documentation. To accomplish this I had to add a new route to my Fastify service to return the SDL. Here is how I added the route:
// Define a route to retrieve the SDL
fastify.post('/schema', (req, reply) => {
    reply.type('text/plain').send(schema);
});

fastify.get('/schema', (req, reply) => {
    reply.type('text/plain').send(schema);
});
Now that you have this routes, you can download the SDL using /schema for the route.
Setting up your Xcode project structure
In the root directory where you keep your swift code, create a new directory called /graphql. This directory will contain your GraphQL queries and your schema, as well as your generated code. This folder will need to be added to your Xcode project as well as a folder group. When adding to your Xcode project navigator, make sure to choose the create groupsnext to theadded folders` option.

      
    
  
  
    
Generate apollo configuration
I used the following command in the root of my code folder to create the apollo-codegen-configuration.json file:
$ apollo-ios-cli init --schema-name <What_YouWill_Call_Your_Schema> --module-type embeddedInTarget --target-name <Your_Target_Name>
Once you have created the apollo-codegen-configuration.json file, we will need to modify it to point to the /grapghql folder. Look for the output section, and change it so that it points to the correct directory path:
  "output" : {
    "testMocks" : {
      "none" : {
      }
    },
    "schemaTypes" : {
      "path" : "./graphql",
      "moduleType" : {
        "embeddedInTarget" : {
          "name" : "YourTargetName"
        }
      }
    },
    "operations" : {
      "inSchemaModule" : {
      }
    }
  },
Add the SDL to your grapghql folder
Apollo needs the definition as one of the inputs to generate code. Now that we have our schema endpoint setup in Fastify, we can add it to our graphql folder by running the following command.
$ curl http://localhost:3000/schema > graphql/schema.graphqls
Any file that contains the definition or SDL for our GraphQL endpoint should end with a .grapghqls extension. The extra s at the end signifies that it is the schema.
Create a file with our GraphQL query
I have a query that will work with our book query from my previous post.
query BookQuery {
    books {
        id
        title
        author
    }
}
Save this into the /graphql directory as bookquery.graphql.
Generate your swift files
Now that you have the config file, the SDL and a graphql query file, we can generate our swift code. Run the following command in your terminal under your root directory:
$ apollo-ios-cli generate
Using your generated code to display query in a SwiftUI View
We will create a new class and call it BooksQueryViewModel.
Once you have created the class, we will add an init constructor. We will also add a property for our Apollo client. It should look like the following:
import Foundation
import Apollo

class BooksQueryViewModel: ObservableObject {
    
    var apollo = {
        guard let url = URL(string: "http://localhost:3000/graphql") else {
            fatalError("Could not create URL for GraphQL endpoint.")
        }
        return ApolloClient(url: url)
    }()
    
    typealias Book = Bookschema.BookQuery.Data.Book
    @Published var books: [Book] = []
    
    init() {
        apollo.fetch(query: Bookschema.BookQuery()) { [weak self] result in
            switch result {
            case .success(let graphResult):
                self?.books = graphResult.data?.books ?? []
            case .failure(let error):
                print("\(error.localizedDescription)")
            }
        }
    }
}
As you can see from the code above, we create a typealias to make an easier to use Book type based off of the generated type of Bookschema.BookQuery.Data.Book. Then in the fetch method, we use a resultType, which can take either a success or a failure from the fetch result. If it is successful we set the books property to the result, which is an array of Books.
Now we will modify our SwiftUI view to use this view model and display the results in a list using a ForEach function.
import SwiftUI

struct ContentView: View {
    
    @ObservedObject var viewModel = BooksQueryViewModel()
    
    var body: some View {
        VStack {
            List {
                ForEach(viewModel.books, id: \.id) { book in
                    Text("\(book.title) by \(book.author)")
                }
            }
        }
        .padding()
    }
}
Now when we run the app with this view, we will see a list of our books and authors.
Conclusion
It takes a lot of set up to get the Apollo working with a Mercurius/Fastify backend. Once you have all of these pieces in place, it does make it a lot easier to develop and use GraphQL with your iOS code.
You can set up your Xcode project to automatically generate code every time you build or run your app. I do not think that is a best practice. It is better to generate when you know new types have been added to your schema. Some environments make frequent changes to their GraphQL backend, so you may need to add a script to run this each time you build your app.Tags: Node.js,   iOS,   GraphQL,   Apollo,   Mercurius   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeMarch 5th, 2023I recently came across this post from Raymond Camden on how to use the Photoshop APIs with Node.js. If you are not familiar with Raymond Camden, he is an engineer at Adobe, and has worked with some cool server and client side technology. He is currently the Senior Developer Evangelist for Adobe.
In the post he shows how to use the Photoshop API to remove the background from an image, and save it to a Azure File Storage.
I decided to play around with the API, but I wanted to use AWS S3 storage instead. I have not found and good documentation on how to use the Photoshop API with S3, so I decided to write this post on how to use the Photoshop API with AWS S3.
Image processing on the server
For a little background, I started my career as graphic artist, and I have been working with Photoshop since version 1.0. One of the first big programming projects I had at my first job was
taking a large collection of high resolution images, and saving out thumbnails for a web server with the background knocked out. I did this using a Photoshop extension that allowed developers to use AppleScript to run a series of actions and save a new version of the image. Back in the 90s we did not have a lot of the tools that we have now for doing image processing on a server.
Saving a thumbnail of an image can be done easily now with Node.js using Sharp or Jimp. These tools are great, but what if you want to use some of the advanced features of Photoshop to manipulate with the fool power of Photoshop. It is not realistic to run Photoshop on server since most servers nowadays are running linux.
Adobe has solved this problem by giving developers access to the Photoshop API.
How much does it cost?
Adobe provides three different pricing models: a free trial up to 5000 API calls, Individual Developer with $0.15 per API call and custom pricing for the Enterprise.
I got set up with a free trial. You can to by following this free trial link.
Starting a new project
Once you have signed up, go to the I/O console, and create a new project. There are three options after creating a new project in the I/O console: Add an API, Add event and Add plugin. You will want to select Add an API. Select the Adobe Photoshop API, and then select next. The wizard will ask whether you want to Generate a key pair, or upload a public key for your JWT credentials. For out example we will choose option 1 to generate a key pair.
Once you select a new key pair, your browser will download a config.zip that contains your keys. Don't loose this, you will need this to authenticate against the Adobe Photoshop service. Unzip your config.zip. It contains two files: certificate_pub.crt and a private.key. You will also be shown a scree with your API Key (client Id).
Make sure to go to your project in the console and select the service account (JWT). This page contains your Client Id, Client Secret, Technical Account Id, Technical Account Email and Organization Id. You will need these when we go to set up our Node.js application.
File Storage
Adobe gives you three options for file storage. Those providers are as follows:

Azure File Storage
AWS S3
Dropbox

For this example I chose to use S3 because I have worked with it before, and it is probably the most popular of the three.
Create an AWS account
If you do not already have one, go ahead and create an AWS account. Once you have created your AWS account, we are going to create a new S3 bucket in AWS. We will call it photoshopservice.
You will also need to install the AWS cli. Once you have installed the cli, you will need to login to AWS through the cli in order to authenticate AWS on your development computer.
What are we building with the PS API
We will be creating a service that takes an existing photograph and makes it look like an oil painting. Here is an example of a before and after image.

      
    
  
  
    
Once we have run the action, we will save the output back to our S3 bucket.
Setting up the Environment Variables
Since we are using Node.js, we will use the dotenv package to load our environment variables.
CLIENT_ID=<the client id>
CLIENT_SECRET=<the client secret>
TECHNICAL_ACCOUNT_ID=<account id>
TECHNICAL_ACCOUNT_EMAIL=<account email>
ORGANIZATION_ID=<org id>
KEY="<The private key here>"

BUCKET='photoshopservice'
REGION=<Your AWS Region>
The code
For our code we will use a Node.js module. We can do this by giving our file extension the .mjs or changing the type in the project.json to module.
The next thing we will need to do is include the Node.js modules we need to run our code. You can install these modules by using the following NPM command.
> npm install @adobe/jwt-auth @aws-sdk/client-s3 @aws-sdk/s3-request-presigner dotenv node-fetch
Now we can can create our JavaScript module file with the following code:
// Code taken from Raymond Camden's example, but using S3
import fetch from 'node-fetch';
import dotenv from 'dotenv';
dotenv.config();

import { S3Client, GetObjectCommand, PutObjectCommand } from '@aws-sdk/client-s3';
import { getSignedUrl } from '@aws-sdk/s3-request-presigner';

import auth from '@adobe/jwt-auth';
import fs from 'fs';

const CLIENT_ID = process.env.CLIENT_ID;
const CLIENT_SECRET = process.env.CLIENT_SECRET;
const TECHNICAL_ACCOUNT_ID = process.env.TECHNICAL_ACCOUNT_ID;
const ORG_ID = process.env.ORGANIZATION_ID;
const KEY = process.env.KEY;

async function delay(x) {
	return new Promise(resolve => {
		setTimeout(() => {
			resolve();
		}, x);
	});
}

const run = async () => {
    const s3Client = new S3Client({ region: process.env.REGION });

    const getParams = {
        Bucket: process.env.BUCKET,
        Key: 'miles1.jpg',
        Expires: 3600 
    };
    
    const putParams = {
        Bucket: process.env.BUCKET,
        Key: 'miles1_oilpaint2.png'

    };

    const actionsGetParams = {
        Bucket: process.env.BUCKET,
        Key: "Oil-paint.atn",
        Expires: 3600
    };

    const inputCommand = new GetObjectCommand(getParams);
    const inputActionsCommand = new GetObjectCommand(actionsGetParams);
    const outputCommand = new PutObjectCommand(putParams);

    const inputSignedUrl = await getSignedUrl(s3Client, inputCommand, { expiresIn: 3600 });
    const inputActionsSignedUrl = await getSignedUrl(s3Client, inputActionsCommand, { expiresIn: 3600 });
    const outputSignedUrl = await getSignedUrl(s3Client, outputCommand, { expiresIn: 3600 });
    
    let config = {
        clientId: CLIENT_ID,
        clientSecret: CLIENT_SECRET, 
        technicalAccountId: TECHNICAL_ACCOUNT_ID,
        orgId: ORG_ID,
        privateKey: KEY,
        metaScopes:'ent_ccas_sdk'
    }

    let { access_token } = await auth(config);

    let data = {
        "inputs": [
            {
                "storage":"external",
                "href": inputSignedUrl
            }
        ],
        "options": {
            "actions": [
                {
                    "href": inputActionsSignedUrl,
                    "storage": "external",
                    "actionName": "Action 51"
                }
            ]
        },
        "outputs": [
                {
                    "storage":"external",
                    "href": outputSignedUrl,
                    "type": "image/png"
                }
            ]      
    };

    let resp = await fetch('https://image.adobe.io/pie/psdService/photoshopActions', {
        method: 'POST', 
        headers: {
            'Authorization':`Bearer ${access_token}`,
            'x-api-key': CLIENT_ID
        }, 
        body: JSON.stringify(data)
    });
    let result = await resp.json();
	console.log(result);

    let status = 'running';
    let jobResult;
	while(status === 'running' || status === 'pending' || status === 'starting') {
		console.log('delaying while checking');
		await delay(5000);

		let jobReq = await fetch(result['_links']['self']['href'], {
			headers: {
				'Authorization':`Bearer ${access_token}`,
				'x-api-key': CLIENT_ID
			}
		})
		
		jobResult = await jobReq.json();
		
		status = jobResult['status'];
	}

	console.log('Final result', jobResult);
};
run();
To run this example you will have needed to upload two files to your S3 bucket already. One for the input file and one for the action. The oil painting action can be found at the following link on GitHub.
So lets break down what this code is actually doing. The top portion of the code seen below imports the AWS code modules and the Adobe auth library. It also sets up our environment variables for the auth and the S3 bucket and region.
import fetch from 'node-fetch';
import dotenv from 'dotenv';
dotenv.config();

import { S3Client, GetObjectCommand, PutObjectCommand } from '@aws-sdk/client-s3';
import { getSignedUrl } from '@aws-sdk/s3-request-presigner';

import auth from '@adobe/jwt-auth';
import fs from 'fs';

const CLIENT_ID = process.env.CLIENT_ID;
const CLIENT_SECRET = process.env.CLIENT_SECRET;
const TECHNICAL_ACCOUNT_ID = process.env.TECHNICAL_ACCOUNT_ID;
const ORG_ID = process.env.ORGANIZATION_ID;
const KEY = process.env.KEY;
The next part of the code creates an S3 client and code for creating the presigned S3 URLs that Adobe will need for our inputs and output.
const s3Client = new S3Client({ region: process.env.REGION });

const getParams = {
    Bucket: process.env.BUCKET,
    Key: 'miles1.jpg',
    Expires: 3600 
};

const putParams = {
    Bucket: process.env.BUCKET,
    Key: 'miles1_oilpaint2.png'

};

const actionsGetParams = {
    Bucket: process.env.BUCKET,
    Key: "Oil-paint.atn",
    Expires: 3600
};

const inputCommand = new GetObjectCommand(getParams);
const inputActionsCommand = new GetObjectCommand(actionsGetParams);
const outputCommand = new PutObjectCommand(putParams);

const inputSignedUrl = await getSignedUrl(s3Client, inputCommand, { expiresIn: 3600 });
const inputActionsSignedUrl = await getSignedUrl(s3Client, inputActionsCommand, { expiresIn: 3600 });
const outputSignedUrl = await getSignedUrl(s3Client, outputCommand, { expiresIn: 3600 });
After creating the presigned URLs we can create our access_token using the Adobe auth library:
let config = {
    clientId: CLIENT_ID,
    clientSecret: CLIENT_SECRET, 
    technicalAccountId: TECHNICAL_ACCOUNT_ID,
    orgId: ORG_ID,
    privateKey: KEY,
    metaScopes:'ent_ccas_sdk'
}

let { access_token } = await auth(config);
Now that we our access_token, we can define the data for the body of our request to the Photoshop API.
let data = {
    "inputs": [
        {
            "storage":"external",
            "href": inputSignedUrl
        }
    ],
    "options": {
        "actions": [
            {
                "href": inputActionsSignedUrl,
                "storage": "external",
                "actionName": "Action 51"
            }
        ]
    },
    "outputs": [
            {
                "storage":"external",
                "href": outputSignedUrl,
                "type": "image/png"
            }
        ]      
};
As you can see from the example above, we are defining the inputs, options with actions we want to run, and the outputs. All three of these take an array, which is different from some of the other Photoshop APIs which only take a single input and output.
Once we have out body, now we can make out request using node-fetch.
let resp = await fetch('https://image.adobe.io/pie/psdService/photoshopActions', {
    method: 'POST', 
    headers: {
        'Authorization':`Bearer ${access_token}`,
        'x-api-key': CLIENT_ID
    }, 
    body: JSON.stringify(data)
});
let result = await resp.json();
console.log(result);
In Raymond Camden's earlier example he checks the status every five seconds to see if the service has completed running.
let status = 'running';
let jobResult;
while(status === 'running' || status === 'pending' || status === 'starting') {
    console.log('delaying while checking');
    await delay(5000);

    let jobReq = await fetch(result['_links']['self']['href'], {
        headers: {
            'Authorization':`Bearer ${access_token}`,
            'x-api-key': CLIENT_ID
        }
    })
    
    jobResult = await jobReq.json();
    
    status = jobResult['status'];
}

console.log('Final result', jobResult);
Conclusion
For doing simple image manipulation, it is not necessary to use the Photoshop API, but if you have specialized tasks you need to perform on images, the Photoshop API might be the way to go.
If you just need to resize an image, or save in a different format, you do not need the Photoshop API to perform these sort of tasks.
However, if you need to run a set of actions, add typography to your images, use some of Adobe's AI for creating smart objects, the Photoshop API is probably the way to go for these types of jobs.
I will be presenting on the Photoshop API at the next JaxNode User Group meeting on March 16th. If you are in Jacksonville at the time, please come out.Tags: Node.js,   Photoshop,   Photoshop API,   AWS S3   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeFebruary 25th, 2023


I recently needed to add a GraphQL endpoint to an existing Fastify service. I have worked with Apollo before which has a way of hosting on top of an Express service.
There may be a way of hosting Apollo on top of Fastify service, but I have not found a way to do this with the existing version of Fastify.
There is a Fastify plugin for apollo, but it works with older versions of Fastify. In fact if you follow the link to the plugin, it takes you to a 404 page.
It turns out that Fastify has a pretty good solution for hosting a GraphQL service through a tool called Mercurius.
In this post I will show how you can take an existing Fastify service, and add a GraphQL endpoint.
Example Fastify Rest Endpoint
Let us take a look at existing Fastify server.
// Require the framework and instantiate it
import Fastify from 'fastify';

const fastify = Fastify({ logger: true });

// Declare a route
fastify.get('/books', (req, reply) => {
    reply.send([
      { id: 1, title: 'The Great Gatsby', author: 'F. Scott Fitzgerald' },
      { id: 2, title: 'To Kill a Mockingbird', author: 'Harper Lee' },
      { id: 3, title: '1984', author: 'George Orwell' },
      { id: 4, title: 'Pride and Prejudice', author: 'Jane Austen' },
      { id: 5, title: 'The Catcher in the Rye', author: 'J.D. Salinger' },
      { id: 6, title: 'One Hundred Years of Solitude', author: 'Gabriel Garcia Marquez' },
      { id: 7, title: 'Moby-Dick', author: 'Herman Melville' },
      { id: 8, title: 'War and Peace', author: 'Leo Tolstoy' },
      { id: 9, title: 'The Odyssey', author: 'Homer' },
      { id: 10, title: 'The Divine Comedy', author: 'Dante Alighieri' },
    ])
  })

// Run the server!
const start = async () => {
  try {
    await fastify.listen({ port: 3000 })
  } catch (err) {
    fastify.log.error(err)
    process.exit(1)
  }
};
start();
Adding Mercurius to Fastify
The next step is to use NPM or Yarn to add Mercurius.
> npm i mercurius
Now add the following code to your Fastify server.
import Fastify from 'fastify';
import mercurius from 'mercurius';

The Schema
GraphQL servers require two configurations, Type definitions and resolvers. The Type definition or schema uses a GraphQL based type definition to define the data being output as well as any parameters.
For out book service, it will look like the following:
type Book {
  id: ID!
  title: String!
  author: String!
}

type Query {
  books: [Book!]!
}
If we look at the following definition we can see it has a type for the Book, as well as the Query. The Book has thee properties for the id, title and author. In the Query type, we have a query for books that expects an array of [Book].
Resolvers
The other configuration will be the resolver. For every query in our definition, we need to have logic to return the data expected by the query. With Fastify, we can simply inject our route with the data needed by the resolver like the following:
const resolvers = {
  Query: {
    books: async () => {
      const res = await fastify.inject({
        method: 'GET',
        url: '/books'
      })
      return res.json()
    }
  }
};
Instead of doing that, a better way would be to refactor the data returned from book into its own function or variable.
function getBooks() {
  return [
    { id: 1, title: 'The Great Gatsby', author: 'F. Scott Fitzgerald' },
    { id: 2, title: 'To Kill a Mockingbird', author: 'Harper Lee' },
    { id: 3, title: '1984', author: 'George Orwell' },
    { id: 4, title: 'Pride and Prejudice', author: 'Jane Austen' },
    { id: 5, title: 'The Catcher in the Rye', author: 'J.D. Salinger' },
    { id: 6, title: 'One Hundred Years of Solitude', author: 'Gabriel Garcia Marquez' },
    { id: 7, title: 'Moby-Dick', author: 'Herman Melville' },
    { id: 8, title: 'War and Peace', author: 'Leo Tolstoy' },
    { id: 9, title: 'The Odyssey', author: 'Homer' },
    { id: 10, title: 'The Divine Comedy', author: 'Dante Alighieri' },
  ];
}

Now we can share that method with both the get route for books as well as the resolver.
const resolvers = {
  Query: {
    books: async () => {
      return getBooks()
    }
  }
};
Register your GraphQL in Fastify
Now that you have your definition and resolver, lets put this all together in Fastify.
const typeDef = `
  type Book {
    id: ID!
    title: String!
    author: String!
  }

  type Query {
    books: [Book!]!
  }
`;

fastify.register(mercurius, {
  schema: typeDef,
  resolvers: resolvers
});
The final refactored Fastify service should look like the following:
import Fastify from 'fastify';
import mercurius from 'mercurius';

const fastify = Fastify({ logger: true });

function getBooks() {
  return [
    { id: 1, title: 'The Great Gatsby', author: 'F. Scott Fitzgerald' },
    { id: 2, title: 'To Kill a Mockingbird', author: 'Harper Lee' },
    { id: 3, title: '1984', author: 'George Orwell' },
    { id: 4, title: 'Pride and Prejudice', author: 'Jane Austen' },
    { id: 5, title: 'The Catcher in the Rye', author: 'J.D. Salinger' },
    { id: 6, title: 'One Hundred Years of Solitude', author: 'Gabriel Garcia Marquez' },
    { id: 7, title: 'Moby-Dick', author: 'Herman Melville' },
    { id: 8, title: 'War and Peace', author: 'Leo Tolstoy' },
    { id: 9, title: 'The Odyssey', author: 'Homer' },
    { id: 10, title: 'The Divine Comedy', author: 'Dante Alighieri' },
  ];
}

const typeDef = `
  type Book {
    id: ID!
    title: String!
    author: String!
  }

  type Query {
    books: [Book!]!
  }
`;

const resolvers = {
  Query: {
    books: async () => {
      return getBooks()
    }
  }
};

// Declare a route
fastify.get('/books', (req, reply) => {
  reply.send(getBooks());
});

fastify.register(mercurius, {
  schema: typeDef,
  resolvers: resolvers
});

// Run the server!
const start = async () => {
  try {
    await fastify.listen({ port: 3000 })
  } catch (err) {
    fastify.log.error(err)
    process.exit(1)
  }
};
start();
Verify it working
You can use a tool like GraphiQL to verify that your service is working. This tool can be downloaded locally. To test your endpoint, you will just need to use graphql after the domain name of your server.

      
    
  
  
    
Conclusion
GraphQL is becoming an increasing popular way to query and transform data from multiple different endpoints. If you have an existing Fastify service, it is not necessary to have to host a separate service. This can be done to your existing Fastify service.
That being said, it is quite common and sometimes better to use a separate service for hosting you GraphQL. One of the things organizations are doing now is hosting GraphQL as a federated service, and this might be a better option.Tags: Node.js,   GraphQL,   Fastify,   Mercurius   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 25th, 2023


By default when you create a new application in Xcode that is a SwiftUI app, it generates an application without an AppDelegate class. It has been replaced by an App struct. Much like how SwiftUI uses structs
for views, Apple also is creating a struct for the App.
The nice thing about structs in Swift is that they use fewer resources than classes. In Swift structs are value types and classes are reference types. Value types generally are only loaded into the stack while reference types are loaded into the heap of the system.
Why do I need an AppDelegate class?
The AppDelegate is a special object in a MacOS or iOS application that is responsible for handling important events and tasks throughout the lifecycle of the app.
It is typically used to handle events such as the app launching, entering the background, and shutting down. The AppDelegate is also used to set up the initial state of the app, such as creating the main window and loading any necessary data, resources, etc... Additionally, it can handle other system-level events such as push notifications and URL opening.
The app struct that is part of the standard Xcode SwiftUI template does not handle all of the application lifecycle and external events that are handled by the AppDelegate class. This is why you may need to add this class to your app.
SwiftUI file structure
When you create a new SwiftUI iOS app in Xcode, it will create a folder named after your app, and two files for the App struct and the ContentView struct. They look like the following;
// SampleApp.swift
import SwiftUI

@main
struct SampleApp: App {
    var body: some Scene {
        WindowGroup {
            ContentView()
        }
    }
}
// ContentView.swift
import SwiftUI

struct ContentView: View {
    var body: some View {
        VStack {
            Image(systemName: "globe")
                .imageScale(.large)
                .foregroundColor(.accentColor)
            Text("Hello, world!")
        }
        .padding()
    }
}

struct ContentView_Previews: PreviewProvider {
    static var previews: some View {
        ContentView()
    }
}
Add the AppDelegate
In Xcode, add a new swift file, and call it AppDelegate.swift.
import Foundation
import UIKit

class AppDelegate: NSObject, UIApplicationDelegate {

    // swiftlint: disable line_length
    func application(_ application: UIApplication,
                     didFinishLaunchingWithOptions launchOptions: [UIApplication.LaunchOptionsKey: Any]? = nil) -> Bool {
        setupMyApp()
        return true
    }

    private func setupMyApp() {
        // TODO: Add any intialization steps here.
        print("Application started up!")
    }
}
Then in your App.swift file you can add a reference to the AppDelegate file in your struct. Put this line before your body property.
...
struct SampleApp: App {

    @UIApplicationDelegateAdaptor private var appDelegate: AppDelegate

    var body: some Scene {
...
Conclusion
By adding the AppDelegate to your app you can take advantage of a lot of functionality that is not available in a pure SwiftUI app. Use the AppDelegate to have access to the full lifecycle of your app.Tags: Swift,   SwiftUI   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 22nd, 2023


Upgrading to Gatsby 5 from version 4
Gatsby 5 was introduced at the end of last year. I decided to upgrade my site to Gatsby 5 from version 4. Upgrading Gatsby a major version can be complex, especially if you are using a lot of plugins. Here are the steps I usually take to upgrade to a newer version of Gatsby.
The first step is to upgrade the main Gatsby module using NPM or Yarn. I used NPM for this example:
> npm install gastby@latest
After running this command, you will also want to check for any other outdated modules. This can be done by using the npm outaded command. You should get output that looks like the following:
> npm outdated

Package                  Current   Wanted  Latest  Location
gatsby-plugin-sharp      3.1.2     3.1.2   3.4.0   test
You will need to upgrade the modules to the latest version. I also had to force the upgrade by using the --force parameter. You can also use the shortcut -f.
npm install gatsby-plugin-sharp@3.4.0 --force
Errors after upgrade
After finishing the upgrade I ran the gatsby develop command, but I got an error that looked like the following:
ERROR  UNKNOWN

Module not found: Error: Can't resolve 'gatsby-core-utils/create-content-digest' in
'/Users/username/Documents/node/projects/fek.io/.cache/slice'



  ModuleNotFoundError: Module not found: Error: Can't resolve 'gatsby-core-utils/create-content-digest' in '/Users/username/D
  ocuments/node/projects/fek.io/.cache/slice'

  - Compilation.js:2016
    [fek.io]/[webpack]/lib/Compilation.js:2016:28

  - NormalModuleFactory.js:798
    [fek.io]/[webpack]/lib/NormalModuleFactory.js:798:13


  - NormalModuleFactory.js:270
    [fek.io]/[webpack]/lib/NormalModuleFactory.js:270:22


  - NormalModuleFactory.js:434
    [fek.io]/[webpack]/lib/NormalModuleFactory.js:434:22

  - NormalModuleFactory.js:116
    [fek.io]/[webpack]/lib/NormalModuleFactory.js:116:11

  - NormalModuleFactory.js:670
    [fek.io]/[webpack]/lib/NormalModuleFactory.js:670:25

  - NormalModuleFactory.js:855
    [fek.io]/[webpack]/lib/NormalModuleFactory.js:855:8

  - NormalModuleFactory.js:975
    [fek.io]/[webpack]/lib/NormalModuleFactory.js:975:5

  - async.js:6883
    [fek.io]/[neo-async]/async.js:6883:13

  - NormalModuleFactory.js:958
    [fek.io]/[webpack]/lib/NormalModuleFactory.js:958:45

  - Resolver.js:312 finishWithoutResolve
    [fek.io]/[enhanced-resolve]/lib/Resolver.js:312:11

  - Resolver.js:386
    [fek.io]/[enhanced-resolve]/lib/Resolver.js:386:15

  - Resolver.js:435
    [fek.io]/[enhanced-resolve]/lib/Resolver.js:435:5


  - Resolver.js:435
    [fek.io]/[enhanced-resolve]/lib/Resolver.js:435:5


  - DescriptionFilePlugin.js:87
    [fek.io]/[enhanced-resolve]/lib/DescriptionFilePlugin.js:87:43

  - Resolver.js:435
    [fek.io]/[enhanced-resolve]/lib/Resolver.js:435:5


  - Resolver.js:435
    [fek.io]/[enhanced-resolve]/lib/Resolver.js:435:5


  - Resolver.js:435
    [fek.io]/[enhanced-resolve]/lib/Resolver.js:435:5


  - Resolver.js:435
    [fek.io]/[enhanced-resolve]/lib/Resolver.js:435:5


  - DescriptionFilePlugin.js:87
    [fek.io]/[enhanced-resolve]/lib/DescriptionFilePlugin.js:87:43

  - Resolver.js:435
    [fek.io]/[enhanced-resolve]/lib/Resolver.js:435:5


  - Resolver.js:435
    [fek.io]/[enhanced-resolve]/lib/Resolver.js:435:5


  - DirectoryExistsPlugin.js:41
    [fek.io]/[enhanced-resolve]/lib/DirectoryExistsPlugin.js:41:15

  - task_queues:81 processTicksAndRejections
    node:internal/process/task_queues:81:21


not finished Building development bundle - 5.928s
I was able to resolve by installing the gatsby-core-utils module.
npm install gatsby-core-utils
After I made this change the site would run in development mode.
Upgrading GraphQL queries
Gatsby 5 has a newer GraphQL engine. One of the nice things about Gatsby 5 is that it will upgrade your GraphQL queries automatically,
and it will show you how you can make those same changes to your queries.

Current query:

query blogListQuery($skip: Int!, $limit: Int!) {
  allMarkdownRemark(
    sort: {fields: [frontmatter___date], order: DESC}
    limit: $limit
    skip: $skip
  ) {
    edges {
      node {
        fields {
          slug
        }
        frontmatter {
          title
          tags
        }
        excerpt
        timeToRead
      }
    }
  }
}

Converted query:

query blogListQuery($skip: Int!, $limit: Int!) {
  allMarkdownRemark(sort: {frontmatter: {date: DESC}}, limit: $limit, skip: $skip) {
    edges {
      node {
        fields {
          slug
        }
        frontmatter {
          title
          tags
        }
        excerpt
        timeToRead
      }
    }
  }
}
Conclusion
After having done a few major version upgrades of Gatsby in the past, the 4 to version 5 upgrade has actually been one of the easier upgrades.Tags: Gatsby,   node.js,   JavaScript   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeOctober 16th, 2022


I recently ran into a problem trying to set up automated unit testing for a iOS based Swift Package.
There are a couple of different ways of creating packages or libraries of code for an iOS project. The Swift Package Manager has become one of the more popular methods of creating reusable modules.
The Swift Package Manager, or SPM for short, provides an excellent way of authoring and distributing these modules. SPM also is designed to be cross platform in the since that swift packages can be share between the macOS, tvOS, watchOS and iOS. The Swift command line tool has a built in test runner that you can use to execute your unit tests. But what happens if you are using dependencies that are iOS only. In other words, they can not run on the Mac using the built in test runner.
Incorporating Fastlane
Fastlane is a automation tool for Android and iOS developers looking to streamline builds, testing, automated screenshots and builds for your project. In this post I will use Fastlane in combination with SPM to create a way for running unit tests on iOS only packages.
Installing Fastlane
Fastlane requires that you use a Mac with Ruby 2.5 or newer. Once you have validated that you have a new enough version of Ruby, you can install Fastlane.

Install Bundler by running gem install bundler.
Create a ./Gemfile in the root directory of your project with the content.

source "https://rubygems.org"

gem "fastlane"
You can also install Fastlane using Homebrew by running the following brew command:
$ brew install fastlane
Adding fastlane to your Swift Package
From your terminal, navigate to the root folder for your package and type the following command:
$ fastlane init
Select manual setup, which should be option number four. This will create a fastlane folder in your package folder. In this folder you should see an Appfile and a Fastfile.
Swift Packages and Xcode
Xcode no longer requires an xcodeproj project folder in order to open packages. You can open your project by either typing xed . in the terminal at the root of your project or by opening your folder directly in Xcode. In order to run tests in Fastlane, we will need a xcodeproj folder. Here is the SPM command that you can use to generate a the xcodeproj folder.
swift package generate-xcodeproj
You should see a message in your terminal that says something like:
warning: Xcode can open and build Swift Packages directly. 'generate-xcodeproj' is no longer needed and will be deprecated soon.
generated: ./YourPackageName.xcodeproj
Configure fastlane
Edit the Fastfile for your testing. We will create a lane called tests. By default the Fastfile will look like the following example.
# This file contains the fastlane.tools configuration
# You can find the documentation at https://docs.fastlane.tools
#
# For a list of all available actions, check out
#
#     https://docs.fastlane.tools/actions
#
# For a list of all available plugins, check out
#
#     https://docs.fastlane.tools/plugins/available-plugins
#

# Uncomment the line if you want fastlane to automatically update itself
# update_fastlane

default_platform(:ios)

platform :ios do
  desc "Description of what the lane does"
  lane :custom_lane do
    # add actions here: https://docs.fastlane.tools/actions
  end
end
Change the file so it looks like the following example:
default_platform(:ios)

platform :ios do
  desc "This lane is used for running unit tests"
  lane :tests do
    puts "running our tests!"
  end
end
If you want to run a Fastlane lane for tests, this can be done by typing fastlane ios tests. Our current Fastfile only outputs the text running our tests!. We are going to change the Fastfile so that it does the following three actions. We will be telling fastlane to create a new xcodeproj folder for our swift package, then to run our unit tests and finally remove the xcodeproj folder we just created.
Edit your Fastfile so it looks like the following example:
default_platform(:ios)

platform :ios do
  desc "This lane is used for running unit tests"
  lane :tests do
    puts "running a our tests"
    spm(
      command: "generate-xcodeproj"
    )
    
    run_tests(
      project: "./<NameOfYourPackage>.xcodeproj",
      devices: ["iPhone 14 Pro Max"]
    )
    
    sh("rm", "-rf", "<NameOfYourPackage>.xcodeproj")
  end
end
The first part of this tests lane uses the spm action to generate the xcodeproj folder needed to run the tests. The next action is the run_tests action which will compile our package and run the any tests. The last part uses the sh action we are using for running the shell script command to delete our xcodeproj folder since it is not needed other than o run the Fastlane unit tests.
Now when you run the tests lane, you should get output that looks like the following:
[‚úî] üöÄ
[15:29:17]: fastlane detected a Gemfile in the current directory
[15:29:17]: However, it seems like you didn't use `bundle exec`
[15:29:17]: To launch fastlane faster, please use
[15:29:17]:
[15:29:17]: $ bundle exec fastlane tests
[15:29:17]:
[15:29:17]: Get started using a Gemfile for fastlane https://docs.fastlane.tools/getting-started/ios/setup/#use-a-gemfile
[15:29:18]: ------------------------------
[15:29:18]: --- Step: default_platform ---
[15:29:18]: ------------------------------
[15:29:18]: Driving the lane 'ios tests' üöÄ
[15:29:18]: running a our tests
[15:29:18]: -----------------
[15:29:18]: --- Step: spm ---
[15:29:18]: -----------------
[15:29:18]: $ swift package generate-xcodeproj
[15:29:18]: ‚ñ∏ warning: Xcode can open and build Swift Packages directly. 'generate-xcodeproj' is no longer needed and will be deprecated soon.
[15:29:20]: ‚ñ∏ generated: ./AnimalYears.xcodeproj
[15:29:20]: -----------------------
[15:29:20]: --- Step: run_tests ---
[15:29:20]: -----------------------
[15:29:20]: Resolving Swift Package Manager dependencies...
[15:29:20]: $ xcodebuild -resolvePackageDependencies -scheme AnimalYears-Package -project ./AnimalYears.xcodeproj
[15:29:20]: ‚ñ∏ Command line invocation:
[15:29:20]: ‚ñ∏     /Applications/Xcode.app/Contents/Developer/usr/bin/xcodebuild -resolvePackageDependencies -scheme AnimalYears-Package -project ./AnimalYears.xcodeproj
[15:29:20]: ‚ñ∏ User defaults from command line:
[15:29:20]: ‚ñ∏     IDEPackageSupportUseBuiltinSCM = YES
[15:29:20]: ‚ñ∏ --- xcodebuild: WARNING: Using the first of multiple matching destinations:
[15:29:20]: ‚ñ∏ { platform:macOS, arch:arm64, id:00006001-001049DC2109801E }
[15:29:20]: ‚ñ∏ { platform:macOS, arch:x86_64, id:00006001-001049DC2109801E }
[15:29:20]: ‚ñ∏ { platform:macOS, arch:arm64, variant:Mac Catalyst, id:00006001-001049DC2109801E }
[15:29:20]: ‚ñ∏ { platform:macOS, arch:x86_64, variant:Mac Catalyst, id:00006001-001049DC2109801E }
[15:29:20]: ‚ñ∏ { platform:macOS, arch:arm64, variant:DriverKit, id:00006001-001049DC2109801E }
[15:29:20]: ‚ñ∏ { platform:DriverKit, name:Any DriverKit Host }
[15:29:20]: ‚ñ∏ { platform:iOS, id:dvtdevice-DVTiPhonePlaceholder-iphoneos:placeholder, name:Any iOS Device }
[15:29:20]: ‚ñ∏ { platform:iOS Simulator, id:dvtdevice-DVTiOSDeviceSimulatorPlaceholder-iphonesimulator:placeholder, name:Any iOS Simulator Device }
[15:29:20]: ‚ñ∏ { platform:macOS, name:Any Mac }
[15:29:20]: ‚ñ∏ { platform:macOS, variant:Mac Catalyst, name:Any Mac }
[15:29:20]: ‚ñ∏ { platform:tvOS, id:dvtdevice-DVTiOSDevicePlaceholder-appletvos:placeholder, name:Any tvOS Device, error:tvOS 16.0 is not installed. To use with Xcode, first download and install the platform }
[15:29:20]: ‚ñ∏ { platform:watchOS, id:dvtdevice-DVTiOSDevicePlaceholder-watchos:placeholder, name:Any watchOS Device, error:watchOS 9.0 is not installed. To use with Xcode, first download and install the platform }
[15:29:20]: ‚ñ∏ { platform:iOS Simulator, id:4E2D035C-381D-49FA-9840-166C7DE95A8B, OS:16.0, name:iPad (9th generation) }
[15:29:20]: ‚ñ∏ { platform:iOS Simulator, id:45ECB41A-3087-446E-A3F1-FC69100E3A43, OS:16.0, name:iPad Air (5th generation) }
[15:29:20]: ‚ñ∏ { platform:iOS Simulator, id:B8235904-B566-452B-9965-F039070A623A, OS:16.0, name:iPad Pro (9.7-inch) }
[15:29:20]: ‚ñ∏ { platform:iOS Simulator, id:F5C95D29-BAEE-4E34-880D-F3A30370E5F6, OS:16.0, name:iPad Pro (11-inch) (3rd generation) }
[15:29:20]: ‚ñ∏ { platform:iOS Simulator, id:703B802B-C40A-4E93-B01B-E89DA684896D, OS:16.0, name:iPad Pro (12.9-inch) (5th generation) }
[15:29:20]: ‚ñ∏ { platform:iOS Simulator, id:0AD1335D-C7CB-4774-9092-D5790040529B, OS:16.0, name:iPad mini (6th generation) }
[15:29:20]: ‚ñ∏ { platform:iOS Simulator, id:C76866CF-2CEB-41E2-A10C-1317ACF3676A, OS:16.0, name:iPhone 8 }
[15:29:20]: ‚ñ∏ { platform:iOS Simulator, id:C2CB38A7-78D6-4FBA-9200-C793CF23FE02, OS:16.0, name:iPhone 8 Plus }
[15:29:20]: ‚ñ∏ { platform:iOS Simulator, id:7F96AF11-D8C7-452F-88E0-D19413558343, OS:16.0, name:iPhone 11 }
[15:29:20]: ‚ñ∏ { platform:iOS Simulator, id:CD9698BE-177A-43C6-97B5-B2F2A5EBC989, OS:16.0, name:iPhone 11 Pro }
[15:29:20]: ‚ñ∏ { platform:iOS Simulator, id:28B69918-6683-4261-A24A-457EEED330DF, OS:16.0, name:iPhone 11 Pro Max }
[15:29:20]: ‚ñ∏ { platform:iOS Simulator, id:0F8241EF-1EE4-49A7-8912-2B42DC90CD40, OS:16.0, name:iPhone 12 }
[15:29:20]: ‚ñ∏ { platform:iOS Simulator, id:FA363849-543D-44CA-AC7A-4711BB4C6724, OS:16.0, name:iPhone 12 Pro }
[15:29:20]: ‚ñ∏ { platform:iOS Simulator, id:2A8E51FA-CE89-449E-A182-BAB98AE77697, OS:16.0, name:iPhone 12 Pro Max }
[15:29:20]: ‚ñ∏ { platform:iOS Simulator, id:3C349F63-CADD-4E73-832D-318AE15F75DF, OS:16.0, name:iPhone 12 mini }
[15:29:20]: ‚ñ∏ { platform:iOS Simulator, id:4E635B8C-7D66-4D25-9CE4-456834FE65A9, OS:16.0, name:iPhone 13 }
[15:29:20]: ‚ñ∏ { platform:iOS Simulator, id:FEDAB4B2-519F-4594-BC6D-17FAD116DA51, OS:16.0, name:iPhone 13 Pro }
[15:29:20]: ‚ñ∏ { platform:iOS Simulator, id:6A86FD6A-77AC-49C9-B943-C00DCEA96D2B, OS:16.0, name:iPhone 13 Pro Max }
[15:29:20]: ‚ñ∏ { platform:iOS Simulator, id:A00944B0-81BC-4791-8AE1-79209CF4A9DB, OS:16.0, name:iPhone 13 mini }
[15:29:20]: ‚ñ∏ { platform:iOS Simulator, id:14224567-AD97-4E3C-ACD6-DF01E814C11E, OS:16.0, name:iPhone 14 }
[15:29:20]: ‚ñ∏ { platform:iOS Simulator, id:4F88BC99-AC85-4B0D-843B-6DA286CA3C35, OS:16.0, name:iPhone 14 Plus }
[15:29:20]: ‚ñ∏ { platform:iOS Simulator, id:D7BB845C-76B4-490F-A851-15901861D2C8, OS:16.0, name:iPhone 14 Pro }
[15:29:20]: ‚ñ∏ { platform:iOS Simulator, id:7ADD6B5D-B1F0-4C21-8DC9-C9CC7D1B5507, OS:16.0, name:iPhone 14 Pro Max }
[15:29:20]: ‚ñ∏ { platform:iOS Simulator, id:51297DAF-F8D0-4CC1-9A69-8C07DA49849F, OS:16.0, name:iPhone SE (3rd generation) }
[15:29:20]: ‚ñ∏ resolved source packages:
[15:29:20]: $ xcodebuild -showBuildSettings -scheme AnimalYears-Package -project ./AnimalYears.xcodeproj
--- xcodebuild: WARNING: Using the first of multiple matching destinations:
{ platform:macOS, arch:arm64, id:00006001-001049DC2109801E }
{ platform:macOS, arch:x86_64, id:00006001-001049DC2109801E }
{ platform:macOS, arch:arm64, variant:Mac Catalyst, id:00006001-001049DC2109801E }
{ platform:macOS, arch:x86_64, variant:Mac Catalyst, id:00006001-001049DC2109801E }
{ platform:macOS, arch:arm64, variant:DriverKit, id:00006001-001049DC2109801E }
{ platform:DriverKit, name:Any DriverKit Host }
{ platform:iOS, id:dvtdevice-DVTiPhonePlaceholder-iphoneos:placeholder, name:Any iOS Device }
{ platform:iOS Simulator, id:dvtdevice-DVTiOSDeviceSimulatorPlaceholder-iphonesimulator:placeholder, name:Any iOS Simulator Device }
{ platform:macOS, name:Any Mac }
{ platform:macOS, variant:Mac Catalyst, name:Any Mac }
{ platform:tvOS, id:dvtdevice-DVTiOSDevicePlaceholder-appletvos:placeholder, name:Any tvOS Device, error:tvOS 16.0 is not installed. To use with Xcode, first download and install the platform }
{ platform:watchOS, id:dvtdevice-DVTiOSDevicePlaceholder-watchos:placeholder, name:Any watchOS Device, error:watchOS 9.0 is not installed. To use with Xcode, first download and install the platform }
{ platform:iOS Simulator, id:4E2D035C-381D-49FA-9840-166C7DE95A8B, OS:16.0, name:iPad (9th generation) }
{ platform:iOS Simulator, id:45ECB41A-3087-446E-A3F1-FC69100E3A43, OS:16.0, name:iPad Air (5th generation) }
{ platform:iOS Simulator, id:B8235904-B566-452B-9965-F039070A623A, OS:16.0, name:iPad Pro (9.7-inch) }
{ platform:iOS Simulator, id:F5C95D29-BAEE-4E34-880D-F3A30370E5F6, OS:16.0, name:iPad Pro (11-inch) (3rd generation) }
{ platform:iOS Simulator, id:703B802B-C40A-4E93-B01B-E89DA684896D, OS:16.0, name:iPad Pro (12.9-inch) (5th generation) }
{ platform:iOS Simulator, id:0AD1335D-C7CB-4774-9092-D5790040529B, OS:16.0, name:iPad mini (6th generation) }
{ platform:iOS Simulator, id:C76866CF-2CEB-41E2-A10C-1317ACF3676A, OS:16.0, name:iPhone 8 }
{ platform:iOS Simulator, id:C2CB38A7-78D6-4FBA-9200-C793CF23FE02, OS:16.0, name:iPhone 8 Plus }
{ platform:iOS Simulator, id:7F96AF11-D8C7-452F-88E0-D19413558343, OS:16.0, name:iPhone 11 }
{ platform:iOS Simulator, id:CD9698BE-177A-43C6-97B5-B2F2A5EBC989, OS:16.0, name:iPhone 11 Pro }
{ platform:iOS Simulator, id:28B69918-6683-4261-A24A-457EEED330DF, OS:16.0, name:iPhone 11 Pro Max }
{ platform:iOS Simulator, id:0F8241EF-1EE4-49A7-8912-2B42DC90CD40, OS:16.0, name:iPhone 12 }
{ platform:iOS Simulator, id:FA363849-543D-44CA-AC7A-4711BB4C6724, OS:16.0, name:iPhone 12 Pro }
{ platform:iOS Simulator, id:2A8E51FA-CE89-449E-A182-BAB98AE77697, OS:16.0, name:iPhone 12 Pro Max }
{ platform:iOS Simulator, id:3C349F63-CADD-4E73-832D-318AE15F75DF, OS:16.0, name:iPhone 12 mini }
{ platform:iOS Simulator, id:4E635B8C-7D66-4D25-9CE4-456834FE65A9, OS:16.0, name:iPhone 13 }
{ platform:iOS Simulator, id:FEDAB4B2-519F-4594-BC6D-17FAD116DA51, OS:16.0, name:iPhone 13 Pro }
{ platform:iOS Simulator, id:6A86FD6A-77AC-49C9-B943-C00DCEA96D2B, OS:16.0, name:iPhone 13 Pro Max }
{ platform:iOS Simulator, id:A00944B0-81BC-4791-8AE1-79209CF4A9DB, OS:16.0, name:iPhone 13 mini }
{ platform:iOS Simulator, id:14224567-AD97-4E3C-ACD6-DF01E814C11E, OS:16.0, name:iPhone 14 }
{ platform:iOS Simulator, id:4F88BC99-AC85-4B0D-843B-6DA286CA3C35, OS:16.0, name:iPhone 14 Plus }
{ platform:iOS Simulator, id:D7BB845C-76B4-490F-A851-15901861D2C8, OS:16.0, name:iPhone 14 Pro }
{ platform:iOS Simulator, id:7ADD6B5D-B1F0-4C21-8DC9-C9CC7D1B5507, OS:16.0, name:iPhone 14 Pro Max }
{ platform:iOS Simulator, id:51297DAF-F8D0-4CC1-9A69-8C07DA49849F, OS:16.0, name:iPhone SE (3rd generation) }

+------------------------------------------------+-------------------------------------------------------------------+
|                                              Summary for scan 2.210.1                                              |
+------------------------------------------------+-------------------------------------------------------------------+
| project                                        | ./AnimalYears.xcodeproj                                           |
| devices                                        | ["iPhone 14 Pro Max"]                                             |
| scheme                                         | AnimalYears-Package                                               |
| skip_detect_devices                            | false                                                             |
| ensure_devices_found                           | false                                                             |
| force_quit_simulator                           | false                                                             |
| reset_simulator                                | false                                                             |
| disable_slide_to_type                          | true                                                              |
| reinstall_app                                  | false                                                             |
| clean                                          | false                                                             |
| open_report                                    | false                                                             |
| output_directory                               | ./fastlane/test_output                                            |
| output_types                                   | html,junit                                                        |
| buildlog_path                                  | ~/Library/Logs/scan                                               |
| include_simulator_logs                         | false                                                             |
| xcodebuild_formatter                           | xcpretty                                                          |
| output_remove_retry_attempts                   | false                                                             |
| derived_data_path                              | /Users/davidfekke/Library/Developer/Xcode/DerivedData/AnimalYear  |
|                                                | s-dayuikxpsxpsdzetpvevoekrqzec                                    |
| should_zip_build_products                      | false                                                             |
| output_xctestrun                               | false                                                             |
| result_bundle                                  | false                                                             |
| use_clang_report_name                          | false                                                             |
| disable_concurrent_testing                     | false                                                             |
| skip_build                                     | false                                                             |
| slack_use_webhook_configured_username_and_icon | false                                                             |
| slack_username                                 | fastlane                                                          |
| slack_icon_url                                 | https://fastlane.tools/assets/img/fastlane_icon.png               |
| skip_slack                                     | false                                                             |
| slack_only_on_failure                          | false                                                             |
| xcodebuild_command                             | env NSUnbufferedIO=YES xcodebuild                                 |
| skip_package_dependencies_resolution           | false                                                             |
| disable_package_automatic_updates              | false                                                             |
| use_system_scm                                 | false                                                             |
| number_of_retries                              | 0                                                                 |
| fail_build                                     | true                                                              |
| xcode_path                                     | /Applications/Xcode.app                                           |
+------------------------------------------------+-------------------------------------------------------------------+

[15:29:21]: Disabling 'Slide to Type' iPhone 14 Pro Max
[15:29:21]: $ /usr/libexec/PlistBuddy -c "Add :KeyboardContinuousPathEnabled bool false" /Users/davidfekke/Library/Developer/CoreSimulator/Devices/7ADD6B5D-B1F0-4C21-8DC9-C9CC7D1B5507/data/Library/Preferences/com.apple.keyboard.ContinuousPath.plist >/dev/null 2>&1
[15:29:21]: $ set -o pipefail && env NSUnbufferedIO=YES xcodebuild -scheme AnimalYears-Package -project ./AnimalYears.xcodeproj -derivedDataPath /Users/davidfekke/Library/Developer/Xcode/DerivedData/AnimalYears-dayuikxpsxpsdzetpvevoekrqzec -destination 'platform=iOS Simulator,id=7ADD6B5D-B1F0-4C21-8DC9-C9CC7D1B5507' build test | tee '/Users/davidfekke/Library/Logs/scan/AnimalYears-AnimalYears-Package.log' | xcpretty  --report html --output '/Users/davidfekke/Documents/xcode/AnimalYears/fastlane/test_output/report.html' --report junit --output '/Users/davidfekke/Documents/xcode/AnimalYears/fastlane/test_output/report.junit' --report junit --output '/var/folders/1g/xfq3km511r9gjpgh1qk6ldvm0000gn/T/junit_report20221016-84929-prcaby'
[15:29:21]: ‚ñ∏ Loading...
[15:29:22]: ‚ñ∏ Processing ApolloAPI_Info.plist
[15:29:24]: ‚ñ∏ Compiling Interface.swift
[15:29:24]: ‚ñ∏ Compiling Object.swift
[15:29:24]: ‚ñ∏ Compiling Union.swift
[15:29:24]: ‚ñ∏ Compiling Selection+Conditions.swift
[15:29:24]: ‚ñ∏ Compiling DataDict.swift
[15:29:24]: ‚ñ∏ Compiling FragmentProtocols.swift
[15:29:24]: ‚ñ∏ Compiling GraphQLEnum.swift
[15:29:24]: ‚ñ∏ Compiling EnumType.swift
[15:29:24]: ‚ñ∏ Compiling InputObject.swift
[15:29:24]: ‚ñ∏ Compiling Selection.swift
[15:29:24]: ‚ñ∏ Compiling SelectionSet.swift
[15:29:24]: ‚ñ∏ Compiling JSON.swift
[15:29:24]: ‚ñ∏ Compiling JSONDecodingError.swift
[15:29:24]: ‚ñ∏ Compiling JSONStandardTypeConversions.swift
[15:29:24]: ‚ñ∏ Compiling LocalCacheMutation.swift
[15:29:24]: ‚ñ∏ Compiling OutputTypeConvertible.swift
[15:29:24]: ‚ñ∏ Compiling ParentType.swift
[15:29:24]: ‚ñ∏ Compiling ScalarTypes.swift
[15:29:24]: ‚ñ∏ Compiling SchemaConfiguration.swift
[15:29:24]: ‚ñ∏ Compiling SchemaMetadata.swift
[15:29:24]: ‚ñ∏ Compiling GraphQLNullable.swift
[15:29:24]: ‚ñ∏ Compiling GraphQLOperation.swift
[15:29:24]: ‚ñ∏ Compiling InputValue.swift
[15:29:24]: ‚ñ∏ Compiling AnyHashableConvertible.swift
[15:29:24]: ‚ñ∏ Compiling CacheKeyInfo.swift
[15:29:24]: ‚ñ∏ Compiling CacheReference.swift
[15:29:24]: ‚ñ∏ Linking ApolloAPI
[15:29:24]: ‚ñ∏ Compiling Record.swift
[15:29:24]: ‚ñ∏ Compiling RecordSet.swift
[15:29:24]: ‚ñ∏ Compiling RequestBodyCreator.swift
[15:29:24]: ‚ñ∏ Compiling RequestChain.swift
[15:29:24]: ‚ñ∏ Compiling RequestChainNetworkTransport.swift
[15:29:24]: ‚ñ∏ Compiling GraphQLResponse.swift
[15:29:24]: ‚ñ∏ Compiling GraphQLResponseGenerator.swift
[15:29:24]: ‚ñ∏ Compiling GraphQLResult.swift
[15:29:24]: ‚ñ∏ Compiling GraphQLResultAccumulator.swift
[15:29:24]: ‚ñ∏ Compiling GraphQLResultNormalizer.swift
[15:29:24]: ‚ñ∏ Compiling GraphQLSelectionSetMapper.swift
[15:29:24]: ‚ñ∏ Compiling AutomaticPersistedQueryInterceptor.swift
[15:29:24]: ‚ñ∏ Compiling Bundle+Helpers.swift
[15:29:24]: ‚ñ∏ Compiling CacheReadInterceptor.swift
[15:29:24]: ‚ñ∏ Compiling CacheWriteInterceptor.swift
[15:29:24]: ‚ñ∏ Compiling Cancellable.swift
[15:29:24]: ‚ñ∏ Compiling Collection+Helpers.swift
[15:29:24]: ‚ñ∏ Compiling ResponseCodeInterceptor.swift
[15:29:24]: ‚ñ∏ Compiling ResponsePath.swift
[15:29:24]: ‚ñ∏ Compiling TaskData.swift
[15:29:24]: ‚ñ∏ Compiling URLSessionClient.swift
[15:29:24]: ‚ñ∏ Compiling UploadRequest.swift
[15:29:24]: ‚ñ∏ Compiling DataLoader.swift
[15:29:24]: ‚ñ∏ Compiling DefaultInterceptorProvider.swift
[15:29:24]: ‚ñ∏ Compiling Dictionary+Helpers.swift
[15:29:24]: ‚ñ∏ Compiling DispatchQueue+Optional.swift
[15:29:24]: ‚ñ∏ Compiling GraphQLDependencyTracker.swift
[15:29:24]: ‚ñ∏ Compiling GraphQLError.swift
[15:29:24]: ‚ñ∏ Compiling JSONRequest.swift
[15:29:24]: ‚ñ∏ Compiling JSONResponseParsingInterceptor.swift
[15:29:24]: ‚ñ∏ Compiling JSONSerialization+Sorting.swift
[15:29:24]: ‚ñ∏ Compiling JSONSerializationFormat.swift
[15:29:24]: ‚ñ∏ Compiling MaxRetryInterceptor.swift
[15:29:24]: ‚ñ∏ Compiling HTTPRequest.swift
[15:29:24]: ‚ñ∏ Compiling HTTPResponse.swift
[15:29:24]: ‚ñ∏ Compiling HTTPURLResponse+Helpers.swift
[15:29:24]: ‚ñ∏ Compiling InMemoryNormalizedCache.swift
[15:29:24]: ‚ñ∏ Compiling InputValue+Evaluation.swift
[15:29:24]: ‚ñ∏ Compiling InterceptorProvider.swift
[15:29:24]: ‚ñ∏ Compiling ApolloClient.swift
[15:29:24]: ‚ñ∏ Compiling ApolloClientProtocol.swift
[15:29:24]: ‚ñ∏ Compiling ApolloErrorInterceptor.swift
[15:29:24]: ‚ñ∏ Compiling ApolloInterceptor.swift
[15:29:24]: ‚ñ∏ Compiling ApolloStore.swift
[15:29:24]: ‚ñ∏ Compiling Atomic.swift
[15:29:24]: ‚ñ∏ Compiling MultipartFormData.swift
[15:29:24]: ‚ñ∏ Compiling NetworkFetchInterceptor.swift
[15:29:24]: ‚ñ∏ Compiling NetworkTransport.swift
[15:29:24]: ‚ñ∏ Compiling NormalizedCache.swift
[15:29:24]: ‚ñ∏ Compiling PossiblyDeferred.swift
[15:29:24]: ‚ñ∏ Compiling GraphQLExecutor.swift
[15:29:24]: ‚ñ∏ Compiling GraphQLFile.swift
[15:29:24]: ‚ñ∏ Compiling GraphQLGETTransformer.swift
[15:29:24]: ‚ñ∏ Compiling GraphQLHTTPMethod.swift
[15:29:24]: ‚ñ∏ Compiling GraphQLHTTPRequestError.swift
[15:29:24]: ‚ñ∏ Compiling GraphQLQueryWatcher.swift
[15:29:24]: Running Tests: ‚ñ∏ Touching ApolloAPI.framework (in target 'ApolloAPI' from project 'AnimalYears')
[15:29:24]: ‚ñ∏ Processing Apollo_Info.plist
[15:29:24]: ‚ñ∏ Linking Apollo
[15:29:25]: Running Tests: ‚ñ∏ Touching Apollo.framework (in target 'Apollo' from project 'AnimalYears')
[15:29:25]: ‚ñ∏ Processing AnimalYears_Info.plist
[15:29:25]: ‚ñ∏ Linking AnimalYears
[15:29:25]: ‚ñ∏ Build Succeeded
[15:29:25]: ‚ñ∏ Linking AnimalYearsTests
[15:29:25]: ‚ñ∏ Processing AnimalYearsTests_Info.plist
[15:30:07]: ‚ñ∏ All tests
[15:30:07]: ‚ñ∏ Test Suite AnimalYearsTests.xctest started
[15:30:07]: ‚ñ∏ AnimalYearsTests
[15:30:07]: ‚ñ∏     ‚úì testCalculateDogYearstohumanyears (0.002 seconds)
[15:30:07]: ‚ñ∏     ‚úì testCalculateDogYearstohumanyearsfor1and78lbs (0.001 seconds)
[15:30:07]: ‚ñ∏     ‚úì testCaluclateCatYears (0.001 seconds)
[15:30:07]: ‚ñ∏ 	 Executed 3 tests, with 0 failures (0 unexpected) in 0.003 (0.004) seconds
[15:30:07]: ‚ñ∏
[15:30:07]: ‚ñ∏ 2022-10-16 15:30:07.809 xcodebuild[85053:3665062] [MT] IDETestOperationsObserverDebug: 42.348 elapsed -- Testing started completed.
[15:30:07]: ‚ñ∏ 2022-10-16 15:30:07.809 xcodebuild[85053:3665062] [MT] IDETestOperationsObserverDebug: 0.000 sec, +0.000 sec -- start
[15:30:07]: ‚ñ∏ 2022-10-16 15:30:07.809 xcodebuild[85053:3665062] [MT] IDETestOperationsObserverDebug: 42.348 sec, +42.348 sec -- end
[15:30:07]: ‚ñ∏ Test Succeeded
+--------------------+---+
|      Test Results      |
+--------------------+---+
| Number of tests    | 3 |
| Number of failures | 0 |
+--------------------+---+

[15:30:11]: ------------------------------------------
[15:30:11]: --- Step: rm -rf AnimalYears.xcodeproj ---
[15:30:11]: ------------------------------------------
[15:30:11]: $ rm -rf AnimalYears.xcodeproj

+------+------------------------------+-------------+
|                 fastlane summary                  |
+------+------------------------------+-------------+
| Step | Action                       | Time (in s) |
+------+------------------------------+-------------+
| 1    | default_platform             | 0           |
| 2    | spm                          | 1           |
| 3    | run_tests                    | 50          |
| 4    | rm -rf AnimalYears.xcodeproj | 0           |
+------+------------------------------+-------------+

[15:30:11]: fastlane.tools finished successfully üéâ
Fastlane will also generate three report files under the following paths:
/fastlane/report.xml
/fastlane/test_output/report.html
/fastlane/test_output/report.junit
Conclusion
I am not sure how I managed to build mobile apps for the last couple of years without using Fastlane. Fastlane incorporates many essential tools for building, testing and deploying your applications. It can also be extended to write your own plugins.
Fastlane is build on top of Ruby, so it helps to have some experience with Ruby when working with Fastlane, but it is not necessary. If you want to write Fastlane plugins, it might come in handy to know a little Ruby.Tags: iOS,   Swift Packages,   Fastlane,   CI/CD   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJuly 27th, 2022When running JavaScript applications outside of browser, there used to be essentially one choice, Node.js. Now we have a few different options. Deno was introduced a couple of years ago from Ryan Dahl, the creator of Node.js. Both JavaScript engines are based on V8, the same JavaScript engine that is used by Chrome.
Now we have a new contender, Bun! But Bun does a few more things than just execute JavaScript, it is also a bundler and transpiler.
JavaScript Engine
Bun uses JavaScriptCore for it's engine. JavaScriptCore is part of the WebKit Safari source code. JavaScriptCore is also used with React Native, but is being phased out for a new engine called Hermes.
JavaScriptCore is also extremely fast, one of the reasons that it is used in Bun.
Transpiler
Transpilers are usually added on with modules in Node.js, but both Bun and Deno can transpile or run TypeScript automatically. Running TypeScript in Node usually requires using tools like WebPack, but these features are built into Bun natively.Tags: Node.js,   JavaScript,   JavaScriptCore   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJuly 24th, 2022


I am in the process of trying to learn more about machine learning. AI and machine learning on the surface can appear to be daunting when you hear terms like multi-layered neural networks and linear regression. But for simple tasks you can leverage machine learning fairly easily using either your browser or Node.js
I currently receive hundreds of emails a day. A lot of those emails are either newsletters or technology publications that send out hyperlinks to stories I find interesting. The headlines I am most interested in are programming related. I have been looking for ways to streamline going through these emails to find just the headlines I want to read. So I decided to use Node.js to parse through my email using machine learning.
Is Node.js the best language for doing Machine Learning
The short answer is no. That being said it is the language I chose because it is one that I am already familiar with for writing my own home automation. If you are serious about learning AI and ML, Python is a better language to start with because there are a ton of resources and frameworks for doing this type of computing.
Some of the tools that are popular for doing ML are Keras, TensorFlow, NLTK, PyTorch, Scikit, Pandas, Numpy and MXNet. There are a lot more that I did even mention.
With Node.js, there are a couple of different modules I looked at using including TensorFlow.js, Brain.js, Natural and ML-classify-text. I wound up going with Natural because what I wanted to do was to classify a headline as a specific subject I might be interested in reading.
ML Workflows
Machine learning workflows can be broken down into a couple of steps. The first step is finding the best algorithm for building your model. For text classification I was looking for something that was pretty simple. Natural has a couple of different classifiers, I chose the BayesClassifier.
The next step is finding or defining data you can use to train your model. For my project I used previous headlines that I had already selected for subject areas that I found interesting. This step is probably the most important. The more data you have, and the more accurate your data is, the better your model will perform at selecting the right classification.
After training your model, he next step is to test how accurate your model is against actual data.
The last step is deploying your model into an application. Some ML frameworks allow for models to be updated after they have been created. This is nice because you can continue to iterate on your model to make it more accurate over time.
Natural example
The following example is from the Natural source code example, but it gives an idea of how easy it is to design, train and use a model.
import natural from 'natural';

const { BayesClassifier } = natural;
const classifier = new BayesClassifier();

classifier.addDocument('my unit-tests failed.', 'software');
classifier.addDocument('tried the program, but it was buggy.', 'software');
classifier.addDocument('the drive has a 2TB capacity.', 'hardware');
classifier.addDocument('i need a new power supply.', 'hardware');

classifier.train();

console.log(classifier.classify('did the tests pass?')); // software
console.log(classifier.classify('did you buy a new drive?')); // hardware

Once you have trained your model and tested it for it's validity, you will need to save it so you can reuse it in your application. Here is an example of how you can save your model using Natural.
classifier.save('classifier.json', function (err, classifier) {
  if (err) {
    console.log(err)
  }
  // the classifier is saved to the classifier.json file!
});
Once you have your model saved, you can reload it using the following function.
natural.BayesClassifier.load(filepath, null, (err, classifier) => {
    if (err) console.log(err);
    //  use your classifier
});
The saving and loading functions are both asynchronous tasks. If you want to load your model up in a more synchronous way, you can always use async/await in modern JavaScript.
import natural from 'natural';

function loadClassifier(filepath) { 
    return new Promise((resolve, reject) => {
        natural.BayesClassifier.load(filepath, null, (err, classifier) => {
            if (err) reject(err);
            resolve(classifier);
        });
    });
}

const classifier = await loadClassifier('classifier.json');
Hardware requirements
The NLP or natural language processing we have used in this post do not require a lot of computational power, but if you want to get into deep learning and image recognition you will want to investigate GPUs and other specialized processors. Many of the frameworks have hardware acceleration that takes advantage of these types of processors.
Nvidia has a library called CUDA that lets developers take advantage of their hardware for doing the kind of linear algebra required for accelerated machine learning.
Google also has a processor they call a TPU, or Tensor Processing Unit. This is a processor specifically designed for processing Tensors using application specific integrated circuits or ASICs.
Apple also has part of their M1 processor that is dedicated to ML tasks called a Neural Core. One caveat to using the M1 with existing ML frameworks is that many of the existing projects have a reliance on Python 2.7. Python 2.7 will have to run under Rosetta 2 on M1 Macs. There are some frameworks that are taking advantage of the neural core in the M1s, but you will have to research if this will work for your needs.
Conclusion
It is fairly easy to add ML to your Node.js projects. It is worth taking some time to understand some of the other ML frameworks that are available such as Brain.js and TensorFlow.js. These frameworks can do some advanced things like build neural networks and do image classification. Think Hotdog/Not Hotdog.Tags: Node.js,   JavaScript,   Machine Learning   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJune 26th, 2022
I have been starting to use React Native in an existing iOS and Android app that I am maintaining. One of the problems I am finding in the React Native docs is the guides they give for adding to an existing iOS application are out of date.
How to add React Native as of 2022
For this post, I will assume that you already have Xcode installed. You will also need to configure your environment for the React Native CLI Quickstart in the environment setup guide. The setup will make sure that you have a current version of Homebrew, Node.js installed. I have another post I created recently on how to get React Native setup and running on a M1 based Mac.
Set up directory structure
Create a new folder for your project. This is where we will keep the React Native code. After creating this folder, copy your existing iOS project to a folder underneath your project folder called android.
Install Node dependencies
In the root of your project folder, create a package.json file with the following contents:
{
  "name": "YourReactNativeApp",
  "version": "1.0.0",
  "private": true,
  "scripts": {
    "start": "yarn react-native start"
  }
}
Make sure you have the yarn package manager installed. If you do not have this installed, you can install it by using the following command:
> npm install yarn -g
To install your Node dependencies, you can use the following command:
> yarn add react-native
When you run this command, it will display a message in your terminal that should look like the following:
|  > react-native@0.68.1" has unmet peer dependency "react@17.0.2".
If your unmet dependency is a specific version of react, you will need to add React for the specific version specified in the message:
yarn add react@17.0.2
Adding the React View to your Android App
Now that we have added the React Native dependencies to your iOS app, we have the dependencies we need to in order to run the React Native content in your app. Lets' go ahead and modify a ViewController to display our React Native app:
// MainActivity.java

Now lets' modify the index.js file so it looks like the following:
import React from 'react';
import {
    AppRegistry,
    Text,
    View
  } from 'react-native';

const YourApp = () => {
  return (
    <View style={{ flex: 1, justifyContent: "center", alignItems: "center" }}>
      <Text>
        Hello World! üéâ
      </Text>
    </View>
  );
}

AppRegistry.registerComponent('YourApp', () => YourApp);
To test and make sure that this is set up correctly, we to start Metro first by running the following command at the root of our project:
> yarn start
Once we have started Metro, we can run our iOS app again and navigate to the ViewController that contains our RCTRootView view. This should create a screen that looks like the following:

Conclusion
I hope this explains how you can add React Native to an existing Android application. React Native is one of many tools that are available to Android developers to build native applications. One of the nice things about React Native is that it is cross platform. This makes it easy to share code between both iOS and Android applications.Tags: Node.js,   JavaScript,   React-Native   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeMay 17th, 2022I spent last Saturday going to the 2022 SQL Saturday event here in Jacksonville, FL. You can think of this event as a conference in a day, where system admins, developers and Devops workers get together to learn more about Microsoft SQL Server.
Microsoft SQL Server was the first enterprise relational database I worked with as a programmer. Sql Server like many other relational database systems share something in common, and that is the Structured Query Language.
Back in 2003 I went to a big box store to buy a laptop that was powerful enough to run SQL Server. This was long before Docker. The salesman at the store asked me what I was planning on using the laptop for, and I told him I was planning on using it to run SQL Server. He told me that he had recently graduated from a college with a degree in computer science, and now he wanted to learn SQL. I was shocked that they did not teach any SQL databases in his course work, but I have heard this from other computer science students since.
No matter what type of development you wind up doing, their is a good chance that you will have to work with some type of database. Data does not have much value if it can not be persisted. The statistic I heard at the time was that over 50% of development jobs required the use of some sort of database.
Relational Database Drawbacks
As great as relational databases are, they do have some drawbacks. One of the drawbacks is that they can be difficult to scale. Scaling most relational databases used to mean scaling vertically, meaning that because of having data consistency, all data had to be persisted on some sort of disk or volume. There are tricks that some vendors and projects have used to make these databases scale.
One of the methods is to use database mirroring or clustering, where data can be copied from disk to another for the same database. While this method offers failover reliability it still means using a server or service that can be a single point of failure.
Another method that can be used is database sharding. Sharding a database can be as simple as breaking a database over several servers. So for example if you had a database of users, you could break the users up over several database servers where users that had a name that started with the letters A-H where on one server, and users whose name started with letters I-Z where on another server.
NoSQL Databases
There are a number of non-relational databases that are offered as a service or as a standalone service. They usually belong to one of the following three categories, Big table, Graph and Document databases. These databases tend to be performant, but may not offer ACID compliance that relational databases tend to offer.
ACID compliance usually means that your database server offers the following features - atomicity, consistency, isolation and durability. In a nutshell this means that you data can be relied upon to be consistent even though multiple processed may all be trying to write to the same data at the same time. Having this kind of reliability also makes it hard to scale.
Most NoSQL database servers do not offer all, but may offer a lot of the features available in ACID compliant database servers.
Document databases

      
    
  
  
    
There are a number of different document databases that are available. On of the most popular is one called MongoDB. Mongo databases store their data as documents in a JSON format. Unlike relational databases where you would store orders and line items in a separate tables, you can store on order in a single document. This allows data to maintain it's original structure without having to break it up into smaller pieces.
Graph databases
Graph databases like Neo4J allow object relationships to be stored. If you think of a website like Facebook or Linkedin as an example, users have to maintain a relationship with other users, and possibly to users that are connected to those users.
Big table
Big table databases like Cassandra DB can store large amounts of data and are highly scalable. Many cloud services like AWS and Azure offer some type of database service that is based on this type of database. AWS's DyanamoDB is a key value store like Cassandra that can store lots of data, and is highly scalable.
These databases while be fast and large have the drawback of not being relational. This means if you want to relate data from two different stores, this can be a slow an expensive operation.
Modern Database servers
While NoSQL databases have attractive features, if you look at most modern SQL database platforms you will find that they offer similar features and capabilities to the NoSQL alternatives. Database servers like Microsoft SQL Server and Postgres offer developers features for storing documents similar to Mongo and graph data like Neo4J.
They also allow developers to index this type of data for fast querying. There are even forks like TimeScaleDB that allow for the creation of large datasets based on time series data.
Another nice feature of SQL database servers is that they share a common language, SQL. Pronounced Sequel, SQL stands for the structured query language, and is based on a standard that vendors adopt when creating their servers. ANSI standard SQL statements can be used that are vendor agnostics, meaning that you can possible reuse the same query on database software from different vendors. While this may be difficult to achieve in practice, if you learn SQL for one vendor, it is pretty easy to write SQL for another vendor.
SELECT *
FROM users
WHERE clue > 0
The following SQL statement would return all columns from a table called users where the value in the column clue was greater than zero for that row in the table. This query could in theory be run against any database server that can execute ANSI SQL.
Data persistence in Modern Application Design
In modern scalable applications, it is becoming increasingly unlikely to use one type of database or data persistence. A modern server application may be use a front side key value store like Redis, an event processing store like Kafka, a search server like Elasticsearch and any number of NoSQL databases in addition to a relational database.
Patterns like CQRS (Command Query Responsibility Separation) also make it easier to scale applications. By separating events into commands (write operations) and queries (query or read operations). Using this pattern we can break an application up into commands which change the state of our data and queries that simply read data. This pattern lends towards event sourcing, where changes to the state of our data can eventually make it into a relational database system.
This is really not that different from how a lot of organizations used to create different databases for transaction systems and reporting systems. A lot of the production databases I used to use would only have three to six months worth of transactional data. We would use ETL (Extract Transform and Load) procedures to create a separate reporting database.
Conclusion
I used to think that relational databases would be phased out by newer NoSQL databases. It has become clear to me now that a lot of the features that are in NoSQL databases have made their way into relational database systems. It is now possible to have the best of both worlds by using modern relation database servers with the newer NoSQL features like document storage and graph modeling.
It is worth taking the time to learn the structured query language. Once you have learned SQL, this knowledge can be applied to a lot of different software that use some form of SQL.Tags: SQL,   Development   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeMay 11th, 2022


I have been using Next.js for a new project I am currently working. Most of my Node.js experience working with web apps has been using the Express.js framework. One of the tools I like using for my testing is Jest.
If you have not had a chance to use Jest, it is definitely worth checking out. It is very popular with the React community and it has test coverage built into the framework.
The easy way to add Jest to Next.js
The easiest way to add Jest to Next.js is to do so when scaffolding out a new app using the create-next-app command line tool. Here is an example of how you can create a Next app using that tool:
npx create-next-app --example with-jest with-jest-app
# or
yarn create next-app --example with-jest with-jest-app
# or
pnpm create next-app -- --example with-jest with-jest-app
This will create an example Next.js app with Jest already configured and ready to go.
The not so hard way to add Jest to Next.js
If you have a pre-existing Next.js app, jest can be added fairly easily. We are going to add Jest to a Next.js 12 app by using the following steps;
Add Testing Modules
Add the @testing-library/react, @testing-library/jest-dom, jest-environment-jsdom modules using your package manger of choice. I am going to use yarn for my examples:
yarn add jest @testing-library/react @testing-library/jest-dom jest-environment-jsdom --dev
Add Jest Config
The next thing we need to do is add a jest.config.js file to the root directory of our project, and code the following configuration:
const nextJest = require('next/jest');

const createJestConfig = nextJest({
  // Provide the path to your Next.js app to load next.config.js and .env files in your test environment
  dir: './',
});

// Add any custom config to be passed to Jest
const customJestConfig = {
  // Add more setup options before each test is run
  // setupFilesAfterEnv: ['<rootDir>/jest.setup.js'],
  // if using TypeScript with a baseUrl set to the root directory then you need the below for alias' to work
  moduleDirectories: ['node_modules', '<rootDir>/'],
  testEnvironment: 'jest-environment-jsdom',
};

// createJestConfig is exported this way to ensure that next/jest can load the Next.js config which is async
module.exports = createJestConfig(customJestConfig);

Add Unit Test
Now we will add out first unit test for the landing page. We will create a folder in the root directory for all of our tests. Jest uses the following convention of a __tests__ directory for storing all of your Jest tests. We will create this directory and add a test file called index.test.js for our test. Add the following code to this file:
// __tests__/index.test.js

import { render, screen } from '@testing-library/react';
import Home from '../pages/index';
import '@testing-library/jest-dom';

describe('Home', () => {
  it('renders a heading', () => {
    render(<Home />)

    const heading = screen.getByRole('heading', {
      name: /welcome to next\.js!/i,
    })

    expect(heading).toBeInTheDocument()
  })
});
Add a Test Runner to package.json
Our last step will be to modify our package.json file to add a test runner script to the scripts section. My scripts section look like the following example:
...
  "scripts": {
    "dev": "next dev",
    "build": "next build",
    "start": "next start",
    "lint": "next lint",
    "test": "jest"
  },
...
Running our unit test
Now that we have made these four changes we can run our first test:
> yarn test
yarn run v1.22.18
$ jest
 PASS  __tests__/index.test.js
  Home
    ‚úì renders a heading (94 ms)

Test Suites: 1 passed, 1 total
Tests:       1 passed, 1 total
Snapshots:   0 total
Time:        1.419 s
Ran all test suites.
‚ú®  Done in 3.29s.
Now if we want to add a test coverage report, we can add the --coverage flag in the test command in the scripts section of our package.json file.
"test": "jest --coverage"
If you run the test runner again, your output should look like the following:
‚ùØ yarn test
yarn run v1.22.18
$ jest --coverage
 PASS  __tests__/index.test.js
  Home
    ‚úì renders a heading (90 ms)

----------|---------|----------|---------|---------|-------------------
File      | % Stmts | % Branch | % Funcs | % Lines | Uncovered Line #s
----------|---------|----------|---------|---------|-------------------
All files |     100 |      100 |     100 |     100 |
 index.js |     100 |      100 |     100 |     100 |
----------|---------|----------|---------|---------|-------------------
Test Suites: 1 passed, 1 total
Tests:       1 passed, 1 total
Snapshots:   0 total
Time:        1.382 s
Ran all test suites.
‚ú®  Done in 3.13s.
Conclusion
Next.js offers a lot of options when it comes to testing and mocking. Along with Jest, you can also test using Cypress, Playwright or Vitest.
The example of using Jest in this post is using the Rust compiler, but you can also set up Jest to run using Babel if you prefer. Have fun testing!Tags: Node.js,   JavaScript,   Jest,   React,   Unit testing   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeApril 23rd, 2022The Node.js foundation just released the first version of Node v18.0.0. The Node.js foundation maintains multiple versions, including the current release along with a long term support (LTS) release. The current v18 release will become the LTS release sometime in October 2022. This is the normal release schedule for Node.

      
  
    
Fetch
One of the new features getting a lot of attention is the new fetch API. Fetch has been around for awhile in the browser, and has been module you could add into your Node.js project by running npm install node-fetch. There have been complaints that the two are not completely interoperable.
fetch() has shipped in Node and now people are complaining that it does not work like node-fetch ü§¶‚Äç‚ôÇÔ∏è. However, EVERYBODY said they wanted more standard-compliant APIs from Node.js.‚Äî Matteo Collina (@matteocollina) April 22, 2022 
The Fetch API provides a simple promise based API for making client based HTTP requests. Previously you had to use the XMLHttpRequest API to make HTTP requests which required multiple lines of code to be written to make a request. Now with the Fetch API a HTTP request can be made as simply as the following example:
const response = await fetch('https://swapi.dev/api/people/1');
const data = await response.json();
console.log(data);
HTTP Timeouts
The http.server timeouts have changed in Node.js v18. The headersTimeout is set to 60000 milliseconds (60 seconds), and requestTimeout is set to 300000 milliseconds (5 minutes) by default. The headersTimeout is the time that is allowed for a http request header to be parsed. The requestTimeout is the timeout used for a http request.
Test Runner module
While there have been many popular options for unit testing your code in Node.js, Node has never had a built in test runner. Node v18 now includes a node:test module. The example below shows how to set up test and assertions.
import test from 'node:test';

test('Math tests', async (t) => {
  await t.test('test equality 1', (t) => {
    assert.strictEqual(1, 1);
  });

  await t.test('test equality 2', (t) => {
    assert.strictEqual(2, 2);
  });
});
You can read more about the new test running in the docs here https://nodejs.org/dist/latest-v18.x/docs/api/test.html.
Web Streams API
The new Web Streams API is now exposed globally in the global scope. While streams have been a part of the Node.js API from the very beginning, this API is shared between both the browser and Node.js, though this is considered an experimental feature in Node.
Web Streams support both ReadableStream and WriteableStream readers, writers and controllers. These can be used in combination with the new fetch API.
The following API objects are now globally available in Node v18:

ReadableStream
ReadableStreamDefaultReader
ReadableStreamBYOBReader
ReadableStreamBYOBRequest
ReadableByteStreamController
ReadableStreamDefaultController
TransformStream
TransformStreamDefaultController
WritableStream
WritableStreamDefaultWriter
WritableStreamDefaultController
ByteLengthQueuingStrategy
CountQueuingStrategy
TextEncoderStream
TextDecoderStream
CompressionStream
DecompressionStream

V8 10.1
There are three notable changes to V8 10.1. One of those additions are new array methods for finding the last element and index of an array:
// 
const arr = [{v:1}, {v:2}, {v:3}, {v:4}, {v:5}];
const lastElement = arr.findLast(l => l.v % 2 === 0);
// lastElement {v:4}
const lastIndex = arr.findLastIndex(l => l.v % 2 === 0);
// lastIndex 3
Another improvement in V8 has been internationalization support. With the addition of the Intl.Locale and the Intl.supportedValuesOf functions you can now retrieve calendar, currency, numbering as well as timeZone data about a location as seen in this example:
const arabicEgyptLocale = new Intl.Locale('ar-EG')
// ar-EG
arabicEgyptLocale.calendars
// ['gregory', 'coptic', 'islamic', 'islamic-civil', 'islamic-tbla']
arabicEgyptLocale.collations
// ['compat', 'emoji', 'eor']
arabicEgyptLocale.hourCycles
// ['h12']
arabicEgyptLocale.numberingSystems
// ['arab']
arabicEgyptLocale.timeZones
// ['Africa/Cairo']
The V8 engine has also made strides in improving the performance of class fields and private class methods.
The data format of the v8.serialize function has changed, and it will not be backwards compatible with earlier versions of Node.js.
Toolchain and Compiler
Linux versions of Node are now built on Red Hat Enterprise Linux and are compatible with glibc 2.28 or later. Prebuilt binaries for macOS will not require macOS 10.15 (Catalina) or later. The minimum supported architecture for AIX is now Power 8.
Prebuilt binaries for 32-bit Windows are not available at this time because of a V8 update, but may be restored if 32-bit support is added back to V8.
Conclusion
Version 18 of Node.js is packed with some neat features, and more should be coming prior to the LTS release. As the V8 runtime is upgraded with new features, Node gets these features with the new version of V8. I am looking forward to the LTS release in October as I am sure other Node developers will be.Tags: Node.js,   JavaScript   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeApril 16th, 2022


I have been starting to use React Native in an existing iOS and Android app that I am maintaining. One of the problems I am finding in the React Native docs is the guides they give for adding to an existing iOS application are out of date.
Cocoapods
React Native uses Cocoapods to add iOS dependencies when you add new modules to your application. Cocoapods is a dependency manager for the Apple development ecosystem. Since Cocoapods was introduced Apple has added their own called the Swift Package Manager, but React Native was created before this existed. Cocoapods is the only way to add React Native and its' native modules to iOS projects.
Cocoapods uses a configuration file called a Podfile to instruct the Cocoapods dependency manager which modules to add to your Xcode project. It does this by creating a workspace file, and then adding the project and any needed modules to the workspace.
The Podfile given in the guides for adding React Native to an existing iOS project will not work! I repeat that. Their Podfile will not work in an existing iOS project. They have example for both Objective-C and Swift, and neither is up to date with the current version of React Native.
How to add React Native as of 2022
For this post, I will assume that you already have Xcode installed. You will also need to configure your environment for the React Native CLI Quickstart in the environment setup guide. The setup will make sure that you have a current version of Homebrew, Node.js installed, along with watchman and Cocoapods. I have another post I created recently on how to get React Native setup and running on a M1 based Mac.
Set up directory structure
Create a new folder for your project. This is where we will keep the React Native code. After creating this folder, copy your existing iOS project to a folder underneath your project folder called ios.
Install Node dependencies
In the root of your project folder, create a package.json file with the following contents:
{
  "name": "YourReactNativeApp",
  "version": "1.0.0",
  "private": true,
  "scripts": {
    "start": "yarn react-native start"
  }
}
Make sure you have the yarn package manager installed. If you do not have this installed, you can install it by using the following command:
> npm install yarn -g
To install your Node dependencies, you can use the following command:
> yarn add react-native
When you run this command, it will display a message in your terminal that should look like the following:
|  > react-native@0.68.1" has unmet peer dependency "react@17.0.2".
If your unmet dependency is a specific version of react, you will need to add React for the specific version specified in the message:
yarn add react@17.0.2
Setting up Cocoapods for your iOS app
Now that you have React and React Native installed, cd into you ios subdirectory, and execute the following command:
> pod init
This command will create a Podfile, the configuration file that Cocoapods uses for adding dependencies to you iOS app. The Podfile should look something like this:
# Uncomment the next line to define a global platform for your project
# platform :ios, '9.0'

target 'yourreactnativeapp' do
  # Comment the next line if you don't want to use dynamic frameworks
  use_frameworks!

  # Pods for yourreactnativeapp

end
Every Xcode project should have a target. The target is the target for compilation. Usually if you have multiple platforms that you would support, i.e. MacOS, tvOS and iOS, you would have a target for each platform. For this example we will only modifiy the target for our iOS app. In the example above my iOS target is called yourreactnativeapp.
require_relative '../node_modules/react-native/scripts/react_native_pods'
require_relative '../node_modules/@react-native-community/cli-platform-ios/native_modules'

platform :ios, '13.0'

target 'yourreactnativeapp' do
  use_react_native!
end
Once you modified your Podfile to include the use_react_native! function for your target, you now run the following command to add your React Native dependencies:
pod install
After you have installed your dependencies using the pod install command, Cocoapods will have created a workspace (yourreactnativeapp.xcworkspace) for your project. It should have the same name as the project file. You will want to use the workspace file to open your project in Xcode from now on.
Your new workspace will have two projects in it, one with your iOS app, and one called Pods. The Pods project will contain all of the dependencies you will need to run React Native in your app.
Adding the React View to your iOS App
Now that we have added the React Native dependencies to your iOS app, we have the dependencies we need to in order to run the React Native content in your app. Lets' go ahead and modify a ViewController to display our React Native app:
// ViewController.swift

import UIKit
import React

class ViewController: UIViewController {

    override func viewDidLoad() {
        super.viewDidLoad()
    }

    override func loadView() {
        loadReactNativeView()
    }

    func loadReactNativeView() {
        let jsCodeLocation = URL(string: "http://localhost:8081/index.bundle?platform=ios")!
        
        let rootView = RCTRootView(
            bundleURL: jsCodeLocation,
            moduleName: "YourApp",
            initialProperties: nil,
            launchOptions: nil
        )
        self.view = rootView
    }
    
}
Now lets' modify the index.js file so it looks like the following:
import React from 'react';
import {
    AppRegistry,
    Text,
    View
  } from 'react-native';

const YourApp = () => {
  return (
    <View style={{ flex: 1, justifyContent: "center", alignItems: "center" }}>
      <Text>
        Hello World! üéâ
      </Text>
    </View>
  );
}

AppRegistry.registerComponent('YourApp', () => YourApp);
To test and make sure that this is set up correctly, we to start Metro first by running the following command at the root of our project:
> yarn start
Once we have started Metro, we can run our iOS app again and navigate to the ViewController that contains our RCTRootView view. This should create a screen that looks like the following:

      
    
  
  
    
Conclusion
I hope this explains how you can add React Native to an existing iOS application. React Native is one of many tools that are available to iOS developers to build native applications. One of the nice things about React Native is that it is cross platform. This makes it easy to share code between both iOS and Android applications.Tags: Node.js,   JavaScript,   React-Native   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeApril 13th, 2022


I recently purchased a M1 Mac for development. It is my first time using an M1 Mac, so I thought share my experiences.
Going through the React-Native documentation, I found a lot of it to be out of date. Here is what I had to do to get React-Native running on my new Mac.
Make sure you have Xcode installed
Make sure to install the latest version of Xcode onto your Mac. This can be installed by going to the App Store on your Mac, and searching for Xcode, then installing.
Make sure to install Xcode Command Line tools are installed
When you open Xcode, you should be prompted to install the Xcode command line tools. To verify that you have installed the tools, go to the preferences, choose locations, and make sure you have the current version of the tools installed. It should look something like the following;

      
    
  
  
    
Install homebrew
Homebrew is like apt-get if Apple had a package manager. You can install Homebrew by running the following command in your terminal;
> /bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"
This might take a little while to install, be patient.
Install the current LTS version of Node.js
Next you will want to install the LTS version of Node.js. I recommend using the installer from their website, but you can also install using Homebrew.
Install watchman
Use Homebrew to install watchman. Run the following command in your terminal to install watchman;
> brew install watchman
Install Cocoapods
Install Cocoapods using homebrew, do not use the Ruby gem command listed in the documentation. Cocoapods is like NPM for Node. It is used for installing dependencies for your project. You cannot use React Native on iOS with a working installing of Cocoapods.
> brew install cocoapods
Lets' create a new project to make sure your installation is working properly
Once you have all of the prerequisites installed, you can run the following example from their documentation
> npx react-native init AwesomeProject
After installing the example project, you can run it by using the following command;
> npx react-native run-ios
Conclusion
Not all of the kinks of developing on the Apple Silicon Macs have been worked out yet, but with just a few small changes you can get React-Native running on your M1 Mac.Tags: Node.js,   JavaScript,   React-Native,   M1   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeFebruary 11th, 2022I am in the process of trying to get caught up on a lot of the new CSS technologies. One of those technologies that has become increasingly popular over the last couple of years has been Tailwindcss.
If you are not familiar with Tailwindcss, it is a CSS framework that gives web developers a set of low level components to style web sites. Unlike frameworks like Bootstrap, instead of giving you a single class for a button, it allows you to use multiple classes to specifically style the element with specific classes. One way you might style a button using Tailwind would be like the following example;
<button class="bg-green-500 text-white px-4 py-2 mt-3 mb-4 rounded">Press Me</button>
The previous code will create a button that looks like the following;

      
    
  
  
    
I have also started using Next.js for building web applications. Next, developed by the Vercel hosting company, is a server side framework based on React. You can pre-load data for your React applications and build static content as well.
It is actually very easy to add Tailwindcss to your Next.js projects.
Lets' create a Next.js project using the following steps. First, make sure you have Node.js installed. Both Tailwindcss and Next.js both require Node. Then execute the following commands in your terminal to create a new Next.js project and go into the directory that was created for your project.
> npx create-next-app tailwind-next-project
> cd tailwind-next-project
Now that we have created our project, we can add the modules we need to use Tailwindcss;
> npm install -D tailwindcss postcss autoprefixer
> npx tailwindcss init -p
Those commands will add the tailwindcss, postcss and autoprefixer modules to our project, as well as add references to our package.json file. The tailwindcss init will create a config file in the root of our project called tailwind.config.js.
Now we need to modify our tailwind.config.js file so that it will scan our Next.js pages and components for Tailwind's utility classes. Modify the tailwind.config.js file so that it looks like the following;
module.exports = {
  content: [
    "./pages/**/*.{js,ts,jsx,tsx}",
    "./components/**/*.{js,ts,jsx,tsx}",
  ],
  theme: {
    extend: {},
  },
  plugins: [],
}
We just added search paths in the content for the pages and components in our config.
Now add the following @tailwind directives to your ./styles/globals.css file.
@tailwind base;
@tailwind components;
@tailwind utilities;
Start using Tailwindcss
Now we have everything we need to start using Tailwindcss in our project. We can test this by running the following command to start the Next.js development server;
> npm run dev
Conclusion
Both Tailwind and Next.js make it very easy to integrate into other frameworks. Another thing that is nice about Tailwind 3.0 and above is that it only adds the CSS you need for your site. Previous version of Tailwind included all of the CSS components, but the current version are very lightweight.
Install Tailwindcss with Ne.jsTags: Node.js,   JavaScript,   Next.js,   Tailwindcss   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 30th, 2022


I am in the process of trying to get caught up on all of the new CSS technologies. One of those technologies that has become increasingly popular over the last couple of years has been Tailwindcss.
If you are not familiar with Tailwindcss, it is a CSS framework that gives web developers a set of low level components to style web sites. Unlike frameworks like Bootstrap, instead of giving you a single class for a button, it allows you to use multiple classes to specifically style the element with specific classes. One way you might style a button using Tailwind would be like the following example;
<button class="bg-green-500 text-white px-4 py-2 mt-3 mb-4 rounded">Press Me</button>
The previous code will create a button that looks like the following;

      
    
  
  
    
While using all of these classes might seem verbose at first, it gives web developers very precise control of their layouts with having to write a lot of CSS.
Adding Tailwind to Gatsby
One of the other things that is nice about is they have very good documentation on all of their component classes as well as how to integrate Tailwind with other frameworks like Next.js, Vite and Gatsby. I wanted to use this post to show how easy it is to add Tailwind to an existing Gatsby site.
The first thing you will need to do is add the following modules to your Gatsby site;
> npm install -D tailwindcss postcss autoprefixer gatsby-plugin-postcss
This adds the Tailwind modules along with the gatsby plugin you will need to use Tailwind with Gatsby. After you have added these modules you will need to init Tailwind using the following command;
> npx tailwindcss init -p
This will create the tailwind.config.js file along with the postcss.config.js files.
Next we will need to enable PostCSS in our gatsby.config.js file. Add the following plugin to this config file.
module.exports = {
  plugins: [
    'gatsby-plugin-postcss',
  ],
}
Now that we have added the postcss plugin to Gatsby we can configure the tailwind.config.js file to scan our templates for any tailwind class usage. This can be done by adding our source path to the tailwind.config.js file.
module.exports = {
  content: [
    "./src/**/*.{js,jsx,ts,tsx}",
  ],
  theme: {
    extend: {},
  },
  plugins: [],
}
Now lets' add a styles folder underneath our src folder. In the styles folder we will create a file called global.css. Add the following @include lines to the `global.css file.
/* ./src/styles/global.css */
@tailwind base;
@tailwind components;
@tailwind utilities;
Now that we have added a global.css file, we can add it as an import into the gatsby-browser.js file. If you do not have a Gatsby-browser.js file, go ahead and create one and add the following line.
// gatsby-browser.js
import './src/styles/global.css'
Start using Tailwindcss
Now that we have Tailwind configured in our Gatsby site, we can now run either gatsby develop or gatsby build to start using Tailwindcss in our project.
Conclusion
Both Tailwind and Gatsby make it very easy to integrate into other frameworks. Another thing that is nice about Tailwind 3.0 and above is that it only adds the CSS you need for your site. Previous version of Tailwind included all of the CSS components, but the current version are very lightweight.
Tailwindcss Gatsby integration instructions
Gatsby Tailwindcss instructionsTags: Node.js,   JavaScript,   Gatsby,   Tailwindcss   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeDecember 27th, 2021


Every computer programmer/software engineer should learn a new programming language each year. In the book the Pragmatic Programmer, the book postulates that everyone should try to learn a new programming language each year. I decided to compile a list of languages that if you are not really familiar with, you might be interested in learning more about the language.
10: Shell Scripting
Whether you use bash, zsh or powershell, shell scripting is becoming more important with cloud based computing. Most cloud environments solely use command line based terminals. Continuous Integration and Continuous Deployment (CI/CD) are heavily dependant on shell scripting.
Shell scripts allow for easily repeatable steps to ensure that your environments are always configured the same way each time a deployment is performed.
9: Julia
Julia has been becoming more important over the last couple of years as it is being used for data science and other scientific based computing, but can also be used for writing micro-services. Julia is dynamically typed with the feel of a scripting language, but is compiled and extremely efficient.
# Taken from: https://rosettacode.org/wiki/Mandelbrot_set#Julia
function mandelbrot(a)
    z = 0
    for i=1:50
        z = z^2 + a
    end
    return z
end

for y=1.0:-0.05:-1.0
    for x=-2.0:0.0315:0.5
        abs(mandelbrot(complex(x, y))) < 2 ? print("*") : print(" ")
    end
    println()
end
Julia has features that make it easy to use object oriented and functional style programming. Julia is open source and has a package manager.
8: C++/C
The C programming language has been around since the 70s, but continues to be staple when it comes to doing lower level systems programming. C++ adds types and object oriented features on top of C. While C does not change or get new features frequently, C++ receives new features every couple of years.
C has been criticized for not being as safe as other languages, but there are tons of pre-existing applications and operating systems built on C. In fact, C was originally created to help create UNIX. C is also the primary language used in the Linux kernel.
Pointers and manual memory management are some of the programming concepts are some of the concepts you will have to master in order to write C, but C++ now has features like smart pointers that make this type of programming easier. These languages will be in high demand for some time.
7: C#
C#, also pronounced C-sharp, is the main language used for .NET development. While many associate C# and .NET as Microsoft technologies, they have been open sourced and multi-platform for years. You can run C# code on Windows, Linux and MacOS.
C# is a type based object oriented language like Java or C++, but has many functional features. C# is primarily used for writing web applications and services, but it can also be used for creating desktop applications or even IoT applications.
.NET is still heavily used in the enterprise with 20 years of legacy code and projects, so there will be many opportunities with C# for the forseeable future.
6: Java
Java is a general purpose, type based object oriented language like C# and C++. This language is very mature and has been around for a quarter of a century. Java excels at network based computing such as web services and web applications. Java is also used for mobile applications on the Android operating system.
Unlike C and C++, Java uses a feature called garbage collection for memory management. The garbage collector is part of the Java virtual machine, and cycles through the memory of an application shedding stored values once they are no longer needed. This eliminates most of the memory management from the programmer.
public class HelloWorldApp {
    public static void main(String[] args) {
        System.out.println("Hello World!"); // Prints the string to the console.
    }
}
5: Python
Python was originally developed as a scripting language, but has become popular with data scientists and machine learning engineers. Python is an interpreted general purpose language with dynamic typing.
Python has become even more popular in recent years because of machine learning/AI libraries like Tensorflow.
Python is also popular as a learning language, but can be used to write web applications and services.
Python is unique in that blocks are defined with indentation. If you do not format your code correctly, it will not run correctly as you can see from the example below.
n = int(input('Type a number, and its factorial will be printed: '))

if n < 0:
    raise ValueError('You must enter a non-negative integer')

factorial = 1
for i in range(2, n + 1):
    factorial *= i

print(factorial)
4: Go Lang
Golang or Go is a newer language developed by Google as a possible replacement for C. Go is a strongly typed general purpose language, but unlike Java or C++ is not object oriented.
All Go code has to be compiled from source, which means you can not include in pre-compiled libraries. Go can be compiled to run on many different operating systems and processor architectures.
Go simplifies asynchronous programming with a feature called Go routines. These routines are designed to take advantage of modern processors that have multiple cores. This makes it easier for the programmer to write code without having to do manual thread management.
3: JavaScript
JavaScript, also known as EcmaScript, is the primary language used in all web browsers. JavaScript has become even more popular since Node.js was introduced in 2009. With Node, JavaScript programmers can write code for both client side and server side applications, or the full stack.
JavaScript may look similar to Java or C, but more closely models functional languages like Scheme or Clojure. JavaScript is also dynamically typed like Python.
2: Swift
Swift was originally introduced by Apple in 2014 has since become open sourced and can be used for writing mobile and desktop applications as well as server applications running on Linux or Windows.
Swift has modern features like type inference and optional syntax, but also recently received a major update with support for asynchronous programming with async/await syntax and actors. These features make it easier for programmers to take advantage of multiple core processor architectures.
Swift is unique in that it can be used as a teaching language as well one for writing operating systems.
1: Rust
Rust was originally introduced by the Mozilla organization. It is type base general purpose programming language like Go, but has safety built into the language be default.
One of the key features of Rust is the concept of memory safety and ownership. Rust does not allow for dangling pointers or null pointers. All inputs must be initialized. All values must have a unique owner.
Conclusion
These languages just scratch the surface of some of the popular languages that are out there to learn. I sure that there are some I have not mentioned in this post that deserved to be mentioned.
If you are looking for a scripting language, consider learning Python or JavaScript. If you are looking at enterprise development, you might want to take a look at C# or Java. If you are interested in writing lower level applications, C/C++ or Rust might fill that need.
If you are looking at doing high performance cloud based applications, you can take a look at Go lang or Rust.
Update
I received a note from Toptal about an article they have comparing C# to C++. It covers the full history and differences between the languages. Please check it out if you like this post.Tags: Node.js,   JavaScript,   C,   C++,   C#,   .NET,   Python,   Shell,   Julia,   Java,   Swift,   Rust   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeDecember 18th, 2021


Or how to over engineer your Christmas Lights.
I have wanted to get light bulbs that you could control over a network or smart phone for years. I finally splurged and got the Philips Hue bridge and bulb. You can find these at most hardware stores now. The bridge ran me about $59 US. You can also purchase starter kits with some bulbs for about $69.
There are number of smart bulbs that you can purchase that connect directly to the Internet using your WiFi connections, but not all of them have the same IoT like capabilities. The Hue bridge can be controlled over a smart phone app, Amazon Dots, Google Home and also with a number of open source APIs.
I have a color bulb, and I wanted to make a light that cycled between green and red for the Christmas Holidays. In order to write an application that can communicate with the Hue bridge, you will need two pieces of information, the IP address of the bridge on your network, and user id.
You can find the IP address of your Hue bridge by using the smart phone app you used to configure and setup the bridge. In the app you can select the settings tab, then select Bridges > and then the bridge you setup. It will have the IP address listed in the info for the bridge.
The next step for getting a whitelisted user you can use for the bridge is to make a HTTP post to the Hue bridge. View the instructions down below;
https://developers.meethue.com/develop/get-started-2/
Once you have the IP address and user token, you have all of the information you need to control the bulbs on your bridge.
Getting a list of bulbs on your Bridge
Before we can send commands to a bulb, we will need to find the bulbs and their Ids so we can make calls using the Hue REST API. Here is a script for returning a list of all devices on your bridge;
import axios from 'axios';
import dotenv from 'dotenv';

dotenv.config();

const ip_address = process.env.IP_ADDRESS;
const user = process.env.USERTOKEN;

const endpoint = `http://${ip_address}/api/${user}/lights/1`;

async function listAllBulbs() {
    const result = await axios.get(endpoint);
    console.log(result.data);
}

listAllBulbs();

Right now I only have one bulb on, so I will only get the result for the one bulb;
{
  '1': {
    state: {
      on: true,
      bri: 254,
      hue: 41371,
      sat: 82,
      effect: 'none',
      xy: [Array],
      ct: 153,
      alert: 'select',
      colormode: 'xy',
      mode: 'homeautomation',
      reachable: true
    },
    ...
  }
}
If I want to get the bulb state for a specific bulb, I can add the number of the bulb to the end point. We can rewrite that script to return just the first bulb;
...

const endpoint = `http://${ip_address}/api/${user}/lights/1`;

async function listAllBulbs() {
    const result = await axios.get(endpoint);
    console.log(result.data);
}

listAllBulbs();

{
  state: {
    on: true,
    bri: 254,
    hue: 41371,
    sat: 82,
    effect: 'none',
    xy: [ 0.3085, 0.3266 ],
    ct: 153,
    alert: 'select',
    colormode: 'xy',
    mode: 'homeautomation',
    reachable: true
  },
  ...
}
If I want to change the color of the bulb to green, I can pass a new state to the bulb using the PUT verb and adding state to the end of the URL endpoint. Here is an example of setting the bulb to green;
const endpoint = `http://${ip_address}/api/${user}/lights/1/state`;

const state = {
    "on": true,
    "bri": 254,
    "hue": 25600,
    "sat": 254
};

async function setBulbState(state) {
    const result = await axios.put(endpoint, state);
    console.log(result.data);
}

setBulbState(state);

Cycling the bulb between green and red
To give the bulb a Christmas feel, I am going to cycle the bulb between green and red every two seconds. For the main script I will use a setInterval function, and set it run every 2000 milliseconds.
let toggle = true;

async function cycleXMASLights() {
    await axios.put(endpoint, {
        "on":true,
        "sat":254,
        "bri":254,
        "hue": toggle ? 25600 : 0
    });
    toggle = !toggle;
}

let timer = setInterval(await cycleXMASLights, 2000);

Are full script should look like the following;
// cyclexmaslights.js
import axios from 'axios';
import dotenv from 'dotenv';

dotenv.config();

const ip_address = process.env.IP_ADDRESS;
const user = process.env.USERTOKEN;

const endpoint = `http://${ip_address}/api/${user}/lights/1/state`;

let toggle = true;

async function cycleXMASLights() {
    await axios.put(endpoint, {
        "on":true,
        "sat":254,
        "bri":254,
        "hue": toggle ? 25600 : 0
    });
    toggle = !toggle;
}

let timer = setInterval(await cycleXMASLights, 2000);

Run as a service
If we want to run our script as a service, we can do this my using pm2. PM2 to is a process manager written in node that can run on just about any operating system. Use the following command to install pm2 on our computer.
> npm i pm2 -g
This will install pm2 globally on our system. Now we can take our main script and install it as a service on our computer.
> pm2 install cyclexmaslights.js --name xmaslights
Now if we want to save this configuration so that our computer will remember this service, we can use the following command.
> pm2 save
If we want to continue to use our pm2 configuration after restart, we can use the following command to generate the command we will need to use to make pm2 a system service.
> pm2 startup

To setup the Startup Script, copy/paste the following command:
sudo env PATH=$PATH:/usr/bin /usr/lib/node_modules/pm2/bin/pm2 startup systemd -u pi --hp /home/user
On Linux it will probably use systemd. On the Mac it will probably use launchd.
What if my computer goes to sleep or I turn it off?
If you are like me, and you want your lights to run all night long, using a computer that goes to sleep or that you turn off will kill the script. A good option here is to use a computer like the Raspberry Pi. They do not use a lot of power, and you can leave them just about anywhere in your home.
Conclusion
IoT projects like this can be fun projects to do with your family at home. It is also fun learning more about hardware and embedded systems. Projects like this also help us learn more about APIs and Rest.
Hue also has a remote API that can be used over the internet to control a Hue bridge. There are a number of open source frameworks in many different languages that can be used for controlling lighting.Tags: Node.js,   Hue Lights,   IoT,   Raspberry Pi,   Github Actions   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeNovember 28th, 2021


I have made a number of videos on what kinds of development you can do on M1 Macs. Lately I have received a number of posts about specific cases where the M1 based Macs are not the best fit for certain types of software engineering.
Before we can discuss which type of development we can't do on these new M1 processors, we will need to look at what architecture the M1 is based on, and what has changed.
When I first started using Macs, they were based on a processor called Motorola 68000. In the mid-nineties Apple moved to another processor called the PowerPC. The PowerPC was based on a RISC processor, or reduced instruction set computing. At the same time PCs where using Intel based chips that were based on x86 architecture. The x86 chips are often referred to as CISC or complex instruction set computing.
Both chips were originally 32 bit processors, but both eventually made the transition to 64 bits. In the mid 00s the Intel chips started to outpace the performance of the PowerPC chips. Not only were the Intel chips faster than the PowerPC chips, they were also more energy efficient.
Apple wisely at that time decided to transition away from the PowerPC to the Intel x86 architecture. When they made this change, I was extremely happy because I could now run x86 based software on my Mac. A number of companies also provided ways you could run Linux and Windows virtually on the Mac while using MacOS as the host operating system.
At the time I was doing .NET and SQL Server development. Now I could run both on the same laptop. This was a huge win for developers because we could run Microsoft software like Visual Studio, and still use the Unix style tools on the Mac.
A couple of years later Apple started secretly working on a new device that would be come known as the iPhone. Apple chose to use an ARM based processor for the first iPhone.
ARM processors are a licensed design, not an actual type of chip. Any company that has a chip fab can license the ARM design, and make their own chips. Apple started designing their own chips for the iPhone and iPad. It is from this design that the new M1 chips are based. This is why you can run software that was compiled for the iPhone on one of the new M1 based Macs.
The M1 based chips are more than just another ARM chip, they are specially designed by Apple to accelerate graphics processing along with machine learning. They are what is know as System on a Chip, or SOC.
The ARM architecture is actually a RISC based architecture. Microsoft has been making versions of Windows for years that will run on ARM based processors, but unlike Apple, you can still run x86 code on the M1s using Rosetta 2. Rosetta can emulate the instructions needed to run x86 code.
Rosetta 2
While Rosetta is fine for the average user, it is not ideal for software engineers. While a lot of the tooling seems to run fine under Rosetta, there are certain things that do not. It is always better to have software that was written specifically to run the architecture you are using.
Mobile development
When we are writing software, we generally target a specific platform I like to define these into four different groups; Mobile, Desktop, Cloud or server and embedded. Most mobile devices use ARM based processors. For mobile developers the M1 is a good choice because you are essentially developing on the same chip architecture that your software will running on eventually. The M1 is a good option specifically for iOS and iPadOS development. The newest version of Android Studio has also been upgraded to develop on the M1 Macs.
Desktop development
For years when writing software for desktop computers, Mac or PC, they both used x86 based processors. There are a number of static libraries that could be used in desktop applications. These libraries are typically written with compiled languages like C and C++. These libraries would need to be rewritten to run on M1 Macs, but a lot of these applications can still be run under Rosetta.
Server development
Most servers still run x86 based processors. There are some exceptions like AWS's graviton EC2 service. If you are writing software for cloud based infrastructure you most likely want to use the same type of processor architecture as the machine you are developing on.
Predicting the Future
Apple usually tries to stay out in front of the rest of the industry when comes to using certain technology as well as dropping technology. The real question now is when will the rest of industry follow what Apple has done with their hardware. Intel is trying to catch up with TSMC's 4 nanometer process, which I am sure they will at some point. The other advancement with the M1 processor is the system on the chip (SoC) architecture. I would not be surprised if Microsoft, Intel and AMD follow suit with similar designs.
Docker buildx
One solution that developers may be interested in using is Docker's new buildx feature.
$ docker buildx build --platform=value[,value]
With this build command you can target multiple platforms as in this example below;
$ docker buildx build --platform=linux/amd64,linux/arm64,linux/arm/v7 .
Now you can create a docker image that supports multiple processors.
Conclusion
At the end of the day you will probably want to develop on similar technology that you are planning on targeting. A lot of systems and languages are processor independent. Languages such as Java, JavaScript, .NET, Python, Ruby are either interpreted or run on a intermediate runtime can be written on just about any processor.
Compiled languages like Golang, Rust, C, C++, Objective-C and Swift are compiled for the processor. These compiled languages should probably be developed on a computer that uses a similar architecture.Tags: M1,   M1 Max,   M1 Pro,   Apple,   x86,   Intel   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeOctober 10th, 2021


For my day job I write software for iOS and iPad devices, but while I earn my living as a software engineer, I am also a FAA licensed Commercial Pilot.
While I do not fly for an airline, those pilots have a different certification called a ATP, or Airline Transport Pilot, I do fly general aviation aircraft.
Most general aviation aircraft are old, on average about 50 years old. The airplane I typically fly was manufactured by Cessna in the 1970s. As part of regular maintenance and also in some cases in the regulations, we do upgrade the avionics in these aircraft. Avionics are the electronic instruments and radios that we use to navigate and communicate with the aerospace system and air traffic control.
One of the quiet technological revolutions that has happened in aviation has been the use of iPads in the cockpit. For those who do not remember how it used to be when you were walking through the airport and saw a pilot, they would be carrying a large suitcase like briefcase or bag, usually strapped to an overnight piece of luggage. The reason why pilots lugged this giant case around with them was because it had all of the maps and charts, as well as books of approach plates and procedures they needed while navigating our friendly skies.

      
    
  
  
    
Companies like ForeFlight (now part of Boeing) and Garmin both make software that runs on iPads that contains all of the charts, approach and departure procedures that pilots used to lug around in that giant bag. The FAA refers to these type of devices and software as EFBs, or Electronic Flight Bags. One of the first things that pilots learn is the FAA has a three letter abbreviation for about everything.
With iPads being so common now in cockpits, I was often surprised how this community of iPad users has been ignored by Apple.
Introducing the new iPad Mini
Last month with Apple's new product announcements for the iPhone, they also introduced a new iPad mini. In their marketing, Apple now shows pilots using iPads and as in this image below an iPad actually running ForeFlight, one of the apps pilots use to help them navigate.

      
    
  
  
    
The iPad has become such an essential tool for pilots that many carry two in the cockpit with them, and some even have a mount in the instrument panel or yoke that can hold an iPad.

      
    
  
  
    
While I am happy that Apple has started recognizing pilots as an important user segment, I hope they realize that iPads should not be considered avionics. As a matter of fact, legally they are not.
Any equipment that pilots use that are a part of an aircraft, specifically instruments, avionics and radio equipment are strictly regulated by the FAA. Companies such as Garmin as well as being a consumer electronics company also makes electronics for naval and aviation markets. As a matter of fact Garmin got its start manufacturing GPS navigation receivers for aircraft. Any equipment we use that is part of an aircraft has to have extremely high tolerances. Aircraft have to be able to operate in very hot environments as well as very cold environments. Sometimes well below freezing. Check out the video below on FlightChops about some of the testing that Garmin does on their equipment.



Since most general aviation aircraft are old, a lot of them were built without air conditioners. As a matter of fact, a lot of general aviation aircraft are not made with air conditioners today. I am based in Florida, and it can get pretty hot here during the Summers, as well as the Spring and Fall. Something that commonly occurs to my iPad while I am flying is my iPad will overheat and shutdown while I am trying to use it in the cockpit. I have to be careful to not let it sit out on top of the instrument panel or sit in direct sunlight.

      
    
  
  
    
If Apple is going to market their equipment to pilots, they need to make they will operate reliably in the harsh environments that pilots operate in every day. I don't like the idea of inviting in new regulations, but maybe the FAA should look into Apple and their marketing.
Conclusion
I love the iPad and ForeFlight. I can't imagine flying without these tools. It has made flight planning and weather briefing much easier.
If Apple is going to market to Pilots, they need to do a better job at making sure that their devices will operate in the same environments that pilots operate in the cockpit every day.Tags: iPad Mini,   Apple,   EFBs,   FAA   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeSeptember 29th, 2021


One of the things I first came across when I started to work on legacy iOS applications was Method Swizzling. Swizzling lets' developers change the underlying implementation of a pre-existing method without having to change the original implementation. In affect you can swap one method with another method. JavaScript developers might be familiar with this concept if they have ever done monkey patching.
Most modern object-oriented and statically typed languages have a way of overriding existing methods if you are inheriting from  base class. This is sometimes referred to as polymorphism. But what if you want to change the original implementation with out changing the original underlying code in the base class?
You can do this in most of Apple's languages using method swizzling. You may asking yourself why do this if you have the original code of the method you need to change. The main reason is usually if you are using a library that you can not change or do not have permission to alter, you can at least change the behavior of a method using swizzling at runtime.
Objective-C Runtime
The runtime for Objective-C provides some nice utilities for executing operations at application runtime. You can use selectors to create references to method signatures in Objective-C, and then use those selectors to manipulate the runtime.
In the following example we have a class that has a method that we need to change. We will call the class TaxCalculator and our method that we want to swizzle whatAreMyTaxes.
// TaxCalculator.h
#import <Foundation/Foundation.h>

@interface TaxCalculator : NSObject

@property (nonatomic, retain) NSNumber *revenue;

-(NSNumber *)whatAreMyTaxes;

@end

// TaxCalculator.m
#import "TaxCalculator.h"

@implementation TaxCalculator

- (instancetype)init
{
    self = [super init];
    if (self) {
        _revenue = 0;
    }
    return self;
}

-(NSNumber *)whatAreMyTaxes {
    float rev = [self.revenue floatValue];
    float taxesDue = 0.39 * rev;
    NSNumber *nsTaxesDue = [NSNumber numberWithFloat:taxesDue];
    return nsTaxesDue;
}

@end
Now we are going to create a Objective-C category, which is like an extension in swift, to add a new method to our TaxCalculator class.
// TaxCalculator+rates2018.h
#import "TaxCalculator.h"

@interface TaxCalculator (rates2018)

-(NSNumber *)swizzle_whatAreMyTaxes;

@end

// TaxCalculator+rates2018.m
#import "TaxCalculator+rates2018.h"
#import "SimpleSwizzleHelper.h"

@implementation TaxCalculator (rates2018)

-(NSNumber *)swizzle_whatAreMyTaxes {
    float rev = [self.revenue floatValue];
    float taxesDue = 0.21 * rev;
    NSNumber *nsTaxesDue = [NSNumber numberWithFloat:taxesDue];
    return nsTaxesDue;
}

@end
This category adds a new method called swizzle_whatAreMyTaxes. This will be the method we use to swizzle the original method whatAreMyTaxes.
In order for our application to use the swizzled method, we will need to swap the methods when our application is first loaded. We will use Objective-C's load method to swap our methods. The load method on a class always executes when the application is initialized. We will also need to make sure that this is loaded only once. We will use grand central dispatch (GCD) to make sure that the method is only loaded once. The implementation will look like the following example;
+ (void) load {
    if (self == TaxCalculator.self) {
        static dispatch_once_t onceToken;
        dispatch_once(&onceToken, ^{
            Class class = [self class];
            
            SEL originalSelector = @selector(whatAreMyTaxes);
            SEL swizzledSelector = @selector(swizzle_whatAreMyTaxes);

            Method originalMethod = class_getInstanceMethod(class, originalSelector);
            Method swizzledMethod = class_getInstanceMethod(class, swizzledSelector);
            
            method_exchangeImplementations(originalMethod, swizzledMethod);
        });
    }
}

Looking at the method above, lets' break down what we are doing for each line. The first thing we do in the load method is check that self is an instance of the TaxCalculator class. Once we have verified we are loading the correct class at runtime, we create a dispatch_once_t token which we will use in the dispatch_once method. This method takes two parameters, the first being the address to the token, and the second being a closure or block.
In out dispatch_once closure we create a reference to the current class by using the Class type and calling [self class]. Then we can create two selectors for our original method and our swizzled method. In Objective-C we use @selector method to get the reference to our method signatures.
After defining our selectors, we will need to get the actual method reference. Here is where we start using the Objective-C runtime. We will create references for both methods using the class_getInstanceMethod method. If you are swizzling out class methods, there is a different runtime method you can use called class_getClassMethod. Both methods take the class reference and selector references as parameters.
Now that we have both method references, we swizzle them using the method_exchangeImplementations method. This method can also be used to swap them back.
Swizzle utility
I created a utility class that you can use to easily swap out either instance or class methods. Here is my SimpleSwizzleHelper class;
// SimpleSwizzleHelper.h header file

//
//  SimpleSwizzleHelper.h
//  SwizzleExample
//
//  Created by David Fekke on 9/29/21.
//

#import <Foundation/Foundation.h>

NS_ASSUME_NONNULL_BEGIN

@interface SimpleSwizzleHelper : NSObject

+ (void)swizzleMethod:(SEL)originalSelector with:(SEL)swizzledSelector forClass:(Class)clazz isInstanceMethod:(BOOL)isInstanceMethod;
+ (void)swizzleInstanceMethod:(SEL)originalSelector with:(SEL)swizzledSelector forClass:(Class)clazz;
+ (void)swizzleClassMethod:(SEL)originalSelector with:(SEL)swizzledSelector forClass:(Class)clazz;

@end

NS_ASSUME_NONNULL_END

// SimpleSwizzleHelper.m implementation file

//
//  SimpleSwizzleHelper.m
//  SwizzleExample
//
//  Created by David Fekke on 9/29/21.
//

#import "SimpleSwizzleHelper.h"
#import <objc/runtime.h>

@implementation SimpleSwizzleHelper


+ (void)swizzleMethod:(SEL)originalSelector with:(SEL)swizzledSelector forClass:(Class)clazz isInstanceMethod:(BOOL)isInstanceMethod {
    Method originalMethod;
    Method swizzledMethod;
    
    const char *className = [NSStringFromClass(clazz.self) UTF8String];
    Class myClazz = objc_getMetaClass(className);
    
    if (isInstanceMethod) {
        originalMethod = class_getInstanceMethod(clazz, originalSelector);
        swizzledMethod = class_getInstanceMethod(clazz, swizzledSelector);
        method_exchangeImplementations(originalMethod, swizzledMethod);
    } else {
        originalMethod = class_getClassMethod(myClazz, originalSelector);
        swizzledMethod = class_getClassMethod(myClazz, swizzledSelector);
        BOOL didAddMethod = class_addMethod(myClazz, originalSelector, method_getImplementation(swizzledMethod), method_getTypeEncoding(swizzledMethod));
        
        if (didAddMethod) {
            class_replaceMethod(myClazz, swizzledSelector, method_getImplementation(originalMethod), method_getTypeEncoding(originalMethod));
        } else {
            method_exchangeImplementations(originalMethod, swizzledMethod);
        }
    }
}

+ (void)swizzleInstanceMethod:(SEL)originalSelector with:(SEL)swizzledSelector forClass:(Class)clazz {
    
    Method originalMethod = class_getInstanceMethod(clazz, originalSelector);
    Method swizzledMethod = class_getInstanceMethod(clazz, swizzledSelector);
    method_exchangeImplementations(originalMethod, swizzledMethod);
}

+ (void)swizzleClassMethod:(SEL)originalSelector with:(SEL)swizzledSelector forClass:(Class)clazz {
    const char *className = [NSStringFromClass(clazz.self) UTF8String];
    Class myClazz = objc_getMetaClass(className);
    
    Method originalMethod = class_getClassMethod(myClazz, originalSelector);
    Method swizzledMethod = class_getClassMethod(myClazz, swizzledSelector);
    method_exchangeImplementations(originalMethod, swizzledMethod);
}

@end
Using this helper class, we can now refactor our load method to enable the swizzling. Note that SimpleSwizzleHelper can handle both instance and class methods.
+ (void) load {
    if (self == TaxCalculator.self) {
        [self enableSwizzledMethods];
    }
}

+ (void) enableSwizzledMethods {
    static dispatch_once_t onceToken;
    dispatch_once(&onceToken, ^{
        Class class = [self class];
        
        SEL originalSelector = @selector(whatAreMyTaxes);
        SEL swizzledSelector = @selector(swizzle_whatAreMyTaxes);
        [SimpleSwizzleHelper swizzleMethod:originalSelector with:swizzledSelector forClass:class isInstanceMethod:YES];
    });
}
Example Swizzling repo
Conclusion
Method swizzling is a very powerful feature that comes as part of the Objective-C runtime. Be wary of using this feature. This should only be used when you are not able to change the underlying implementation directly.
Any developer using this feature should also be careful about swizzling out methods where you do not know what the original implementation, i.e. you have the headers and a static library, but no access to the original code. I would also avoid swizzling out any system code from Apple's operating systems. This can cause harm if not used properly.
Now that you have read this post, have fun swizzling!Tags: objective-c,   method swizzling,   Apple,   iOS   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeSeptember 10th, 2021


With the release of Node.js 16.9.0 comes a new tool called Corepack. Corepack is described as a zero-runtime-dependency Node script that acts a bridge between Node projects and package managers like Yarn and Pnpm. Node.js comes with a package manager called NPM that gets installed with Node.js every time that Node.js is installed on a computer or server.
So essentially Corepack allows us to use third party package managers without having to install them globally on our development computers or our build servers.
While NPM is most likely the largest package managers, there are some considerations that many organizations have to make when choosing the package manager for their needs. Many organizations can not use NPM because when Node.js developers have dependencies for their application, they are copied into a subdirectory called node_modules. Most CI/CD servers and processes do not allow for a build server to access or pull down modules from outside their network. This was one of the reasons that Yarn was invented. Yarn and PNPM can both archive and cache modules on the developers computer as well as in packages that can be stored in the source of the application.
Introducing Corepack
Corepack is a script that is included with Node.js that can be accessed with the command line. It has commands the specifically for enabling, disabling, preparing and hydrating package managers. Since it is still considered an experimental feature, it comes disabled by default. To enable Corepack, just type the following command into your terminal;
> corepack enable
You can also enable a specific package manager shim by including it's name after the enable. In the following example we will enable just the shim for yarn.
> corepack enable yarn
If you want to disable corepack, you can turn it off by simple using the following command;
> corepack disable
Activating a package manager
In this example I am going to activate the yarn package manager. With Corepack you can activate one package manager, all package managers or a specific version of a package manager. We will install a specific version of the yarn package manager;
> corepack prepare yarn@1.22.11 --activate
This will install yarn version 1.22.11 and activate for our project. Once we have activated our package manager we can run existing package manger commands using Corepack. If we want to add a module using a specific package manager, we simply append those commands to the corepack command;
> corepack yarn add axios
If we had yarn installed globally, this would work the same if just ran yarn add axios. If we look at the package.json file, it will have a dependency for axios. We also have a packageManager setting in our package.json file that lists which package managers we want to use with our project.
{
  "name": "sampleproject",
  "version": "1.0.0",
  "main": "index.js",
  "type": "module",
  "license": "MIT",
  "scripts": {
    "start": "node index.js"
  },
  "packageManager": "yarn@1.22.11",
  "dependencies": {
    "axios": "^0.21.4"
  }
}
Archiving and Distributing our Package Managers
Corepack also allows us to archive up our package managers into our project. These archives can then be hydrated back when our project is deployed into our build environment.
To archive our package manager, we can add an -o output flag when we use the prepare command.
> corepack prepare yarn@1.22.11 --activate -o
This will add a corepack.tgz file to out project that includes our package manager. If we copy the source for our project to another machine, we can unarchive the package manager by using the hydrate command as follows;
> corepack hydrate --activate corepack.tgz
Conclusion
Corepack is another example of how the Node.js community is making Node a better tool incrementally. By providing support for the different package managers, this is another way the tooling is making our lives easier.
Right now Corepack is preview only, but by installing and using the latest version of Node.js, you can start to get the feel of this new tooling before it becomes part of the default release.Tags: Node.js,   yarn,   pnpm,   corepack   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeSeptember 5th, 2021Note: This is a re-post of an article I wrote for Logrocket. You can read the original here
When Swift was first introduced by Apple in 2014, it promised to meet the demands software engineers needed in modern programming languages. Since then Apple has open sourced the language and continued to evolve the language. Chris Lattner, who designed the language at Apple, had the goal of making a language that could be used to teach programming as well as build software for operating systems.
One of the key features that has been missing from the language has been primitives for concurrency and parallelism. In the past it was possible to do this kind of programming with Swift, but by using libraries like Grand Central Dispatch and libdispatch.
Why concurrency is important
Concurrency has become increasingly important because of changes that have been made to processors over the last decade. While newer processors have more transistors on them, there has been no significant improvement in clock speed. The one continuous improvement we are seeing in newer processors is more CPU Cores on each chip.
Apple's newer processors such as the A14 found in the iPhone 12 now has six cores, and their M1 processor in Apple Silicon based Macs and the iPad has eight CPU cores. The clock speed for the A14 is still around 3.1 gigahertz.
The real advancements in CPU design has come to the number of cores that are designed in the modern chips. To take advantage of these newer processors we need to do a better job of doing concurrent programming.
Do not block the Main Threat
One of the important things that is often stressed to iOS/iPad OS developers is to never block the main thread. In most modern computer systems the main thread is used to render and handle the user interface as well as user interactions. If a user tries to interact with the UI of your app, and they can't because your UI is frozen because of a long running task, it can be very frustrating user experience.
For this reason, Apple has provided a number of different tools we can use to prevent the UI of our applications from being blocked by a long running task.
Some example of tasks that can take a long time is any task that involves making a network request, interacting with the file system and querying a database.
Concurrency options in Swift
Modern concurrent programming has been made easier through improvements to frameworks like Grand Central Dispatch and libdispatch. For iPhone and iPad developers the default option has been to use Grand Central Dispatch.
Currently on iOS/iPad OS devices the current practice is to offload any task that would block the main thread to a background thread or queue until that task has completed. Once background tasks are completed, the results are usually handled in a block or trailing closure.
Prior to Grand Central Dispatch Apple provided APIs that used delegation to offload work that would require running a separate thread to a delegated object, and that object would call a method on the calling class to handle the completion of the task.
While both of these solutions worked, and can be difficult to read that kind of code, and it also allows for new kinds of bugs to be introduced if the completions are not handled correctly.
In 2017, Chris Lattner wrote his Swift Concurrency Manifesto which expressed his ideas on how to add concurrency to Swift using Async/await and Actors.
Grand Central Dispatch
Grand Central Dispatch, or GCD, was first introduced in 2009 by Apple. It is Apple's way of managing task parallelism through a managed thread pool on Apple's operating systems.
GCD's implementation originated as a C library, so it could be used with C, C++ and Objective-C. Those languages were the main languages used by iOS and MacOS developers at the time. After Swift was introduced, a Swift wrapper for GCD was created for developers using Apple's newer language.
GCD has also been ported to 'libdispatch' which is used in other open source software. The Apache web server has incorporated this library to do multi-processing.
A simple example of how to use GCD now is to assign work to another dispatch queue. Here is an example of a function assigning some of it is work to an asynchronous task.
func doSomethinginTheBackground() {
    DispatchQueue.global(qos: .background).async {
        // Do some long running work here
        ...
    }
}
The DispatchQueue class provides methods and properties that allow developers to run code in a trailing closure. A very common scenario is to run a long running task in a trailing closure that produces some type of result, and then return that result back to the main thread. Here is an example of DispatchQueue that does some work, and returns a result back to the main thread.
DispatchQueue.global(qos: .background).async {
    // Do some work here
    DispatchQueue.main.async {
        // return to the main thread.
        print("Work completed and back on the main thread!")
    }
}
A more common scenario would be making a networking call using NSURLSession, handling the results in a trailing closure, and then returning to the main thread.
func goGrabSomething(completion: @escaping (MyJsonModel?, Error?) -> Void) {
    let ourl = URL(string: "https://mydomain.com/api/v1/getsomejsondata")
    if let url = ourl {
        let req = URLRequest(url: url)
        URLSession.shared.dataTask(with: req) { data, _, err in
            guard let data = data, err == nil else {
                return
            }
            do {
                let model = try JSONDecoder().decode(MyJsonModel.self, from: data)
                DispatchQueue.main.async {
                    completion(model, nil)
                }
            } catch {
                completion(nil, error)
            }
        }.resume()
    }
}
The following example will compile and run, there are some bugs in the example. I am not using completion handlers everywhere this function can exit. It is also harder to read if I was writing my code synchronously.
Using Async/Await in your code
When iOS/iPad OS 15 and MacOS 12 are released this Fall, developers will start to be able to use the new Async/await syntax. Async/await can already be found in languages such as JavaScript and C#. These keywords are starting to become the way modern programming languages can write concurrent code. Lets' take a look at the previous function goGrabSomething rewritten to use the new Async/await syntax.
func goGrabSomething() async throws -> MyJsonModel? {
    var model: MyJsonModel? = nil
    let ourl = URL(string: "https://mydomain.com/api/v1/getsomejsondata")
    if let url = ourl {
        let req = URLRequest(url: url)
        let (data, _) = try await URLSession.shared.data(for: req)
        model = try JSONDecoder().decode(MyJsonModel.self, from: data)
    }
    return model
}
As we can see from my example above, we added the async keyword before the throws and after the function name. If our function did not throw, async would go before the ->. I was able to change the function signature so that it no longer requires a completion. We can now return the object that has been decoded from our API call.
Inside of our function I am using the keyword await in front of my URLSession.shared.data(for: URLRequest). Since the URLSession data function can throw an error, I have put a try in front the await keyword. Every time we use an await in the body of our function it creates a continuation. When the system processes our function, if it has to wait, it can now suspend our function until it is ready to return from its suspended state.
If we try to call the goGrabSomething function from synchronous code, it will fail. But Swyft provides a nice workaround for that use case. We can use an async closure in our synchronous code to be able to call our async functions.
Task.init {
    var myModel = try await goGrabSomething() 
    print("Name: \(myModel.name)")
}
Swift now has it own system for managing concurrency and parallelism. By leveraging these new keywords, we can take advantage of these new concurrency features in the system.
The end result is we are able to write a function that is easier to read and contains less code.
Conclusion
Async/await in Swift greatly simplifies they way we write concurrent code in our iOS/iPad OS applications. You can start to play around with these new features by downloading Xcode 13 and running these examples on the betas of iOS/iPad OS 15 or MacOS 12.
This article is just scratching the surface of what you can do with these new concurrent features. Swift also has added an actor object type to language so developers can create write objects that contain shared mutable state that can be used across threads without having race conditions.
Please watch Apple's WWDC21 presentation, Meet async/await in Swift to find out more about Async/await in Swift.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeSeptember 1st, 2021


Whether you are doing test driven development (TDD) or are just looking for a way to add automated testing to your express app, this can be accomplished fairly easily using many different unit testing frameworks. With Node.js, I have used a number of different testing frameworks. One of the nice things about Node is that there are no shortage of options when it comes to testing.
The testing framework I prefer to use is Jest, but it is not a requirement for unit testing an express application. Jest is extremely popular with React developers, but it can be used with just about any JavaScript application.
I like to use Jest because on top of having all of the tools needed to run unit tests, it also can check code coverage.
Writing Testable Code
One of the good things about TDD is that helps developers write code that is more loosely coupled, which not only makes the code more easy to test, but makes the code more reusable.
Express follows a basic structure for responding to requests based on a route signature, i.e.;
app.get('/users/report', function(req, res) {
    res.render('userreport', { title: 'Users Report' });
});
It is a good practice to break the handler code into its own function, and then use that handler in the route.
function userReportHandler(req, res) {
    res.render('userreport', { title: 'Users Report' });
}

app.get('/users/report', userReportHandler);
Not only does this make the express code more organized, now we test just the handlers without having to run express.
Adding Jest
To add Jest to your application, we can do this by running the following command in the root of our application directory;
> npm i jest --save-dev
This will install Jest tooling into our node_modules folder. Now that Jest is installed, lets' change the scripts section of our package.json file to run jest in the test property. It should look like the following in our scripts section;
"scripts": {
    "test": "node --experimental-vm-modules node_modules/.bin/jest --coverage",
    "start": "node <name_of_mainjs_file>"
},
Lets' take a quick look at what this command is doing. We are telling Node to run the jest command in the node_modules/.bin/jest location. This in turn runs the jest-cli. We are also running a flag --experimental-vm-modules to allow us to run ESModule import/export syntax. We are also using jest's --coverage flag to get a code coverage report to let us know what percentage of our code is covered by unit tests.
Express App Example
For the purposes of this example, I am going to create a simple Express app that has two routes. One that will operate as a home page with a route of /, and one that has a route called /hello that takes one input parameter called :name.
// routes/default.js
function index(req, res) {
    res.send('hello world!');
}

function hello(req, res) {
    const name = req.params.name ?? "world";
    res.send(`hello ${name}!`);
}

export { index, hello };

// routes/main.js
import { Router } from 'express';
import { index, hello } from './default.js';

const router = Router();

router.get('/', index);
router.get('/hello/:name', hello);

export default router;

// app.js
import express from 'express';
import http from 'http';
import router from './routes/main.js';

const app = new express();

app.use('/', router);

const port = process.env.PORT || '3000';
app.set('port', port);

const server = http.createServer(app);
server.listen(port);
Now we can add a folder called __tests__ to our project. Jest automatically looks for any JavaScript or TypeScript files inside of this directory.
Before we create our first test, lets add supertest to our project using the following command;
npm i supertest --save-dev
Supertest is used to mock out our express server so we do not have to run a http server in order to test our routes.
Unit Tests
Lets' create a unit test just to test our route handlers.
import { index, hello } from '../routes/default.js';

describe('Test Handlers', function () {

    test('responds to /', () => {
        const req = {  };

        const res = { text: '',
            send: function(input) { this.text = input } 
        };
        index(req, res);
        
        expect(res.text).toEqual('hello world!');
    });

    test('responds to /hello/:name', () => {
        const req = { params: { name: 'Bob' }  };

        const res = { text: '',
            send: function(input) { this.text = input } 
        };
        hello(req, res);
        
        expect(res.text).toEqual('hello Bob!');
    });

});
Both of our route handlers both use the send function on the res object, so I created a simple mock response object that duplicates what the Express response object would do if we used this in a real application. In this case send just echos out whatever we pass in onto the text property.
In both of my unit tests I am using jest's expect function to compare our expected results in the toEqual function. If they match, both tests will pass.
Now lets' add another test suite with supertest to test the routes. We will create a new file called routes.t.js to test the actual routes.
import request from 'supertest';
import express from 'express';
import router from '../routes/main.js';

const app = new express();
app.use('/', router);

describe('Good Home Routes', function () {

  test('responds to /', async () => {
    const res = await request(app).get('/');
    expect(res.header['content-type']).toBe('text/html; charset=utf-8');
    expect(res.statusCode).toBe(200);
    expect(res.text).toEqual('hello world!');
  });
  
  test('responds to /hello/:name', async () => {
    const res = await request(app).get('/hello/jaxnode'); 
    expect(res.header['content-type']).toBe('text/html; charset=utf-8');
    expect(res.statusCode).toBe(200);
    expect(res.text).toEqual('hello jaxnode!');
  });

  test('responds to /hello/Annie', async () => {
    const res = await request(app).get('/hello/Annie'); 
    expect(res.header['content-type']).toBe('text/html; charset=utf-8');
    expect(res.statusCode).toBe(200);
    expect(res.text).toEqual('hello Annie!');
  });

});
Using supertest we can see these tests our more thorough and accurate of what our express app is doing. In the test suite above we use supertest to run the specific routes. We can also look at specific express properties to make sure the application is returning the expected results.
In all three unit tests we use expect to check that we have the correct header results, statusCode and text.
Running our tests
To test our unit tests, all we have to do is run npm test in out command line.
> npm test

> expresstest@1.0.0 test
> node --experimental-vm-modules node_modules/.bin/jest --coverage

(node:56591) ExperimentalWarning: VM Modules is an experimental feature. This feature could change at any time
(Use `node --trace-warnings ...` to show where the warning was created)
 PASS  __tests__/routes.t.js
 PASS  __tests__/handlers.t.js
------------|---------|----------|---------|---------|-------------------
File        | % Stmts | % Branch | % Funcs | % Lines | Uncovered Line #s
------------|---------|----------|---------|---------|-------------------
All files   |     100 |       50 |     100 |     100 |
 default.js |     100 |       50 |     100 |     100 | 7
 main.js    |     100 |      100 |     100 |     100 |
------------|---------|----------|---------|---------|-------------------

Test Suites: 2 passed, 2 total
Tests:       5 passed, 5 total
Snapshots:   0 total
Time:        0.782 s, estimated 1 s
Conclusion
As you can see from the example above it is actually quite easy to add unit testing to your express app.
I had a former co-worker who had the following slogan in his cubicle; "Test, test, test, and once you think you are done, test again". Unit testing is just one small aspect to the quality assurance of your code, but if used correctly with CI/CD it will help you discover bugs well before they even make it to a staging or test environment.
Example on GithubTags: JavaScript,   Node.js,   Jest,   Unit Testing   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeAugust 22nd, 2021One of the many popular applications that can be written using JavaScript and Node.js is a Bot. Bots can be thought of simple applications that can be used to advertise or respond to users on chat services, social media platforms and team communication software.
Some services heavily rely on Bots while others outright ban Bots when they are encountered. But Bots can be used for good as well as evil. Bots can also be used with some sort of AI for interacting with users. You might have encountered this on some websites when a chat window will open asking if it can assist you.
For this post I am going to create a Bot to answer simple questions about a meetup group. This meetup group has a Twitter account which I will use to respond to questions on Twitter.
Creating the Application
To create this Bot I am going to use Node.js and a node module called twit. You can install this into your Node application by using the following NPM command;
npm install twit --save
Twit is a module for using Twitters API. To use Twitter's API you will need to register an app. Twitter needs the following keys in order to be able to interact with their API. Those keys are as follows;

consumer_key
consumer_secret
access_token
access_token_secret

Once you have these keys, make sure you keep these keys in a safe place, otherwise you will need to regenerate your keys. You can either store these in a dotenv file or add them to your environment variables.
Configuring our Bot
To create our Bot the first thing we will need to do is configure twit to use our keys.
import twit from 'twit';

const config = {  
    consumer_key: process.env.twitter_consumer_key,  
    consumer_secret: process.env.twitter_consumer_secret,
    access_token: process.env.twitter_access_token,  
    access_token_secret: process.env.twitter_access_token_secret
}
  
const Twitter = new twit(config);
Now that we have configured our application to use our keys, we are going to use Twitter's stream API. With the stream API we can listen for certain words or hashtags. For our meetup application I am going to listen for the name of my meetup group, JaxNode.
const stream = Twitter.stream('statuses/filter', { track: ['jaxnode'] }); 

stream.on('tweet', function (tweet) {
    console.log(tweet);
});
The code example above filters the stream to listen for the jaxnode keyword. Anytime someone tweets a tweet with that keyword, we can use the on('tweet') event to capture those tweets in realtime. For our application we will respond to any tweet that contains one of the following words in tweets in our filtered stream, what, where and when. To do this I will take the text of the tweet, and turn it into an array, and filter for one of those determiners.
stream.on('tweet', function (tweet) {    
    const tweetwords = tweet.text.split(' ');
    const hasWhat = tweetwords.filter(w => w.toUpperCase() === 'WHAT');
    if (hasWhat.length > 0) {
        // respond with an answer
    }
});
Using the Meetup API
To answer questions about our next meeting, we will use meetup's API to lookup the latest information about our next meeting. We can use the axios http client to retrieve information back from Meetup.
async function getNextMeetingInfo() {
    const result = await axios.get('https://api.meetup.com/Jax-Node-js-UG/events?page=2');
    return result.data[0];
}
This API returns a JSON array with all of the upcoming events for our meetup group. To answer any tweets with what we will assume the user want to know what the next meeting will be about. There is a name property in the object that is returned. We will use the name to answer the what question.
To reply with a tweet, we will use another part of the twitter API to send tweets. To do this we will create the following function;
function tweetNow(tweetTxt) {  
    const tweet = {
        status: tweetTxt
    }
    Twitter.post('statuses/update', tweet, function(err, data, response) {
        if (err) {
            console.log('Error in Replying');
            console.error(err);
        } else {
            console.log('Tweet sent successfully');
        }
    });
}
Now we can complete our bot logic by constructing a reply and tweeting out an update.
stream.on('tweet', async function (tweet) {    
    const tweetwords = tweet.text.split(' ');
    const hasWhat = tweetwords.filter(w => w.toUpperCase() === 'WHAT');
    if (hasWhat.length > 0) {
        const nextMeetingInfo = await getNextMeetingInfo();
        const eventname = nextMeetingInfo.name; 
        const nextMeetingTopic = `@${tweet.user.screen_name} The next meeting is on '${eventname}'`;
        tweetNow(nextMeetingTopic);
    }
});
Now we can add the logic to answer all three of our questions for our what, where and when questions.
stream.on('tweet', async function (tweet) {    
    const tweetwords = tweet.text.split(' ');
    const hasWhat = tweetwords.filter(w => w.toUpperCase() === 'WHAT');
    if (hasWhat.length > 0) {
        const nextMeetingInfo = await getNextMeetingInfo();
        const eventname = nextMeetingInfo.name; 
        const nextMeetingTopic = `@${tweet.user.screen_name} The next meeting is on '${eventname}'`;
        tweetNow(nextMeetingTopic);
    }

    const hasWhen = tweetwords.filter(w => w.toUpperCase() === 'WHEN');
    if (hasWhen.length > 0) {
        const nextMeetingInfo = await getNextMeetingInfo();
        const time = nextMeetingInfo.time;
        const date = new Date(time);
        const eventDateAndTime = date.toLocaleDateString('en-us', { weekday:"long", year:"numeric", month:"short", day:"numeric", hour:"2-digit", minute:"2-digit"});
        const neetMeetingTime = `@${tweet.user.screen_name} Our next meeting will be on ${eventDateAndTime}`;
        try {
            tweetNow(neetMeetingTime); 
        } catch (err) {
            console.error(err);
        }
    }

    const hasWhere = tweetwords.filter(w => w.toUpperCase() === 'WHERE');
    if (hasWhere.length > 0) {
        const nextMeetingInfo = await getNextMeetingInfo();
        const venue = nextMeetingInfo.venue;
        const maplink = `We meet at ${venue.name} https://www.google.com/maps/place/${venue.name}/@${venue.lat},${venue.lon},15z`;
        try {
            tweetNow(`@${tweet.user.screen_name} ${maplink}`);  
        } catch (err) {
            console.error(err);
        }
    }
});
Hosting your Bot
There are a couple of options for hosting your Bot. If you have an existing Node.js server, you can run your b=Bot there, but you can also host using a service like Zeit or Heroku. These cloud application servers generally require an http listener in order to host your Bot. We can accomplish this by adding the following line to the end of our Bot;
require('http').createServer().listen(3000);
Our final Bot should look like the following when we our completed;
import twit from 'twit';
import axios from 'axios';
import http from 'http';

const config = {  
    consumer_key: process.env.twitter_consumer_key,  
    consumer_secret: process.env.twitter_consumer_secret,
    access_token: process.env.twitter_access_token,  
    access_token_secret: process.env.twitter_access_token_secret
}
  
const Twitter = new twit(config);

async function getNextMeetingInfo() {
    const result = await axios.get('https://api.meetup.com/Jax-Node-js-UG/events?page=2');
    return result.data[0];
}

function tweetNow(tweetTxt) {  
    const tweet = {
        status: tweetTxt
    }
    Twitter.post('statuses/update', tweet, function(err, data, response) {
        if (err) {
            console.log('Error in Replying');
            console.error(err);
        } else {
            console.log('Tweet sent successfully');
        }
    });
}

const stream = Twitter.stream('statuses/filter', { track: ['jaxnode'] }); 

stream.on('tweet', async function (tweet) {    
    const tweetwords = tweet.text.split(' ');
    const hasWhat = tweetwords.filter(w => w.toUpperCase() === 'WHAT');
    if (hasWhat.length > 0) {
        const nextMeetingInfo = await getNextMeetingInfo();
        const eventname = nextMeetingInfo.name; 
        const nextMeetingTopic = `@${tweet.user.screen_name} The next meeting is on '${eventname}'`;
        tweetNow(nextMeetingTopic);
    }

    const hasWhen = tweetwords.filter(w => w.toUpperCase() === 'WHEN');
    if (hasWhen.length > 0) {
        const nextMeetingInfo = await getNextMeetingInfo();
        const time = nextMeetingInfo.time;
        const date = new Date(time);
        const eventDateAndTime = date.toLocaleDateString('en-us', { weekday:"long", year:"numeric", month:"short", day:"numeric", hour:"2-digit", minute:"2-digit"});
        const neetMeetingTime = `@${tweet.user.screen_name} Our next meeting will be on ${eventDateAndTime}`;
        try {
            tweetNow(neetMeetingTime); 
        } catch (err) {
            console.error(err);
        }
    }

    const hasWhere = tweetwords.filter(w => w.toUpperCase() === 'WHERE');
    if (hasWhere.length > 0) {
        const nextMeetingInfo = await getNextMeetingInfo();
        const venue = nextMeetingInfo.venue;
        const maplink = `We meet at ${venue.name} https://www.google.com/maps/place/${venue.name}/@${venue.lat},${venue.lon},15z`;
        try {
            tweetNow(`@${tweet.user.screen_name} ${maplink}`);  
        } catch (err) {
            console.error(err);
        }
    }
});

http.createServer().listen(3000);
Conclusion
I think it is important to remember that these Bots should be used for good purposes. Most online services will try to prevent you from spamming their users. Try to be respectful of the other users that share your platforms.
These Bots can be extremely useful, and when coupled with AI can be very powerful.Tags: JavaScript,   Bot,   Twitter,   Node.js   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJuly 20th, 2021


I am often amazed at some of the software that people write using JavaScript as the language. When JavaScript was first introduced in 1995 it was considered by many as a 'Toy' language. At that time Java was considered to be the serious language with 'Java Applets' that could be run in web pages.
JavaScript since then has been implemented into a number of different places including micro-controllers, server applications and even desktop applications. There are also a number of different engines that can be used that portable so JavaScript can basically be run anywhere.

      
    
  
  
    
One of my favorite laws is Atwood's Law from blogger and software engineer Jeff Atwood. Atwood's Law states: any application that can be written in JavaScript, will eventually be written in JavaScript. I have been shocked at the kinds of applications that can be written using JavaScript. In my mind this means an application that you thought would have to be written in C or another low level language can be written in JavaScript.
Image Processing
Believe it or not you can do image processing with JavaScript. There are a number of libraries and tools you can use, but there is one in particular that is written in pure JavaScript, and it is called 'Jimp'. Named similar to the 'Gimp' open source application, Jimp allows you to do simple transformations like resizing, applying filters and converting to other file formats. Check out this example below;
import jimp from 'jimp';

jimp.read("lenna.png").then(function (lenna) {
    lenna.resize(256, 256)            // resize
         .quality(60)                 // set JPEG quality
         .greyscale()                 // set greyscale
         .write("lena-small-bw.jpg"); // save
}).catch(function (err) {
    console.error(err);
});
Programming Robots
Yes, robots. Not only are there micro-controllers that run JavaScript, there are also a number of different NPM modules that you can use to control traditional micro-controllers like the Raspberry Pi and the Arduino.
Johnny Five
Johnny-five has been ported to almost every micro-controller board. Simply connect your Arduino to your computer, and you can run JavaScript code to control your hardware projects. The equivalent to a 'Hello-World!' program for a micro-controller is to blink a LED bulb. Here is an example of how you would do that with Johnny-five;
const { Board, Led } = require("johnny-five");
const board = new Board();

board.on("ready", () => {

  // Create a standard `led` component instance
  const led = new Led(13);

  // "blink" the led in 500ms
  // on-off phase periods
  led.blink(500);
});
System Scripting
While many write all of their system scripts with languages like Bash or Python, you can do system level scripting with Node.js.
Lets' say you have a task where you need to clear or delete the contents of a folder, this can be accomplished by executing command using the exec function. Here is an example of this function deleting a folder;
const { exec } = require("child_process");

exec("rm -rf ~/Library/Developer/xcode/DerivedData", (error, stdout, stderr) => {
    if (error) {
        console.log(`error: ${error.message}`);
        return;
    }
    if (stderr) {
        console.log(`stderr: ${stderr}`);
        return;
    }
    console.log(`stdout: ${stdout}`);
});
Machine Learning and Artificial Intelligence
Machine Learning is becoming increasingly important in modern computing tasks. Multi-layered neural networks using advanced models are being used from natural language processing to creating self-driving autopilots for vehicles.
Most of the frameworks for building machine learning applications tend to be focused at the Python community, but there are a number that are available for JavaScript developers.
Brain.js
Brain.js is a JavaScript framework that works in Node.js as well as the browser and can use GPU acceleration. It uses a native module called headless-gl for GPU support. It also has a dependency on Python 2.7.
TensorFlow.js
TensorFlow.js is based on Google's TensorFlow library. TensorFlow is an end to end open source library for machine learning.
Like Brain.js TensorFlow.js can run in either the browser or in Node.js. It can run pre-trained models or retrain existing models.
Write Native Mobile Apps
Yes, native mobile apps. There are a number of frameworks that can be used to create native apps based on JavaScript.
React Native
Probably the most popular of these native frameworks is React Native. Introduced by Facebook, this framework uses the React application framework to build apps, but in combination with a JavaScript bridge to render and control the native components.
This framework is not a wrapper around a WebView like Cordova or PhoneGap, but is an actual native implementation. They have even created their own JavaScript engine that runs on both Android and iOS called Hermes.
NativeScript
NativeScript like React Native allows developers to write native apps, but you can use multiple different frameworks including React, Angular, Vue.js or Svelte.
NativeScript also ships with a command line tool that you can use to create new projects based on templates for the framework of your choice.
Cordova
Cordova is the open source version of PhoneGap. This framework allows developers to use their skills building HTML/CSS/JavaScript apps to reuse those apps inside of a WebView. The framework simply packages up your HTML based apps inside of a native WebView. It uses the WKWebView in iOS and the WebView control in Android. These packaged apps can be posted to the native app stores just like a native app.
Write Video Games
A lot of people used to make the assumption that 3D first person shooters had to be written in languages like C++, but a number of years emscripten showed how these types of games could be ported to run in the browser.
One of the first Emscripten examples that I saw was a 3D first person shooter port from a game that had be written in C++. These types of projects helped inspire the creation of WebAssembly.
WebAssembly gives compiler makers a target that can be used for porting almost any program to the JavaScript runtime using a lower level binary format called WASM.
There are also a number of JavaScript frameworks that allow you to build games in pure JavaScript, like Kaboom.js.
While there are many game frameworks, Kaboom is geared to making games fun and fast. It includes support for sprites, fonts and shaders.
Connect to Musical Instruments
JavaScript lets' web developers take advantage of a host of Web APIs. One of the more interesting Web APIs is for connecting and controlling musical instruments with a Web-MIDI interface.
The Web-MIDI API allows developers to connect and control digital instruments. Check out this article about making music in the browser.
Conclusion
It is difficult to think of an application that can't be written in JavaScript. Especially now with tools like WebAssembly, applications that would have seemed impossible can now run in the JavaScript runtime.Tags: JavaScript,   IoT,   Image Processing,   ML,   AI,   Gaming   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJuly 12th, 2021


I will be doing a presentation to the JaxNode User Group on July 15th on the Async and Await feature in JavaScript. I have done some posts on Async and Await recently as well. One of the neat things about Async and Await is that it is finding it's way into more and more programming languages.
Concurrency
Concurrency is becoming more and more important in today's software. The reason is pretty simple. If you look at the processors that are being manufactured today, we are getting more and more transistors onto chips as well as more cores, but the chips are not really getting improved clock speeds. Clock speeds have been at a virtual standstill for the last decade or so.
If you look at some of the modern processors that we are getting in laptops and desktops, it is not uncommon to see eight or more cores. Apple's M1 chip, which is meant to be their low end chip has eight CPU cores. AMD's Rizen chip can come with as many as 32 cores.
CPU Cores allow us to run multiple processes at the same time. In the past developers could take advantage of multiple cores by spawning a new thread, doing some work, and then joining back to the main thread. This type of multi-threaded programming is a form of concurrent programming.

      
    
  
  
    
Concurrency is Hard
Spawning multiple threads also presents new types of challenges for developers. While threads can work independently of each other, they can also interact with each other. This can cause new kinds of bugs like race conditions and deadlocks.
JavaScript is single-threaded, but we can still do concurrent programming in JavaScript. Node.js as an example uses a library called LibUV. LibUV takes advantage of the Node.js event loop. When a long running process is started, it will register a callback on the event loop freeing up Node.js to do other work. When the operation is completed, it triggers the callback completing the process.

      
    
  
  
    
Before we dive too deeply into the async/await keywords, we need to look at why these keywords are being added to existing programming languages. The reason is that in most programming languages that are popular today, concurrent programming involves the use of callback functions, blocks, delegates or pointer functions.
If you are not familiar with the async/await keywords in JavaScript, they allow you to explicitly designate a function as asynchronous, but write the function as if it were synchronous. This is extremely powerful because in the past the way you had to write asynchronous JavaScript involved using some form of callback. If you have multiple callbacks in a single function, this could devolve into a large callback structure that could be extremely difficult to read as in the example below;
fs.readdir(source, function (err, files) {
  if (err) {
    console.log('Error finding files: ' + err)
  } else {
    files.forEach(function (filename, fileIndex) {
      console.log(filename)
      gm(source + filename).size(function (err, values) {
        if (err) {
          console.log('Error identifying file size: ' + err)
        } else {
          console.log(filename + ' : ' + values)
          aspect = (values.width / values.height)
          widths.forEach(function (width, widthIndex) {
            height = Math.round(width / aspect)
            console.log('resizing ' + filename + 'to ' + height + 'x' + height)
            this.resize(width, height).write(dest + 'w' + width + '_' + filename, function(err) {
              if (err) console.log('Error writing file: ' + err)
            })
          }.bind(this))
        }
      })
    })
  }
})
This was improved somewhat with the arrival of Promises. Promises are created with a constructor function that takes two parameters, resolve and reject. The resolve parameter function is a callback for the successful result of the Promise while reject is the callback for the error.
const promise = new Promise(function(resolve, reject) {
  // do a thing, possibly async, then‚Ä¶

  if (/* everything turned out fine */) {
    resolve("Stuff worked!");
  }
  else {
    reject(Error("It broke"));
  }
});

promise
    .then(result => {
        console.log(result);
    }).catch(err => {
        console.error(err);
    });
While this is an improvement over Error first callbacks, it still does not have the elegance of a synchronous function.
Async and Await
Expressing a function as an asynchronous function essentially turns that function into a promise. As a matter of fact, Promises in JavaScript and Async functions are interchangeable. Lets' take the node-fetch module as an example which is a promise. We can use it to retrieve data from a Rest API.
import fetch from 'node-fetch';

function getFact() {
    fetch('https://cat-fact.herokuapp.com/facts/random')
        .then(result => {
            return result.json();
        }).then(json => {
            console.log(json.text);
        });
}

getFact();
// This will return a random fact about a feline
Using async/await syntax, we can rewrite this function so that we do not have to pass or write callback functions;
import fetch from 'node-fetch';

const catFact = async () => {
    const result = await fetch('https://cat-fact.herokuapp.com/facts/random');
    const json = await result.json();
    return json.text;  
};

const fact = await catFact();
console.log(fact);
// This will return a random fact about a feline
The example above is a JavaScript module, so I can write my top level JavaScript to use the await keyword without having to use it inside of a function marked async.
The result of having refactored this is that I can actually use the return keyword to pass a result. This feature makes developers much more productive. It makes the code easier to read, and it also makes it easier to debug. Plus I can take any async function in JavaScript and execute it like it were a Promise.
catFact().then(fact => { console.log(fact) });
JavaScript was not First
JavaScript was not the first language to use async and await. There were multiple functional languages that used these keywords before JavaScript including Haskell and F#.
open System
open System.IO

let printTotalFileBytes path =
    async {
        let! bytes = File.ReadAllBytesAsync(path) |> Async.AwaitTask
        let fileName = Path.GetFileName(path)
        printfn $"File {fileName} has %d{bytes.Length} bytes"
    }

[<EntryPoint>]
let main argv =
    printTotalFileBytes "path-to-file.txt"
    |> Async.RunSynchronously

    Console.Read() |> ignore
    0
Anders Hejlsberg, the original architect of C# at Microsoft, took inspiration from this form of expressive concurrency, and added it to C# around 2011. C# does not have Promises, but it does have Tasks. You can use the Task type with the async/await keywords to make your C# methods asynchronous.
private static async Task<int> DownloadDocsMainPageAsync()
{
   Console.WriteLine($"{nameof(DownloadDocsMainPageAsync)}: About to start downloading.");

   var client = new HttpClient();
   byte[] content = await client.GetByteArrayAsync("https://docs.microsoft.com/en-us/");

   Console.WriteLine($"{nameof(DownloadDocsMainPageAsync)}: Finished downloading.");
   return content.Length;
}
If you need to return a specific type from your method, the Task is a generic type, and you can specify a certain type you would like returned from your Task<T>.
Rust
Rust recently added the async and await keywords to the language as a way of handling Futures. Futures in Rust are very similar to Promises in JavaScript. They can be polled to see if the Future is still pending, and once it is ready handle the result.
async fn example(min_len: usize) -> String {
    let content = async_read_file("mycatdata.txt").await;
    if content.len() < min_len {
        content + &async_read_file("myfelinedata.txt").await
    } else {
        content
    }
}
Swift
As of Swift version 5.5, async/await has found its way into the Language. iOS and iPadOS developers will start to be able to use these new concurrent features in iOS/iPadOS 15 this Fall.
This was originally proposed by Chris Lattner back in 2017 in his famous Swift Concurrency Manifesto. Previously Swift developers did asynchronous programming using Grand Central Dispatch, or GCD for short. This involved using trailing closures, essentially the same thing as a callback in Swift.
Apple has been able to add concurrency into the Swift by adding async/await keywords as well as other features such as actors.
func processImageData1() async -> Image {
    let dataResource  = await loadWebResource("dataprofile.txt")
    let imageResource = await loadWebResource("imagedata.dat")
    let imageTmp      = await decodeImage(dataResource, imageResource)
    let imageResult   = await dewarpAndCleanupImage(imageTmp)
    return imageResult
}
Swift's implementation is a little different from the other languages we have seen because the async keyword trails the func name instead of leading like it does in JavaScript. Swift also allows developers to spawn multiple threads inside the body of our function by using the async keyword in front of the variable assignment.
async let firstPhoto = downloadPhoto(named: photoNames[0])
async let secondPhoto = downloadPhoto(named: photoNames[1])
async let thirdPhoto = downloadPhoto(named: photoNames[2])

let photos = await [firstPhoto, secondPhoto, thirdPhoto]
show(photos)
I am sure iOS and MacOS developers cannot wait to start using these concurrent language features in their apps.
Conclusion
Pretty soon if your preferred programming language does not have async/await, it probably will soon. The one exception to this is probably Java, but new features always seem to come last to Java.
I am extremely happy to see async/await make it into more languages. It has certainly made me more productive as a software engineer.Tags: C#,   JavaScript,   Async,   Await,   F#,   Concurrency   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJuly 7th, 2021I was running into nasty crash whenever I tried to debug the WKWebView in one of my iOS apps. It is a common practice among developers to debug using Safari while running JavaScript code in their WebViews.
I noticed several months ago whenever I had Safari running on my Mac, and I was running the debugger in Xcode, I would get a crash with the following exception.
WebThread (9): EXC_BAD_ACCESS (code=2, address=0x16b6c2320)

JavaScriptCore`invocation function for block in Inspector::RemoteConnectionToTarget::dispatchAsyncOnTarget(***::Function<void ()>&&):
It turns out there is a bug in iOS 14.5 and 14.6 that prevents developers from running a debug session in Xcode while Safari is running. You can read about it here in Apple's forum;
https://developer.apple.com/forums/thread/679015
Workaround
In the Apple forum there were some suggestions on installing the Safari Technology Preview. I installed that version of Safari, and it did not resolve the issue for me, but it might for others.
What did wind up working for me was downloading an older version of the iOS simulator. Version 14.3 of the simulator seems to have done the trick for me with my debugging sessions.
You can install older versions of iOS in your simulator by going to Xcode preferences -> Components, and clicking on the download button on the version of the simulator you want.

      
    
  
  
    
Then you can run in the simulator, and debug using Safari.
Conclusion
There are thousands of iOS/iPad OS apps that use the WKWebView and Safari for debugging. Many frameworks like Ionic and Cordova use the WKWebView, as well as native apps that require the ability to render and run web content. It is unfortunate that Apple has not addressed this yet with the current versions of iOS and Safari, but hopefully they will soon.Tags: iOS 14.6,   WKWebView,   Safari,   Debugging,   iOS App Crash   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJuly 3rd, 2021


MDX is a hybrid of Markdown syntax and React JSX syntax. Authors who are writing posts in Markdown can use React components in their posts.
Currently Markdown allows authors to  add HTML tags to their posts. One of the nice things about React is that it makes it possible for us to create components of a combination of HTML elements, and then reuse those elements in our React applications. MDX allows us to take those same components and use it in our Markdown posts.
import { Link } from 'gatsby'

import Layout from '../components/layout'
import Image from '../components/image'
import SEO from '../components/seo'

<SEO title="Home" keywords={['gatsby', 'application', 'react']} />

# Hi people

Welcome to your new Gatsby site.

Now go build something great.

<div style={{ maxWidth: '300px', marginBottom: '1.45rem' }}>
  <Image />
</div>
<Link to="/page-2/">Go to page 2</Link>

Adding MDX to your Blog
Currently I use regular Markdown for my blog. I decided I wanted to see what would be involved to add MDX to my blog. In my current implementation of my Gatsby site I am using the gatsby-transformer-remark plugin for converting markdown into Gatsby data that can be used to render my blog posts.
Gatsby provides an excellent tutorial on how to take an existing Gatsby blog using starter site, and convert it to use MDX instead of markdown.
https://www.gatsbyjs.com/blog/2019-11-21-how-to-convert-an-existing-gatsby-blog-to-use-mdx/
This post is from 2019, and some of the line numbers do not match, but it can still be used for a basis of converting your blog to use MDX.
W will use the Gatsby Starter Blog as the basis for our conversion. You can install that using the following Gatsby command;
gatsby new gatsby-blog https://github.com/gatsbyjs/gatsby-starter-blog
You will need to add the mdx plugins to your gatsby site before you make any code changes. Here is the NPM command to add the MDX plugins.
> npm install --save gatsby-plugin-mdx gatsby-plugin-feed-mdx @mdx-js/mdx @mdx-js/react
In your gatsby-config.json file, we will replace the gatsby-transformer-remark config with the gatsby-plugin-mdx config setting. Under options you will need to add property for the extensions and change the name of the plugins property to gatsbyRemarkPlugins. The final configuration should look like the following example.
{
  resolve: `gatsby-plugin-mdx`,
  options: {
    extensions: [`.mdx`, `.md`, `.markdown`],
    gatsbyRemarkPlugins: [
      {
        resolve: `gatsby-remark-images`,
        options: {
          maxWidth: 590,
        },
      },
      {
        resolve: `gatsby-remark-responsive-iframe`,
        options: {
          wrapperStyle: `margin-bottom: 1.0725rem`,
        },
      },
      `gatsby-remark-prismjs`,
      `gatsby-remark-copy-linked-files`,
      `gatsby-remark-smartypants`,
    ],
  },
},
Then replace the gatsby-plugin-feed plugin in the config with gatsby-plugin-feed-mdx. Once you are done making your configuration changes, you can remove the old NPM modules.
> npm uninstall --save gatsby-transformer-remark gatsby-plugin-feed
Changing Node API
There are some changes we will need to make to the gatsby-node.js file. We will need to replace any references to allMarkdownRemark to allMdx. We will also need to change any reference types that are using MarkdownRemark to us Mdx instead.

- allMarkdownRemark(
+ allMdx(

...

- const posts = result.data.allMarkdownRemark.edges
+ const posts = result.data.allMdx.edges

...

- if (node.internal.type === `MarkdownRemark`) {
+ if (node.internal.type === `Mdx`) {
Changing any page reference to Markdown
Now that we have changed the Node API to use Mdx, we can focus on changing any pages or templates that still have references to MarkdownRemark to use Mdx. In the index.js page we replace all markdown references with Mdx instead.
- const posts = data.allMarkdownRemark.edges
+ const posts = data.allMdx.edges

...

- allMarkdownRemark(sort: { fields: [frontmatter___date], order: DESC }) {
+ allMdx(sort: { fields: [frontmatter___date], order: DESC }) {
Now we can make these changes to the src/templates/blog-post.js template, but this time the references will be markdownRemark and mdx respectively.
// Add import statement for the MDXRenderer
+ import { MDXRenderer } from "gatsby-plugin-mdx"

...

- const post = this.props.data.markdownRemark
+ const post = this.props.data.mdx

...

- markdownRemark(fields: { slug: { eq: $slug } }) {
+ mdx(fields: { slug: { eq: $slug } }) {

...

- <section dangerouslySetInnerHTML={{ __html: post.html }} />
+ <MDXRenderer>{post.body}</MDXRenderer>
Replace html with body in your GraphQL queries once you change the markdownRemark to mdx.
mdx(id: { eq: $id }) {
    id
    excerpt(pruneLength: 160)
    body
    frontmatter {
        title
        date(formatString: "MMMM DD, YYYY")
        description
    }
}
Now lets' add a MDX blog post. We will name this file example.mdx and place it into blog directory with our other posts.
// example.mdx
---
title: MDX Example
date: "2021-07-03T22:12:03.284Z"
description: "MDX Example"
---

# My first MDX post

This is a post showing MDX in action.

MDX lets you write JSX embedded inside markdown, perfect for technical blogs.
Now lets` create a component for adding Youtube videos to our MDX posts.
import React from "react"

const Youtube = props => (
    <div style={{textAlign: 'center'}}>
        <iframe 
            title="YoutubeIframe" 
            width="700" 
            height="393" 
            src={`https://youtube.com/embed/${props.yid}`} 
            frameBorder={`0`} 
            allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" 
            allowfullscreen></iframe>
    </div>
)

export default Youtube;
Now we can add this component to our MDX post.
// example.mdx
---
title: MDX Example
date: "2021-07-03T22:12:03.284Z"
description: "MDX Example"
---
import Youtube from "../../../src/components/yt.js"

# My first MDX post

This is a post showing MDX in action.

<Youtube yid="jYVM6KOWYBs" />

## MDX

MDX lets you write JSX embedded inside markdown, perfect for technical blogs.
Conclusion
By making some simple changes to our Gatsby blog, we can now use MDX based React components to our blog posts. Now we can start using own components mixed in with our simplified markdown based markup. Now we can do things like add video and audio to our posts with just one React element.Tags: Gatsby,   MDX,   JavaScript,   React   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJune 28th, 2021


I recently posted on how to add tags to your Gatsby site using FrontMatter. After doing that change to my blog, I also wanted to add linking as well to my posts, as well as a page that listed all Tags.
Gatsby actually has the queries and code examples you need pretty well documented. I wanted to show how I used these on my site. The Creating Tags Pages for Blog Posts documentation describes the code you will have to write in order to add the tag linking and templates to your site. The code is divided into three different areas, a tag template, an addition to the createPages function in the gatsby-node.js file and a Tags page for listing all of the tags.
Graphql queries
The Tag template will need a query to select all of the blog posts that match a particular tag. This parameter for the Tag gets passed into template through the context. We can test using the graphiql editor that comes with Gatsby, and can be browsed to at 'http://localhost:8000/___graphql'.
{
    allMarkdownRemark(
      limit: 2000
      sort: { fields: [frontmatter___date], order: DESC }
      filter: { frontmatter: { tags: { in: "JavaScript" } } }
    ) {
      totalCount
      edges {
        node {
          fields {
            slug
          }
          frontmatter {
            title
          }
        }
      }
    }
  }
In the example above, we searched for any post that had a tag named 'JavaScript'. We can then make this a query dynamic by setting it up to use a query parameter passed from the template context. Here is how that query would look.
export const pageQuery = graphql`
  query($tag: String) {
    allMarkdownRemark(
      limit: 2000
      sort: { fields: [frontmatter___date], order: DESC }
      filter: { frontmatter: { tags: { in: [$tag] } } }
    ) {
      totalCount
      edges {
        node {
          fields {
            slug
          }
          frontmatter {
            title
          }
        }
      }
    }
  }
`
Here is how my tag template looks with this query.
import React from "react"
import { Link, graphql } from "gatsby"
import Layout from "../components/layout"
import Navbar from "../components/navbar.js"
import Header from "../components/blogheader.js"
import Footer from "../components/footer.js"
import Article from "../components/article.js"
import MainHelmet from "../components/mainhelmet.js"

const TagList = ({ pageContext, data }) => {
    const { tag } = pageContext
    const { edges, totalCount } = data.allMarkdownRemark
    const tagHeader = `${totalCount} post${
        totalCount === 1 ? "" : "s"
    } tagged with "${tag}"`;

    return (
        <Layout>
            <MainHelmet title="Fek.io" />
            <Navbar />
            <Header headline={tagHeader} />
            <Article>
          <h1>{tagHeader}</h1>
          <ul>
            {edges.map(({ node }) => {
              const { slug } = node.fields
              const blogslug = `/blog${slug}`;
              const { title } = node.frontmatter
              return (
                <li key={slug}>
                  <Link to={blogslug}>{title}</Link>
                </li>
              )
            })}
          </ul>
          <Link to="/tags">All tags</Link>
          </Article>
          <Footer />
        </Layout>
    );
}

export default TagList;

export const pageQuery = graphql`
  query($tag: String) {
    allMarkdownRemark(
      limit: 2000
      sort: { fields: [frontmatter___date], order: DESC }
      filter: { frontmatter: { tags: { in: [$tag] } } }
    ) {
      totalCount
      edges {
        node {
          fields {
            slug
          }
          frontmatter {
            title
          }
        }
      }
    }
  }
`;
Modifying createPages Function to use Tag Template
Now that we have created our template, we can now use the createPages function in the gatesby-node.js file to create our tag pages. If you already have a blog, you probably are already using the createPages function to create your blog posts. I modified my existing function to also use the tag template.
The first thing I did was modify the graphql query to also query for tags. The original query I had only queried for blog posts.
{
posts: allMarkdownRemark(
    sort: { fields: [frontmatter___date], order: DESC }
    limit: 1000
) {
    edges {
        node {
            fields {
                slug
            }
            frontmatter {
                title
                category
            }
        }
    }
}
}
I modified this query to also include all of my tags.
{
posts: allMarkdownRemark(
    sort: { fields: [frontmatter___date], order: DESC }
    limit: 1000
) {
    edges {
        node {
            fields {
                slug
            }
            frontmatter {
                title
                category
            }
        }
    }
}
tags: allMarkdownRemark(limit: 2000) {
    group(field: frontmatter___tags) {
        fieldValue
    }
}
}
Now that we have our query modified, we will need to create a page for all of the different tags. We can do this by using the createPage function that is injected into our createPages function.
const tagTemplate = path.resolve('src/templates/tags-list-template.js');

const tags = result.data.tags.group
// Make tag pages
tags.forEach(tag => {
    createPage({
    path: `/tags/${_.kebabCase(tag.fieldValue)}/`,
    component: tagTemplate,
    context: {
        tag: tag.fieldValue,
    },
    })
});
My completed createPages function looked like the following once I was done making my modifications.
exports.createPages = async ({ graphql, actions, reporter }) => {
    const { createPage } = actions;
    const postPage = path.resolve('src/templates/blog-post.js');
    const tagTemplate = path.resolve('src/templates/tags-list-template.js');

    const result = await graphql(`
      {
        posts: allMarkdownRemark(
          sort: { fields: [frontmatter___date], order: DESC }
          limit: 1000
        ) {
          edges {
            node {
              fields {
                slug
              }
              frontmatter {
                title
                category
              }
            }
          }
        }
        tags: allMarkdownRemark(limit: 2000) {
          group(field: frontmatter___tags) {
            fieldValue
          }
        }
      }
    `);
    if (result.errors) {
      console.log(result.errors);
      reporter.panicOnBuild(`Error whil running GraphQL query`);
    }

    const posts = result.data.posts.edges;
    const postsPerPage = 10;
    const numPages = Math.ceil(posts.length / postsPerPage);

    Array.from({ length: numPages }).forEach((_, i) => {
      createPage({
        path: i === 0 ? `/blog` : `/blog/${i + 1}`,
        component: path.resolve("./src/templates/blog-list-template.js"),
        context: {
          limit: postsPerPage,
          skip: i * postsPerPage,
          numPages,
          currentPage: i + 1
        }
      })
    });

    posts.forEach((edge, index) => {
      const next = index === 0 ? null : posts[index - 1].node;
      const prev = index === posts.length - 1 ? null : posts[index + 1].node;

      createPage({
        path: `blog${edge.node.fields.slug}`,
        component: postPage,
        context: {
          slug: edge.node.fields.slug,
          prev,
          next,
        },
      });
    });

    // Extract tag data from query
    const tags = result.data.tags.group
    // Make tag pages
    tags.forEach(tag => {
      createPage({
        path: `/tags/${_.kebabCase(tag.fieldValue)}/`,
        component: tagTemplate,
        context: {
          tag: tag.fieldValue,
        },
      })
    });

};
Creating an All Tags page
Now that we have created the template and the all of the tag pages using the createPages function in the Node API, we can create a page for displaying all of the tags. This works just like any other Gatsby page that uses a GraphQL query.
import React from "react"
import kebabCase from "lodash/kebabCase"
import Layout from "../components/layout"
import Navbar from "../components/navbar.js"
import Header from "../components/header.js"
import Footer from "../components/footer.js"
import Article from "../components/article.js"
import MainHelmet from "../components/mainhelmet.js"
import { Link, graphql } from "gatsby"

const TagsPage = ({
  data: {
    allMarkdownRemark: { group },
  },
}) => (
    <Layout>
        <MainHelmet title="Fek.io" />
        <Navbar />
        <Header headline="Tags" />
        <Article>
        <h1>Tags</h1>
      <ul>
        {group.map(tag => (
          <li key={tag.fieldValue}>
            <Link to={`/tags/${kebabCase(tag.fieldValue)}/`}>
              {tag.fieldValue} ({tag.totalCount})
            </Link>
          </li>
        ))}
      </ul>
      </Article>
      <Footer />
    </Layout>
);

export default TagsPage;

export const pageQuery = graphql`
  query {
    allMarkdownRemark(limit: 2000) {
      group(field: frontmatter___tags) {
        fieldValue
        totalCount
      }
    }
  }
`;
Making my Tags Linkable in my posts
Now that my Gatsby site is creating Tag pages for all of my different tags, I decided to add links to those pages in my posts. The first thing I did was add a new component called TagDecorator that I used to put a <Link> component around my Tag.
import React from "react"
import { Link } from "gatsby"
import kebabCase from "lodash/kebabCase"

const TagDecorator = props => {
    return (
        <span>
            <Link to={`/tags/${kebabCase(props.tag)}`}>{props.tag}</Link>
        </span> 
    );
}

export default TagDecorator;
I then modified my blog post template to use this new component around the tags in my post. I decided to leave them as comma separated list.
Since my tags are an array, I used the map function to populate the tags into my page. I also added some logic to add commas after each tag except for the last tag.
{tags.length &&
    <div style={{ fontWeight: 'bold' }}>
        <p>Tags: {tags.map((tag, i, arr) => (<>
            <TagDecorator tag={tag} />
            <span>
                {arr.length === i+1 ? `` : `, ` } 
            </span> 
        </>))} </p>
    </div>
}
Conclusion
Gatsby makes it very easy to query data from your site using GraphQL, and generate content and pages based on those query results. The more I use Gatsby, the more I am impressed with how you can make your content so dynamic using a static site generator.Tags: JavaScript,   Gatsby,   Tags,   Graphql   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJune 25th, 2021


Nearly a decade ago I used to use jQuery for manipulating the document object model, or (DOM), in my web applications. jQuery has been supplanted in popularity by other frameworks like Angular, Backbone and React. These frameworks have become almost a standard for web development.
I ran into a situation a couple of years ago where I had to watch for changes to a particular DOM element, and remove any children that were being added by another framework inside of a WebView. While it would have been more ideal to change the code in that framework not to add these unnecessary DOM elements, I did not have that option.
Welcoming the Mutation Observer
The Mutation Observer allows you to monitor any changes that are made to the DOM, and run your own code if needed. This code could be used if any elements are added, removed or attributes are added or changed. The Mutation Observer is one of the Web APIs that we get for free from the browser.
A common scenario of when we would use this API would be if a div element is added to a particular section, and we wanted to add an event listener for a mouse over.
The MutationObserver requires a constructor that takes a function that is used to handle those mutations. The constructor function takes the mutation list and an observer as parameters.
After defining a MutationObserver, you will also need to select the element or node you want to watch and call the observe function on the MutationObserver object. The observe function takes two arguments, one being the element to watch and the other being options we want to pass to the observer.
// Create your observer
const observer = new MutationObserver(function(mutationList, observer) {
    // Your handling code here
});

// Select the element you want to watch
const elementNode = document.querySelector('.myClassName');

// Call the observe function by passing the node you want to watch with configuration options
observer.observe(elementNode, { 
    attributes: false, 
    childList: true, 
    subtree: false }
);

// When ready to diconnect
observer.disconnect();
MutationObserver options
The Mutation Observer lets' us pass a lot of different options on what we want to observe. You can observe all items under the tree structure of the DOM element you are watching. You can also watch for the attributes changes to the element. At a minimum at least the childList, attributes, and or characterData must be true in order for the observer to watch a node. Here is a list of the different options you can pass.

subtree
childList
attributes
attributeFilter
attributeOldValue
characterData
characterDataOldValue

Click Listener Example
One example of how we could use the Mutation Observer if we are adding a div element to an element in out HTML, and we want to add an event listener to the div element any time the element is moused over. Lets' create a section with an id of 'div_section';
<section id="div_section">

</section>
Now lets' write some JavaScript to add a div element to this section.
const section = document.querySelector('#div_section');
let my_div_element = document.createElement('div');
my_div_element.className = 'div_element';
my_div_element.textContent = `My content goes here`;
section.appendChild(my_div_element);
The resulting HTML will look like the following once the JavaScript is executed.
<section id="div_section">
    <div class="div_element">My content goes here</div>
</section>
Now lets' write an event handler that prints a console.log anytime an event is fired.
function eventMouseOver(event) {
    console.log('This element was just moused over');
}
Now we can write a Mutation Observer to add this event listener anytime that a new div element with the class of div_element is added to our section.
const div_section = document.querySelector('#div_section');

const observer = new MutationObserver((mutationsList, observer) => {
    for(const mutation of mutationsList) {
        if (mutation.type === 'childList') {
            console.log('A child node has been added or removed.');
            const nodes = mutation.addedNodes;
            nodes.forEach(node => {
                node.addEventListener('mouseover', eventMouseOver);
            });
        }
    }
});

observer.observe(div_section, { 
    attributes: true, 
    childList: true, 
    subtree: true }
);
Now whenever someone mouses over our div element, we will get a console.log message that it has been moused over.
Here is a complete example below.
<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Sample</title>
    </head>
    <body>
        <h1>Sample</h1>

        <section id="div_section">

        </section>

        <script type="text/javascript">
            const div_section = document.querySelector('#div_section');

            const observer = new MutationObserver((mutationsList, observer) => {
                for(const mutation of mutationsList) {
                    if (mutation.type === 'childList') {
                        console.log('A child node has been added or removed.');
                        const nodes = mutation.addedNodes;
                        nodes.forEach(node => {
                            node.addEventListener('mouseover', eventMouseOver);
                        });
                    }
                }
            });
            
            observer.observe(div_section, { 
                attributes: false, 
                childList: true, 
                subtree: false }
            );

            function eventMouseOver(event) {
                console.log('This element was just moused over');
            }

            (function (){
                const section = document.querySelector('#div_section');
                let my_div_element = document.createElement('div');
                my_div_element.className = 'div_element';
                my_div_element.textContent = `My content goes here`;
                section.appendChild(my_div_element);
            })();
        </script>
    </body>
</html>
Conclusion
As we can see from my example above the Mutation Observer gives web developers a lot pf power over the DOM. This is especially in use cases where we may be required to use another framework that may be manipulating our HTML in a way we cannot control.
There are some frameworks that I have scene that are constantly traversing the entire DOM looking for changes. This is not necessary when you use the Mutation Observer API. Check out the documentation below.
https://developer.mozilla.org/en-US/docs/Web/API/MutationObserverTags: JavaScript,   Document Object Model,   DOM,   Mutation Observer   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJune 21st, 2021


I moved my site to Gatsby a couple of years ago. I have used several different blogging engines in the past including Orchard for .NET and BlogCFC. Both of these blogging engines support adding tags to your posts.
When I setup my blog I never bothered setting up tags because I could never get them to show up in my GraphQL queries. Going through my build logs today I discovered what the problem was, I was using two different types of tags in my FrontMatter.
Frontmatter
FrontMatter is a header that is placed at the beginning of your markdown files. FrontMatter usually contains properties for title and date, but you can also include other meta information that can be used by GraphQL when you are querying your markdown files.
---
title: "My Title Here!"
date: 2021-06-21
---
Usually in my markdown files I include a category, description and cover_image field. All of these fields are generally strings, a fairly simple type. For the markdown files I created, I did have a tag property for some of my posts, but I was not setting the value properly and consistently in my FrontMatter.
Since you can have more than one tag per post, it really is a list. In FrontMatter, if you have a property that requires a list, that is really an array.
FrontMatter is based on YAML or YML. If you want to express an array of data in FrontMatter, there are two ways you can do it. One way is to put your values inside of square brackets. This can look like the following example.
---
title: "My Title Here!"
date: 2021-06-21
tags: ["Gatsby", "JavaScript", "GraphQL"]
---
Another way of expressing this would be to add a new line and a dash for each item in your array.
---
title: "My Title Here!"
date: 2021-06-21
tags: 
    - "Gatsby"
    - "JavaScript"
    - "GraphQL"
---
Some of my posts had all of my tags inside of a single string. This was causing a conflict in the 'gatsby-transformer-remark' plugin when it was trying to resolve what type to render the tag.
// Don't do this
---
title: "My Title Here!"
date: 2021-06-21
tags: "Gatsby JavaScript GraphQL"
---
Render you tags
Once I had my tags changed to the correct type, I was able to query them in my Graphiql query tool. Here is the query I used for listing the posts I had with the tags included. You can find it in the edges.node.frontmatter.tags.
export const blogListQuery = graphql`
  query blogListQuery($skip: Int!, $limit: Int!) {
    allMarkdownRemark(
      sort: { fields: [frontmatter___date], order: DESC }
      limit: $limit
      skip: $skip
    ) {
      edges {
        node {
          fields {
            slug
          }
          frontmatter {
            title
            tags
          }
          excerpt
          timeToRead
        }
      }
    }
  }
`
In the data being fed by the query into the template component, I can't count on always having a tag because many of my previous posts did not have any tags. So I set up a default of an empty array when that is the case.
const tags = node.frontmatter.tags || [];
let taglist = 'Tags: ';
if (tags.length > 0) {
    taglist += tags.join(', ');
}
This creates an array that I can use in my render function to display the tags in my post.
{tags.length > 0 && 
    <div>
        <strong>{taglist}</strong>
    </div>
}
This checks to see if I have any tags, then uses && operator to display my tags. In React you can do this to conditionally display something in your render method.
Gatsby documentation
Gatsby actually does a pretty good job of documenting how to query FrontMatter in your Gatsby site. Check out their page on adding tags and categories to blog posts.
Conclusion
Tagging is considered an essential feature in Web 2.0. It gives users instant insights into what king of content is in your post, and it can also help with SEO.
I plan on adding a template to display all posts that match a particular tag listed in my post in an upcoming release.Tags: JavaScript,   Gatsby,   Graphql,   React   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJune 18th, 2021Like many other HBO Max subscribers I received an email titled "Integration Test Email #1" to the email I use for my HBO Max account. I decided to write a post about how you can send your own 'Integration Test Email' from Node.js. There are a couple of different ways.

      
    
  
  
    
Sending automated emails from a server application is something you need to be careful about. Email is typically sent out through the SMTP protocol. Internet service providers are cautious that bad actors are not using their networks for sending SPAM. So when when writing software that sends email we need to make sure that we do not do anything to get us blacklisted. It is very easy to do if you are not careful.
Nodemailer
The way I have sent email from Node.js in the past is by using a NPM module called Nodemailer. You can install it into your project by using the following terminal command.
> npm i nodemailer --save
To send out our "Integration Test Email" we can write a simple program that creates network connection to a SMTP server.
import nodemailer from 'nodemailer';

const mailconnection = nodemailer.createTransport({
    host: 'smtp.mydomain.com',
    port: 2525,
    auth: {
       user: '<USERNAME>',
       pass: '<PASSWORD>'
    }
});

const messageObj = {
    from: 'intern@hbomax.com',
    to: 'me@mydomain.com',
    subject: 'Integration Test Email #1',
    text: 'This template is used by integration tests only.'
};

mailconnection.sendMail(messageObj, function(err, result) {
    if (err) {
      console.err(err)
    } else {
      console.log(result);
    }
});
Testing with a development server
If you are going to test sending email, you might want to start by using a fake SMTP service. Mailtrap.io offers a free service you can use for testing your email features. I would use a service like this before trying to run an integration test on every customer email account in my database.
Third party services
There are third party services like Sendgrid and mailchimp that you can use for sending emails to your customers. The great thing about these services is they manage the complexity of staying off of email blacklists, and they offer APIs you can use for sending email rather than having to manage your own SMTP server.
These third party services also allow you to maintain lists. When you are sending out bulk emails, these services can also manage the users who want to opt out of receiving any more emails.
Conclusion
There are a lot of great tools available to Node.js developers who want to leverage automated email services. As our Intern found out at HBO MAX, we need to very careful how we use these tools so we do not SPAM our own customers with 'Integration Test Emails'. I am hoping that HBO is kind to this intern because this appears to be an honest mistake. Hopefully the Intern will be able to laugh about this soon as me an my friends have been this morning.Tags: JavaScript,   Node.js,   email,   nodemailer   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJune 16th, 2021


This is part three of a series of posts I am doing on using Postgres and TimescaleDB with Node.js.
In the previous posts I discussed how setup a dev instance of Postgres or TimescaleDB with Docker, and connect and query data from Node.js.
In this post we discuss TimescaleDB, and how to use it as an extension of Postgres.
TimescaleDB
TimescaleDB extends the functionality of Postgres by allowing a high volume of inserts and queries across a horizontally scalable version of Postgres. It does this with a new table type called a 'Hypertable'.

      
    
  
  
    
Hypertables are partitioned into 'chunks'. Chunks are created by partitioning the hypertable based on values belonging to a time column. Chunks are created automatically as data is added to the hypertable. TimescaleDB automatically determines the size of the chunk based on data being inserted over time.
Hypertables can also be partitioned by an additional column. These are called 'time and space' partitions. 'Time and space' partitioning are known as distributed hypertables. In this two dimensional partitioning, hypertables are partitioned over separate nodes.
Each chunk uses a standard database table, but these tables are child tables of one parent table, which is the hypertable. Each chunk includes constraints that contain the time ranges for that chunk. Even the space chunks contain those ranges.
When data is inserted into the hypertable, it is then routed into the proper chunk by the time constraint. When you query a time range, TimescaleDB will optimize the query to make sure that only the chunks are used that fit that time range.
In-memory
TimescaleDB places certain chunks in available memory. When querying data from a disk vs random access memory, memory is always faster. The most recent chunks will be kept in-memory. This ensures that the most recent data is stored in-memory, speeding up queries.
Not all chunks are kept in-memory. TimescaleDB uses LRU caching to decide which chunks are kept in memory and which is kept on disk pages.
Local Indexes
Indexes are kept in their respective chunks. This maintains that data and the indexes resides in the same memory. This ensures that inserting data is kept speedy since it is being performed in the RAM.
TimescaleDB ensures that primary keys remain unique because they are usually a combination of a unique column and a time column. When a user creates a new index, it is passed down to every chunk in the hypertable.
Deleting Data
Data retention in TimescaleDB is made easy because time ranges can be set on a hypertable to remove data based on a time period. Since the data is stored in chunks instead of a single table, TimescaleDB simply removes the associated file. No defragging of a table is required since the data is kept in separate chunks.
Data retention policies can be created to manage this maintenance automatically.
Creating a Hypertable
To a create a hypertable in TimescaleDB, we only need to do two things. Make sure the table you want to base you hypertable on has a primary key based on a timestamp column, and use the create_hypertable function on that table. Thats it! TimescaleDB does the rest for us automatically.
Lets' define a table for storing an account_transaction table. This table will contain a reference to a user, the time the record was inserted, and a transaction amount. We will make the primary key be a combination of the user_id and the time. After that we will use the create_hybertable function to create the actual hypertable.
CREATE TABLE account_transaction (
    user_id INTEGER NOT NULL,
    dt TIMESTAMP WITHOUT TIME ZONE NOT NULL,
    amount DECIMAL NOT NULL,
    source TEXT NULL,
    PRIMARY KEY(user_id, dt) 
);

SELECT create_hypertable('account_transaction', 'dt');
Congratulations! You just created your first hypertable.
Conclusion
Both TimescaleDB and Postgres solve many of the issues that prevented application developers from using relational databases in their solutions. Relational databases can scale and perform in modern scalable cloud based architectures.
There is a lot more to TimescaleDB than what I have posted here. Please take the time to review the documentation on the TimescaleDB site.Tags: Postgres,   SQL,   TimescaleDB,   Node.js   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJune 13th, 2021


I was getting ready to create a set of slides for my next presentation. I usually use slides.com to create and host my slides. If you have not looked at slide.com before, it is a great example of the power of web applications. Slides.com has a presentation editor that is based on Reveal.js, a JavaScript library for making animated slide shows. I am a firm believer that you do not need Powerpoint to make slide shows. This can be done as a web app.
As I was getting ready to start my next set of slides I found out I had exceeded my limit of free slides. So I have decided to move my slides over to my Gatsby site.
The first thing I had to do was export all of my slides. Slides.com gives you the ability to import and export slides into and out of their application. It will allow you to export your slides as a self contained HTML application in a single HTML file.
Gatsby allows you to host static content in your site so that if you need to serve static css or images, this can be easily configured. You will need to install the 'gatsby-source-filesystem' plugin in order to serve these files.
> npm i gatsby-source-filesystem --save
The above command will install the plugin into your Gatsby site. After it has been installed, you will need to configure the plugin in your 'gatsby-config.json' file. Add the following configuration into the plugins export.
plugins: [
      {
        resolve: `gatsby-source-filesystem`,
        options: {
          name: `static`,
          path: `${__dirname}/static`
        },
      }
];
This will look into a 'static' folder for any static files you need to serve. I added another folder underneath my static folder called 'slides', and placed my HTML files in that folder.
To retrieve a list of slides from our static folder, we will need to write a graphql query to get that list of files. You can test this by using the Graphiql editor hosted in the development server. You can access this by going to http://localhost:8000/___graphql.
{
    myslides: allFile(filter: { relativeDirectory: {eq: "slides" }}) {
      edges {
        node {
          name
          relativePath
        }
      }
    }
}
The next need you will need to do is create a Gatsby page to list the slides in your 'slides' folder. I created one underneath the root of my '/src/pages' called 'slides.js'. Here is what my react code looked like in my 'slides.js' file.
import React from "react"
import { Link, graphql } from "gatsby" 
import Layout from "../components/layout"
import Navbar from "../components/navbar.js"
import Header from "../components/contactheader.js"
import Footer from "../components/footer.js"
import Article from "../components/article.js"
import MainHelmet from "../components/mainhelmet.js"

const Slides = ({ data }) => (
    <Layout>
        <MainHelmet title="Fek.io" />
        <Navbar />
        <Header headline="About FEK.IO" />
        <Article>
        <div>
            <h1>Slides</h1>
            <p>Here are copies of my slides from my presentations.</p>
            {data.myslides.edges.map( ({node}) => {
                const link_path = `/${node.relativePath}`;
                return (<div key={node.name}>
                        <a href={link_path}>{node.name}</a>
                    </div>)
                })
            }
        </div>
        </Article>
        <Footer />
    </Layout>
)

export const query = graphql`{
    myslides: allFile(filter: { relativeDirectory: {eq: "slides" }}) {
      edges {
        node {
          name
          relativePath
        }
      }
    }
}`;

export default Slides;
If you look at the section on line 22 that has a map on the edges of the result data.myslides.edges.map, I am returning an anchor tag instead of a Link tag for displaying the link. This is because the Link tag is only used for gatsby pages. Since this is static HTML content we want to use a normal anchor tag.
Conclusion
Gatsby is great at doing many different things. On top rendering react content and Gatsby content, you can also use it to serve up static content as well as long as you configure your site correctly.
There are also a number of plugins you can use for creating slides from markdown that I plan on looking at as well.
You can view my slides page at here.Tags: Slides,   HTML,   Reveal.js   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJune 11th, 2021


This is part two of a three part series on using Postgres DB with Node.js.
Read part one here.
In the first part of this series I wrote about how to get an instance of Postgres or TimescaleDB running and communicating with Node.js. In this post we will describe how tables and indexes are used to store and query data. We will also cover DDL, DML and DQL SQL statements.
Tables and Indexes
Relational database software is composed of specific database objects such as tables and indexes. Some systems also have objects like sequences. This will depend on the vendor.
Tables are used to store your raw data. Tables are composed of columns and rows. You will use columns to store individual fields in your table, while rows are used to store entire records.

      
    
  
  
    
Defining Tables
Creating tables is fairly simple. This can be done with a CREATE TABLE statement. This kind of query is considered part of the Data Definition Language or DDL for short.
Lets' say we wanted to create a table for storing persons. We would probably need to have columns for the person's name, the date the record was created and some sort of record identifier or id. We could create a table like this with the following statement in Postgres;
CREATE TABLE person (
    id SERIAL PRIMARY KEY,
    firstname TEXT NOT NULL,
    lastname TEXT NOT NULL,
    createdate TIMESTAMP DEFAULT NOW() NOT NULL,
    active BOOLEAN DEFAULT TRUE NOT NULL
);
In the table we just created we have a column we defined as id which will be the primary key for our table. The primary key is the way we can uniquely identify a specific record in our table. In the example above we have given it a type of SERIAL which tells Postgres to autogenerate a new value every time we create a new record. Internally this value is stored as an INTEGER.
For the firstname and lastname we created TEXT columns. The TEXT type can represent any varying sized text data in that column. Most database systems allow the developer to limit the size of these columns using a VARCHAR type. So if we only want to allow the column to store a maximum of 30 characters, we can express that by defining a VARCHAR(30).
Most of the columns in our table end with a NOT NULL. This tells Postgres that we will not allow a record to be added to our table unless it has a non-null value for that column. We could also have specified NULL. This will allow the column to store NULL values.
We can also specify a DEFAULT value. For our createdate column and our active columns, we have specified a default value. For the createdate column we are using the NOW() function to use Postgres for the date if we do not pass a value into that column. The active column can by true or false, so I used a default of TRUE.
Indexes
Most relational databases allow for the creation of indexes. Indexes make it possible to quickly search through a table for a row or rows by maintaining a reference to a column in a table. You will want to add an index to any column that you want to reference in query for specifically related rows.
CREATE UNIQUE INDEX person_firstname_idx ON person (firstname);
Structured Query Language (SQL)
One of the hallmarks of relational databases is the Structured Query Language, or SQL for short. SQL is actually a standard. While most database software will have their own flavor of SQL, they all should at least correspond to an ANSI SQL standard.
The idea is if write a query for one vendor, it should work for all of the other vendors as long as you follow that standard. I have worked at a couple of companies that used the same SQL queries across multiple database systems from different vendors.
SQL has essentially four commands that you can use when you are writing queries.

SELECT
INSERT
UPDATE
DELETE

The SELECT command is used to query data from the table. The INSERT command is used to add records to a table. UPDATE is used to update columns in a table, and DELETE is used to remove records from a table.
The INSERT, UPDATE and DELETE commands are all considered a Data Manipulation Language or DML. The SELECT command is usually just used for querying data from tables, and is considered a Data Query Language.
SELECT
Lets' say we have a table that stores an entity called person. If we want to query all of the records from that person table, we can express that with the following SQL statement.
SELECT * 
FROM person;
The query above will return all rows from our table. If we only need the id, firstname and lastname from that table, we can express that with the following query.
SELECT id, firstname, lastname
FROM person;
If we only want to return the records in a table that match a specific value in one of the columns, we can do that with the WHERE clause.
SELECT id, firstname, lastname
FROM person
WHERE username = 'admin';
INSERT
If we want to add a record to our table, we can do this by specifying the columns we want to add and their respective values.
INSERT INTO person
    (firstname, lastname, active)
VALUES
    ('Phil', 'White', TRUE);
UPDATE
UPDATE can change the values of individual records or multiple records at the same time. If we wanted to set the active column to false for one record in our table, we could express that with the following example.
UPDATE person
    SET active = TRUE
WHERE
    lastname = 'White';
DELETE
If we want to delete a record or records we can do that using the DELETE. Please be careful using this command. If you make a mistake there is no edit -> undo. To see the danger, lets' look at the following statement.
-- Please don't do this!
DELETE person;
The statement above will delete every record from our table. The only way to retrieve your deleted data would be with a database restore, with most database systems is not an easy task.
If you want to remove one specific record, you can do this by adding a WHERE clause.
DELETE person
WHERE
    id = 68978921;
The Relational in a Relational Database
Whats makes SQL databases relation is the ability to query data from multiple tables at the same time, and combine the records into a single result that makes sense. SQL databases do this through JOIN syntax in the query.
Lets' say we have our person table, and we want to add a user_t table. I am naming the user table with a '_t' at the end because the user object name is already used in Postgres. We can create this user_t table, there is no reason to recreate firstname or lastname columns because we can store a reference back to the person table. Lets' create a user_t table to see how we would do that in SQL.
CREATE TABLE user_t (
    id SERIAL PRIMARY KEY,
    username TEXT NOT NULL,
    passwordhash TEXT NOT NULL,
    person_id INTEGER NOT NULL REFERENCES person(id), 
    createdate TIMESTAMP DEFAULT NOW() NOT NULL,
    active BOOLEAN DEFAULT TRUE NOT NULL
);

CREATE INDEX user_t_username_idx ON user_t (username);
Now we can query both the person table and the user_t table at the same time. We can do this by using the JOIN keyword in the FROM clause.
SELECT 
	person.id, person.firstname, person.lastname, user_t.username
FROM
	person
		JOIN user_t
			ON person.id = user_t.person_id
WHERE person.lastname = 'White';
If I were to perform the query above without a matching person_id in my user_t table, the query will not return any results. But if I make the join a LEFT JOIN, this will return all records in the person table that have a matching lastname, and it will leave username NULL. The table on the left hand side of the join will have precedence.
Adding Postgres to Node.js
Assuming we have our Postgres or TimescaleDB database running, and we want to start using it as our persistence store in Node, we can do this with the pg module. If you want to add the pg model to an existing Node.js project, you can npm install it in your terminal like so.
> npm i pd --save
This will install the module into our Node.js project and create a dependency in our 'package.json' file.
Query Postgres data in Node.js
Now that we have the pg module installed, lets' create a simple app that can query our person data, and output the results on the command line. Lets' create a file in our project called 'printallpeople.js'.
After we create the file lets' import the pg module, and create a Pool from pg module to query the data from our Postgres database.
// printallpeople.js

// import in the Postgres module
import PG from 'pg';

// Get Pool object from using a destructor 
const { Pool } = PG;

const pool = new Pool({
    user: 'postgres',
    host: 'localhost',
    database: 'etfdb',
    password: 'password',
    port: 5432
});

// I am defining my query in this statement variable. 
// Notice how I am using $1 for the parameter in the WHERE clause
const statement = `
    SELECT firstname, lastname, createdate 
    FROM person 
    WHERE active = $1;
`;

// This is where we make our query against Postgres, passing in any parameters into an array.
const data = await pool.query(statement, [true]);

// The records will be returned in a result object.
// The result object has a property called `rows` that has an array of objects for each record being returned.
for (let row of data.rows) {
    console.log(`firstname: ${row.firstname}, lastname: ${row.lastname}`);
}

// We close the pool once we are done.
pool.end(() => {
    console.log('closing the pool');
});
Conclusion
As you can see it is very easy to connect to a Postgres database and query the data in database tables using Node.js. We are only scratching the surface here of what we can do in Postgres and TimescaleDB.
In the next post in this series I plan on showing the additional functionality that you get from Postgres and TimescaleDB, and how we can use it in Node.js.Tags: Postgres,   SQL,   TimescaleDB,   Node.js   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJune 9th, 2021


This is part one of a three part series on using Postgres DB with Node.js.
Prerequisites
To use the examples in this post you will need to have the Docker client and Node.js installed on your computer.
Postgres
I am going to be giving a presentation next week and using Postgres SQL and TimescaleDB with Node.js for the JaxNode user group. If you are not familiar with Postgres, it is a relation database server that is very popular in the open source world, but also used heavily by large organizations. Whether you are large or small, you can use Postgres. There are Postgres services that are available on most of the large cloud providers.
To understand what a relation database is and how we can use it in our applications we need to understand what a relational database does. At the end of the day all a database is a piece of software that lets' us persist data onto non-volatile memory, and query the data back quickly in our applications. Non-volatile memory can be anything from flash memory to a large drive array.
NoSQL vs SQL Databases
Postgres is a SQL database, or Structured Query Language database. SQL is an industry standard for a query language. There are many of other types of databases including graph databases, document databases and column stores. There are many reasons why you may want to use a NoSQL database, but the main reason might be scalability. While NoSQL database in many cases might be more scalable, they tend not to be as consistent as a SQL database because of the nature of how they store data. The nice thing about about Postgres is that it offers features that can be found in both types of database systems.
Developing with Docker
You have to option to install Postgres on whatever machine you are developing on, or even a server, but I like to use Docker. You can install the Docker client by going to Docker.com, and downloading the docker installer.
To run this project you will need to have Node.js and Docker installed on your computer. These examples require a TimescaleDB database. TimescaleDB is an extension to the Postgres database.

Add a directory to your local file system for storing the data. On my system I created one called timescale-data.

> mkdir ${HOME}/timescale-data

Run the following command in your terminal to start a local instance of TimescaleDB

> docker run -d --name dev-timescaledb -e POSTGRES_PASSWORD=password -v ${HOME}/timescale-data/:/var/lib/postgresql/data -p 5432:5432 postgres
This will have started a local instance of TimescaleDB.

Now check and see if TimescaleDB is running. Run the following command;

> docker ps
This will list all running instance on your docker machine.

Stop the docker instance by using the following command;

> docker stop dev-timescaledb

To view your local image of this in docker use the following command;

> docker ps -a

Start the instance back up by using the following command;

> docker start dev-timescaledb

Enter into the TimescaleDB container by typing in the following command;

> docker exec -it dev-timescaledb psql -U postgres

Create a database in postgres that we can use for our data by entering the following command into your container;

postgres=# create database etfdb;
\c etfdb;
You have now created a database called etfdb. All of our tables and queries will be using this database.
Add the following tables to your etfdb database;
CREATE TABLE stock (
    id SERIAL PRIMARY KEY,
    symbol TEXT NOT NULL,
    name TEXT NOT NULL,
    exchange TEXT NOT NULL,
    is_etf BOOLEAN NOT NULL
);

CREATE TABLE mention (
    stock_id INTEGER,
    dt TIMESTAMP WITHOUT TIME ZONE NOT NULL,
    message TEXT NOT NULL,
    source TEXT NOT NULL,
    url TEXT NOT NULL,
    PRIMARY KEY (stock_id, dt),
    CONSTRAINT fk_mention_stock FOREIGN KEY (stock_id) REFERENCES stock (id)
);

CREATE INDEX ON mention (stock_id, dt DESC);
Populating the Tables
I have some data that you can use to populate your tables in the following github repo.
https://github.com/davidfekke/wallstreetbets
To create the stock records, run the following nodejs script;
> git clone https://github.com/davidfekke/wallstreetbets && cd wallstreetbets
> npm install
> node importstocks.js
You now have the working data to run the main index.js example.
Conclusion
From this first post we can see it is very easy to install and get Postgres running on your development machine. Over the course of our next few posts we will write data to the database and query data back.Tags: Postgres,   SQL,   TimescaleDB,   Node.js,   Docker   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJune 7th, 2021I live streamed the WWDC21 developer keynote tonight to go over new features Apple is adding for iOS and Swift developers.



I will be discussing some of the new APIs announced by Apple, the developer tools and new async language features added to Swift.
Updated 8:27 PM
So I was able to watch both the Keynote as well as the Platforms State of the Union. Apple announced MaxOS 12 Monterey, iOS/iPadOS 15, watchOS 8 and a new tvOS. There was a lot of emphasis placed on the SharePlay API, AR technologies as well different modes for 'do not disturb'. Users can now tailer how and what kind of notifications they depending how busy they are at the time.
Xcode Cloud
A couple of years ago Apple bought a company that allowed developers to build their Xcode projects in the Cloud. This may be the end result of that purchase. Apple unveiled a beta for 'Xcode Cloud' today. It gives developers on a team a way of creating apps on a build server. It also looks like Xcode will allow developers to use qit pull requests to kick off new builds, and send the updated apps to TestFlight.
There are other services that allow you to do this now, but it looks like Apple is providing a way for you to do this using their services. Currently GitHub users can do this using GitHub actions. There is some setup, but I am guessing Apple is going to try to streamline the whole process.
Swift Concurrency
Chris Lattner originally published his Concurrency Manifesto back in 2017. We are finally seeing really cool concurrency features being added to Swift as language.
Async/Await
The async and await keywords are currently already in use in languages like C# and JavaScript. Async and await effectively allow a developer to take a function that calls a long running process that requires a trailing closure, and replace it with a call that looks more like a synchronous call. Lets' take a look at a function that that has five embedded trailing closures listed in the manifesto.
func loadWebResource(_ path: String, completionBlock: (result: Resource) -> Void) { ... }
func decodeImage(_ r1: Resource, _ r2: Resource, completionBlock: (result: Image) -> Void)
func dewarpAndCleanupImage(_ i : Image, completionBlock: (result: Image) -> Void)

func processImageData1(completionBlock: (result: Image) -> Void) {
    loadWebResource("dataprofile.txt") { dataResource in
        loadWebResource("imagedata.dat") { imageResource in
            decodeImage(dataResource, imageResource) { imageTmp in
                dewarpAndCleanupImage(imageTmp) { imageResult in
                    completionBlock(imageResult)
                }
            }
        }
    }
}
We can take this and rewrite it as function that uses the async keyword instead of a trailing closure, and we simply place the await keyword in front of any function call that we would normally wait for a response.
func loadWebResource(_ path: String) async -> Resource
func decodeImage(_ r1: Resource, _ r2: Resource) async -> Image
func dewarpAndCleanupImage(_ i : Image) async -> Image

func processImageData1() async -> Image {
    let dataResource  = await loadWebResource("dataprofile.txt")
    let imageResource = await loadWebResource("imagedata.dat")
    let imageTmp      = await decodeImage(dataResource, imageResource)
    let imageResult   = await dewarpAndCleanupImage(imageTmp)
    return imageResult
}
As you can see from this second example, this is much easier to read and is missing that tree-like structure of callbacks.
Actors
Actors have been popular in other languages for while as a way to encapsulate data inside of a DispatchQueue. They have their own keyword called actor for constructing objects similar to the class or struct keyword. But unlike classes or structs, actors eliminate shared mutable state.
// Sample from swift.org
// https://docs.swift.org/swift-book/LanguageGuide/Concurrency.html
actor TemperatureLogger {
    let label: String
    var measurements: [Int]
    private(set) var max: Int

    init(label: String, measurement: Int) {
        self.label = label
        self.measurements = [measurement]
        self.max = measurement
    }
}
SwiftUI improvements
SwiftUI is still a fairly new framework for building UIs, so I am expecting to see a lot of improvements this year. I am looking forward to seeing what new features they are adding. The one thing I did see so far is a way of determining which os the view is running on so you can turn certain functionality on or off depending the operating system.
SharePlay API
In multi-user apps like FaceTime and Messages, Apple showed how many users can now interact with the same content in a app at the same time using the SharePlay API. They demonstrated users sharing a whiteboard and multiple users controlling the playback of a movie at the same time.
Conclusion
I am looking forward to drilling down into the details of these different features and APIs over the next couple of days.Tags: WWDC21,   Swift,   iOS,   iPadOS   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJune 6th, 2021


I recently wrote about creating your own tools using Node.js. There are a lot of applications now that are based on Node.js that you can extend using JavaScript. One of those applications is one that I am using right now as I write this post, Visual Studio Code.
VS Code
If you are not familiar with Visual Studio Code, or VSCode for short, it is Microsoft's open source code editor. It is used for many different types of application development, everything from C++ to Salesforce. From the very beginning VSCode has been extensible, in other words you add functionality to it very easily with extensions. These extensions are written in JavaScript.
VSCode code is built on top of Electron, a framework from GitHub that is based on Chromium and Node.js. Electron was created to make it easier for web developers to create desktop applications. Web developers can use their existing skillsets to create application based on web technologies like HTML, CSS and JavaScript. These electron apps can run cross platform on Windows, MacOS and Linux.
Creating a plugin
I created a command line tool for generating new blog posts a couple of years ago called 'blogpostgenerator'. You can find it on NPM. This tool creates a folder named after the current date, and then creates a markdown file with some frontmatter for metadata.
Microsoft has pretty good documentation on how to create an extension for VSCode, but I was looking at creating an extension that could take some user input for the name of the file I was trying to create. Here is how I created my extension.
You can create a hello world extension using Yoeman and a VSCode generator called 'generator-code'.
npm install -g yo generator-code
yo code
When running this, I chose JavaScript over TypeScript. If you are adding modules you will need to add a bundler like esbuild or webpack. If you use the TypeScript option, it will give you an option to install it with webpack.
This will generate a new extension project. This newly scaffolded extension can be opened and debugged in Visual Studio Code.
code .
You will see a number of files in your project, including an extension.js, jsconfig.json and package.json files. Open up the extension.js file.
// The module 'vscode' contains the VS Code extensibility API
// Import the module and reference it with the alias vscode in your code below
const vscode = require('vscode');

// this method is called when your extension is activated
// your extension is activated the very first time the command is executed

/**
 * @param {vscode.ExtensionContext} context
 */
function activate(context) {

	// Use the console to output diagnostic information (console.log) and errors (console.error)
	// This line of code will only be executed once when your extension is activated
	console.log('Congratulations, your extension "myhelloworld" is now active!');

	// The command has been defined in the package.json file
	// Now provide the implementation of the command with  registerCommand
	// The commandId parameter must match the command field in package.json
	let disposable = vscode.commands.registerCommand('myhelloworld.helloWorld', function () {
		// The code you place here will be executed every time your command is executed

		// Display a message box to the user
		vscode.window.showInformationMessage('Hello World from myhelloworld!');
	});

	context.subscriptions.push(disposable);
}

// this method is called when your extension is deactivated
function deactivate() {}

module.exports = {
	activate,
	deactivate
}

The activate function is the main entry point for the extension. It registers a command with the vscode.commands.registerCommand function. The command corresponds with the commands that are listed in the package.json file in the "contributes" key.
  "contributes": {
    "commands": [
      {
        "command": "myhelloworld.helloWorld",
        "title": "Hello World"
      }
    ]
  },
We can run and test this in VSCode by pressing the F5 key, which will launch an extension host. We can then press 'command-shift-P' on the MacOS or 'control-shift-P' on Windows or Linux. This will prompt the user with the Command Palette. Here we can type in Hello World. This will show the information box with a message from our command.
Lets' modify this to create a markdown file we can use to add to our blog.
Add the following requires to the beginning of our file underneath the line with const vscode = require('vscode'). It should look like this when you are done.
const path = require('path');
const fs = require('fs');
const _ = require('lodash');

let blogfolder = 'src';
The 'path' and 'fs' modules are included for free with VSCode, but we will need to install 'lodash' into our dev dependencies. We can do this in the command line in the same path as our project.
npm install lodash --save-dev
This will add 'lodash' into our "devDependencies" section of our 'package.json' file and the actual module to our 'node_modules' folder. An important point to note here is that when it comes time to package and publish our actual extension, the 'node_modules' folder will be excluded. We will need to add a bundler to make sure that the functionality we need from lodash is included in our final extension. We will do into more detail on how to add and configure a bundler at the end of this post.
Now lets' add the following functions to the end of our extension.js file.
function startInputProcess() {
	vscode.window.showInputBox({
		value: '',
		placeHolder: 'Enter Your Title Here'
	}).then(result => { 
		createMarkdownFolder(result);
	}).catch(err => console.log(err));
}

function createMarkdownFolder(input) {
	let folderPaths = vscode.workspace.workspaceFolders;
	const allWorkspaceolders = folderPaths.map(folder => {
		return folder.uri.path;
	});

	if (allWorkspaceolders.length > 0) {
		const myConfig = vscode.workspace.getConfiguration('myhelloworld');
		const subfolder = myConfig.blogSourcePath || blogfolder;
		const currDate = getDateString();
		const title = input || 'Your Title Here';
		const folderPath = path.join(allWorkspaceolders[0], subfolder, currDate);
		let markdownFilename = 'index.md';
	
		if (!fs.existsSync(folderPath)) {
			fs.mkdirSync(folderPath);
		}
		
		if (title !== 'Your Title Here') {
			markdownFilename = _.kebabCase(title) + '.md';
		}
	
		const frontmatter = `---
layout: post
title: "${title}"
description: ""
category: 
date: ${currDate}
cover_image: "./unnamed.jpg"
---
`;
	
		const markdownPath = path.join(folderPath, markdownFilename);
		createMarkdownFile(markdownPath, frontmatter);
		vscode.window.showInformationMessage(`Created a COOL post at ${markdownFilename} in ${subfolder}`);
	} else {
		vscode.window.showErrorMessage('Must have a workspace folder selected');	
	}
}

function getDateString() {
	const currDate = new Date();
	const month = currDate.getMonth() + 1;
	const date = currDate.getDate();
	const year = currDate.getFullYear(); 
	const formattedDate = `${year}-${addLeadingZeros(month)}-${addLeadingZeros(date)}`;
	return formattedDate;
}

function addLeadingZeros(n) {
	if (n <= 9) {
	  return "0" + n;
	}
	return n
}

function createMarkdownFile(mdp, frontmatter) {
	if (!fs.existsSync(mdp)) {
		fs.writeFileSync(mdp, frontmatter);
	} else {
		vscode.window.showErrorMessage(`This file ${mdp} already exists.`);
	}
}
The first function here, 'startInputProcess' actually will prompt the user for what title they want to assign to their post. Once the title has been captured, it calls the 'createMarkdownFolder' function, which will create the subdirectory for our content and markdown file. The folder name will be based after the current date, We use two functions 'getDateString' and 'addLeadingZeros' to create a folder name. The last function 'createMarkdownFile' will actually create the markdown file in the folder we just created.
Now lets' alter the `activate(context)' function so that it uses the code we added to our 'extension.js' file.
async function activate(context) {

	// Use the console to output diagnostic information (console.log) and errors (console.error)
	// This line of code will only be executed once when your extension is activated
	console.log('Congratulations, your extension "myhelloworld" is now active!');

	// The command has been defined in the package.json file
	// Now provide the implementation of the command with  registerCommand
	// The commandId parameter must match the command field in package.json
	let disposable = vscode.commands.registerCommand('myhelloworld.createMarkdownPost', function () {
		// The code you place here will be executed every time your command is executed

		// We start the process here
		startInputProcess();
	});

	context.subscriptions.push(disposable);
}
This extension also uses a settings that we can assign to the extension, and can be modified by the end user. We will need to modify the package.json file to add these settings options. We can do this by adding a "configuration" key to the "contributes" section of our 'package.json'.
    "contributes": {
		"configuration": {
			"title": "Gatsby Blog Post",
			"properties": {
				"myhelloworld.blogSourcePath": {
					"type": "string",
					"default": "src",
					"description": "This is the path where you store your blog markdown"
				}
			}
		},
		"commands": [
			{
				"command": "myhelloworld.createMarkdownPost",
				"title": "Create Markdown Post"
			}
		]
	},
This will add a setting that can be looked up in our code. Here we have defaulted it to 'src', but the user will be able to change this to any path underneath their project they desire.
Bundling our extension
I previously mentioned that since we are using the external module 'lodash' that we will need to bundle this extension. It is a good practice to bundle your extension no matter what. We will use 'esbuild' to bundle our extension. Lets go to the command line again for our project and add the following modules.
npm i --save-dev esbuild
We will need to add the following script properties to the "scripts" section of our 'package.json' file.
    "vscode:prepublish": "npm run -S esbuild-base -- --minify",
    "esbuild-base": "esbuild ./extension.js --bundle --outfile=out/main.js --external:vscode --format=cjs --platform=node",
    "esbuild": "npm run -S esbuild-base -- --sourcemap",
    "esbuild-watch": "npm run -S esbuild-base -- --sourcemap --watch",
    "test-compile": "tsc -p ./"
We will also need to change the "main" property so that it points to our 'main.js' file in the 'out' subdirectory.
"main": "./out/main.js"
Now we can bundle our extension using the following npm script in the command line.
npm run esbuild
Packaging our extension
Packaging our extension for local use or publishing to their marketplace requires adding and using the 'vsce' command line tool and registering as an organization on Azure DevOps. Lets install 'vsce' first.
npm i -g vsce
If you do not have an organization on Azure DevOps, you can do this by following the instructions here. Once you have created an org, you will need to create a personal access token. This token will need to have the following details when you create it.

Assign a Name
Make sure the Organization is accessible to all organizations
Set the Scopes to 'Custom defined', and make sure to assign Marketplace > Manage scope

Once the Personal Access Token has been created, make to copy it in a safe place because you will need it once you login with the 'vsce' command line tool.
Now that you have the public access token, we can login and package our extension using 'vsce'.
vsce login <YourOrgName>
It will prompt you for your personal access token. Once you have successfully logged into 'vsce', you can package your extension with the following command.
vsce package
This will create a .vsix file. You can share this file and install it locally to VSCode by
entering the following command.
code --install-extension <yourExtensionName>-0.0.1.vsix
Conclusion
One of the wonderful things about VSCode is that we can extend it using JavaScript and TypeScript. This makes it very easy for creating our own developer tools as publishing extensions. Kudos to Microsoft for sponsoring such a wonderful tool for developers!
https://code.visualstudio.com/api/get-started/your-first-extension
https://code.visualstudio.com/api/working-with-extensions/bundling-extension
https://code.visualstudio.com/api/working-with-extensions/publishing-extensionTags: VSCode,   JavaScript,   Extensions,   Node.js   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJune 3rd, 2021


It has been just over five years since the event known as 'LeftPad Apocalypse'. In March of 2016 an NPM user removed their module 'Left-pad' from the NPM repository, resulting in the breaking of any Node.js application which had that dependency.
It was a wake up call for the Node.js community, and some changes where implemented to NPM after this incident to prevent this from happening again.
What exactly happened
A company called Kik with a messenger app wanted to use the same module named 'kik' as another user, Azer Ko√ßulu, on NPM. They sent Mr. Ko√ßulu an e-mail from a patent attorney asking him to relinquish the module named 'kik'. Mr. Ko√ßulu declined to give up the module name. Kik then went to NPM with a trademark request to give them access to the module, which they eventually did.
Mr. Ko√ßulu after loosing the module name decided to un-publish all 250 of his other modules from NPM. One of those modules was a module that was used in thousands of projects including Babel.js. When he un-published 'left-pad', it essentially broke the internet. This is because so many projects rely on NPM, not to mention that modules also have their dependencies. You wind up with these giant tree structures of dependencies sometimes 10 levels deep. If you want to visualize this, simply run npm list in your modules directory.
This was caused by a module at the time that was only 11 lines long.
module.exports = leftpad;

function leftpad (str, len, ch) {
  str = String(str);

  var i = -1;

  if (!ch && ch !== 0) ch = ' ';

  len = len - str.length;

  while (++i < len) {
    str = ch + str;
  }

  return str;
}
Laurie Voss, who was the CTO of NPM at the time took the unprecedented step of un-un-publishing a module. NPM as a company was still fairly young, and had not run into this scenario before. They made a change to their system that would prevent users from un-publishing a module if there were dependencies on that module to prevent a repeat of this incident.
Here are some posts on the actual incident;
Kik: A discussion about the breaking of the Internet
Azer Ko√ßulu: I've just liberated my modules
David Haney: Have we forgotten how to program?
NPM Blog: kik, left-pad, and npm
Rethinking NPM modules
One of the great things about Node can also be a weakness, the ability to npm i any functionality at a whim.

      
    
  
  
    
Before installing any NPM module you should first ask yourself, do I really need to include this module? A great example of this is moment.js. Moment is primarily used for working with date objects in JavaScript. It can also format dates and get date parts.
const year = moment().format('YYYY'); 
You can also accomplish the same thing by calling the getYear() function on the date object in JavaScript.
const year = new Date().getYear();
Local repos
A lot of larger organizations now pre-approve which NPM modules can be used in a project. Some use local repos so that their developers only use pre-approved modules in their applications.
NPM also offers a local version of NPM so you can run just run it for your organization.
Deno's Approach
If you are not familiar with Deno, it is an alternative JavaScript runtime from Ryan Dahl, the inventor of Node.js. One of the things that Ryan did when he created Deno was rethink how he did certain things in Node.
Node.js does not have a standard library. When Ryan created Deno, he also made sure that it included a standard library of modules you can use without having to install third party modules.
Deno also allows developers to import modules directly from the source, so there is no need for a package manager. You can simply import 'https://github.com/someuser/mymodule/main/src.js' in your app, and Deno will cache the module locally on your system.
Deno also has a dependency inspector you can use to evaluate your dependencies. Simply run deno info, and Deno will run it's inspector.
Researching your modules
Before you npm install any module you have not worked with before, take a look at the source. Most of the modules on NPM are open source or have a license where you can look at the source code. LOOK AT THE SOURCE!!!
Another thing to look at is the dependencies used by that module. One of the things you should look at is how old are those dependencies, and are there any security concerns. NPM provides a security audit you can perform on your modules.
npm audit
nome audit will generate a report with any vulnerabilities. You can also use npm audit fix to address any vulnerabilities in the module.
Conclusion
NPM can add a ton of extra functionality to your Node applications, but you should only use it when you need a specific functionality not already provided. Consider writing your own modules when possible.
Most modules on NPM are open source projects, and most are also on Github. If you find a problem with an existing module, consider making a pull request to give back to this awesome community.Tags: JavaScript,   NPM,   Node.js   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJune 1st, 2021


In a lot of the C based languages such as C#, Java and C++, a semicolon is required to end the line.
String foo = "Hello World!";
JavaScript does not require the developer to use a semicolon to terminate their lines of code. This leaves the developer with the option of whether they want to use a semicolon or not.
The JavaScript interpreter/compiler will automatically add a semicolon to the end of your line if you do not have one at the end of your line. This is called Automatic Semicolon Insertion or ASI.
// So
const foo = 'Hello World!'

// will become
const foo = 'Hello World!';
I run across a lot of JavaScript developers who do not use semicolons because of this feature. I always try to semicolons at the end of my lines for a couple of different reasons.
Uglifiers and Transpilers
Transpilers are a kind of compiler that takes JavaScript or another language like TypeScript or JSX, and recompiles it into vanilla JavaScript. Most of the transpilers like Babel do a pretty good job of converting the code into something that will run without errors.
Uglifiers are another type of transpiler that renames variables and obfuscates the JavaScript, making it difficult to read the source. Some of them will rewrite the JavaScript so all of it fits on one line. These are the types of tools where I have seen problems with the newly outputted code not running correctly.
If you are using good tooling, this may not ever be an issue.
Declaring variables
JavaScript allows for multiple variables to be declared on the same line, but those variables have to be separated with commas.
let
foo, bar= 
9;

console.log(bar);
// Outputs: 9
This will become the following with ASI;
let foo; 
let bar = 9

console.log(foo);
console.log(bar);
// Outputs: 
// Outputs: 9
Code to be aware of
There are a number of different situations in your JavaScript code where a semicolon might be inferred where you do not want one inferred. An example of this might be were you are returning an object in a function.
function getUser() {
    return
    {
        username: 'bobsmith',
        id: 'jklj9786dsa990ad#',
        nick: 'bob'
    }
}
ASI will cause this function to return nothing because the beginning curly brace is on a line below the return. ASI will make it look like the following;
function getUser() {
    return;
    {
        username: 'bobsmith',
        id: 'jklj9786dsa990ad#',
        nick: 'bob'
    }
}
This can be corrected by moving the curly brace to the same line as the return keyword.
function getUser() {
    return {
        username: 'bobsmith',
        id: 'jklj9786dsa990ad#',
        nick: 'bob'
    }
}
Keywords
There are certain keywords in JavaScript that are commands. You will want to add a semicolon after those commands.
continue;
break;
debugger;
Objects and Arrow Functions
Functions and code blocks do not require a semicolon, but if you are setting a variable to an object or arrow function, stylistically it looks better to end those lines with a semicolon.
const myCoolObj = { name: 'cool' };

const printCount = (arr) => console.log(`Array len: ${arr.length}`);
Linters
It is very common for JavaScript developers to use linters like 'JSLint' or 'ESLint'. These linters allow JavaScript developers to set up rules on how your code is written, and can warn the developer if their code is not formatted the way they want.
// ESLint
{
    "semi-style": ["error", "always"],
}
The previous rule will force the developer to end every line with a semicolon.
Conclusion
Semicolons are not required in JavaScript, but stylistically it is probably better to use them. If you are using other languages in combination with JavaScript like C# or Go, it is probably better to continue using the semicolon because it is less of a contextual shift going back and forth between those languages.Tags: Semicolons,   JavaScript,   Node.js   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeMay 28th, 2021


One of the powerful things about Gatsby is the way you can pull multiple sources of content from completely different areas into your site. Gatsby does this through plugins.
There are two primary forms of plugins for Gatsby, 'source' and 'transformer'. Source plugins allow you to bring data from out side of your Gatsby site into Gatsby, and Transformer plugins allow you to massage and transform the data from your sources into the specific content you need in your site.
Once data is configured to be brought into your site through a source plugin, you will be able to use GraphQL queries to query the specific content you need added to your site.
You can also use Gatsby's built in query editor that can be accessed via the GraphiQL http://localhost:8000/___graphql url after you run gatsby develop.
Sources
There are an unlimited number of sources for Gatsby that include APIs, content engines, static files and even databases. In this post I am going to create a plugin that pulls in content from an external API.
Creating the plugin
To create my Gatsby plugin, I am going to create a new Gatsby site and a Gatsby plugin module using the Gatsby CLI. Lets' create the site first using the 'Hello World' starter.
gatsby new playground-site gatsby-starter-hello-world
Now lets' create a source plugin in the same directory we created the playground site.
gatsby new source-plugin https://github.com/gatsbyjs/gatsby-starter-plugin
If you want to, you can also create the plugin into the 'plugins' folder in your playground-site folder. For this example we will keep the site and plugin in separate folders.
/playground-site
/source-plugin
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ gatsby-browser.js
‚îú‚îÄ‚îÄ gatsby-node.js
‚îú‚îÄ‚îÄ gatsby-ssr.js
‚îú‚îÄ‚îÄ index.js
‚îú‚îÄ‚îÄ package.json
‚îî‚îÄ‚îÄ README.md
Configuring your plugin
Now lets' configure are 'playground-site' to use the plugin by editing the 'gatsby-config.json' file in the root of our 'playground-site' folder.
module.exports = {
  plugins: [require.resolve(`../source-plugin`)],
}
We can test that this is configured properly by run gatsby develop on our playground-site. You should see 'Loaded gatsby-starter-plugin' from the terminal when you go to run the playground-site.
Adding data to our Plugin
Now that we have our sample plugin, lets' modify it so that it will pull in a source from an API. For this example I am going to use the Star Wars API. I want to be able to use GraphQL to query ship data from the Star Wars API.
Gatsby provides an API you can use to create GraphQL nodes through a function called createNode. We can use this inside of a function in the gatsby-node.js file that exports an async function called sourceNodes.
For this example I am going to get the data from the Star Wars API using the 'axios' module. In your plugin module you can add this with the following npm command;
source-plugin> npm i axios --save
This will add 'axios' to the project.json dependencies. Now that we have added 'axios' we can modify the gatsby-node.js file so that the sourceNodes function looks like the following;
/**
 * Implement Gatsby's Node APIs in this file.
 *
 * See: https://www.gatsbyjs.com/docs/node-apis/
 */
// You can delete this file if you're not using it

/**
 * You can uncomment the following line to verify that
 * your plugin is being loaded in your site.
 *
 * See: https://www.gatsbyjs.com/docs/creating-a-local-plugin/#developing-a-local-plugin-that-is-outside-your-project
 */
const axios = require('axios');

exports.onPreInit = () => console.log("Loaded ships");

// constants for your GraphQL Post and Author types
const SHIP_NODE_TYPE = `Ship`;

exports.sourceNodes = async ({
  actions,
  createContentDigest,
  createNodeId,
  getNodesByType,
}) => {
  const { createNode } = actions

    let shipsleft = true;
    let currentpage = 1;
    let ships = [];

    while (shipsleft) {
        let shippages = await getShipsPage(currentpage); 
        ships.push(...shippages.results);
        if (!shippages?.next) {
            shipsleft = false;
        } else {
            currentpage++;
        }
    }
    
  // loop through data and create Gatsby nodes
  ships.forEach(ship =>
    createNode({
      ...ship,
      id: createNodeId(`${SHIP_NODE_TYPE}-${ship.name}`),
      parent: null,
      children: [],
      internal: {
        type: SHIP_NODE_TYPE,
        content: JSON.stringify(ship),
        contentDigest: createContentDigest(ship),
      },
    })
  )

  return
}

async function getShipsPage(page = 1) {
    const ships = await axios.get(`https://swapi.dev/api/starships/?page=${page}`);
    return ships.data;
}
We have modified the 'gatsby-node.js' file in the plugin so that it queries all of the ships in the Star Wars API, and adds nodes for each ship. We now test that the plugin is adding the nodes by using the GraphQL by running gatsby develop command and doing a query against the GraphiQL tool at [http://localhost:8000/___graphql].
Try making the following query in graphiql;
query MyQuery {
  allShip {
    edges {
      node {
        id
        name
        model
      }
    }
  }
}
Using this data in our Site
Now that we have the plugin querying data, we can use it to query data and display it on our Homepage. Lets' modify the 'index.js' file so that it uses GraphQL to query the data from our plugin;
import React from "react"
import { graphql } from "gatsby"

const HomePage = ({ data }) => {
  console.log(data);
  return (
    <>
      <h1>Ships</h1>
      {data.allShip.edges.map(ship => (
        <div id={ship.node.id}>
          <h3>{ship.node.name}</h3>
          <p>Model: {ship.node.model}</p>
          <p>hyperdrive_rating: {ship.node.hyperdrive_rating}</p>
        </div>
      ))}
    </>)
};

export const query = graphql`
  query {
    allShip {
      edges {
        node {
          id
          name
          model
          passengers
          crew
          hyperdrive_rating
          manufacturer
          starship_class
          url
        }
      }
    }
  }
`

export default HomePage;
As you can see from the above example we are importing in 'graphql', creating a query to get our ship data, then outputting through the 'data' de-constructor in the HomePage function.
Conclusion
Gatsby makes it very easy to extend the built in functionality to import data through the use of source plugins. Combined with the power of GraphQL, we can now easily add new data sources to our Gatsby sites.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeMay 26th, 2021I have recently seen a bunch of different reports in the press about UAPs, or unidentified aerial phenomena. These used to be called UFOs or unidentified flying objects.
After watching several of the Navy videos a thought occurred to me, are these vehicles aware of the FAA? Don't they know we have Federal Aviation Regulations? I have decided to make a list of the regulations they are possibly breaking. Do they even have an up to date copy of the FAR/AIM?
Airspace
A lot of these sightings have occurred off of the US coast and in Navy practice areas. Some of these areas are known as Air Defense Identification Zones, or ADIZ for short. Any aircraft entering or leaving an ADIZ must provide identification. This is covered in FAR part 99.
All aircraft must also file a flight plan. Since these flights possibly began outside of our solar system this would most likely require filing an international flight plan under the ICAO format.
I have not heard about one of these things bothering to call Air Traffic Control.
Required Equipment
Since the beginning of 2020, aircraft flying into rule airspace must have ADS-B out equipment installed in their aircraft. This is covered in FAR Part 91.225. I have not heard of any specific Class B or Class C airspace violations yet, but this could become a problem if they were to fly into this airspace. I doubt these "Tic-Tacs" have all of the necessary equipment.
Visual Flight Rules
Are these UAPs following proper clearances from the clouds? Are they even maintaining proper VFR weather minimums? Here is a reminder;

      
    
  
  
    
Part 21
Are these UAPs even following the type certification requirements under Part 21? I seriously doubt it. According to the eye witness accounts, there was no known or recognized form of propulsion. Have these engines been properly tested under Part 91.128?
Ignorance is no excuse
I am sure people will probably say that whoever is operating these vehicles is not of this world, and are not aware of regs. I was always taught growing up when it came to the law, ignorance was no excuse. It seems to me if these UAPs have the technology to fly here from outer space, they ought to be able to hack into SpaceX's Starlink satellites, and doa little research before they start violating our airspace.
I just hope that the FAA will take regulatory violations seriously from this point on.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeMay 25th, 2021


Not only does Apple Think Differently, they also like to name things differently as well. In languages like Java and C#, if you want to share a contract between objects that guarantees the same interface, that is called an 'Interface'. On MacOS, iOS/iPadOS, watchOS and tvOS, that is called a 'Protocol'. Just like you can make a class or struct conform to an interface, you can also make a Swift class or struct conform to a 'Protocol'.
In Objective-C, if you want extend an existing class, that is called a 'Category', but it is called an extension in C# and Swift.
Developers that are learning how to program for Apple operating systems may be curious about how they can serialize and deserialize objects. On MacOS and iOS that is called 'archiving' and 'unarchiving'.
If you have a class that you want to serialize or archive, your class will need to implement the 'NSCoding' protocol. The NSCoding protocol requires that you have a method on your class called encode, and an init constructor that takes a coder for decoding the archived object.
Implementing NSCoding
Lets' take a look at a class I have defined for keeping track of a vehicle.
class Vehicle {
    var make: String
    var model: String
    var tires: Int = 0
    
    public init(make aMake: String, model aModel: String, tires aTires: Int) {
        self.make = aMake
        self.model = aModel
        self.tires = aTires
    }
}
If you are using Xcode, it has a nice feature that will prompt the developer to create any missing methods if you are adding a protocol to your class. When we add the NSObject and the NSCoding protocol to our class, the end result will look like this in our editor.
class Vehicle: NSObject, NSCoding {
    var make: String
    var model: String
    var tires: Int = 0
    
    public init(make aMake: String, model aModel: String, tires aTires: Int) {
        self.make = aMake
        self.model = aModel
        self.tires = aTires
    }
    
    func encode(with coder: NSCoder) {
        
    }

    public required init?(coder: NSCoder) {
        
    }
}
Now lets' implement these two methods. For the init?(coder: NSCoder) we are going to want to make this a convenience init because we want it to call the existing init constructor once it has been decoded.
public required convenience init?(coder: NSCoder) {
    guard let aModel = coder.decodeObject(forKey: "model") as? String,
            let aMake = coder.decodeObject(forKey: "make") as? String
    else { return nil }
    
    self.init(make: aMake, model: aModel, tires: coder.decodeInteger(forKey: "tires"))
}
For encode method we will need to take the values of our class and encode them using the encoder passed into the method.
func encode(with coder: NSCoder) {
    coder.encode(make, forKey: "make")
    coder.encode(model, forKey: "model")
    coder.encode(tires, forKey: "tires")
}
By adding these two methods we have made our object serializable or archivable depending on the terminology you want to use. The final class should look like the following example.
class Vehicle: NSObject, NSCoding {   
    var make: String
    var model: String
    var tires: Int = 0
    
    open func encode(with coder: NSCoder) {
        coder.encode(make, forKey: "make")
        coder.encode(model, forKey: "model")
        coder.encode(tires, forKey: "tires")
    }
    
    public init(make aMake: String, model aModel: String, tires aTires: Int) {
        self.make = aMake
        self.model = aModel
        self.tires = aTires
    }
    
    public required convenience init?(coder: NSCoder) {
        guard let aModel = coder.decodeObject(forKey: "model") as? String,
              let aMake = coder.decodeObject(forKey: "make") as? String
        else { return nil }
        
        self.init(make: aMake, model: aModel, tires: coder.decodeInteger(forKey: "tires"))
    }
}
Secure Coding
For archiving and unarchiving classes, Apple has provided the following classes for their different OSs.

NSKeyedArchiver
NSKeyedUnarchiver

Starting in iOS 12 Apple deprecated some of the original methods in these classes for performing the archiving, and added new methods that support 'Secure Coding'. Apple has provided a new protocol that your objects must support if you want to support 'Secure Coding'.
This new protocol called NSSecureCoding will require a boolean property be added to your class called 'supportsSecureCoding'. This flag can be used along with parameters to the archiving and unarchiving methods to enforce 'Secure Coding'.
Secure Coding will enable the encoding and decoding in a way that will prevent object substitution attacks. If an object substitution attack were to occur, it is possible that object being unarchived could inflate into an object that could potentially allow an attack.
Lets' add the NSSecureCoding protocol to our class.
class Vehicle: NSObject, NSCoding, NSSecureCoding {
    public static var supportsSecureCoding = true
    
    var make: String
    var model: String
    var tires: Int = 0
...
Now we can create a new instance of this 'Vehicle' class and archive to a 'Data' object.

let myVehicle = Vehicle(make: "Tesla", model: "Model 3", tires: 4)
let flatVehicle: Data?

do {
    flatVehicle = try NSKeyedArchiver.archivedData(withRootObject: myVehicle, requiringSecureCoding: true)
} catch {
    print("\(error.localizedDescription)")
}
In the example above we can see that archivedData function has a second parameter called requiringSecureCoding. This function can also throw an error if the function is unable to archive the object.
The flatVehicle object is of type Data, and can be written to the filesystem or some other persistent store.
If we want to unarchive that data, we can use the NSKeyedUnarchiver class.
do {
    let deserializedObj = try NSKeyedUnarchiver.unarchivedObject(ofClass: Vehicle.self, from: flatVehicle)!
    print("\(deserializedObj.make)") // Output: Tesla
} catch {
    print("\(error.localizedDescription)")
}
Some other things
Not all classes are unarchivable using the unarchivedObject(ofClass:from: function. If you are using a datatype like a Swift Dictionary, you will have to use another function like the unarchiveTopLevelObjectWithData function which does not specify a specific data type.
Conclusion
As you can see it is possible to serialize and deserialize objects on Macs, the iPhone, iPad and other Apple devices using the NSKeyedArchiver and NSKeyedUnarchiver classes. These utilities should be used with care and security in mind.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeMay 21st, 2021


Monkey Patching is the capability in JavaScript to swap out a function in a JavaScript object with your own function. This can come in handy, but also be dangerous. One of JavaScript's strengths is its ability to easily make changes to objects and modules. It also makes it fairly easy to introduce new bugs.
This kind of functionality can also be found in languages like Objective-C and Swift where developers can swap out the functionality of methods in their classes using a runtime feature called 'Method Swizzling'.
To illustrate this functionality, we can create a object that has a simple add function.
class SimpleMathObject {
    
    add(a, b) {
        return a + b;
    }

}
We can then instantiate this object and call the add function on our object.
const MathObject = new SimpleMathObject();
const result = MathObject.add(1, 2);
console.log(`Result of 1 + 2 = ${result}`);
// Output: Result of 1 + 2 = 3
Adding a Monkey Patch
To add a Monkey Patch to our object we simply need to assign a new function to the add function on our instantiated object. We will need to get a reference to the original function so we can continue to use it in our new function, or possibly reassign it back to the object once we are done with our patching.
We can now add our own version of the add function without having to change the original version of the SimpleMathObject. This can be useful if we need to inject some new functionality into this object.
const MathObject = new SimpleMathObject();

// Make a copy of the original add function 
const origAdd = MathObject.add;

// Making Monkey Patch
MathObject.add = function(a, b) {
    console.log(`Adding the result of ${a} and ${b}`);
    return origAdd(a, b);
}

const result = MathObject.add(1, 2);
console.log(`Result of 1 + 2 = ${result}`);
// Output: Adding the result of 1 and 2
// Output: Result of 1 + 2 = 3
Preventing Monkey Patching
One of the problems with using the class keyword or object prototypes is that can leave your objects open to this type of manipulation. If you do not want your functions to be Monkey Patched, there are ways of preventing that type of execution from happening in your code. One way of accomplishing this is to use factory function and Object.freeze when returning your object.
function createAddObject() {
    if (new.target) {
        throw `This function is a factory function, and does not allow the 'new' keyword`;
    }
    function add(a, b) {
        return a + b;
    }
    return Object.freeze({
        add
    });
}
Now if you try to replace the add function with your own like in the example below, the JavaScript engine will throw a TypeError;
const MyObject = new createAddObject();

const origAdd = MyObject.add; 

MyObject.add = function(a, b) {
    console.log(`First param ${a} and second param is ${b}`);
    return origAdd(a, b);
}
The error from trying to execute this code should look similar the following error.
TypeError: Cannot assign to read only property 'add' of object '#<Object>'
    at file:///Users/davidfekke/Documents/monkeypatch/monkey.js:39:23
Conclusion
Monkey Patching is a very powerful concept in JavaScript. You can use to add aspects or inject new functionality into existing libraries or modules. It can also be dangerous. But if you do not want your code to be Monkey Patched, you can use Object.freeze to make your objects read only.
You certainly can use this feature in your JavaScript applications, but beware that when change default functionality of an object that can create unexpected behavior if you forget about that change. Or even worse, that next developer working on your code is not aware of the change.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeMay 16th, 2021One of my favorite laws is Atwood's Law. Atwood's Law states: any application that can be written in JavaScript, will eventually be written in JavaScript. I have been shocked at the kinds of applications that can be written using JavaScript.

      
    
  
  
    
If you are not familiar with Jeff Atwood, he writes the popular blog Coding Horror.

      
    
  
  
    
When you ask yourself should I use Node.js to process images, this is a question that definitely qualifies for Atwood's Law.
Image Processing
One of the first programming jobs I had in the 90s was writing an AppleScript that could leverage Adobe PhotoShop to create images for a high resolution library the company I was working for at the time was trying to build. At the time Adobe did not have scripting capability built into Photoshop like they do know. I found a Photoshop plugin that would allow me to write code that could command Photoshop to automate our imaging needs.
Nowadays there are all kinds of tools at our disposal for image processing that can be scripted. But what about Node.js? It turns out there are a lot of tools for image processing in Node.js that are available through NPM.
There are a number of use cases where you might need image processing. Here are a couple of those use cases;

Convert to Different file format
Resize the image
Crop the image
Make a Composite image
Do Color correction
Create Blurs and Effects

A couple of years ago I built a tool called jimp-appicon for creating icons for iOS/iPadOS and Android apps. Apple and Google both require many different dimensions of these square images in order to create icons for all of the different devices with varying screen sizes.
Jimp
Jimp, a tool named after the popular GIMP image processing application, is an image processing tools written entirely in JavaScript. It does not have any external dependencies, and can run on any processor architecture.
Jimp also has an easy API to understand with a promise library allowing Node.js developers to run multiple operations on an image. In the following example we will take the Lenna image, and resize it 256 pxiels square, make it a greyscale and save our results as a JPEG. Here is the original image;

      
    
  
  
    
Now we will u run the following script to create our new greyscale JPEG image.
import jimp from 'jimp';

jimp.read("lenna.png").then(function (lenna) {
    lenna.resize(256, 256)            // resize
         .quality(60)                 // set JPEG quality
         .greyscale()                 // set greyscale
         .write("lena-small-bw.jpg"); // save
}).catch(function (err) {
    console.error(err);
});
The resulting image will look like the following image;

      
    
  
  
    
Sharp
I am came across the Sharp image module a couple of years ago when I first started using Gatsby. Gatsby uses the Sharp image module in their image plugins. This is exetermely fast because it is mostly written in C++ code as a native module for Node.js. And unlike some of the other native image modules for Node.js, it will compile and run on most processor architectures. So if you are running on a large x86_64 server or on a Raspberry Pi running on an ARM processor.
import sharp from 'sharp';

sharp('lenna.png')
  .rotate()
  .resize(200)
  .jpeg({ mozjpeg: true })
  .toFile('output.jpg', (err, info) => {
    if (err) console.error(err);
    console.log(info);
  });
PhotoShop and Adobe Generator
PhotoShop is probably my favorite application of all time. I have been using PhotoShop for 30 years. Adobe created a way in 2013 to add plugins to PhotoShop using Node.js. It is called Adobe Generator-core. If there is specific functionality that you want to use in PhotoShop, you can now write Node.js code that will add a plugin option to PhotoShop and execute that script. Here is an example of a generator plugin that can take the path called "Path 1" and create a new layer in PhotoShop with just the contects of that path selected;
(function() {
    "use strict";

    const PLUGIN_ID = require("./package.json").name,
          MENU_ID = "makelayerfrompath1",
          MENU_LABEL = "$$$/JavaScripts/Generator/Make Layer From Path 1/Menu=Make Layer From Path 1";

    var _generator = null,
        _currentDocumentId = null,
        _config = null;

    // Using Adobe ExtendScript to create a new layer from a path named 'Path 1'
    const makeNewLayerFromPath1 = `if (app.documents.length > 0) {
        var docRef = app.activeDocument;
        var n = docRef.pathItems.length;
            if((n>0)&&(docRef.pathItems[0].name=="Path 1" ))  {
                docRef.pathItems[0].makeSelection();
                docRef.selection.copy();
                var coolLayer = docRef.artLayers.add();
                coolLayer.name = "My Layer";
                docRef.paste();
            }
        }`;

    /*********** INIT ***********/

    function init(generator, config) {
        _generator = generator;
        _config = config;

        console.log("initializing generator getting started tutorial with config %j", _config);

        _generator.addMenuItem(MENU_ID, MENU_LABEL, true, false).then(
            function() {
                console.log("Menu created", MENU_ID);
            },
            function() {
                console.error("Menu creation failed", MENU_ID);
            }
        );
        _generator.onPhotoshopEvent("generatorMenuChanged", handleGeneratorMenuClicked);

        function initLater() {
            _generator.onPhotoshopEvent("currentDocumentChanged", handleCurrentDocumentChanged);
            _generator.onPhotoshopEvent("imageChanged", handleImageChanged);
            _generator.onPhotoshopEvent("toolChanged", handleToolChanged);
            requestEntireDocument();

        }

        process.nextTick(initLater);

    }

    /*********** EVENTS ***********/

    function handleCurrentDocumentChanged(id) {
        console.log("handleCurrentDocumentChanged: " + id)
        setCurrentDocumentId(id);
    }

    function handleImageChanged(document) {
        console.log("Image " + document.id + " was changed:"); //, stringify(document));
    }

    function handleToolChanged(document) {
        console.log("Tool changed " + document.id + " was changed:"); //, stringify(document));
    }

    // This is the method that gets called if the user clicks on a the menu.
    function handleGeneratorMenuClicked(event) {
        // Ignore changes to other menus
        const menu = event.generatorMenuChanged;
        if (!menu || menu.name !== MENU_ID) {
            return;
        }

        sendJavascript(makeNewLayerFromPath1);

        const startingMenuState = _generator.getMenuState(menu.name);
        console.log("Menu event %s, starting state %s", stringify(event), stringify(startingMenuState));
    }

    /*********** CALLS ***********/

    function requestEntireDocument(documentId) {
        if (!documentId) {
            console.log("Determining the current document ID");
        }

        _generator.getDocumentInfo(documentId).then(
            function(document) {
                console.log("Received complete document:", stringify(document));
            },
            function(err) {
                console.error("[Tutorial] Error in getDocumentInfo:", err);
            }
        ).done();
    }

    function updateMenuState(enabled) {
        console.log("Setting menu state to", enabled);
        _generator.toggleMenu(MENU_ID, true, enabled);
    }

    /*********** HELPERS ***********/


    function sendJavascript(str) {
        _generator.evaluateJSXString(str).then(
            function(result) {
                console.log(result);
            },
            function(err) {
                console.log(err);
            });
    }

    function setCurrentDocumentId(id) {
        if (_currentDocumentId === id) {
            return;
        }
        console.log("Current document ID:", id);
        _currentDocumentId = id;
    }

    function stringify(object) {
        try {
            return JSON.stringify(object, null, "    ");
        } catch (e) {
            console.error(e);
        }
        return String(object);
    }

    exports.init = init;

    // Unit test function exports
    exports._setConfig = function(config) { _config = config; };

}());
While this is extremely neat that it is possible to use PhotoShop and Node.js together, it is not practical to keep both Node.js and PhotoShop on the same server. Plus PhotoShop only runs on Windows and MacOS.
Make an AppIcon with Sharp-AppIcon
I decided to write a new AppIcon maker using Sharp because it is so performant. It can create all of the icons you need for your iOS/iPadOS and Android apps in about a second. Here is how you can install and use Sharp-AppIcon. Make sure you have Node.js installed on your computer. Then you can NPM install sharp-appicon globally using the following command;
$ npm install sharp-appicon -g
Once it finishes install this module, you can execute it in the command line using appicon command. You just need to navigate to the location of your source icon. It should probably be an image with the dimensions of 1536 pixels by 1536 pixels. Lets' say your icon is called MyAppIcon.png. You can create your appicons by running the following command;
$ appicon MyAppIcon.png
This will create a directory called 'icons' with all of the icons required for your iOS/iPadOS and Android apps. Watch the video below to see how to use this utility.



Conclusion
It is extremely practical to use Node.js for creating thumbnails, creating simple operations and cropping and saving your images into different formats. You do not have to use these modules, and you can choose to use modules that work with GraphicsMagic and ImageMagic as well.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeMay 12th, 2021


I did a presentation a couple of years ago to JaxNode User Group about building your own tools. As a user it is very common to find yourself repeating the same series of commands over and over again. In software development you often hear about the SOLID principles. One of those principles is DRY principle, which stands for Don't Repeat Yourself.
If you don't want to repeat yourself as a developer, why would you want to do it as a user? This is one of the reasons why I build my own tools. Here are some examples of tasks I ran across where I built my own tools.

I created a command line tool for generating thumbnails for iOS and Android apps
I also created a tool for generating a markdown folder for new blog posts
I then created a tool for generating a new Node.js project

Command Line Tools
I have used a couple of different frameworks for creating command line tools with Node.js. You don't have to use Node.js. Python and Shell scripts are also popular for creating command line tools. You can even use C.
When using Node.js for command line tools, there are a couple of popular frameworks. The first one that became popular was Commander by TJ Holowaychuk. Commander is still a very popular framework.
Oclif
Lately I have been using Oclif. This was developed out of Heroku for their command line tool. Their parent company Salesforce then used it to build SFDX.
Oclif is feature rich with the ability to create multiple commands, add plugins and use either TypeScript or JavaScript for developing your utilities. I will use Oclif for my examples in this post.
Creating a New App in Node.js
When I am testing out a new NPM package that I might want to use or testing a new JavaScript feature in Node.js, I usually do a number of things to setup a new project. The tasks I go through are usually as follows;

Create a directory and change into that directory
Init a new project using NPM
Create a README file
Create a .gitignore file
Create an index.js file for that start of my application
Initialize a git repo, and commit all of the files

If I was to do all of these commands from the command line in the shell, it would look like the following;
root> mkdir mytestapp && cd mytestapp
mytestapp> curl https://www.toptal.com/developers/gitignore/api/node > .gitignore
mytestapp> npm init -y
mytestapp> echo "# mytestapp" > README.md
mytestapp> touch index.js
mytestapp> git init
mytestapp> git add .
mytestapp> git commit -m "Initial Commit"
After doing this enough times, I decided to create a command line tool to generate a new project.
Creating a New Command Line tool with oclif
You can generate a new oclif application using npx. Oclif gives you options for either a single command or a multi command tool. For our example application, we are just going to use the single command.
> npx oclif single mytestconsole
This will generate a new project that with the following directory structure;
MYTESTCONSOLE
--bin
  --run
  --run.cmd
--node_modules
--src
  --index.js
.editorconfig
.gitignore
package-lock.json
package.json
The index.js file will contain the settings and the main entry point to your command line app.
const {Command, flags} = require('@oclif/command')

class MytestconsoleCommand extends Command {
  async run() {
    const {flags} = this.parse(MytestconsoleCommand)
    const name = flags.name || 'world'
    this.log(`hello ${name} from ./src/index.js`)
  }
}

MytestconsoleCommand.description = `Describe the command here
...
Extra documentation goes here
`

MytestconsoleCommand.flags = {
  // add --version flag to show CLI version
  version: flags.version({char: 'v'}),
  // add --help flag to show CLI version
  help: flags.help({char: 'h'}),
  name: flags.string({char: 'n', description: 'name to print'}),
}

module.exports = MytestconsoleCommand

As you can see from the file generated above, it contains a class that extends the command class with an async run function. It also contains a description and flags configuration. The run function is the main function and the starting point for our console app.
The description property is part of the self documentation part of oclif. Whatever text you put in this property will display in the help for the application.
The flags object property is where you configure the different flags for controlling the logic from your command line.
SetupNodeProject (snp)
For my Setupnodeproject app, I added a flag for creating a new folder when generating a new application. The final object definition will look like the following;
SetupnodeprojectCommand.flags = {
  // add --version flag to show CLI version
  version: flags.version({char: 'v'}),
  // add --help flag to show CLI version
  help: flags.help({char: 'h'}),
  name: flags.string({char: 'n', description: 'name to print'}),
  folder: flags.boolean({char: 'f', description: 'create Folder for project', default: false })
}
As you can see from the example above the folder flag is defined as a boolean. If the user does not use the flag, it will default to false.
Now we need to define the function for creating the folder.
async createFolder(name) {
    await fsPromises.mkdir(name);
}
To create the folder I am using the Node.js fs/promises module, and requiring it at the beginning of my 'index.js' file.
const fsPromises = require('fs/promises');
To create the .gitignore file, I am going to copy it from a template from the root level of my project.
  async createGitIgnoreFile() {
    this.log(`Creating git ignore file.`);
    const contentFile = path.join(__dirname, '../gitignoretemplate.txt');
    const workingdir  = process.cwd();
    const gitIgnorePath = path.join(workingdir, '.gitignore');
  
    return await fsPromises.copyFile(contentFile, gitIgnorePath);
  }
For the rest of my commands I will need to use the exec module in Node.js to execute command line tools against the system. To do this I am going to create a async function that can execute my commands as a Promise.
const execPromise = async command => {
  return new Promise(async (resolve, reject) => {
      exec(command, { shell: '/bin/zsh' }, (error, stdout, stderr) => {
        if (error) {
          console.log(`error: ${error.message}`);
          reject(`error: ${error.message}`);
        }
        if (stderr) {
          console.log(`stderr: ${stderr}`);
          reject(`stderr: ${stderr}`);
        }
        resolve(`stdout: ${stdout}`);
      });
  });
};
The execPromise function is a arrow function that returns a Promise. Promises and async/await functions are interchangeable in JavaScript. Now I can use this function in my createGitIgnore function.
async npmInitProject() {
    this.log(`NPM Initing project.`);
    return await execPromise("npm init -y");
}
As we can see from the function above, we execute the npm init -y command. This will generate the package.json file. I want to make one small modification that allows me to use the import/export syntax available in Node.js. I need to add a 'type' key with the value of 'module'. To do this I will use the following function;
async modifyPackageJson() {
    const packageFile = await fsPromises.readFile('./package.json');
    const jsonObj = JSON.parse(packageFile);
    jsonObj['type'] = 'module';
    await fsPromises.writeFile('./package.json', JSON.stringify(jsonObj, null, 4), 'utf8');
}
The last three things I need to do is to create a blank 'index.js' file, a 'README.md' file and initialize the git repository for saving my project into git source control.
async createIndexFile() {
    this.log(`Creating blank index file.`);
    return await execPromise("touch index.js");
}

async createReadme(name) {
    this.log(`Creating README file.`);
    return await execPromise(`echo "# ${name}" > README.md`);
}

async gitInit() {
    await execPromise("git init");
    await execPromise("git add .");
    await execPromise(`git commit -m "Initial Commit"`);
}
Now we can call all of these functions from the run function to create our app.
async run() {
    const {flags} = this.parse(SetupnodeprojectCommand);
    const name = flags.name || 'node_project';
    if (flags.folder) {
      await this.createFolder(name);
      process.chdir(`./${name}`);
    }
    await this.createGitIgnoreFile();
    await this.npmInitProject();
    await this.modifyPackageJson();
    await this.createIndexFile();
    await this.createReadme(name);
    await this.gitInit();
}
If you look at the logic for where we create the folder, I have a command to change the working directory to the directory we just created. If we are not creating a directory for our new application, we can leave the working directory alone so that it uses the same directory as we are running the command line.
We can even test this and run it locally by NPM installing it globally.
> npm i -g
I have this current project available to view on Github.
Conclusion
There are already a lot of different projects for generating out a node project. One popular project is called Yeoman, or 'YO'. But as you can see it is very easy to create our own tools for automating workflows using Node.js.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeMay 9th, 2021


Building apps for the iOS/iPadOS and Android platforms may seem daunting if you are new to mobile development, but there are many different options for developing these apps that may suit your needs. In this post I will cover some of the options for developing mobile applications and the discuss the pros and cons for each of the different options.
Mobile development options can be broken into three main groups: Web based, cross-platform native and pure native development. I will try to drill down into each option that developers might want to use for building their mobile apps.
Web Based Frameworks
There are a number of different frameworks that target web developers, and allow them to build an application that can be installed from the respective stores. These applications can be built just using HTML, CSS and JavaScript. We can also think of these types of applications as being packaged WebViews.

      
    
  
  
    
Cordova
Cordova is a framework that sprang out of building applications using web technologies like HTML/CSS and JavaScript, and embedding the HTML app in a native container. This has been a huge boost to existing web front-end developers who where already knowledgable in web technologies. The native applications can be submitted to the individual app stores just like regular native applications.
If you are using Cordova, make sure to use the latest version of Cordova. Earlier versions contained references to the UIWebView from Apple. Apple will not accept new apps that contain references to the UIWebView.
Pros

Easy to transition if you are a existing web developer
Many HTML and JavaScript frameworks built for mobile applications
Easily add Plugins to utilize native functionality like Push Notifications

Cons

At the end of the day this is an Encapsulated WebView
Because UI is built with Web Frameworks instead of native users make get a sense of uncanny valley
Extending functionality requires knowledge of Objective-C and Java


      
    
  
  
    
PhoneGap
DEPRECATED! Cordova is the open source project the sprung out of PhoneGap. PhoneGap was a commercial project that eventually was purchased by Adobe. Adobe has discontinued their investment in PhoneGap and Cordova. Cordova continues as a open source project.
Do not start any new applications using PhoneGap. If you are taking over a project built on PhoneGap, transition over to Cordova, or think about rebuilding in another framework.
Ionic
Ionic is a framework built around Angular and Cordova. If you are familiar with the Angular ecosystem and like Cordova, this may a framework you may be interested in learning.
Alternative WebView Development
I have some blog posts I have done on how to create your own WebViews on the specific platform native. In this post I describe how to use the WKWebView in iOS in a native iOS application without having to use Cordova. In a follow up post I show how to do the same thing in an Android application.
Cross Platform Options
There are a number of different options for building mobile apps that are multi-platform that share code. One of the wishes of software engineers is the ability to build applications that are WORA, or Write Once/Run Anywhere. The Java platform was originally supposed to be a language and a system for writing your application once and running anywhere.
Flutter
Flutter is another cross platform framework from Google. Unlike Cordova, Flutter does not use a WebView, but uses a common language for developing applications called Dart. Dart originally was targeted as an alternative to JavaScript.
Pros

Build cross platform apps for not just Android and iOS, but many other operating systems
Good tools for animation
You can build applications with 'Widgets'
Will be Fuscha compatible

Cons

The main development language is Dart
Some performance problems
Not all native features available to Flutter developers
Not many plugins for extending functionality
Difficult to make platform specific UI
Not a mature technology


      
    
  
  
    
Xamarin
Xamarin, now officially part of Microsoft and Visual Studio, this framework is based off of .NET and C#. If you are a .NET developer and unfamiliar with Java/Kotlin on Android and Swift/Objective-C on iOS, this may be the framework for you. You can build and structure your applications using Visual Studio solutions. In your solutions, you can divide your project into shared code projects, and individual projects for iOS and Android. This allows the developer to custom tailer their app to the specific UI of the platform they are targeting. It also allows the developer to share business logic for both platforms.
Pros

If you have developers that are familiar with .NET, the language and tools are the same ones they are used using
Allows the reuse of code between Android and iOS
Uses Ahead of Time compiling to create native apps
Some APIs from .NET available for use with Xamarin

Cons

Does require a Mac for compiling iOS apps
No Visual Studio support for M1 Macs

Xamarin Forms
Xamarin forms present a cross-platform tool for creating User Interfaces that work on both iOS and Android. Not all UI elements available on both platforms.

      
    
  
  
    
React Native
This framework is the same framework used for React.js applications. React is a very popular JavaScript based view engine for building component based UIs. React Native has its own native views that can be composed using React. It also has its own implementation of Flexbox for laying out your UIs.
A JavaScript bridge is used to bind your business logic to your User Interface components. React Native uses JavaScript Core for the bridge. Like React.js, this project is sponsored by Facebook.
Pros

Build Native Apps using JavaScript JSX while still being a native app
Easily extend your application with React Native modules
Can use React developers to build mobile apps
Can also build React Native Web applications

Cons

Can run into performance problems using the JavaScript bridge
Writing custom modules requires knowledge of Objective-C on iOS and Java on Android
Scroll performance suboptimal
AirBNB wrote a number of posts on problems they had with React Native here, here, here, here and here


      
    
  
  
    
NativeScript
NativeScript has a similar model to that of React Native. But unlike React its framework was originally based on Angular. NativeScript also has support for Vue, Svelte and React.
NativeScript shows how Angular, Vue and React are not just web application frameworks, but can be used as just application frameworks. This project is part of the OpenJS foundation
Pros

Similar framework to React
build Native apps with JavaScript or TypeScript
Support for multiple application frameworks including Vue, Svelte and Angular

Cons

Similar performance problems that you have in React Native
Limited set of Native APIs that accessible to the developer

Native iOS/iPadOS
The way that Apple and Google would prefer you write applications for their respective OS's would be natively. iOS and iPadOS have their own frameworks and languages. Apple's MacOS was originally based on the NextStep operating system which used Objective-C for all of its frameworks.
IDE and Tools

      
    
  
  
    
Apple has an integrated development environment called Xcode that has all of the tools you need for building native applications in one tool. Xcode allows developers to write code in C, C++,Objective-C and the Swift programming languages. It includes the LLVM based Swiftc and Clang compilers.
It also comes with the frameworks that make up CocoaTouch designed by Apple for developing software for iOS/iPadOS. It was originally derived from the Objective-C Cocoa APIs from MacOS.
Objective-C
Objective-C was the primary language used for developing software for the NextStep and Mac OS X, and for the first seven years of iOS. Objective-C was originally designed as a way of building Object-Oriented software on top of the C programming language. Objective-C classes are usually made from two files, a header '.h' and an implementation '.m' file. You can also combine C++ code by adding an extra m '.mm' to the implementation file for whats called Objective-C++.

      
    
  
  
    
Swift
In 2014 Apple introduced the Swift programming language. Swift like Objective-C is a general purpose language, but with many functional features. Swift has advanced Generic features, closures and error handling syntax.
let greeting = "Hello!"
print(greeting)
// Output: Hello!
SwiftUI
Apple introduced SwiftUI in 2019, which allows developers to build declarative UIs in code. Views are composed from lightweight structs as opposed to classes in traditional CocoaTouch.
Pros

Build apps specific for the platform
Strong support options from Apple
Full access to all publicly available APIs

Cons

Objective-C and C may be too low level for some developers, but must development can be done now with Swift
Steeper learning curve for Web Developers


      
    
  
  
    
Native Android
The Android operating system is based on Linux and the APIs are based on Java. Since it is based on Java, developers can add existing Java libraries into their applications.
IDE and Tools

      
    
  
  
    
Android Studio is the IDE Google licensed from Jet Brains, the company that makes the IntelliJ family of IDEs. It comes with a cod editor, ADB tools and Android emulators for testing your applications.
Java
Originally developed by Sun in the 1990s, Java is an object-oriented general purpose programming language. Java code is typically compiled into bytecode, or intermediate code instead of an executable built for one processor. Current versions of the Android Developer tools actually compile the applications using ART which does ahead of time compiling for machine code.

      
    
  
  
    
Kotlin
Kotlin is a newer general purpose object oriented programming language developed originally out of Jet Brains, the makers of popular programmer IDEs and developer tools. It is now the default programming language for Android development and runs in the Java eco-system.
// Hello, World! example
fun main() {
    val scope = "World"
    println("Hello, $scope!")
}

fun main(args: Array<String>) {
    for (arg in args) {
        println(arg)
    }
}
Jetpack Compose
Google currently is developing a new declarative UI framework similar to SwiftUI for Android called Compose. It is still in beta, but developers can download and start using the Canary release.
Pros

Build apps specific for the Android platform
Full access to all publicly available APIs

Cons

Java and C may be too low level for some developers, but most development can be done now with Kotlin
Steeper learning curve for Web Developers

Game Development
There are a number of different options for building cross-platform games on mobile. I am only going to attempt to cover a few in this post. You can also develop games using native tools from each vendor, but frameworks below are higher level and considered easier for building games.
Unity
Unity3D is a program and engine for building apps and games on multiple platforms including iOS and Android. They have options for 3D games and 2D games. They also have options for multiple programming languages including Lua, C# and JavaScript.
Pros

Easily create games using the Unity3D engine
Can extend those games with JavaScript, Lua, C#, C++, IronPython, Rust and Boo

Cons

Unity licensing may be too expensive for some developers
Unity may provide too much of an abstraction for developers who may need GPU access

MonoGame
The MonoGame framework allows game developers to target multiple platforms including iOS/Android. Developers can use C# or other .NET languages to build their games.
Pros

Open Source project
Build Games using .NET like frameworks and languages like C#

Cons

No professional support options

Conclusion
There is an expression that says that you should use the best tool for the Job. I have been developing mobile software for over 10 years and I have used the native tools for most of my development. This is mainly due to the fact that I like to have fool access to all of the APIs on the platform.
One of the things you can do is mix and match frameworks. You can build a native app for iOS that also uses pieces that are built from Cordova. It is also common for some React Native apps to have parts that are completely native with some views built using React. Pick the tool that best fits your needs.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeMay 8th, 2021


There are actually times when you want to use object inheritance in your applications. I have seen a lot of applications that extend a lifecycle API through object inheritance.
Inheritance was designed as a way for software developers to extend existing functionality and add properties to an existing base class or object. When modeling data as objects it is very common to create object graphs where one object may be a grandchild or great grandchild of a base object.

      
    
  
  
    
As an example we might have a Person object that is a parent object. We can create User object that extends the Person object. We may also have an AdminUser object that extends the User object. Any change I make to the Person object will automatically inherited by the User and AdminUser objects.
Some of the side affects of inheritance is that if we make a change to the definition of the base object, it is now tightly coupled to the entire chain of objects. This can create something known as the Fragile Base Class problem. Another problem if we are trying to add functionality to our objects using inheritance, in most general purpose languages we can only inherit from one  object. C++ is one of few languages that allows developers to do multiple inheritance. Languages such as C#, Objective-C, Java and Swift only allow for single inheritance.
Delegation Pattern
One of the patterns I was introduced when I started learning Objective-C was the Delegation pattern that is common through a lot of Apple's APIs. This is similar to the Observer pattern mentioned in the Gang of Four Design Patterns book.

      
    
  
  
    
Objective-C is a language that was made popular by Next Computer, the company Steve Jobs started when he left Apple, and which he sold back to Apple in 1996. Next adopted Objective-C as their default language because it could be used to create Object-Oriented applications and frameworks, but it also allowed developers to use existing C code.
Since Objective-C only allows for single inheritance, Apple developed a lot of their APIs to make use of a delegation pattern. The idea is pretty simple. If the developer is writing a class in a program, and they need to consume a network or database server resource, they can create an instance of the API class, and make their class a delegate of that object. Making a networking call can be a blocking process if you are waiting for the response on a single thread. Apple was able to abstract away of a lot of the complexity of making networking calls by encapsulating the threading into their API. All the consumer had to do was implement certain methods on their class to consume the results from the networking API, and set their class as the delegate of the networking class.
Today Apple has a lot of modern APIs that use closures and blocks to handle a networking requests in a non-blocking way, but the Delegation pattern is still used in a lot of their APIs.
Inheriting Functionality in JavaScript
Lets' say we have an object we are creating that needs to offload some work to another object, and then needs to have a function called on once the other object has completed that task. One way of doing this is to inherit that functionality from a parent object. For this example we create two objects, one called parent, and the other called child. The child is going offload some of its work to the parent object. The parent object will have functions called doWorkForChild, setStatus and sayHelloToMe.
The child object will inherit the methods from the parent object, but we are going to override the functionality of the setStatus function, and add functions for start and print.
function parent() {
    return this;
}

function child() {
    return this;
}
Then we are going to set the prototype of the child to the parent so we can inherit the functionality of the parent.
child.prototype = Object.create(parent.prototype);
Now we can define the functions for each of our objects.
//parent functions
parent.prototype.doWorkForChild = function() {
    console.log('Doing something');
    setTimeout(() => {
        const time = new Date();
        const currentTime = time.getTime();
        this.setStatus(currentTime);
    }, 5000);
}

parent.prototype.sayHelloToMe = function(name) {
    this.setStatus(`Hello ${name}`);
}

parent.prototype.setStatus = function(status) {
    console.log('setStatus called');
}

// child functions
child.prototype.start = function() {
    console.log('Starting child');
    this.sayHelloToMe('Parent');
    this.doWorkForChild();
}

child.prototype.print = function() {
    console.log('Printing child');
}

child.prototype.setStatus = function(status) {
    console.log(`Current Status: ${status}`);
}
As we can see from the example above we have overridden the setStatus function on the child object so that it prints the status parameter using the console.log.
To run this example we need to create a new instance of the child object and call the start function on the instance.
const childInstance = new child();
childInstance.start();
// Output should look like the following
// Starting child
// Current Status: Hello Parent
// Doing something
// Current Status: 1620506525300
Decoupling the objects using the Delegate Pattern
Lets' put the functionality we have in the parent object into a new factory function called 'worker'.
// worker.js file
function createWorker() {
    if (new.target) 
        throw 'createWorker() must not be called with new';
    
    let delegate;

    function setDelegate(observer) {
        delegate = observer;
    }

    function doWorkForDelegate() {
        console.log('Doing something');
        setTimeout(() => {
            const time = new Date();
            const currentTime = time.getTime();
            delegate.setStatus(currentTime);
        }, 5000);
    }

    function sayHelloToMe(name) {
        delegate.setStatus(`Hello ${name}`);
    }

    return Object.freeze({
        setDelegate,
        doWorkForDelegate,
        sayHelloToMe
    });
}

export default createWorker;
As you can see this function creates an object with the same functions we had in the parent object previously. The main difference here is that we have variable called delegate that we use to store a reference back to a delegate object. Now we need to create an object that will observe calls made from the worker object.
import createWorker from './worker.js';
const worker = createWorker();

function createDelegate() {
    
    function start() {
        console.log('Starting delegate');
        worker.sayHelloToMe('Delegate');
        worker.doWorkForDelegate();
    }

    function print() {
        console.log('Printing delegate');
    }

    function setStatus(status) {
        console.log(`Current Status: ${status}`);
    }

    const instance = Object.freeze({
        start,
        print,
        setStatus
    });

    worker.setDelegate(instance);

    return instance;
}
As you can see from the example above we are creating an instance variable of our delegate object. We then assign this instance of our delegate to the delegate property in the worker object. Once the worker has this reference, it can now call functions on the delegate object.
Now all we have to do is start up the delegate object to start observing responses from the worker object.
const delegate = createDelegate();

delegate.start();
// Output:
// Starting delegate
// Current Status: Hello Delegate
// Doing something
// Current Status: 1620523716260
Alternative Approaches
The wonderful thing about JavaScript is that there are multiple ways of achieving the same result. We can do the same thing we did above by using callbacks or event listeners. A lot of modern JavaScript APIs you can use Promises in combination with async/await in accomplishing the same result.
Conclusion
The Delegation Pattern is a great alternative to having to inherit functionality from a base object, and allows the developer to observe multiple objects at the same time. This is also a great pattern to use if you need to wire up many different lifecycle events to an API without having to use an actual event listener.
Example Code‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeMay 5th, 2021A couple of years ago I wrote a post on Medium for the Node.js Foundation on how to start and run a Node.js User Group. A lot of people have read this post over the years since I wrote it and used it as a guide.
I have been running different user groups for several decades, and I currently run the JaxNode User Group here in Jacksonville, Fl. This last year has been the most challenging year so far for running the group. I wanted to share some of my experiences with hopes that this could assist others who are running or would like to start a user group.
March 2020 üò±
In March of last year I received an email from the company that has hosted our meeting for the last several years. They informed us that they would no longer have any public events until they received CDC guidance that it was safe to reopen to the public. Around that same time Meetup.com, the site we use to advertise our meetings, added a feature to list a link for online meeting software like Zoom.
We did not meet for a couple of months after our location was closed to our group. At that time we were hoping that pandemic would go away after a couple months, but as we know now, the restrictions did not ease after a couple of months.
Online Meetings
Last Summer we transitioned to using Zoom.us for our meetings. Our meetings are usually held on the third Thursday of each month at 6:30 PM. We continued meeting at that same time and the same day of week, just virtually.

      
    
  
  
    
There are a lot of different software options for virtual meetings with different features and costs. Here are some of the options;

Webex
Zoom.us
Google Meet
Microsoft Teams

While all of these options are good for online meetings, they still lack the feel of meeting in person. For now, they will have to do until we can meet in a physical location.
Advertising upcoming Meetings
The ways we advertise our meetings has not changed that much during the pandemic. We primarily use email and Meetup to notify our members about upcoming meetings. The week before a meeting I will send a note out about the upcoming meeting. I then send out an additional email the day before the meeting to remind our users about the meeting. Since we started using online meeting software, we have also been sending out a message right before the meeting starts with the login information.
Future Meetings
I spoke recently with the company that used to host our in-person meetings, and they are not planning on returning to the office until the Fall. Right now we are continuing to use Zoom for our meetings.
One of the requests we have had from our members is once we start in meeting in a physical location again, some would like to continue to meet online as well. We are fortunate because the company we host our meetings at is already set up to use Zoom in their meeting space.
One of the side benefits of using the online meeting software is we can now record the meetings. Since we started meeting last year I have been posting our recorded meetings to Youtube on our channel. So now any user that misses a meeting can now watch the presentation online.
Here is a Youtube video of our last meeting.



Conclusion
Meeting online is not ideal. I am happy that our users still have an outlet and a sense of community with our user group. The other nice thing about the online meetings is that users that do not live in our location here in Jacksonville, Fl can still attend out meetings. Please feel free to attend our next meeting virtually.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeMay 4th, 2021


I recently did a blog post on using Dependency Injection in JavaScript. This technique comes in handy, and can be really useful when using web application frameworks like Express.
Express makes it very easy to inject dependencies into you web application through middleware or into individual routes. In my Express applications when I need a dependency, I inject it directly into a route by injecting it as a service on the request object. But before we do that, lets' break our app up into different modular components.
The Service
For the first part of this application, we will create the actual HTTP requests using the axios library. We will make these requests asynchronous.
// dataservice.js
import axios from 'axios';

async function getVehicles() {
    const results = await axios.get('https://swapi.dev/api/vehicles/');
    return results.data.results;
}

async function getPlanets() {
    const results = await axios.get('https://swapi.dev/api/planets/');
    return results.data.results;
}

async function getStarships() {
    const results = await axios.get('https://swapi.dev/api/starships/');
    return results.data.results;
}

export { getVehicles, getPlanets, getStarships };
I am using the Star Wars API for my example. I have created three functions for getVehicles,getPlanets and getStarships. These methods are using the async/await syntax, which will allow them to be used asynchronously by the module that imports these functions.
Routes
For my Express routes, I like to break the handlers up into their own module. We can then use these handlers in the actual routes, and this will make them easier to test.
// requesthandlers.js
async function vehicles(req, res) {
    try {
        const results = await req.service.getVehicles();
        res.send(results);
    } catch (err) {
        console.error(err);
        res.status(500).send({ error: 'Failed due to Server error!' });
    }
}

async function planets(req, res) {
    try {
        const results = await req.service.getPlanets();
        res.send(results);
    } catch (err) {
        console.error(err);
        res.status(500).send({ error: 'Failed due to Server error!' });
    }
}

async function starships(req, res) {
    try {
        const results = await req.service.getStarships();
        res.send(results);
    } catch (err) {
        console.error(err);
        res.status(500).send({ error: 'Failed due to Server error!' });
    }
}

export { vehicles, planets, starships };
As you can see from the example above, each handler can make service requests from the req parameter, and we are not importing the service explicitly into our handlers. Now we can create the routes we will make for our API calls in its own module.
// apiroutes.js
import { Router } from 'express';
import { vehicles, planets, starships } from './requesthandlers.js';

const router = Router();

router.get('/vehicles', vehicles);
router.get('/planets', planets);
router.get('/starships', starships);

export default router;
The example above shows boiler plate Express route setup in this module.  We can now reference this in our main express app module.
Injecting the Service
For injecting our service, we will need to create a service object that we can attach to the req object, and create a middleware component that actually injects the service into our API route.
import { getVehicles, getPlanets, getStarships } from './dataservices.js';

const service = () => {
    return Object.freeze({
        getVehicles, 
        getPlanets, 
        getStarships
    });
};

const exposeService = async (req, res, next) => {
    req.service = service();
    next();
};
As we can see from the example above we are now importing the individual API functions that we created using axios and creating a service factory that combines all three functions into a single service object. We then create the exposeService middleware that will actually inject this service into our route.
Our completed application should look like the following example;
// app.js
import express from 'express';
import { getVehicles, getPlanets, getStarships } from './dataservices.js';
import routes from './apiroutes.js';

const service = () => {
    return Object.freeze({
        getVehicles, 
        getPlanets, 
        getStarships
    });
};

const exposeService = async (req, res, next) => {
    req.service = service();
    next();
};

const app = express();

app.get('/', (req, res) => {
    res.send('My index route.');
});

app.use('/api', exposeService, routes);

app.listen(3000, () => {
    console.log('Server is started');
});
In the example application we have injected the service into our api routes so it will have access to the Star Wars API on the service property of the req parameter. We also have a default route for the index which point to the '/' route. This 'index' route does not have access to the service because we did not pass the middleware globally, we only passed it into the 'api' route.
Conclusion
Dependency Injection is a very powerful tool that allows us to decouple our application. By breaking these services into their own modules we have also made our application more easily testable using one of the many testing frameworks available to JavaScript. May the 4th be with You!‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeMay 1st, 2021


I have seen some posts on JavaScript and for other languages that dissuade the use of Dependency Injection. I even had a boss at one company I worked for tell his developers that we should never use Dependency Injection.
Dependency Injection, (DI), sometimes referred to as 'Inversion of Control' is where an object receives other objects or functions it depends on for part of its functionality. This can be achieved by passing an object through object instantiation with a constructor or with a property setting. This is very common in the world of statically typed languages like Java or C#. There are many popular frameworks built specifically for managing dependencies in the statically typed object-oriented world.
DI allows specific functionality to be loaded at runtime. One of the advantages of being able to change the functionality of an object at runtime is to provide greater flexibility and make our applications more loosely coupled. A very common use case is using mocking during testing. The are some great libraries in Node.js like Sinon that make mocking very easy, but we can accomplish the same task by using DI.
Testing scenario
It is very common with testing to substitute code that communicates with a database or a network request with a mock or fake. This is because in a lot of CI/CD workflows the build or testing server may not have access to a database server or a network needed for the actual service. This is an excellent use case for DI to substitute an actual service with a mock or fake service.
There are many different reasons to use DI, but testing is one of the most common reasons.
Poor Mans DI
I have a technique that I have used throughout the years for configuring DI in my applications whether they are statically typed or duct-typed like JavaScript that I like to call 'Poor Mans Dependency Injection'. With this technique I usually create default dependent objects if a required object is not passed in on object instantiation.
Lets say we have a cart object that needs to calculate a tax rate for a certain location. In a lot of e-commerce systems that kind of data has to be calculated based on the location of the user, with the sales tax being different for every location. We can create a factory function that creates a shopping cart with an injectable function for calculating the tax.
function createCart(settings) {

    const { taxrepository } = settings;
    let items = [];    

    function addItemToCart(item) {
        items.push(item);
    }

    function removeItemFromCart(removeThisItem) {
        items = items.filter((item, index, arr) => { return item.sku !== removeThisItem.sku });
    }

    function getSubTotal() {
        return items.map(item => item.price * item.quantity)
                    .reduce((accum, item) => accum + item, 0);
    }

    function getTotal() {
        return taxrepository(getSubTotal()) + getSubTotal();
    }

    function getTaxes() {
        return taxrepository(getSubTotal());
    }

    return Object.freeze({
        addItemToCart,
        removeItemFromCart,
        getSubTotal,
        getTotal,
        getTaxes
    });
}
If we look at the following example, we are creating a object with functions for adding items to the cart and calculating the totals and subtotals. We have a function that we can pass into our settings constructor object called taxrepository. We will us this function to calculate our taxes.
Lets create a test function for calculating our taxes. We will make this a pure function without any side effects.
function calculateMyTax(subtotal) {
    return subtotal * 0.11;
}
When we instantiate this object with our factory function, we can just pass it into our settings object;
const cart = createCart({ taxrepository: calculateMyTax });
myCart.addItemToCart({ sku: 'DEF456', price: 2.00, quantity: 2 });
myCart.addItemToCart({ sku: 'HIG789', price: 6.00, quantity: 1 });
myCart.addItemToCart({ sku: 'ABC123', price: 12.00, quantity: 1 });
We can now get the subtotal and calculate the taxes.
console.log(`subtotal:  ${myCart.getSubTotal()}`);
// subtotal:  22
console.log(`taxes:  ${myCart.getTaxes()}`);
// taxes:  2.42
console.log(`total:  ${myCart.getTotal()}`);
// total:  24.42
Defaulting Behavior
All of the objects that I define, I try to create defaults for whenever an injectable behavior is not included in the constructor. That way if someone is using my object without passing in the needed objects, it will either get an error or a default function if it is missing from the constructor. We can modify the factory function to use a default if no taxrepository is passed in the settings object.
const defaultTaxRepository = (subtotal) => { return 0; };

const taxrepository = settings.hasOwnProperty('taxrepository') 
    ? settings.taxrepository 
    : defaultTaxRepository;
We also might to want to have our factory function fail if the developer calling our function forgets to pass the taxrepository into the constructor.
if (!settings.hasOwnProperty('taxrepository')) {
    throw Error(`This function requires a 'taxrepository' to be passed into the contructor!`)
}
Dependency Injection Frameworks
DI frameworks are extremely popular in the statically typed object oriented world of Java and .NET development, but there are DI frameworks you can use for JavaScript. One of the frameworks is called di4js, and will work with either Node.js or plane old JavaScript in the browser. Here is an example from the di4js readme;
var Car = function (engine, year) {
  this.engine = engine;
  this.year = year;
};

Car.prototype.start = function () {
  this.engine.start();
};

var DieselEngine = function () {
  this.hp = 0;
};

DieselEngine.prototype.start = function () {
  console.log("Diesel engine with " + this.hp + " hp has been started...");
};

di
  .autowired(false)
  .register('dieselEngine')
    .as(DieselEngine)
    .withProperties()
      .prop('hp').val(42);
  .register('car')
    .as(Car)
    .withConstructor()
      .param().ref('dieselEngine')
	  .param().val(1976);

var car = di.resolve('car');

car.start(); // Diesel engine with 42 hp has been started...
Conclusion

      
    
  
  
    
Dependency Injection is a very powerful tool for configuring an application to use certain dependencies when creating objects. Whether you are using 'Poor Mans' Dependency Injection or a full fledged DI framework, it can be a very useful tool for configuring different behavior in application.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeApril 26th, 2021As the pandemic winds down, and more and more people start flying again, it is important to remember that the air traveling experience is not all it is cracked up to be sometimes.
A couple of years ago I made a business trip to Northern California on Delta Airlines. I am a Delta Airlines SkyMiles member, and have been for over a decade. I like thousands of other travelers got caught up in the delays and cancellations that affected Delta after a five hour hold on April 5th, 2017 at Atlanta‚Äôs Hartsfield airport. This stoppage caused over 3000 cancellations over the next 5 days.
We have an expression in the South: ‚ÄúIf you die and goto Heaven, you have to stop in Atlanta first‚Äù. Delta‚Äôs biggest hub is in Atlanta. Even though Delta is the second largest carrier in the United States, over 60% of Delta‚Äôs flights go through ATL.
On Thursday of that week I was traveling to San Francisco airport when I got a notification from Delta on my phone that our flight was being delayed from the noon departure time to 3:30 PM. After going through security at SFO I received another notification that my flight to ATL was being bumped back until 8:00 PM.
I decided to make the best of it by reading a book I had in a quiet section of SFO. At 5:30 PM I received a text message from someone who was on the same flight that he had heard that our flight had been rescheduled to leave at 6:00 PM. I preceded to the gate and boarded. I did not receive another notification from Delta about this until 6:00 pm. If Delta had actually left at 6:00 PM, I would have missed my flight back to ATL.
Because like so many other passengers had not received a notification about the departure time, Delta did not depart until just after 7:00 PM. They waited for the 40 passengers who had checked in, but had not boarded yet. We eventually departed SFO at 7:40 PM.
By the time we had landed in ATL is was nearly 3:00 AM in the morning. When I deplaned, I expected that the terminal would be empty. Instead I found thousands of other passengers sprawled out wherever they could find a space sleeping. If they were not sleeping, they were standing in one of the many lines that seemed to go on for miles waiting to try to get rebooked on a flight the next day.

      
    
  
  
    
I was able to book a flight back to Jacksonville for 10:25 AM. While waiting for the next flight, I with the thousands of other passengers got to sit through an alarm that went on for what seemed like hours in Terminal A. You can listen to it below.



While I was waiting for the plane to arrive at my gate, I could not help but notice that there was another flight at my gate that had not left yet. It turns out that the flight before ours needed an additional Flight Attendant, and they would not let anyone board the aircraft until they had one for that flight.
35 minutes before my flight to JAX was supposed to depart, I and the other passengers waiting for our flight got a text message from Delta saying that our flight had been moved to another terminal. I made it with the other passengers to the new gate and proceeded to board the aircraft for JAX. This flight was only 25 minutes late, and we arrived in JAX just after noon on Friday. My colleague was not as lucky. Even though he boarded his connection to JAX an hour before my flight, they did not touch down until 2:00 PM. The reason for the delay was that aircraft they boarded was originally headed to Portland, and they had too much fuel to land at JAX. Everyone had to deplane that aircraft because they could not get a fuel truck out to empty fuel from the tanks. By the time one had arrived, it was too late. Delta had already changed the manifest.
Why did no one hear of this Massive Delay for Delta
In what turned out to be one of the luckiest PR events in the history of the airline industry, in the same week that Delta‚Äôs system wide travel failure occurred, United Airlines forced a Doctor off one of their flights. This became the prevailing horrible airline news story from that week. United got all of the bad ink for that week, and Delta escaped any public ridicule.
Read about Dr. David Dao at ABC News.
End Result
I am a licensed commercial pilot, but at this point I had not flown in two decades. After going through this ordeal and given the extra special treatment from the TSA one too many times, I decided to get current and start flying again.
Since then I have purchased a partnership in a Cessna Cardinal. This is not as fast or inexpensive as traveling on an airline, but I no longer have to go through the TSA, and I can set my own schedule for when I want to travel and where.
If you hate traveling with the airlines, you should seriously consider getting a pilots license.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeApril 25th, 2021


A while back I wrote a quick and dirty aviation weather proxy for the FAA's weather service. The existing weather service returns the data in an XML format. So I created an express app that proxies two of the web methods from that service so they will return JSON instead of XML.
The original proxy service I wrote is a simple express app. Last year during the start of the pandemic I started looking at alternate frameworks. Fastify has become increasingly popular of the last couple of years.

      
    
  
  
    
Fastify is also a more modern framework for writing web apps. It has some unigue features like JSON schemas for the request and response. It also has its own JSON parser. The one used by express is the default parser used in V8.
Here is what the original express app looks like for hosting those two methods;
const express = require('express');
const axios = require('axios');
const parser = require('fast-xml-parser');
const cors = require('cors');

const port = process.env.PORT || '3000';
const app = express();

app.use(cors())

app.get('/metar/:icaoidentifier', (req, res) => {
    axios.get(`https://www.aviationweather.gov/adds/dataserver_current/httpparam?dataSource=metars&requestType=retrieve&format=xml&stationString=${req.params.icaoidentifier}&hoursBeforeNow=2`).then(xml => {
        const jsonObj = parser.parse(xml.data);
        if (jsonObj.response.data.METAR.length > 0) {
            res.json(jsonObj.response.data.METAR);    
        } else {
            res.json(jsonObj.response);
        }
    }).catch(err => {
        res.json(err);
    });
});

app.get('/taf/:icaoidentifier', (req, res) => {
    axios.get(`https://www.aviationweather.gov/adds/dataserver_current/httpparam?dataSource=tafs&requestType=retrieve&format=xml&stationString=${req.params.icaoidentifier}&hoursBeforeNow=4`).then(xml => {
        const jsonObj = parser.parse(xml.data);
        res.json(jsonObj.response.data);
    }).catch(err => {
        res.json(err);
    });
});

app.use(function (req, res) {
    res.status(404).send('404');
});

app.listen(port, () => console.log('Example app listening on port 3000!'));
As you can see from this example, I am using axios as my HTTP client. I prefer axios over node-fetch because of some of the options available to axios, and that it does not require resolving two promises.
Upgrading to Fastify
The first change I wanted to make was to use the new module import syntax over the commonjs require nethods for importing in my modules. You can turn this on by default in version of node.js 14 and later by adding the following key to your package.json.
"type": "module"
Node.js still defaults to 'commonjs' if you do not specify a type in the package.json.
Adding Fastify Module
Now you can use NPM or YARN to add the Fastify module. I am also using CORS, so we can add this and update our package.json file for these dependencies at the same time by running the following command;
> npm i fastify fastify-cors --save
Here I am using the shortcut of i for install, and I am using NPM's --save flag to save both modules to the package.json file. Your package.json file should have the following module in the dependency section.
    "axios": "^0.18.0",
    "cors": "^2.8.5",
    "express": "^4.16.3",
    "fast-xml-parser": "^3.12.5",
    "fastify": "^3.15.0",
    "fastify-cors": "^5.2.0"
Adding the Import statements to our App
Add the following import statements to the beginning of our app.
import Fastify from 'fastify';
import fastifyCors from 'fastify-cors';
import axios from 'axios';
import * as parser from 'fast-xml-parser';
At this point we can create our Fastify object and register any plugins that we will need in our app. Previously I was using CORS, so I will register that plugin once the object has been instantiated for Fastify.
const fastify = Fastify({ logger: true });

const port = process.env.PORT || '3000';

fastify.register(fastifyCors, { 
    // put your options here
});
Typically in most Node.js web apps, the routes are configured separate from the main application file, in their own module or plugin. This will make the application more loosely coupled and easier to test. For this example I am just going to configure the two methods in the same file as the main application.
fastify.get('/metar/:icaoidentifier', async function(request, reply) {
    const path = `https://www.aviationweather.gov/adds/dataserver_current/httpparam?dataSource=metars&requestType=retrieve&format=xml&stationString=${request.params.icaoidentifier}&hoursBeforeNow=2`;
    const xml =  await axios.get(path);
    const jsonObj = parser.parse(xml.data);
    if (jsonObj.response.data.METAR.length > 0) {
        return jsonObj.response.data.METAR;    
    } else {
        return jsonObj.response;
    }
});

fastify.get('/taf/:icaoidentifier', async function(request, reply) {
    const path = `https://www.aviationweather.gov/adds/dataserver_current/httpparam?dataSource=tafs&requestType=retrieve&format=xml&stationString=${request.params.icaoidentifier}&hoursBeforeNow=4`;
    const xml = await axios.get(path);
    const jsonObj = parser.parse(xml.data);
    return jsonObj.response.data;
});
These two routes are now using async function handlers, so I can use the async/await syntax. I can also use return instead of having to use reply.send(response).
Starting the App
A common example for starting up fastify for hosting the application, we set up a start method that is also asynchronous. Fastify has this in their docs as well.

const start = async () => {
    try {
        await fastify.listen(port);
    } catch (err) {
        fastify.log.error(err);
        process.exit(1);
    }
}

start();
The final application should look like this when you finish updating your express app.
import Fastify from 'fastify';
import fastifyCors from 'fastify-cors';
import axios from 'axios';
import * as parser from 'fast-xml-parser';

const fastify = Fastify({ logger: true });

const port = process.env.PORT || '3000';

fastify.register(fastifyCors, { 
    // put your options here
});

fastify.get('/metar/:icaoidentifier', async function(request, reply) {
    const path = `https://www.aviationweather.gov/adds/dataserver_current/httpparam?dataSource=metars&requestType=retrieve&format=xml&stationString=${request.params.icaoidentifier}&hoursBeforeNow=2`;
    const xml =  await axios.get(path);
    const jsonObj = parser.parse(xml.data);
    if (jsonObj.response.data.METAR.length > 0) {
        return jsonObj.response.data.METAR;    
    } else {
        return jsonObj.response;
    }
});

fastify.get('/taf/:icaoidentifier', async function(request, reply) {
    const path = `https://www.aviationweather.gov/adds/dataserver_current/httpparam?dataSource=tafs&requestType=retrieve&format=xml&stationString=${request.params.icaoidentifier}&hoursBeforeNow=4`;
    const xml = await axios.get(path);
    const jsonObj = parser.parse(xml.data);
    return jsonObj.response.data;
});

const start = async () => {
    try {
        await fastify.listen(port);
    } catch (err) {
        fastify.log.error(err);
        process.exit(1);
    }
}

start();
Conclusion
As you can see from this example, the structure of a Fastify app is not that dissimilar to an Express app. For a simple application like this, this is a good example of an app that can be upgraded to Fastify.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeApril 21st, 2021The Node.js foundation just released the first version of Node v16.0.0. The Node.js maintains multiple versions, including the current release along with a long term support (LTS) release. The current v16 release will become the LTS release sometime in October 2021. This is the normal release schedule for Node.

      
    
  
  
    
Apple Silicon Support
Apple released a new CPU architecture last November based on ARM64. These are the Macs using the M1 chip from Apple. While Node.js did run on these newer machines, it did so through Apple's Rosetta technology. Rosetta allows x86_64 code to run in emulation on the newer chips. While this is stable, it is not ideal.

      
    
  
  
    
You can now download this release through the Node foundation as a .pkg file or through the Node Version Manager. This is the first release with Apple Silicon binaries. The .pkg installer will install a universal binarythat will run either on Apple Silicon processors or on Intel based Macs.
V8 version 9.0
The version of V8, the JavaScript engine for Node.js, has been upgraded to version 9.0. Previously in Node version 15, they were using V8 8.6.
Part of this new version of V8 includes new Regular Expression capabilities for start and end indices of a captured string. This is available when you use the /d flag and access the .indices array property.
Stable Timers Promises API
Stable Timers were previously available in Node v15 under an experimental status. They are now considered a stable feature.
import { setTimeout } from 'timers/promises';

async function doSomething() {
  console.log('doSomething started!');
  await setTimeout(2000);
  console.log('Delayed Timers!');
}
doSomething();
Experimental Web Crypto API
The Web Crypto API is the newer more well defined version of the Crypto library for JavaScript. All of the new Web Crypto methods are available on the subtle interface.
Many browsers used an interface called Crypto without having a specific specification. The Web Crypto API adds a standard to the Crypto library.
import { webcrypto } from 'crypto';
const { subtle } = webcrypto;

(async function() {

  const key = await subtle.generateKey({
    name: 'HMAC',
    hash: 'SHA-256',
    length: 256
  }, true, ['sign', 'verify']);

  const digest = await subtle.sign({
    name: 'HMAC'
  }, key, 'I love node.js');

  console.log(digest);
})();
Node-API version 8
The Node API provides an interface for writing Native C++ add-ons as node modules. Version 8 of the Node-API adds native methods for the following methods;

napi_add_async_cleanup_hook
napi_object_freeze
napi_object_seal
napi_type_tag_object
napi_check_object_type_tag
napi_type_tag

AbortController
The AbortController Web API provides a global API that can be used to cancel select promised based APIs. Event listeners should use the { once: true } option  ensure that the event listener is removed. Here is an example of the AbortController being used with a event listener;
const abortC = new AbortController();
abortC.signal.addEventListener('abort', () => {
    console.log('Just cancelled')
}, { once: true });
abortC.abort();
console.log(abortC.signal.aborted);
Buffer atob and btoa
These methods for converting data into base64 encoded strings and back where added to support legacy web platform APIs. This is not the preferred way, and should not be used in new code.
The preferred way to convert data into a base64 encoded string is to use the Buffer.from(data, 'base64') method or buf.toString('base64') to convert the buffer into a 'base64' string.
const str = 'Hello JavaScript Developer!';

const strBuf = Buffer.from(str, 'utf8');
console.log(strBuf);
// <Buffer 1d e9 65 a0 96 af 69 27 2b 8a 9b 43 7a f7 a5 a2 97 ab>

const base64Buf = Buffer.from(strBuf, 'base64');
const base64Str = base64Buf.toString('base64');
console.log(base64Str);
// SGVsbG8gSmF2YVNjcmlwdCBEZXZlbG9wZXIh

const bufFromBase64Str = Buffer.from(base64Str, 'base64');

const decodedStr = bufFromBase64Str.toString('utf-8');
console.log(decodedStr);
// Hello JavaScript Developer!
console.log(str === decodedStr);
// true
Other features

npm v7.10.0
Source Maps v3
process.binding() has been deprecated

Conclusion
Node.js upgrades are usually incremental upgrades. As the V8 runtime is upgraded with new features, Node gets these features with the new version of V8. I am looking forward to the LTS release in October.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeApril 20th, 2021


I posted a video to Youtube back in November on whether Apple Silicon M1 Macs could and should be used by Developers and Software Engineers. I received more views for that video than any other video, with the exception of one I made of my broken air conditioner.
As I write this, Apple did their big April 20th, 2021 product announcements. One of the products they announced was the new M1 iMac. I have not purchased one of the new M1 Apple Silicon Macs yet, but I may buy one of these iMacs. The computer I am writing this on right now is a 27" iMac with an I7 processor.
I primarily use my iMac for development, so I wanted to see where the development tools I use are as far as support for the new M1 Macs. When the M1 Macs were first released, there was pretty good support for regular user software through either universal apps or through a program on the Mac called Rosetta 2 that will allow you to run x86_64 code on an M1 chip. Lets' take a look to see where we currently are with the tools that developers need.
Tools
Homebrew is similar to package managers like apt-get on Linux or Chocolatey on Windows. It is a command line tool for installing applications and libraries targeting Unix like operating systems. When the original M1s were released, there was not good support for Homebrew. My understanding is that it has been completely ported to the new ARM64 based architecture.
Integrated Development Environments and Code Editors

Xcode: This is fully supported on the M1 Macs as a Universal App. Xcode also has cli based tools for compiling code for Homebrew and other tools.
Android Studio: Google currently has a developer preview available that runs on the M1. There is basic support for running Android simulators, but your best success will be trying to run directly on a device.
Visual Studio Code: The editor is very popular with Web Developers, and has wide language support. Microsoft has released it as a Universal App, so it will run natively on both M1s and x86 based Macs.
JetBrains: This IDE is very popular with Java developers, and it now fully supports the M1 processor.
Eclipse: Here is a Java IDE I stopped using nearly 20 years ago. There is currently no builds of this for the M1 processor, but you can supposedly run it using Rosetta 2.

Language Support

C, C++, Objective-C and Swift: All of these languages have native compiler support on the M1 Macs through Clang and the Swift compiler. These come included with the Xcode tools.
Java: The Oracle OpenJDK currently has support for the M1 processors.
Node.js: This very popular JavaScript runtime can now run natively as of Node.js v16. If you are looking for a long term support release, you will have to compile from source or run under Rosetta 2.
Python: Python now has native support for the M1 processor.
R: No support for the R programming language. The reason for this is because R is built using a newer version of Fortran. Fortran code can be converted to C, but only Fortran-77. R was built with a newer version of Fortran.
Go Lang: Go is now fully supported on the M1 processor.
Rust: The Rust compiler was built with LLVM, the same compiler technology used for Xcode languages. It is now supported on the M1 processor.

Docker and Virtualization

Docker: There was an early release of Docker that came out last year, but as a couple of days ago Docker released full support for the M1 processor. Docker supports images that run on both ARM and x86.
VMWare Fusion: VMWare says they are commited to an M1 version, but they have had no annuncements around an M1 release. Hopefully they will have something soon.
Parallels: As of April 19th, Parallels just released Desktop 16.5 for the Mac.
UTM: This looks like a newcomer. I think it is based on QEMU, but this app will allow you to run Windows and Linux based ARM OSs.

Frameworks

.NET: .NET 6.0 which is in preview has a installer for the M1 based Macs. If you are trying to run an earlier version, you will need Rosetta 2.
Electron: Electron is a framework for turning HTML and JavaScript based applications into Desktop apps. Visual Studio COde is based on Electron. Electron is now natively supported on the M1 processor.
Flutter: This works under Rosetta 2. No word yet when it will be native on the M1 processor.

Conclusion
When I first looked at developer support for Apple Silicon when the M1 Macs were first released, the support was really poor. As of today, the support looks much better. Some of the native tools are in a preview and are not official releases. If you are doing Android development, you may want to keep using an x86 based machine. For most other kinds of development the M1s look a lot safer than they did in November 2020.
Please do your own homework to make your own decision, but I hope the research I have done can assist.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeApril 18th, 2021


Apple will be releasing OS updates for most of their mobile devices pretty soon. There is a change that has ruffled the features of a lot of people in the online advertising industry.
The issue revolves around an API that Apple has for iOS called the Advertising Identifier, or IDFA for short.
The IDFA is used by advertisers to tie advertising campaigns back to a specific device. This is very similar to how they track users with cookies on certain browsers. I say certain browsers because Apple's Safari and Brave have blocked this type of tracking. This is why when you are searching for a certain product or service on one page, and then you browse to another website you will sometimes see ads for what you were just searching. Advertisers are doing this mainly so they can tie campaigns and their success to the users viewing the ads.
For mobile app developers like Facebook, they sell advertising campaigns for other mobile apps. If a user installs a mobile app based on an ad campaign they saw on Facebook, they use the IDFA to tie the device back to the campaign to know how effective the campaign was for that app install.
What is Apple doing?
In the upcoming release of iOS 14.5 developers are being required to get permission from the user to get their IDFA. Facebook and other companies believe that when users are prompted to allow them to track, the users will simply deny them that permission.
If the user does not give permission to use their IDFA, the app developer will get a series of zeros when they look up this identifier. It will look something like this to the developer;
00000000-0000-0000-0000-000000000000
By doing this, all users that opt out will have the same IDFA, rendering it useless for the campaign.
How do you currently get the IDFA
To retrieve the IDFA for the device now, their is a simple API call that is made to the ASIdentifierManager in the code. Here are some examples in Swift and Objective-C;
// Swift
import AdSupport

...

let idfa = ASIdentifierManager.shared().advertisingIdentifier
// Objective-C
#import <AdSupport/AdSupport.h>

...

NSUUID *IDFA = [[ASIdentifierManager sharedManager] advertisingIdentifier];
In iOS 14.5 and greater, if you want to get a valid identifier back, you will need to add a key to your info.plist for NSUserTrackingUsageDescription. You will have to make sure the description here is valid, otherwise Apple will reject your application. Here is what it looks like on the Xcode project 'info' tab;

      
    
  
  
    
Solutions when the User Ops Out of App Tracking
If you were to ask most mobile phone users if they want to be tracked, I believe most would say no. This is one of the reasons why Facebook is so upset. This may not satisfy Facebook, but Apple has added an API to try to find a middle ground with advertisers while satisfying the privacy concerns of their customers.
Apple has a framework called SKAdNetwork which allows advertisers to run campaigns without gathering the unique identifier of a users device. While this does not replace what advertising networks can do with a IDFA, it does give them feedback on the success of a campaign.

      
    
  
  
    
Graphic courtesy of Apple, Inc.
To use the new functionality, developers will need to register their Ad Network with Apple. Once they have registered their network, the developer will need to configure the participating apps for the network identifier, or SKAdNetworkIdentifier. This can be done by adding a dictionary to the 'info.plist' for the key 'SKAdNetworkItems'.
<array>
    <dict>
        <key>SKAdNetworkIdentifier</key>
        <string>adnetworkA</string>
    </dict>
    <dict>   
         <key>SKAdNetworkIdentifier</key>
         <string>adnetworkB</string>
    </dict>
</array>
The apps that are installed can update Apple about the conversion by calling the registerAppForAdNetworkAttribution() or updateConversionValue(_:) methods in SkAdNetwork. No personal information is shared with the advertiser. Apple will update the advertiser with a callback within 24 hours of the conversion.
The advertiser will have to host a service to receive the callback. This is done when registering the advertising network. Apple will provide feedback with 24 hours. If the request is unsuccessful, they will try again nine times over nine days.
Relevant documentation
Registering an Ad network
Configuring the Participating Apps
Receiving Ad Attributions
Summary
I am sure that advertisers are going to find ways to get around this limitation with the IDFA, but there are tools that we can use to track the success of a campaign.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeApril 17th, 2021


I recently wrote a post on the way I like to create objects in JavaScript. I call this style of object creation 'Crockford Objects', named after Douglas Crockford, author of "JavaScript: The Good Parts".

      
    
  
  
    
I received a lot of feedback from people telling me that I did not explain why they should not use the 'class' keyword in JavaScript. I didn't explain why because I was not saying that you can't use it, I just prefer not to use the 'class' keyword for defining an object.
JavaScript is not an Object-Oriented Language
If you are familiar with the history of JavaScript, Brendan Eich was told they he was going to be able to write a scripting language for the Netscape Navigator to be based on Scheme. Scheme is a functional programming language. Then Eich was told that it had to look similar to Java, hence the name 'JavaScript'. Oh, by the way, he only had two weeks to get it done.
So JavaScript was never intended to be an Object-Oriented language. It is actually a Prototype-Oriented language.
Douglas Crockford likes to joke that most developers who start using JavaScript never bother to actually learn the language first. And if you start looking at the language it has a lot of similiarities to Java and C#. In Java and C# you define classes as a template for a new object. In JavaScript, everything is an object.
Classes were added to JavaScript as a concession for C# and Java developers. Underneath the hood, the JavaScript engines still create objects the same way.
Binding
Binding is an issue that longtime React developers are familiar with in their applications. Objects defined with classes havto explictly use the this keyword. If you pass your class method to a callback, you can run into binding issues. This is why you will see a lot of code where the method has to be bound to the correct context. Lets take a look at an example;
class Thing {

    constructor() {
        this.myMethod = this.myMethod.bind(this);
    }

    myMethod() {
        // Does something here
    }

}
As you can see from the example above, the myMethod is being bound back to itself. To perform this function in the constructor, we have had to use the this keyword three different times.
Inheritance is bad
When I was first learning Object-Oriented programming, one of the three main features is inheritence. You can do this with the extends keyword by extending from a base class.
class Cat extends Animal {
    // Body here
}
Under the hood in JavaScript this is done by a delegate to the parents prototype property. There are performance considerations with this type of operation, but that is not the main reason to avoid inheritance.
Even in true Object-Oriented languages, inheritance should be avoided. A common problem that developers run into with inheritance chains is the fragile base class problem. This is sometimes referred to the Gorilla/Banana problem. The main issue has to do with tight coupling to a parent object. If you need to make a change to the parent object, it is reflected down the entire tree of objects. I am currently working with a Java API where this is a huge problem.
Composition of objects in most cases is a better approach than inheriting from parent objects, even in Object-Oriented languages. In strictly typed languages like Java or Swift you are better off inheriting from an interface or a protocol than from a class. Also in Java and C# you can inherit from an Abstract class.
Encapsulation
Encapsulation is another feature of Object-Oriented programming that is actually a good feature. Te idea behind encapsulation is that we are able to hide the implementation details of our object by using data and methods that are only accessible from inside the body of our class. While it is possible to create private functions inside of a class by using the '#' character, we can not make variables private in JavaScript.
class APerson {
    constructor(first, last) {
        this.firstname = first;
        this.lastname = last;
    }
    printName() {
        console.log(`${this.firstname} ${this.lastname}`);
    }
}

const somePerson = new APerson('David', 'Fekke');
somePerson.firstName = 'Bob';
somePerson.printName();
// Output: Bob Fekke
As you can see from the example above, we set the all of the properties in our class from outside the class. This violates one of the key principles Object-Oriented programming.
React
React is one of the front end frameworks I have used, and they recently made a change to the default way they create components. Previously in React you would create a class that extended React.Component. When React 16.8 was released they added a new feature called 'Hooks'. If you need to manage state in your component, you would use the useState hook in your function. This allows us to write and return components that export a function instead of a class.
Using classes previously we would create components that looked like the following;
import React from 'react';

class Example extends React.Component {
  constructor() {
      super();
      this.state = {
          count: 0
      }; 
  }

  incrementCount() {
      const countPlusOne = this.state.count + 1;
      this.setState({ count: countPlusOne });
  }

  render() {
      return (
        <div>
            <p>You clicked {this.state.count} times</p>
            <button onClick={() => { this.incrementCount() }}>
                Click me
            </button>
        </div>
    );
  }
  
}

export default Example;
Now we can compose the same component using just a function and the useState hook.
// Example taken from https://reactjs.org/docs/hooks-intro.html
import React, { useState } from 'react';

function Example() {
  // Declare a new state variable, which we'll call "count"
  const [count, setCount] = useState(0);

  return (
    <div>
      <p>You clicked {count} times</p>
      <button onClick={() => setCount(count + 1)}>
        Click me
      </button>
    </div>
  );
}

export default Example;
As we can see from the last example, it is much easier to create a function for a component rather than using the class as we did in the previous example.
Summary
When I am writing JavaScript objects I prefer to use factory functions instead of classes. By using a factory function we no longer need to use the this keyword or the new keyword for creating a new object. There are still some reasons why you might want to continue to use classes in JavaScript. It is technically faster to use the new keyword over Object.create or Object.freeze, but we are talking about a few milliseconds. Eric Elliot has writen a number of good posts on the class keyword at the JavaScript Scene. I would recommend reading his post on the class keyword.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeApril 14th, 2021In a previous post I discussed how we can create objects from a function using a closure. I based this example on a presentation Douglas Crockford made at JS Fest 2018.
Constructors
Constructors are functions or methods that are used for initializing an object with the values it needs to encapsulate at object creation. If you are using the class syntax in JavaScript, there is actually a built in method for constructors called constructor.
One of the things that Crockford discussed in this presentation was how we define the constructor parameters to the defining function. He suggested to just pass one single object into the function.
JavaScript allows us to pass as many parameters as we want to a function. The issue that we run into is what happens when you add a parameter to your function, you have to refactor every place in your code that is calling that function.
Lets take the example of a function that defines an employee object. For this example we will use a function that has parameters for each property in the object;
function createEmployee(firstname, lastname, department) {
    function getFullname() {
        return `${firstname} ${lastname}`;
    }

    return {
        firstname, 
        lastname, 
        department,
        getFullname
    };
}

const empObj = createEmployee('David', 'Fekke', 'IT');
Now lets say we get a requirement to add an employee number to this object. We now have to add that parameter to every place in our code where we use that function.
function createEmployee(firstname, lastname, department, empNo) {
    function getFullname() {
        return `${firstname} ${lastname}`;
    }

    function getEmployeeNumber() {
        return empNo;
    }

    return {
        firstname, 
        lastname, 
        department,
        empNo,
        getFullname,
        getEmployeeNumber
    };
}

const empObj = createEmployee('David', 'Fekke', 'IT', 890234);
One of the problems of passing each value as a separate parameter is that not all of the parameters may need to be required. There are a lot of use cases where we do not need every possible parameter passed to a construtor. There are use cases where we may want to default to certain values instead.
A more elegant approach would be to pass a parameters object into the constructor function.
function createEmployee(params) {
    
    const {firstname, lastname, department } = params;
    
    function getFullname() {
        return `${firstname} ${lastname}`;
    }

    function getEmployeeNumber() {
        const { empNo } = params;
        return isNaN(empNo) ? 0 : empNo;
    }

    return {
        firstname, 
        lastname, 
        department,
        getFullname,
        getEmployeeNumber
    };
}

const params = {
    firstname: 'David',
    lastname: 'Fekke', 
    department: 'IT',
    empNo: 890234
};

const empObj = createEmployee(params);
One of things that is nice about this approach is that we can use JavaScript destructuring to get the specific values from out parameters object. In the example above we just put the name of the parameter we need inside of the curly braces, and if that property exists, we can use that in our function body.
This technique is also very handy when you have parameters that may not be required or optional. It also does not matter the order of the parameters. We can put our properties in any order when creating our parameters object literal.
Summary
By using function objects instead of separate parameters we have made our constructors more flexible. We also are taking advantage of new JavaScript features for optional checking and destructuring the parameters object to get just the values we need.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeApril 12th, 2021Apple and Google are both large companies. When issues crop up with their technology, and we file bugs, it can sometimes take years to be addressed. For individual developers this can be unbelievably frustrating.
Even though it is highly encouraged for developers to build mobile apps natively, there are lots of apps and frameworks that require the use of web based components.
Cordova, Phonegap and Ionic are all examples of SDKs that let developers build mobile apps using HTML, CSS and JavaScript using native WebViews.
On iOS there are a number of choices. The 'UIWebView' has been deprecated, but Apple offers both the 'WKWebView' and the 'SFWebView' for presenting web content to end users. On Android there is only one WebView called 'WebView'.
The WebView is important
Even if you are building an app that is almost completely native, there are still reasons why you might want to use a WebView. HTML and CSS in a browser turns out to be a powerful rendering engine. There is some content where is just makes sense to render in a WebView.
Another reason is authentication. Whether you are using OpenID or OAuth, many of these frameworks require that users login to their service using a WebView. Facebook, Google and Salesforce all require that users logging in through their sing sign on providers do so through a WebView.
Android WebView issues
There have recently been a series of issues that have cropped up on Android with the WebView that has broken thousands of applications. Google addressed this issue, but there are a host of other issues that Google has not addressed. These issues pertain to the WebView being able to handle incoming HTTP requests.
The WebView gives app developers a number of features that can be overwritten using an interface called the WebViewClient. The WebViewClient includes many different methods that a developer can use to override the default behavior of the WebView. By default on the Android WebView, a user tapping on any link will get kicked out of the current app into Chrome. You can override this by implementing the 'shouldOverrideUrlLoading' method, and returning false.
Overriding requests
The WebViewClient also gives developers a way of overriding incoming requests. To override an incoming request, you can use the 'shouldInterceptRequest' method on your WebViewClient as seen below.
public WebResourceResponse shouldInterceptRequest(WebView view, WebResourceRequest request) {
    return shouldInterceptRequest(view, request.getUrl().toString());
}
This is an improvement over the previous implementation which only included the WebView and the String representation of the incoming URL. It was deprecated in API level 21.
public WebResourceResponse shouldInterceptRequest(WebView view, String url) {
    return null;
}
The original purpose for this method was to handle a request for a specific resource like an image or stylesheet which could be cached locally on the device, and retrieved for faster access. While that is a good use case, it only works for certain types of HTTP requests, like GETS, DELETES. There are other use cases where we need to be able to handle POSTs and PUTs using this interface.
The 'shouldInterceptRequest' cannot really be used for POSTs and PUTs because these include a HTML or JSON body. If you are making a form POST with credentials, this method cannot be used because it does not include the body. This also will not work if you have client side JavaScript making AJAX requests with POSTs and PUTs.
There are workarounds that can be used where you can override the document 'submit' event listener and the XHR object in the DOM of the web content, but this can violate the security policies of some web applications. Ultimately what we need is for Google to add the body to the 'WebResourceRequest' object. Here is what the interface for the 'WebResourceRequest' includes;
package android.webkit;

import android.net.Uri;

import java.util.Map;

public interface WebResourceRequest {
    
    Uri getUrl();

    boolean isForMainFrame();

    boolean isRedirect();

    boolean hasGesture();

    String getMethod();

    Map<String, String> getRequestHeaders();
}

As we can see from the example above, the 'WebResourceRequest' includes the Uri of the request as well as the method and the request headers. But it does not include the body.
Summary
In order for the system 'WebView' on Android to truly be useful, issues like these need to be addressed, otherwise it forces developers to use 'hacky' solutions which can not be guaranteed to work in all security situations. I hope that Google will fix this in future versions of the Android, or with the Jetpack.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeApril 8th, 2021


I wrote a post yesterday on how to use a WebView on iOS without using Cordova. I got a couple of requests to show how to do this on Android using Kotlin and the WebView widget. Like on iOS, this is a very easy task to accomplish on Android.
The first thing we are going to do is create a new Android project using Android Studio. Select 'File' -> 'New' -> 'New Project' from the menu. Android Studio will display a wizard giving you a choice of which Project Template to base your app from.

      
    
  
  
    
We will select the 'Basic Activity'. Then click on the 'Next' button. The next screen asks you what you want to name the app and the Package name.

      
    
  
  
    
Pick a name for your application, package, and choose 'Kotlin' for the language. Then click on the 'Finish' button, and Android Studio will create the template for the application.
Adding the WebView
In your project expand the 'res' folder , then the 'layout' folder in your 'app'. Open the content_mail.xml layout. You will see the white and green preview screens side by side. Click on the white preview to select it, then delete the fragment.
In the palette on the upper left hand side, select 'Widgets', then click and drag the 'WebView' widget into the center of the view. Once you have dropped it into place, we will need to fix the constraints. We can do this by clicking on the 'Infer Constraints' button at the top of the view window. It looks like a magic wand. Once this has been done, the semi-circles at the top, bottom, left and right of the view will turn blue.
In the 'Attributes of the view we are going to rename the id from 'webView' to 'myWebView'.
Changing the activity
Now that we have added the WebView widget the view, we change the code in the main activity to load an external website into the WebView. Open the 'MainActivity' class and delete the following code from the 'onCreate' function.
findViewById<FloatingActionButton>(R.id.fab).setOnClickListener { view ->
    Snackbar.make(view, "Replace with your own action", Snackbar.LENGTH_LONG)
            .setAction("Action", null).show()
}
Now we can add our code for loading the a website into the WebView. Add the following code to the 'onCreate' method after the setSupportActionBar.
val myWebView = findViewById<WebView>(R.id.myWebView)
myWebView.loadUrl("https://fek.io")
You will also need to add the android.webkit.WebView to the imports at the top of the activity.
import android.webkit.WebView
In order to load an external website into the WebView, you will have to add a permission to the AndroidManifest.xml file for INTERNET access. After the <application/> tag, add the INTERNET permission.
<uses-permission android:name="android.permission.INTERNET"></uses-permission>
Tapping on link in the WebView
In order to open up hrefs in the WebView we will have to override the default behavoir of the WebView. We can do this by adding a WebViewClient to the webViewClient property on our WebView. Add the following lines to the 'onCreate' function before we call the 'loadUrl' function. The final 'onCreate' function should look like this;
override fun onCreate(savedInstanceState: Bundle?) {
    super.onCreate(savedInstanceState)
    setContentView(R.layout.activity_main)
    setSupportActionBar(findViewById(R.id.toolbar))

    val myWebView = findViewById<WebView>(R.id.webView)
    myWebView.webViewClient = object : WebViewClient() {
        override fun shouldOverrideUrlLoading(
                view: WebView?, 
                request: WebResourceRequest?): Boolean {
            return false
        }
    }
    myWebView.loadUrl("https://fek.io")
}
Now you should be able to run your app and have it use the new WebView widget.
Summary
We have obviously just scratched the surface on what we can do with WebViews on Android. I intend on doing several more posts on the WebViews on iOS and Android in the near future.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeApril 7th, 2021


Cordova is a very popular framework for creating mobile applications that are based on web technologies. It allows developers to create apps that are based on HTML, CSS and JavaScript. There are a number of different software development kits that are based on Cordova. These include Ionic and PhoneGap.

      
    
  
  
    
Some Cordova apps just use local content in the app, while some point to a remote endpoint. Either way the same thing can be accomplished fairly simply in a native mobile app using the native WebView components. Both iOS and Android have native components that can be used for displaying Web content. For this post I will show how to do this with Swift on iOS using the WKWebView.
iOS WebViews
There are actually three different types of WebView in iOS. Lets look at the differences between these different WebViews.
UIWebView
iOS actually has three different WebViews you can use, but one of these is deprecated. The original framework for displaying web content was the 'UIWebView'. This WebView was slow, and not optimized like the browser built into Safari.
Apple has deprecated the 'UIWebView', and it will no longer accept new apps with any references to the 'UIWebView', so don't plan on using this WebView.
WKWebView
Apple introduced the 'WKWebView' in iOS 8, and has made substantial improvements every year. This is the one you should plan on using if you want to use it as a replacement for Cordova, Ionic or Phonegap.
SFWebView
The 'SFWebView' is the Safari WebView. Think of this as a mini browser you can embed in your app. It has many of the same features you would find in a web browser. If you are mainly trying to display HTML content, and do not need an address bar or back button, you can use the 'WKWebView'.
How to create a WebView app for iOS
Let's build an app in Xcode that simply displays a web page. We will write this application in Swift using a UIKit based app. The first thing you will need to do is create a new project in Xcode.

      
    
  
  
    
On the next screen we want to make sure we set the interface to Storyboard, the life cycle to 'UIKit App Delegate' and the language to 'Swift'.

      
    
  
  
    
In this new Xcode project we will want to delete the scene manifest from the 'info.plist' We can do this by making sure we have the project selected in the Project Navigator on the left hand side of Xcode.

      
    
  
  
    
You will see a series of tabs in the main window. Select the tab that says 'info'. This displays all of the 'info.plist' keys. We want to select the key for the scene manifest, and delete it from the list of keys.
After deleting the scene manifests we want to remove the storyboard reference from the 'Main interface'. Select the 'General' tab, and you should see the 'Main interface'. It should have 'Main.storyboard' currently selected.

      
    
  
  
    
Delete the 'Main.storyboard' from the 'Main interface' field so it is empty.
WebViewDelegate
We are now going to create a new ViewController class called 'WebViewController.swift'. You can do this in Xcode by going to the File menu, selecting New -> File. Make sure to choose the Cocoa Touch Class. On the next screen name the class 'WebViewController', subclass the 'UIViewController' and choose 'Swift' for the language.

      
    
  
  
    
We are going to add the WKWebView to this class as a property. In order to do this we will need to import in the WebKit framework. We will also set up view constraints in the code so we do not have to use the storyboard. The final 'WebViewController' class should look like this next example.
//
//  WebViewController.swift
//  WebViewExample
//
//  Created by David Fekke on 4/7/21.
//
import UIKit
import WebKit

class ViewController: UIViewController {

    private var webView: WKWebView?
    
    private var urlString: String?
    
    init(url: String) {
        super.init(nibName: nil, bundle: nil)
        urlString = url
    }
    
    required init?(coder: NSCoder) {
        fatalError("init(coder:) has not been implemented")
    }
    
    override func loadView() {
        webView = WKWebView()
        webView?.translatesAutoresizingMaskIntoConstraints = false
        view = webView
        
        webView?.topAnchor.constraint(equalTo: view.topAnchor).isActive = true
        webView?.leadingAnchor.constraint(equalTo: view.leadingAnchor).isActive = true
        webView?.trailingAnchor.constraint(equalTo: view.trailingAnchor).isActive = true
        webView?.bottomAnchor.constraint(equalTo: view.bottomAnchor).isActive = true
    }
    
    override func viewDidLoad() {
        super.viewDidLoad()
        if let testedUrl = urlString,
           let url = URL(string: testedUrl) {
                let req = URLRequest(url: url)
                webView?.load(req)
        }
    }

}
In this class we have created an init constructor that overrides the default constructor for the nibName and bundle. This new constructor takes a string parameter called 'url'. This will set the urlString property on this class, which will in turn be used in the 'viewDidLoad' function to load as request in the webView.
AppDelegate
The last thing we need to do to get this to work is to modify the 'AppDelegate' class to use the 'WebViewController' as the 'rootViewController'. Delete the 'UI Session Scene' lifecycle functions, and then modify the 'AppDelegate' class to look like the following example.
//  AppDelegate.swift
//  WebViewExample
//
//  Created by David Fekke on 4/7/21.
//
import UIKit

@main
class AppDelegate: UIResponder, UIApplicationDelegate {

    var window: UIWindow?
    
    func application(_ application: UIApplication, didFinishLaunchingWithOptions launchOptions: [UIApplication.LaunchOptionsKey: Any]?) -> Bool {
        self.window = UIWindow(frame: UIScreen.main.bounds)
        
        self.window?.rootViewController = WebViewController(url: "https://fek.io")
        self.window?.makeKeyAndVisible()
        
        // Override point for customization after application launch.
        return true
    }

}
In the 'AppDelegate' class we have added a property for the 'window'. In the application didFinishLaunchingWithOptions function we the window property to a new UIWindow set to the bounds of the screen. We then set the rootViewController to the 'WebViewController' passing in the URL we want to use in the contructor. The last thing we have to do is call the 'makeKeyAndVisible()' function on the 'window'.
Now we are ready to run our app. When you run this, it should look like the following app.

      
    
  
  
    
Summary
As you can see from the example in this post, it is very easy to create a native mobile app that uses the native WebView on iOS. In a future post I will demonstrate how to do this on Android using Kotlin.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeApril 6th, 2021


One of my favorite expressions is "there is more than one way to skin a cat". Don't get me wrong, I love cats, but this will illustrate my point.
JavaScript as a language gives you many different ways of accomplishing the same task. Iterating or looping through an array is an example of something where you have many different ways to accomplish same task.
For this example lets create an array with five elements in it using an array literal. We will also create a simple function for returning the results to a console.
const arr = ['First', 2, 3.3, 'Foo', 'Bar'];
const prn = item => console.log(item);
Conditional for statement
The original way of looping through an array in JavaScript is using the traditional 'for' loop statement which takes three expressions followed by the statement.
// 1
for (let i = 0; i < arr.length; i++) {
  prn(arr[i]);
}
The first part of the for loop in parenthesis defines an initalizer. This lets the for loop keep a variable to track where it is in the loop. The second part is the condition. Here we are telling the loop we only want to loop through this array until we reach the end. The last part is the final expression where we increment one to our intializer. This will be incremented each time the statement is executed.
This example will return the following values in this order to the console;
First
2
3.3
Foo
Bar
For-in loop
The next way of looping through an array is the for-in loop.
// 2
for (let index in arr) {
  prn(arr[index]);
}
In this second example we just iterate through the array. The variable before the 'in' keyword will assign an index value for each item in the array. So if there are five items in our array, it will assign the numbers '0, 1, 2, 3, 4' to the 'index'. We can then pass this value in the subscript of the array to get the value for that position in the array.
For-of loop
The for-of loop is similar to the for-in loop, but it will actually return the value of each item in the array.
// 3
for (let item of arr) {
  prn(item);
}
As we can see in this example above, the 'item' variable is assigned the actual value of the array. This same statement can also be used to iterate through all members of an object as well as an array.
Do-while loop
The Do-while loop is similar to the original for loop in example 1, but the condition expression is passed at the end of the statement.
// 4
let i = 0;
do {
  prn(arr[i]);
  i++;
} while (i < arr.length)
In the forth example above we define an iterator variable 'i' before our loop. This is not required to use a do-while loop. We just need a condition expression that can be used to exit out of the loop. In this case we incrementing 1 to the 'i' variable everytime the statement is executed in the loop, and in the while condition we check to make sure that the 'i' value is smaller than the array length.
While loop
The while loop is similar to the do-while loop, jut you set the condition expression at the beginning of the statement.
// 5
let j = 0;
while (j < arr.length) {
  j++;
  prn(arr[j]);
}
In our fifth example we set a variable 'j' to our intial iterator, and increment that value by one in the loop statement. The while condition checks to make sure that the 'j' value is smaller than the length of the array.
ForEach loop
The 'forEach' method on the array prototype was added in version 5 of JavaScript. This is actually an example of a higher-order function, or a function that takes another function as a parameter. these types of parameters are sometimes referred to as a 'callback'. The callback for the 'forEach' method takes a parameter of the actual item we are iterating on in the array, but also takes optional parameters for the index and the whole array.
Here is the simplest way we can use the 'forEach' method for looping over an array.
// 6
arr.forEach(item => prn(item));
In this sixth example we are passing in array function that prints the current item being iterated over in the array. We can also do it like the following;
arr.forEach(function(item) {
    console.log(item);
});
Recursion
JavaScript at its heart is a functional programming language. In a lot of functional programming languages the way you loop through an array is by using recursion, or using a function that can call itself.
// 7
function recursive(array) {
  let item = arr.shift();
  prn(item);
  if (array.length > 0) {
    recursive(array);
  }
}

recursive(arr);
In this seventh example we defined a function calld 'recursive' that takes the array as a parameter. Inside the function we 'shift' or remove one item out of the array, then pass this new version of the array into this same function. We have a condition in the function that checks to make sure the array still has any items left in it to process.
If you want to preserve the original array, you can make a copy of the array by using the spread operator '...' like the following example;

const arr2 = [...arr];
recursive(arr2);
Symbol iterator
Yet another way we can loop through our array is using a Symbol.iterator.
// 9
let it = arr[Symbol.iterator]();

let item = it.next();
do {
  prn(item.value)
  item = it.next();
} while (item.done === false)
In the eighth example we use this Symbol iterator to initialize an iterator object. We can then call the 'next' method on the iterator object. We can continue to call this iterator until it's 'done' property returns false.
We are using a do-while statement to check when the 'done' propety is false to end the execution of this iterator.
Generators
Generators are similar to the iterator we used before in example nine. Because of this I am only going to call this example 9 1/2. Generators are defined by using an '*' at the beginning of the function name. I personally do not like the way this is used because if you are coming from a 'C' based language this can be confused for a pointer.
// 8 1/2
function *myGenerator(array) {
  yield *array
}

const gen = myGenerator(arr3);

let item2 = gen.next();
do {
  prn(item2.value)
  item2 = gen.next();
} while (item2.done === false)
In this last example we have defined a generator function called 'myGenerator'. Generators can either return or yield a value. In this example we call the 'myGenerator function to create a generator object. The Generator object much like the iterator object has a 'next' method that will yield the next value in the array. The generator also has a 'done' parameter we can use to tell if the generator has completed execution.
Here we used a do-while loop as the expression for processing the generator.
Summary
As you can see from all of these examples there are multiple ways to skin a cat with JavaScript. Just please don't skin my cat. ;-)‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeApril 5th, 2021


I was watching a video from JSFest 2018 where Douglas Crockford gave a presentation on the Power of the Paradigm. It is an excellent presentation if you have a spare hour to watch. Doug also wrote a book that every JavaScript developer should read called JavaScript: The Good Parts. The whole presentation was great, but I really liked the part where he talked about object creation in JavaScript.

      
    
  
  
    
JavaScript is not a traditional Object-Oriented language like Java or C#, it is considered a Prototype based language with object-oriented features. After watching Doug's presentation, I have come up with my own term that I will call 'Crockford Objects'.
When I first started learning JavaScript, the way I learned for defining a new object was by using a function that returned 'this'. You can create a new object by using the 'new' keyword. Here is a simple example;
function Thing(name) {
    this.thingName = name;
    return this;
}

const myThing = new Thing('My Thing');
You can add functions to this object by using its 'prototype' property. You can add properties and functions by using the prototype property.
Thing.prototype.getName = function() {
    return this.name;
}

const currentName = myThing.getName();
// returns 'My Thing';
ES2015 classes
With the current versions of JavaScript in modern browsers and Node.js, there was a 'class' keyword that was added to the language. This was done mainly as way to make the language more familiar to the developers who use more general purpose languages like Java and C#. The 'class' keyword in Java and C# lets the developer create template for an object. It is not the same thing as a 'class' in JavaScript. In the example below we can see how the 'class' definition looks similar to a 'class' in C# or Java.
class Thing {
    construtor(name) {
        this.thingName = name;
    }

    getName() {
        return this.thingName;
    }
}

const myThing = new Thing('My Thing');
// returns 'My Thing';
A key difference here is how we have to reference the 'this' keyword to access properties on the object. If you really want to use syntax like this I would suggest using TypeScript. TypeScript offers a superset of JavaScript with well defined types and classes.
Crockford Objects
The example that Crockford gave in his presentation on how to create objects is the way developers should use for creating objects. It does not require the 'class' keyword or the 'prototype' property for defining an object. It also does not require using the 'new' keyword for instantiating a new object.
function createThing(name) {
    function getName() {
        return name;
    }

    return Object.freeze({
        name,
        getName
    });
}

const myThing = createThing('My Thing');
// returns 'My Thing';
In the example above we have a function with an inner function. The 'getName' function is a closure. Closures in JavaScript have access to all of the parameters of the parent function, so we have access to the 'name' property. We return a new object with just the properties and functions that we want from inside that 'createThing' function.
We also are using the 'Object.freeze' function to lock in just the parameters and functions that we want in our object. This method prevents properties and functions being added to the prototype of this object after defining the function.
Summary
The Crockford way of defining and creating objects looks to be the preferable way in JavaScript. These Crockford objects are defined with a factory function. In traditional object-oriented languages factories a common pattern for instantiating new objects.
It should be noted that there is some additional overhead for creating objects this way in JavaScript, but in most cases this should not prevent you from using this pattern.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeApril 1st, 2021


One question that might come up in a C# job interview is what is boxing and unboxing. In .NET there are three different types of objects, value types, reference types and pointer types.
The two common types that are usually used are reference types and value types. Value types are normally used for simple values like integers, floats and chars. Reference types are usually used  for more complex types that are based on classes. A string in .NET is an example of a reference type.
When you take a value type and make it a reference type, that is called boxing. When you take a reference type and convert it into a value type, that is called unboxing. If I want to take an Integer and cast it to an object like in the example below, this is an example of boxing.
using System;

class Program
{
    static void Main(string[] args)
    {
        int num1 = 42;

        object obj1 = num1;

        System.ConsoleWriteLine("Value is : {0}", num1);
        // Value is : 42
        System.ConsoleWriteLine("Object is : {0}", obj1);
        // Object is : 42
    }
}
In the example above, the num1 variable is value, and we unboxed it into a reference called obj1. The obj1 reference is of type object, which is the base reference type in .NET.
using System;

class Program
{
    static void Main(string[] args)
    {
        int num1 = 42;

        object obj1 = num1;

        num1 = 10_000;

        System.ConsoleWriteLine("Value is : {0}", num1);
        // Value is : 10000
        System.ConsoleWriteLine("Object is : {0}", obj1);
        // Object is : 42
    }
}
In the example above we changed the value num1 to 10,000, but the obj1 object has a copy of the number 42 from where it was boxed.
Unboxing
If I want to take the reference type of obj1 and cast that back into a integer, that is an example of unboxing. To do that we will have to cast it it back into an Int.
using System;

class Program
{
    static void Main(string[] args)
    {
        int num1 = 42;

        object obj1 = num1;

        num1 = 10_000;
        int num2 = (int)obj1;

        System.ConsoleWriteLine("Value is : {0}", num1);
        // Value is : 10000
        System.ConsoleWriteLine("Object is : {0}", obj1);
        // Object is : 42
        System.ConsoleWriteLine("Value2 is : {0}", num2);
        // Value is : 42
    }
}
Subsequently we can make a new object from the num1 value, and it will maintain a refernce to that first object. if we change the value of the new object, we will lose the refence to the original object.
object obj2 = obj1;
obj2 = num1;
System.Console.WriteLine ("Object1 is : {0}", obj1);
// Object1 is : 42
System.Console.WriteLine ("Object2 is : {0}", obj2);
// Object2 is : 10000
Summary
Boxing and Unboxing is a powerful feature in C#. The important thing to remember is that when we unbox a reference type to a value type, we have made a copy of that value and we are no longer maintaining a reference to the reference type.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeMarch 31st, 2021


I am currently creating a series of videos going over potential interview questions that might come up for a technical interview. I decided to do my first video on the three characteristics of Object-Oriented Programming.
The term Object-Oriented Programming was coined by Alan Kay while developing SmallTalk at Xerox PARC. The key feature is that you can write software in the form objects that can speak to each other, or call on each other.
The three characteristics that actually make Object-Oriented Programming are Encapsulation, Inheritance and Polymorphism.
Encapsulation
Encapsulation is about hiding the implementation details of an object from the consumer of the object. If you are using Java or C#, we use access modifiers like private and protected to make variables and methods available only to the object itself or its library or package. The consumer of the object does not need the internal details of the object, only the publicly available methods and properties. Another reason may that we may want a cunsumer to read a value, but not change a value of a property or value. Allowing this could potentially allow bugs to be introduced into an application.
class Mortgage {
    private float interest = 2.87;

    public float getInterest() {
        return interest;
    }
}
In the example above we have a class that has a private variable for the class that has holds the value of the interest for our Mortgage class. We have a method called getInterest that allows a caller to retrieve the interest value. This is how encapsulation works. We could create a method that increments the interest for this class while still preventing the caller direct access.
class Mortgage {
    private float interest = 2.87;

    public float getInterest() {
        return interest;
    }

    public void incrementInterestBy10() {
        interest = interest * 0.10; 
    } 
}
In this example we were able to modify the interest value without giving the caller access to the private variable.
Inheritance
Another characteristic of OOP is the ability of one object to inherit from another object. Some languages like C++ can inherit from multiple objects. Languages like Java and C# can only inherit from one object, but can inherit from multiple interfaces.
The object that is inheriting the methods, properties and variables from another object is called the child object. The object that is being inherited is the parent object.
using System;

namespace inheritance {
    class Person {
        public string Name { get; set; }
    }

    class Employee : Person {
        public string Department { get; set; }

        public void describe() {
            string desc = $"The person with name {Name} works in Department {Department}";
            Console.WriteLine(desc);
        }
    }
}
In the example above we have two classes, one called Person, and the other called Employee. If we look at the example above, we can see that the class Employee is followed by a colon and then the name of the previous class Person. The Employee class is inheriting the properties from the Person class. This is important because it means we do not have to redeclare the Name property in the Employee class. We get all of methods, properties and variables from Person class for free just by inheriting it into our Employee class.
Polymorphism
The term Polymorphism means the ability to change. For the purposes of OOP, while we can inherit from one class to another, we can also change the behavior of certain methods. We do not have to use the default implementation of all of the properties and methods that we inherited from a parent class. When we do this, we are creating our own or new implementation of a method or property. Most OOP languages have a keyword that allows us to override the default method or property as we can see from the example below.
using System;

namespace inheritance {
    class Person {
        public string Name { get; set; }

        public virtual void describe() {
            string desc = $"The person with name {Name}";
            Console.WriteLine(desc);
        }
    }

    class Employee : Person {
        public string Department { get; set; }

        public override void describe() {
            string desc = $"The person with name {Name} works in Department {Department}";
            Console.WriteLine(desc);
        }
    }
}
As we can see in the Person class above, we have a method called describe that prints out a description of the object with the name of the person. In the Employee class we have created a new implementation of the describe method that includes the name and the department of the employee.
In C# you can tell the compiler that you want a method to be overridable by add the virtual keyword before the return type. When you override the inherited method or property you use the override keyword before the return type.
Summary
This just scratches the surface of some of the things you can do with OOP languages. There are far too many topics to cover in a single post, but I hope this helps you with the basics of the three main characteristics of Object-Oriented Programming languages.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeMarch 29th, 2021I upgraded my website to the newest version of Gatsby JS. If you are not familiar with Gatsby or the jamstack, it is a framework for creating static websites using the React framework. Last month Gatsby 3.0 was released, the first major upgrade since 2.0 in 2018.
They have included a Gatsby 3.0 Migration Guide in their docs, but I wanted to cover the changes I had to make in order to upgrade the site to 3.0.
The first step I did was create a git branch for the upgrade that I could blow away if the upgrade failed. Once I created the new branch, I followed the instructions in the migration guide. The first step was upgrading the dependencies in the Node package.json file. I ran the following command;
npm install gatsby@latest --save
After I upgraded the gatsby module, I then checked which dependencies needed to be upgraded by running the following command;
npm outdated
This command will give you a report of which dependencies in your project need to be upgraded;
> npm outdated

Package                  Current   Wanted  Latest  Location
gatsby-plugin-sharp      2.14.1    2.14.1  3.1.2   test
Breaking changes
There were a number of breaking changes that required code upgrades. One example was the navigateTo function has been renamed to just navigate. Here is an example;
import React from "react"
- import { navigateTo, push, replace } from "gatsby"
+ import { navigate } from "gatsby"
const Form = () => (
  <form
    onSubmit={event => {
      event.preventDefault()
-     navigateTo("/form-submitted/") // or push() or replace()
+     navigate("/form-submitted/")
    }}
  >
)
One of the issues I came across that I did not find in their guide was how to import css styles modules. When writing components in Gatsby, you can write style modules just for an indiviual module. So for example if you have a header component named header.js, you can have a set of styles just for that component named header.module.css. Previously you would import that style in the module like this;
import React from "react"
import headerStyles from "./header.module.css"
Now this has to be imported using the * wildcard;
import React from "react"
import * as headerStyles from "./header.module.css"
Graphql upgrade
Graphql in earlier versions of Gatsby did not require being imported in order to use the graphql function. I had not been importing it in my gatsby_node.js file. I did have to add this import in order for me to use the graphql function;
const graphql = require('gatsby').graphql;
I am also using an extra frontmatter variable for specifying an extra variable for the cover_image. This allows me to specifiy a unique cover graphic in my header for each post. I was able to add this by adding the following schema addition in the gatsby_node.js file;
exports.createSchemaCustomization = ({ actions }) => {
    const { createTypes } = actions
    const typeDefs = `
      type frontmatter implements Node {
        cover_image: String!
      }
    `
    createTypes(typeDefs)
}
Node.js version requirements
I am currently using Netlify to host my site. Netlify defaults to Node v10, but Gatsby 3.0 now requires that you at least have version a minimal Node.js version of no less than 12.13.0. You can specify a newer version of Node on Netlify by using a .nvmrc file. I created one that looks like the following;
-- .nvmrc
14.16.0
Summary
This upgrade was not entirely painless, but I was able to make the upgrade in about an hour by following their guide. There are lots of new additions that have been made to Gatsby that you can now take advantage of by making this upgrade. I hope this post helps you with your upgrade.Tags: JavaScript,   Gatsby,   Graphql,   React,   Node.js,   npm   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeMarch 11th, 2021


One of the things that has always made JavaScript powerful was the way it handles asynchronous behavior. JavaScript from the very beginning has used callbacks as a way of handling a response that may take a while to complete without preventing your program from continuing to process other logic.
Retrieving or writing something to a database, filesystem or network are all examples of something that can block your program. The example below is an example of read request to a filesystem where the result is handled with a callback;
const fs = require('fs');
fs.readFile('/file.txt', function(err, data) {
  if (err) throw err;
});
Promises
Promises were introduced in EcmaScript 2015 as another way of being able to handle asynchronous behavior using a more structured pattern. The basic problem with callbacks is if you have to handle more than one at a time your code can start to look like a tree of callbacks. Promises have then and catch functions tht can be called to handle asynchronous requests. If your promise resolves anther promise, you can just follow that with another then.
The fetch API in chrome is an axample of a promise library that can return multiple promises inside of a single request. Here is an example of fetch request handling a rest API with a JSON response;
import fetch from 'node-fetch';

const apiurl = 'https://sampleapi.me/api/messages/10/';

fetch(apiurl).then(resp => {
    return resp.json();
}).then(json => {
    console.log(json.message);
    // Output: "My message"
}).catch(err => {
    console.error(err);
});
Async and Await
The promise API is more elegant than the traditional error first callback, but the syntax can still be terse because the then and catch functions both are higher order functions that require another function be passed into them in order to handle the completion of the promise.
By adopting the async and await keywords, we can write our code so that it looks synchronous, but we can continue to use promises;
import fetch from 'node-fetch';

const apiurl = 'https://sampleapi.me/api/messages/10/';

(async function() {
    const result = await fetch(apiurl);
    const json = await result.json();
    console.log(json.message);
    // Output: "My message"
})();
As we can see in the example above we have replaced the then higher order functions with the await keyword.  The await keyword has to be used inside of a function that is annotated with the async keyword. If you are using Deno or Nodejs 15 or greater, you can use the await keyword at the top level of your progra without having to run it inside of a async function.
import fetch from 'node-fetch';

const apiurl = 'https://sampleapi.me/api/messages/10/';

const result = await fetch(apiurl);
const json = await result.json();
console.log(json.message);
// Output: "My message"

Defining a new Promise
We can define a promise by creating a new Promise. The constructor for the Promise simply takes a higher-order function with two parameters for resolving and rejecting. Here is an example of a promise that returns a string after a delay of 1000 miliseconds;
function createWorker() {
    return new Promise((resolve, reject) => {
        try {
            let timer = setTimeout(() => {
                resolve('Work completed.');
            }, 1000);
        } catch (err) {
            reject(err);
        }
    });
};

const doWork = createWorker();
doWork.then((result) => {
    console.log(result);
    // Output: "Work Completed."
}).catch(err => {
    console.error(err);
});
We can also rewrite this to use async and await with a Promise for handling the setTimeout.
function oneSecondDelay() {
    return new Promise(resolve => setTimeout(resolve, 1000));
}

async function doWork() {
    await oneSecondDelay();
    return 'Work completed'
}

(async function() {
    console.log(await doWork());
    // Output: "Work Completed."
})();
Summary
As we can see from our previous examples, Promises and async and await are interchangeable with each other.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeMarch 11th, 2021I recently ran into a issue with a mobile application that was trying to call a Salesforce Rest API. Whenever the application tried to call this resource, Salesforce would return a 404 error.
It is a common practice in Rest API development to use HTTP status codes to represent different conditions that can occur. As an example, if a resource requires authentication, you can return a 401. This lets the consumer know that the request did not work because they needed to authenticate, usually with a bearer token with Rest APIs.
Getting a 404 status code for a resource that I knew exists was perperplexing to me. It is considered a good practice to return a 404 if you tried to return an item from a collection, and the id for the parameter is not in the collection.
The Rest resource we were trying to call is one that is used to register a device for push notifications. The path used by the Salesforce Rest API generally always starts with /services/data/v{versoin_number}. The real path is always after the version number. So for the push notification registartion, the full path is /services/data/v50.0/sobjects/MobilePushServiceDevice. This specific API call is done in the form of a POST with four paramaters including the device token for the users device. Salesforce needs this token in order to send push notifications to the device. At my company we have two Salesforce apps, one for iOS and one for Android. This call was working on or iOS app, but not in our Android app.
It turns out the cause for the 404 was rather simple. When any outside application want to access Salesforce APIs, it has to be registered as a 'Connected App' in Salesforce. The connected app uses a 'Consumer Key' for OAuth access back into your Salesforce Org. The Connected App was set to another 'Consumer Key' that was not configured to send push notifications. Because push notifications were not configured, when we tried to call the MobilePushServiceDevice resource, it returned a 404. Once this was configured, we received a 201 from the API call.
I writing this post because it can be tricky sometimes to understand why when a resource is not working it would return a '404 resource not found' error. This does not give the consumer any idea why the call is not working. Some might consider this to be a feature, not a bug because for security reasons you may not want a consumer looking for undocumented resources in your API. In our case it would have saved us a lot of time diagnosing the cause of the problem. I personally would have prefered a 418 status code over the 404.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeFebruary 23rd, 2021Creating a Class in Objective-C



Most modern object oriented languages have the capability of creating a class. Java, C#, Swift and Kotlin all have classes. C++ and Objective-C are a little bit different because they require that you have two files for defining a class.
These files end with a '.m' and '.h' extension. The '.h' file is the header file and the '.m' file is the implemenation file.
The header is generally used for defining public methods, properties and instance variables. The implementation file is used for implmenting the actual methods. Lets take a look at a simple class;
//
//  Person.h
//

#import <Foundation/Foundation.h>

NS_ASSUME_NONNULL_BEGIN

@interface Person : NSObject {
    NSString *firstName;
    NSString *lastName;
}

-(instancetype)initWithFirstname:(NSString *)first lastname:(NSString *)last;
-(NSString *)fullname;

@end

NS_ASSUME_NONNULL_END

As you can see from above this header has @interface keyword used to define the class. The @end keyword is used to define the end of our header definition. The class is named Person and is followed by a : and a NSObject. When defining your class the word following the colon is the class you are inheriting from.
All Objective-C classes must inherit from a parent class. NSObject is the basis for all Objective-C classes, but you can inherit from other classes.
Instance Variables
Instance variables, sometimes called 'ivars', are defined in the curly braces after the end of the @interface line. In the example above we have two variables we have defined for the 'firstName' and the 'lastName'.
Method signatures
After the @interface line or the curly braces we can define properties or methods. In the example above we have defined to methods. The actual methods will be implemented in the implemetation file later on, but here we defined two methods and their parameters.
Implementation file
#import "Person.h"

@implementation Person

- (instancetype)init
{
    self = [self initWithFirstname:@"" lastname:@""];
    return self;
}

-(instancetype)initWithFirstname:(NSString *)first lastname:(NSString *)last {
    self = [super init];
    if (self) {
        firstName = first;
        lastName = last;
    }
    return self;
}

-(NSString *)fullname {
    return [[NSString alloc] initWithFormat:@"%@ %@", firstName, lastName];
}


@end

The implementation file begins with a @implementation and ends with the @end keyword. We begin our file with an import statement for importing the header we defined before. Inside of the implenmentation is where we define the logic for our methods. Any method that has a return type of (instancetype) is used for returning the type of the class, which in this case is one of two inits or constructors we defined.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeFebruary 19th, 2021I came across an use case of using the newer import/export syntax in JavaScript where I was not able to import a native module in Node.js. Node.js recently enabled the ability to have your project use import/export syntax rather than the Common.js require method. Unfortunately the import/export will not work with native modules, but there is a workaround if you look closely enough in the docs.
Native modules
Node.js has always allowed developers to write code or use libraries that are written in C/C++. This allows developers to take advantage of libraries and code that are already optimized to run natively, like the talib stock analysis library. Here is an example of this library being imported into a node application using the older Common.js syntax;
const talib = require('talib');
console.log("TALib Version: " + talib.version);
ES6/ES2015 import/export Syntax
The newer import\export syntax is turned off by default in Node, but you can use these newer style modules by either giving your files a .ejs file extention, or by setting the type setting in your project.json file to 'module'. If you do not set the type setting it defaults to 'commonjs'.
Normally you would be able to import the module using the following syntax in Node.js;
import axios from 'axios';
In order to use the native module you will have to import the createRequire function from the 'module' module. Here is an example of how to use the createRequire method to import the TAlib modile;
import { createRequire } from 'module';
const require = createRequire(import.meta.url);
const talib = require('talib');
console.log("TALib Version: " + talib.version);
As you can see from the previous example once you import the createRequire function it will work like the older Common.js syntax. Hopefully this will solve your problems with using native modules.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeAugust 12th, 2020I have recently started doing a VLOG, or video log on Polyglot programming. I am calling the channel the Polyglot Engineer Channel. You can see the video content here on youtube.
The first series of videos I am doing is on Objective-C. Objective-C is a general purpose dynamically typed object oriented language based on C.
The language started out of a company that went on to become Stepstone by Brad Cox and Tom Love. Brad had read an article about Smalltalk, and deciced to write a pre-compiler that could use objects on top of the C programming language. Objective-C was adopted by NeXT Computer, the company started by Steve Jobs after he left Apple. Objective-C became the basis of the NextStep frameworks in the NeXT operating system. Jobs sold NeXT to Apple to become the macOS X. It is also the basis of iOS, iPadOS, watchOS and tvOS.
I plan on covering multiple languages with the channel. The goal is to create a library of five minute or less videos explaining how different features of a particular language work. Here is a snippet from the channel describing the goals of the channel;
This site is for software engineers and novice programmers alike to learn language features of a specific language when transitioning from one programming language to another.
Most software engineers do not use one programming language, but many, especially over the course of their career. It is important to be able to streamline the learning process by finding common features in a new language that you have used in other languages.
My goal is to create short videos around five minutes that can help software engineers learn just the feature they are looking for in a new language.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeNovember 14th, 2019I saw this headline a couple of days ago that Mooney's factory has shut down. If you try to call the plant in Kerrville, TX, you are greeted with an automated message saying that the employees have been furloughed. Not only is this not good for Mooney, it is not good for General Aviation as a whole.
The Mooney M20 is probably my favorite aircraft that I have flown as a pilot. The Mooneys are known for being efficient sleek airplanes that can travel at 200 MPH. I did my complex commercial and instrument training in M20J models. I absolutely loved every minute I spent in that airplane.
A couple of years ago Mooney was purchased by a Chinese company with plans to build a new trainer. This airplane would have been called the M10. Mooney had shut down right after the financial crisis of 2008, and did not manufacture any new aircraft for five years. If you go to the Wikipedia page for Mooney International you can see they have had a long history and have changed ownership multiple times through the history of the company.
Mooney had started producing Acclaim Ultras again, but had not been producing them in great numbers. According to AvWeb Mooney only produced 14 aircraft in 2018 and four this year. The price tag of $850,000 might have something to do with the low sales numbers.
Why do general aviation cost so much money? Well there are a couple of different reasons for that, but one of the biggest ones is Product Liability Insurance. This problem was supposed to be solved in 1994 with the General Aviation Revitalization Act.
Post WWII, there was a renaissance in General Aviation manufacturing. With many pilots returning from the war, they bought aircraft for their own personal use. Companies like Mooney, Cessna, Piper and Beechcraft produced aircraft for this market of pilots. They reached a zenith in production around the 1970s. Over 18,000 GA aircraft were built in 1978. That was the peak of manufacturing.
It has been on the decline ever since. 1982 was the first year Cessna did not make a profit. Lawsuits soon caused all manufacturers to cease production or seriously curb their production. Cessna declared they would no longer manufacture piston single or twin engine aircraft until the Federal government fixed the product liability problem.
After GARA passed in 1994 Cessna began manufacturing piston singles again, but ceased making the two seat 152. The price tag also increased significantly with a new 172 costing hundreds of thousands of dollars. So while production resumed, there was still a heavy burden placed on the price by the liability insurance.

      
    
  
  
    
In the late 1980s you could purchase a Piper PA-28 called the Piper Cadet for $45,000. Piper just announced a streamlined version of that plane for the training market called the Piper Pilot 100. This version of the PA-28 now costs $259,000. A new Beechcraft Bonanza costs over $1 million. A Cirrus SR20 unit cost is around $454,900. A brand new Cessna 172 will cost you $398,000. Even if you factor in inflation the cost of aircraft has increased far greater than the rate of inflation.
This of course has driven up the cost of the used aircraft market. I currently co-own a Cessna 177RG with three other pilots. It is currently valued more that than what it originally sold for in 1976. While this has increased the value of the existing fleet, the average age is also increasing. The average age of a general aviation aircraft is now 50 years old.
When people ask me why I bought such an old airplane, my response is it is not that old compared to the average. I have flown in aircraft that are older than I am on many occasions. Plus it is what I can afford.
The health of the General Aviation Industry is important for many reasons, but the main reason is we need aircraft to help train the next generation of pilots.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeNovember 4th, 2019Sorting out all of the different JavaScript frameworks can be a chore
Most of the JavaScript frameworks and tools are under constant change. Staying on top of all of the churn can be a chore. I recently came across an issue after I upgraded to the latest version of macOS (10.15.2), Xcode (11.2) and Node.js 13.0.1.
None of my Jest based tests would run anymore. When I ran npm test or yarn test jest would start, but would never run any tests. It was like jest was just hanging or stuck, and not able to run any of the tests.
I tried reinstalling Node.js, downgrading Node. I even emptied the NPM cache and reinstalled jest. Nothing I did worked. I came across a Stackoverflow post. One of the tools Jest uses is called watchman.
The Stackover flow post suggested uninstalling and reinstalling watchman. You can use Homebrew to do this on the Mac. If you are not familiar with Homebrew, it is essentially the missing package manager for macOS.
brew uninstall watchman
brew install watchman
After I made this change, I reinstalled jest onto my computer, and now all of my tests run like they did before. I hope this helps with your set up as well.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeAugust 22nd, 2019Restaurants you can fly to in Florida
Airport Tiki (B, L, D)
KFPR Treasure Coast International Airport
This airport diner is perfect for those who have just cleared customs
coming back from the Bahamas and points south. While your airplane is
fueled you can grab a quick nosh before heading home.
CJ Cannon‚Äôs (B, L, D)
KVRB Vero Beach Regional Airport
Thirty years of airport restaurant service with a smile. Come get your
dose of Southern comfort food in a unique retro decor.
High Jackers (L, D)
KFIN Flagler Executive Airport
People love the peel-and-eat shrimp, and the massive build-your-own
burgers (watch the CG after eating this!). Not fancy but definitely
fun and filling.
The Perfect Spot Airport Restaurant (B, L, D)
KDED Deland Municipal-Sidney H. Taylor Field
You‚Äôll be perfectly positioned to watch the skydivers landing after
each jump. Free parking east of Runway 5/23.
Airport Restaurant and Gin Mill (B, L, D)
KDED Deland Municipal-Sidney H. Taylor Field
Because sometimes one restaurant on the airfield simply isn‚Äôt enough.
It features an awesome porch.
Flightline Caf√© (B, L, D)
KGIF Winter Haven Regional Airport
Winter Haven is seaplane heaven, with plenty of hard surface for those
who don‚Äôt fly floats (but take a lesson while you are in town‚Äîit‚Äôs
fun!) Come to the Flightline Cafe for the pastrami sandwich or the
fried shrimp, and of course, the runway views. Definitely try the
fried green tomatoes (a southern classic).
Pyper Kub Cafe and Restaurant (B, L)
X60 Williston Municipal Airport
Great views of the runway and a funky d√©cor, customers say. All that
and consistently inexpensive self-serve avgas.
Runways at Bartow (B, L)
KBOW Bartow Municipal Airport
Stuffed french toast anyone? Huge omelets are on tap as well. This is
an easy-in, easy-out airport.
Suncoast Caf√© (B, L)
KVNC Venice Municipal Airport
Get the curry! The chef, Tony, is from the Caribbean, and his food
definitely reflects that. From crab-stuffed calamari to curried goat,
you won‚Äôt find more variety on an airport cafe menu. Excellent
omelets, pressed Cuban sandwiches, and crab cakes Benedict. Sign in at
the front desk and your handling fee is waived for the time you are at
the restaurant (not your entire week in Florida).
Tailwind Caf√© (B, L, D)
KOCF Ocala International-Jim Taylor Field
Another airport restaurant where the burger is the thing‚Äîjust get it.
Breakfast menu is standard fare; why mess with simplicity? Rumor has
it that veterans get a 25-percent discount.
The Hangar (B, L, D)
KSPG Albert Whitted Airport
Famous for its burgers and great breakfasts, stick around late and you
can catch First Monday Jazz with Al Downing Jazz. The airport is right
on Tampa Bay, giving you the opportunity to practice that ‚Äúcarrier‚Äù
approach. Airport and water views, plus good food? Divine.
Runway Caf√© (B, L)
KSEF Sebring Regional Airport
Tuck into classic breakfast fare and a shrimp po‚Äôboy at lunch that
patrons rave about. Another easy-in, easy-out airport, with the
benefit of Skip Barber racing within earshot.
Landing Strip Caf√© (B, L)
KOBE Okeechobee County Airport
This is a greasy spoon-style restaurant with a loyal patronage. One
caveat: It draws from both the east and west coasts of Florida, so get
there early on a weekend.
Conch Flyer Restaurant (B, L, D)
KEYW Key West International Airport
If you are stuck hanging out at the Key West Airport, the Conch Flyer
will feed you the town‚Äôs signature fare with a view of the runway. It
is located right next to the fixed-base operator, in the commercial
terminal. That said, you‚Äôll be rubbing shoulders with lots of airline
passengers (or jockeying for a table with them).
Jet Runway Caf√© (B, L)
KFXE Fort Lauderdale Executive Airport
How many airport restaurants are Zagat rated? If you‚Äôve stopped in to
pick up or drop off your overwater safety gear (Banyan FBO rents it),
stay to eat and let your taste buds go wild with this restaurant's
creative American-style menu. The servings are generous, menu
selections are ample, and food is good.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeMay 20th, 2019How to run your Next.js app on Azure
I recently gave a presentation on building universal apps using Next.js and
Express.js. Next.js is a framework from the great people at Zeit.co.
Zeit is a great hosting platform, but I am working on a project that is already using resources on the Azure platform, so I decided to host it there instead of at Zeit or another platform as a service.
I ran into a problem when I tried to deploy my Next.js app on Azure App Services. Azure already provides a several ways of deploying apps using continuous integration through git repos. You can configure your app service to pull from your repo every time a change is pushed.
The problem is that you have to specify a port. Here is how you can configure a port in your code and package.json.
The express part of your express app needs to be able use port provided Azure. Make the following change to your Express app;
// server.js

const express = require('express')
const next = require('next')

const dev = process.env.NODE_ENV !== 'production'
const app = next({ dev })
const handle = app.getRequestHandler()

// Your app will get the Azure port from the process.enc.PORT
const port = process.env.PORT || 3000;

app
  .prepare()
  .then(() => {
    const server = express()

    server.get('*', (req, res) => {
      return handle(req, res)
    })

    server.listen(port, err => {
      if (err) throw err
      console.log('> Ready on http://localhost:3000')
    })
  })
  .catch(ex => {
    console.error(ex.stack)
    process.exit(1)
  })
In your package.json will need to have the following script changes to build and host your Next.js app on Azure;
"scripts": {
      "dev": "next",
      "build": "next build",
      "start": "next start -p $PORT",
      "postinstall": "next build"
  },
The two important scripts are the start and postinstall parts. The start will need to have the -p $PORT. I also added a postinstall script. Many hosts now use the npm run postinstall when you deploy your app.
I hope this helps you if you are trying to host your Next.js app on Azure app services.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeApril 20th, 2019I recently have completed a lot of maintenance on my Cessna 177RG
I had a professor in college who said "Don't ever buy an airplane". I did not listen to him because I bought into a partnership for a Cessna Cardinal last year. General Aviation aircraft are notorious for being expensive to maintain. The more complex the aircraft, the more expensive it is to maintain. The General Aviation fleet of aircraft are just getting older. According the FAA, the average age of a General Aviation Aircraft is 35 years old.
When I was learning to fly, I don't think I ever even refueled the aircraft I rented. We always had mechanics that did all of our maintenance. Not being the owner of the aircraft, I never thought much about the maintenance of the aircraft outside of knowing the legal requirements for inspections by licensed A&P mechanics.
So whenever our mechanic comes out to work on the plane, I alway try to be there to help him with the maintenance. We recently replaced the oil sump gasket and a cylinder in the engine. Replacing the oil sump gasket required removing the engine from the firewall using a cherry picker. As a pilot, I never thought I would ever slide a new cylinder onto the crankcase of an aircraft engine, but I did a week ago.



Engine Oil Sump



New Cylinder
As a Pilot, What are you Allowed to do on your Aircraft
According to Federal Aviation Regulation part 43, a pilot is allowed to do a lot of preventative maintenance. I came across the following FAA document called Maintenance Aspects of Owning Your Own Aircraft. The one caveat is that if the aircraft is used for part 121, 127, 129 or 135 operations the pilot cannot do their own maintenance.
Here are some of the things a pilot can do to their aircraft;

Remove, install, and repair landing gear tires.
Service landing gear wheel bearings (for example, cleaning and greasing).
Service landing gear shock struts (for example, adding oil, air, or both).
Replace defective safety wire or cotter keys.
Lubricate items not requiring disassembly other than removal of nonstructural items (for example, cover plates,

cowling, and fairings).

Replenish hydraulic fluid in the hydraulic reservoir.
Apply preservative or protective material to components where no disassembly of any primary structure or

operating system is involved, and where such coating is not prohibited or contrary to good practices.

Replace safety belts.
Replace bulbs, reflectors, and lenses of position and landing lights.
Replace or clean spark plugs and set spark plug gap clearance.
Replace any hose connection, except hydraulic connections.
Replace and service batteries.
Make simple fabric patches not requiring rib stitching or the removal of structural parts or control surfaces.

(Note: For balloons, this includes making small fabric repairs to envelopes as defined in, and in accordance
with, the balloon manufacturer‚Äôs instructions and which do not require load tape repair or replacement.)

Replace any cowling not requiring removal of the propeller or disconnection of flight controls.

Another important detail hear is to make sure that all maintenance is properly logged in the aircraft's maintenance log book. Each log entry must include a description of the work performed, or references that are acceptable to the administrator. The date the maintenance was completed, and the signature, certificate number and kind of certificate held by the person doing the work.
The Hard Work Payed Off
I felt quite a bit of satisfaction when we finally got the cowling put back on and the engine fired up for the first time. Here is the video of our first engine start after completing the engine work;


‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeApril 7th, 2019Highlights from my 2019 trip to Sun-n-Fun 2019
I went down to Lakeland again this year to visit the Sun-n-Fun aviation airshow and expo. One of the neatest things about Sun-n-fun is that it is not just
an Airshow and general aviation fly-in, it is also a place where many of the venders that serve the aviation industry can come and show off their products and services. This was my second time visiting Sun-N-Fun. I wanted to highlight some of the aircraft and vendors I saw while I was at the show.
Piper
Piper Aircraft was there showing off a new trainer they are marketing to smaller flight schools. The aircraft is called the Piper Pilot 100 and the 100i. These trainers are based on the Piper PA-28 model, but have been streamlined for pilot training. They include Garmin PFD and MFD display and avionics, a single seat in the back, and a Continental IO-370 fuel injected engine rated at 180 BHP.
I joked with the Saleswoman that they should have called them the Piper Cadets because Piper made an aircraft very similar to that in the late 1980s called the Piper Cadet. These new pipers are being priced at $259,000 and $285,000 for the VFR and IFR versions.
Vashon Ranger

      
    
  
  
    
Vashon recently started manufacturing a new LSA (light sport aircraft) out of Washington state. The Ranger is priced at right around $100,000, making it one of the lowest cost aircraft manufactured today.
Vashon was started by entrepreneur John Torode. John is also known for starting Dynon Avionics, and the Rangers come equipped with the latest in Dynon PFD and MFDs.
The Ranger is clearly being targeted not just as an airplane that can be used to train pilots to become sport pilots, but also be used as a recreational plane for going on a camping trip or fishing.
Textron, Cessna and Beechcraft
Textron had a large place in the show with many of their piston powered aircraft. They had a Baron, Bonanza, Skylane and a Caravan all on display.
The one thing that disappointed me is that they did not have a Skyhawk on display, or an airplane aimed the smaller flight school market like Pipe did this year.
Lycoming
Lycoming had a booth in one of the hangers. Lycoming engines can be found in many GA piston powered aircraft. Most of the Cessna, Mooney and Pipers I have flown have had Lycoming 0-320 or I0-360 engines. The aircraft I am a partner in now has a Lycoming engine.
I spoke to one of the salespeople about the direction they are taking the company. He told me that Lycoming is bringing in more of their manufacturing in-house to their factory in Pennsylvania.

      
    
  
  
    
Continental
Continental seemed to have a good presence this year at Sun-n-Fun. They were showing off one of the piston engines they have that can run on Jet-A fuel, which is less expensive than 100LL avgas. They think this will do well in many parts of the world where they may use diesel fuel instead of Jet-A.
The new Piper Pilot 100 uses a Continental IO-370 engine. I also found out they can make parts for Lycoming engines.
Avionics and more Avionics
So many of the exhibitors are avionics manufacturers like Garmin, Bendix King, Dynon, Avidyne and Aspen where in the hangers.

      
    
  
  
    
I went by the Bendix King booth, and they where showing of a PFD running at 4k. Most of the Avionics displays do not have that high of a resolution. So many of the aircraft I have flown used Bendix King communication and navigation radios, it was nice to see Bendix King doing something innovative.
There seems to be a lot of competition in the space, hopefully we will see the prices come down even more.
ADS-B
Many of the Avionics manufacturers were showing their ADS-B options. ADS-B out is going to become a legal requirement in GA aircraft starting in January 1st, 2020. One of the neater solutions I saw was a replacement running light that doubles as an ADS-B out transmitter. The solution called skyBeacon can be mounted in about 10 minutes and costs about $1849.
Youtubers
I have managed to meet a lot of the pilots creating content on Youtube around aviation at Sun-n-Fun. You might have watched some them like FlightChops, Matt Guthmiller and Steveo1Kinevo.

      
    
  
  
    

Jon Kotwicki from Fly8MA

A bunch of them got together and had their own booth in one of the hangers. Some of these Youtubers where Niko's Wings, Corporate Pilot Life, Baron Pilot and Jon Kotwicki from Fly8MA.
Vintage and Current Military Exhibits
The Blue Angels Navy flight demonstration team came and put on quite a show along with so many other acrobatic pilots. On top of the airshow there was a ramp where guests could go and view many of the current, WWII and Vietnam era military aircraft on display.
Check out some of these pictures from the ramp:

      
    
  
  
    

B-25 Bomber


      
    
  
  
    

F-35 Lightning


      
    
  
  
    

KC-135 Stratotanker 


      
    
  
  
    

F-18 Hornet


      
    
  
  
    

P-51 Mustang


      
    
  
  
    

V22 Osprey

If you are lucky enough to live near where there is an airshow, or can travel to one, they are a lot of fun. I hope everyone gets the chance to visit an airshow at least once in their life.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeApril 4th, 2019I decided to make a list of my favorite food and nutrition myths. We get a lot of mixed messages from the media about what is good for you to eat, and what is bad.
One week we will hear a study hat says that food is good for you, and the next week we hear that food a will give you cancer.
Most of the studies that are cited in the news are based on epidemiology. Epidemiology in nutrition is based on surveys that people fill out about what they are eating,
or have eaten over a period of time. Epidemiology is really good at identifying risk factors, but at the end of the day they show an association and not causation.
You will see questions on those surveys like "How many cups of Ribs did you eat in the last six months?"

Surveys are not Science!!!

Here is my list of food and nutrition myths.
1. Salt causes High Blood Pressure
As someone who has suffered through hypertension, I am super sensitive to anything that might raise my blood pressure. Most of the science that says that salt causes high blood pressure comes from a Scientist named Jeremiah Stamler. He even came up with a diet that is given to hypertensive patients called the DASH diet, or Dietary Approaches to Stop Hypertension. The DASH Diet recommends that you eat no more than 2,300 mg of sodium a day. I am surprised we have not all dissolved by now. Your body actually needs sodium, probably a lot more than 2300 mg.
There is no proof that salt has any kind of lasting affect on blood pressure. A more recent study BU could not find example of anyone who had high blood pressure due to sodium. In fact they found that low sodium produced nearly the same risk as a high sodium diet.
2. Eat Egg White Omelettes, don't eat the Yolk
Egg white omelettes became popular because the yolks contain cholesterol. The egg whites also have less calories and fat. Unfortunately, the yolks also contain Vitamins B12, D and Iron. The egg whites also have more Omega 6 fatty acids, where the yolks have Omega 3 fatty acids. So eating just the egg whites is pro-inflammatory. Inflammation is bad because it can cause weakening of the arteries, and eventually arteriosclerosis.
3. Saturated Fat is bad for you
Saturated Fat started being maligned in the 1950s because research done my Ancel Keys, a physiologist from the University of Minnesota. He believed at the time that eating fat would give you heart disease. He even produced a study called the The Seven Countries study. There were actually 22 countries that kept the kind of data that he used in his report, but he excluded the countries that did not prove his theory.
Healthy fats are an essential part of ones diet. The worst part about fat is the name, Fat. People think that if you eat fat, you will get fat. I am sure if you ate enough of it you would get fatter, but getting fat is really a hormonal response due to insulin secretion. Your body produces insulin as a way to lower blood sugar. Anything that is not used up as energy gets stored as long chain triglycerides into your fat cells.
There are fats that are bad for you. Trans-fats, which come from hydrogenated vegetable oil, have been shown to lower HDL, increase LDL, and more importantly increase inflammation.
Nina Teicholz goes into great detail about the studies, how experts made recommendations for women without ever doing any studies on women in her book, The Big Fat Surprise.
4. Don't Eat Red Meat because it is bad for you
Red meat is actually one of the healthiest foods you can eat. Ruminants in general are very high in the nutrients and micro-nutrients we need to live. Red meat also contains Vitamin B12 and Heme Iron.
There was a study that came out of the World Health Organization a couple of years ago that said that red meat and processed meat increases the chances of getting cancer. There were a lot of flaws in the study. Many of the officials at the WHO who conducted the study were vegetarians or vegans. The study was actually produced from an meta analysis from multiple reports based on epidemiology. They never published their data.
In the end they said that there was a 1.17 times greater chance in those who got colorectal cancer from eating fresh or processed meat. You are not even supposed to consider any statistical numbers under 2 because there are too many possible confounders. As and example, smokers are 35 times more likely to get cancer than non-smokers.



5. It is Ok to Eat Sugar, it is Just Empty Calories
Sugar is just empty calories, right? WRONG!!!
The two sugars that are commonly found in our foods, sucrose and high fructose corn syrup. Sucrose is 50% fructose and 50% glucose. High fructose corn syrup is 55% fructose and 45% glucose. They are both equally bad for you. Many of our foods and drinks have replaced sucrose with high fructose corn sugar, mainly because it is cheaper to produce.
Science journalist Gary Taubes wrote an excellent book called The Case Against Sugar. Sugar intake around the world has gone up dramatically around the world over the last 100 years. You certainly make the case based on epidemiology that sugar is also causing heart disease, obesity, diabetes, hypertension and a host of other diseases.

      
    
  
  
    
Check out this video by Dr. Robert Lustig who treats children with adult onset diabetes.



6. An Apple a Day Will Keep the Doctor Away
Apples contain lots of fructose. They also contain fibre, which makes them easier to process than if we just drank apple juice. The fructose has to be processed in your liver. The fiber in an apple helps, but the overall effects of fructose can be harmful. Apples and most fruit are essentially confection on a tree.
Check out this presentation from Dr. Gary Fettke on why fruit may not be as good for you as you think.



7. Breakfast is the Most Important Meal of the Day
The name Breakfast actually comes from two words, break and fast, meaning you are breaking the fast you started from before you went to sleep. The saying Breakfast is the Most Important Meal of the Day actually comes from cereal marketing from the 1800s.
The line ‚ÄúBreakfast is the most important meal of the day‚Äù was invented in the 1800s by Seventh Day Adventists James Caleb Jackson and John Harvey Kellogg to help them sell their  breakfast cereal.
8. Grains are Heart Healthy
There is nothing heart healthy about grains. Grains actually get converted into long chain triglycerides in our liver, and are pro-inflammatory. Wheat and white flour are treated by your liver in a similar way as eating sugar. Eating a slice of bread is like eating seven tea spoons of sugar.
Dr. William Davis chronicled this in his book Wheat Belly.
9. Eat Many Small Meals a Day Instead of Three Large if you are Trying to Lose Weight
Eating six small meals a day is much worse for than eating three meals a day. Every time you eat, especially food with carbohydrates or protein, your pancreas has to produce more insulin to process your blood sugar. Spiking your blood sugar six times day is not going to help you lose weight.
10. Use Margarine over Butter
Margarine is made from vegetable oil, and is actually gray until it is died with food coloring. People started eating Margarine when Butter was maligned because of saturated fat. Margarine contains trans-fats. It is also causes inflammation and should be avoided.
Current forms of Margarine contain polyunsaturated fats, and contain food additives like emulsifiers. It is a highly processed food. There is great article on margarine at healthline.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeApril 3rd, 2019Check out my first post on Gatsby JS
Gatsby is fun to use
I have really enjoyed using Gatsby so far in the process of moving my website to a new site generator. In my previous post I talked about some of the problems I had with Jekyll and ruby. I have used Node.js quite a bit for other applications, so it made the transition much easier.
Hierarchical paths
It is very common to use a URL pattern that simulates a hierarchical structure. If you have different products that you list on your website, you may have a parent directory called products. Then underneath parents you may have a page for a particular product for a baseball. That path might look like /products/baseball. This can be done very easily in Gatsby by creating a similar folder structure;
src/
--pages/
----index.js
----contact.js
----about.js
----products/
------index.js
------baseball.js
React
Gatsby is built on React JS. React is not exactly JavaScript. It is really JSX. There are certain things you can get away with in JSX that you can't get away with in real JavaScript. The main thing is being able to intermingle your HTML and JavaScript in the same class or function;
import React from "react"
import Container from "./container.js"
import headerStyles from "./aboutheader.module.css"

export default props => {
    return (
        <header className={headerStyles.back}>
            <Container>
                <h1 className={headerStyles.about}>{props.headline}</h1>
            </Container>
        </header>
    )
}
One of the great things about transitioning to Gatsby is that it has given me a chance to learn a little more about React and GraphQL. There were a lot of times where I would use JQuery or vanilla JavaScript to manipulate the document object model. Moving to React forced me to use React to manipulate the DOM. React uses a shadow DOM behind the scenes to actually manipulate the DOM.
Another nice thing about React is the way it makes it easy to create reusable components. A breadcrumbs section is great example of the kind of thing that can be turned into a reusable component.
// breadcrumb.js
import React from "react"
import { Link } from "gatsby"
import breadcrumbStyles from "./breadcrumb.module.css"

export default props => {
    return (
        <div>
            <ul className={breadcrumbStyles.breadcrumb}>
                {props.crumbs.map((crumb, index) => (
                    ((props.crumbs.length - index) > 1) ? <li key={index}><Link to={crumb.toLowerCase()}>{crumb}</Link></li> : <li key={index}>{crumb}</li> 
                ))}
            </ul>
            <div style={{ clear: 'both' }}></div>
        </div>
        
    )
}
For this component I created a css module;

ul.breadcrumb {
  display: inline-block;
  padding: 10px 16px;
  list-style: none;
  background-color: #eee;
  border-radius: 6px;
}

ul.breadcrumb li {
  display: inline;
  font-size: 18px;
}

ul.breadcrumb li+li:before {
  padding: 8px;
  color: black;
  content: "/\00a0";
}

ul.breadcrumb li a {
  color: #0275d8;
  text-decoration: none;
}

ul.breadcrumb li a:hover {
  color: #01447e;
  text-decoration: underline;
}
This can easily be included into your page and called using the following implementation;
import React from "react"
import Layout from "../../components/layout"
import Breadcrumb from "../../components/breadcrumb"

export default () => {
    return (
        <Layout>
            <Breadcrumb crumbs={ [ 'Products', 'iLottNum' ] } />
            ... your content here
        </Layout>
    )
}
Plugins
There is a lot of functionality that can be added to a Gatsby project through the use of plugins. The Gatsby project has a list of them you can search through on their plugin site. Gatsby plugins have two basic types, source and transform. Source plugins are used to pull different sources of data that can be used in your Gatsby site. Transformer plugins are used to take data and transform that into something that is more usable for your site. The gatsby-transformer-remark plugin will take markdown content and convert it into frontmatter and HTML.
Here are some the plugins I used to help me add things very easily that would have been harder if I did not have the plugin.
gatsby-remark-prismjs
gatsby-remark-prismjs adds the PrismJS framework to your site making it easier to show code examples in articles and posts.
gatsby-plugin-react-helmet
gatsby-plugin-react-helmet is based on the Reacth-helmet plugin for adding meta data to your header. This becomes important when you try to add SEO to your site and posts. Here is an example of how I am using on my site;
import React from "react"
import { Helmet } from "react-helmet"

export default (props) => {
    return (
        <Helmet
            meta={[ { charSet: 'utf-8'} ]}
            title={props.title}
            link={[
                { rel: 'stylesheet', type: 'text/css', href: 'https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic'},
                { rel: 'stylesheet', type: 'text/css', href: 'https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800'},
                { rel: 'icon', sizes: '16x16', type: 'image/png', href: `/favicon16.png` },
                { rel: 'icon', sizes: '32x32', type: 'image/png', href: `/favicon32.png` },
                { rel: 'shortcut icon', type: 'image/png', href: `/favicon64.png` }
            ]} />
    )
}
As you can see from the example above I am adding some Google fonts and favicons to my header. The resulting HTML looks like the following;
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <title>Fek.io</title>
    <link data-react-helmet="true" rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic">
    <link data-react-helmet="true" rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800">
    <link data-react-helmet="true" rel="icon" sizes="16x16" type="image/png" href="/favicon16.png">
    <link data-react-helmet="true" rel="icon" sizes="32x32" type="image/png" href="/favicon32.png">
    <link data-react-helmet="true" rel="shortcut icon" type="image/png" href="/favicon64.png">
</head>
gatsby-plugin-sitemap
The gatsby-plugin-sitemap plugin lets you add a sitemap.xml file to your page header so search engines and robots can pick up the full site layout of your website.
Google analytics
The gatsby-plugin-google-analytics plugin lets you add Google Analytics to your sites JavaScript. You will need to get a trackingId from your Google Analytics console, and add the following plugin configuration to your gatsby-config.js file.
...
plugins: [{
        resolve: `gatsby-plugin-google-analytics`,
        options: {
          trackingId: "ENTER_YOUR_TRACKINGID",
          // Puts tracking script in the head instead of the body
          head: false,
          // Setting this parameter is optional
          anonymize: true,
          // Setting this parameter is also optional
          respectDNT: true,
          // Avoids sending pageview hits from custom paths
          cookieDomain: "yourdomain.com"
        },
      }
],
...
Summary
This is really just a small set of some of the incredibly useful Gatsby plugins. I will have future posts on how to configure image manipulation as well as markdown content in you Gatsby projects.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeMarch 28th, 2019I was asked to write about how I lost my excess weight, and what I have learned about nutrition
"You know you have gained 10 pounds from last year?" No one likes hearing that question from their doctor. On top of being 10 pounds heavier, my A1C was in a pre-diabetic range and I had high
blood pressure that was making my Doctor prescribe a second blood pressure medication. I was about to turn 48 and my health was headed in the wrong direction.
I tried to look at what I had been doing up until that point as far my lifestyle goes.

I don't smoke
I exercise vigorously about everyday
I was eating what I thought was a healthy diet
I avoid stress

At this point I weighed 240 pounds at 6'3". I thought that I was maybe 10-20 pounds overweight. Then I looked at my BMI. You can argue over how accurate of a scale that is, but at my height,
I should not weigh more than 200 pounds. I was determined to get my weight below 200 pounds by the end of the year. I weighed about 200 pounds when I graduated from High School,
and I wanted to see if I could get back down to that weight.
The next thing I did was buy a scale and read a book called "Fitness Confidential".

      
    
  
  
    

Fitness Confidential by Vinnie Tortorich

If you are not familiar with Vinnie Tortorich, he is kind of like the fitness trainer to the stars, and he is a regular guest on the Adam Carolla Show.
I had heard him on Carolla's podcast before talking about diet and fitness, so I decided to read his book. In the book he says that your should exercise, but it is one of the least effective ways
to lose weight. I was wary of this because in the past I had used exercise to lose weight. At one point I weighed close to 300 pounds I managed to lose a lot of that weight by exercising,
but I never got to where I wanted to with the exercise. And I was sometimes exercising twice a day. Now I was starting to gain weight again.
Then I started reading his book, and looking for things I could change in my diet to help me loose weight.
Vinnie summarized what I needed to do with my lifestyle in one sentence; "You got to cut out Sugars and Grains".
Cutting Out Sugars and Grains
Vinnie has even trademarked a slogan called "NSNG" for No Sugar, No Grains.
The other thing he details in the book are some of the specifics about food and drinks that can be problematic if you are trying to loose weight.
One of the stupid things I was doing was drinking a glass of Gatorade after working out. Real athletes don't drink Gatorade.
I was also drinking a lot of diet drinks like Diet Coke. I figured that since there were no calories it would be Ok for me to drink Diet Coke or other diet drinks.
It turns out that drinking diet drinks tricks your body into producing more insulin, and works against you when you are trying to lose weight.
So I started drinking the one drink every human should be drinking, WATER!
Giving up the drinks was the hardest part. The food was easier than I thought. I just had to avoid foods that had sugars and grains. Some of that is obvious, like candy bars and cookies.
Other foods can be tricky to spot. So many of the foods we eat now have added sugar. An easy way to tell if food has added sugar is if it has "Low Fat" label. Generally when foods have fat removed,
food companies will replace the fat with sugar. Malcolm Gladwell chronicled this in a talk he gave titled "Choice, happiness and spaghetti sauce".

 

What about grains? What exactly is a grain? What kinds of foods have grains? This was a little trickier. Obviously bread has grains. So does rice and pasta. I was eating a lot of rice and pasta.
This was probably one of the harder things to cut out of my diet, but I did it anyways.
Aren't You Eating More Fat?
One of things Vinnie Tortorich has said that I think is a good analogy is the worst part of fat is the name "Fat". There are three Macro-nutrients: Carbohydrates, Protein and Fat.
Sugars and Grains are carbohydrates, and you have to substitute those kinds of carbs with other kinds of foods. I did increase the amount of fat I was consuming,
but it turns out that there are healthy fats that you can eat.
There are three mains types of fats: saturated fats, mono-unsaturated fats and poly-unsaturated fats. I grew up believing that if you ate saturated fat, you would have a heart attack and die.
It turns out that heart disease is a little more complex than that advice. Policy makers and organizations like the American Heart Association has slowly been moving away from these types
of recommendations. I attend to post more on on the policies and science at a later time.
The fats that are really bad for you, you have probably heard of before: trans-fats.
We really don't have to worry to much about trans-fats anymore because they have been banned. I made fun of Michael Bloomberg when he did this as the Mayor of New York city,
but he was right about trans-fats. Trans-fats where actually introduced into our food supply by experts who thought they were healthier than saturated fats.
I Stoped Counting Calories
One of the reasons diets don't work, especially with calorie restriction, is because people can't maintain a low calorie lifestyle for extended periods of time. I am going to save the science behind this
for another post. They key is to eat the right kinds of food, and to eat to satiety. This worked for me, and I realize some people overeat. My experience was that I did not want to overeat if I ate until I was full.
I started all of this in July of 2017. The first week I lost five pounds I continued to lose weight each week, but not at the rate I did the first week. I mentioned I bought a scale.
There are a number of scales that connect to Wi-Fi, and will sync to the cloud. I bought the Fitbit scale which ties into their app. This made it a lot easier for me to track my progress.
Shooting Past My Goal
My original goal was to get below 200 pounds before 2018. I wound up reaching 195 pounds by November of that year. Needless to say I was extremely pleased with the results,
and more importantly I enjoyed the change I had made to my lifestyle. So I decided to see if I could get down to 190 pounds. I eventually did, and then to 185, 180, 175 and 170.
This past August I got down to 167 pounds. That was a little lower than I wanted to go, so I average around 175 pounds now.
I think this is a healthy weight for me, and I intend on maintaining the weight I am at now. I mentioned the BMI scale before, but for someone my height it recommends somewhere
between 155 and 199 pounds. I don't know how accurate this is, but this seems to work for my body type.
Mistakes I Made
The first mistake I made was not talking to my doctor about loosing weight. If I had this all to do over, I would have consulted my doctor so they could monitor changes to my blood pressure
as I lost the weight. I would have also asked for tests to see if my blood work looked ok. In my case I was not getting enough water.
This type of lifestyle change is commonly referred to as LCHF, or low carb, high fat. I think it should be called low carb, heathy fat.
There are a lot of resources for people that are trying to cook and eat with this lifestyle. One of the websites I have been going to is dietdoctor.com.
Vinnie Tortorich also has a great podcast where he talks about diet and exercise. One of his co-hosts is Anna Vocinno, and she wrote a cookbook called Eat Happy.
It has some excellent recipes on how to cook and make NSNG meals.
There are also some excellent Facebook groups for people who are doing LCHF. Vinnie's fans have one called Vinnie Tortorich's No Sugar No Grains.
There is another one I like a lot called Fat Head. This is for fans of Tom Naughton who made a very funny documentary called "Fat Head".
Are you Doing Keto or Intermittent Fasting?
Short answer is no. I am not doing keto. Keto is short for Ketosis. Ketosis is a state you body goes into when you body feeds off of ketone bodies instead of glucose,
usually around a minimum of 0.5 mmol/L of beta-hydroxybutyrate (BHB). I certainly don't have a problem with anyone who is in Ketosis, it is actually a natural state.
Ketosis by its nature is LCHF.
Intermittent Fasting (IF) has also become a popular method, especially when used in combination with LCHF.
There are different was of doing IF. I try to restrict my eating to about eight hours a day. There are some people that fast for a day or two. Some people fast for even longer periods of time.
I do not know enough about it to make any recommendations, but Dr. Jason Fung has a book and runs a medical practice specializing in IF.
What About My Health?
Most of the problems I was having have gone away. I lost the weight, and when I did I lost my hypertension. It turns out that I was really suffering from metabolic syndrome.
Metabolic syndrome is a term that refers to a cluster of diseases like obesity, hypertension, pre-diabetes or type II diabetes and fatty liver disease.
Most of my other markers have improved as well. I was worried about my cholesterol, particularly my LDL numbers. I actually lowered my LDL number significantly.
My overall heart health has improved as well.
I plan on writing more about nutrition on this blog in the future, as well as some of the myths I have discovered about weight loss and healthy living.
I also want to thank Vinnie Tortorich for helping me blow past my weight loss goals.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeMarch 27th, 2019I came across a nasty bug in the WKWebView in iOS 12 today when it comes to dismissing the keyboard. What happens sometime when the user scrolls the webview while a textarea is selected, and then they dismiss the keyboard, it leaves the section of the webview that was covered by the keyboard unusable. We have a reload method that can clear this, but then the user will lose all of the input they have entered into their forms.
I came across this issue on the Cordova repo on github.

Seeing a blocking issue after updating to XCode 10 related to keyboard displacement and then dismissal.


When an input that would require webview centering is clicked, the viewport is repositioned to center that input, as iOS has traditionally done. However, when dismissing the keyboard, the viewport is not re-positioned properly back to its original position.


This can leave large gaps where the webview is no longer visible. In the attached screenshots, you can see that this leaves a large margin where the viewport is rendering, shifted upwards and off-screen by a 100+ pixels. There appears to be no way do re-position the viewport short of additional input focus changes, each resulting in similar offset issues.


To add some additional confusion, it appears this only happens on iOS 12 / XCode 10 produced installs, such that:


This issue is present ONLY on builds produced in XCode 10 targeting iOS 12 devices.
This issue affects ALL tested device types on iOS 12.
This issue is present via Legacy AND Modern build systems
iOS 10 / 11 devices targeted via XCode 10 are NOT affected.
iOS 10 / 11 / 12 devices targeted via XCode 9 are NOT affected.


Any info on potential workarounds or patches would be greatly appreciated. I've already looked into upgrading our cordova-plugin-ionic-webview plugin (as well as various others), but it appears to not have any relevance with the issue. At this point, we're looking at downgrading XCode in order to get working builds out.

We already had some code in our application for triggering methods when the keyboard is shown or dismissed;
        [[NSNotificationCenter defaultCenter] addObserver:self
                                                 selector:@selector(keyboardWillBeHidden:)
                                                     name:UIKeyboardWillHideNotification object:nil];
We added some code from one of the examples for resetting the offsets on the WKWebView subviews once the keyboard has been dismissed.
- (void)keyboardWillBeHidden:(NSNotification*)aNotification {
    ...
    
    if (@available(iOS 12.0, *)) {
        WKWebView *webview = (WKWebView*)self.webViewNew;
        for(UIView *v in webview.subviews) {
            if ([v isKindOfClass:NSClassFromString(@"WKScrollView")]) {
                UIScrollView *scrollView = (UIScrollView *)v;
                [scrollView setContentOffset:CGPointMake(0, 0)];
            }
        }
    }
     
    NSLog(@"Keyboard dismissed");
}
I hope this helps anyone else who comes across this issue with the WKWebView.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeMarch 24th, 2019I recently moved my Website to a new static site generator called Gatsby JS
Gatsby JS is a site generator based on the React framework. I have been using Jekyll for the last couple of years, but I have had real problems with some of the Ruby system not installing ruby gems properly. Another thing that is nice about Jekyll is that itis natively supported on Github pages. All you have to do with any github probject is make sure your jekyll site is checked into the gh-pages branch, and Github will auto-publish your site everytime you check into that branch.
I help run a user group on Node.js called JaxNode here in Jacksonville, Fl. Since we are heavily node focused, I decided to use one of the many site generators available on Node. There are many including Hugo, Hexo and Metalsmith. I opted to go with Gatsby JS.

      
    
  
  
    
Gatsby JS
So why did I choose Gatsby? One reason is that it is based on React JS. Another reason is that it uses GraphQL for pulling in data into the site for things like markdown files, and I have been wanting to learn more about GraphQL. There is also a large ecosystem of plugins for everything from Wordpress support to image manipulation. I have decided to write my first post on some of the challenges I encountered in porting my site and blog over to Gatsby.
Learning the basics
Gatsby is actually very well documented. They have their main documentation site here, and they have a great set of tutorials here. If you are starting from scratch they have great set of starter sites. I initially tried to use a couple of there starter sites, but I was not happy with any of the layouts they used, so I decided to create mine from scratch. This turned out to be a worthwhile thing to do because it gave me a chance to get caught up on some of the trends with styling and web design. It is a lot easier to build good looking responsive website just using the built in tools that come with modern browsers now.
Gatsby has a set of CLI tools you can use for developing, building and browsing your site. Here are some of the basic commands;
// Generate a new site
> gatsby new my-new-site-name

// Develop a site, and see you changes in real-time at localhost:8000
> gatsby develop

// Build your site html
> gatsby build

// Serve the site you just built using localhost:9000
> gatsby serve
Styling
There is a neverending list of options for applying styles to your content. You use plain old CSS, or use styled components, emotion or styling in JS. You can also use SASS or SCSS to compile your CSS. Gatsby also allows you to use something called CSS Modules. These are nice because it allows you to create styles that are scoped locally to a single component.
/* src/components/container.module.css */
.container {
  margin: 3rem auto;
  max-width: 600px;
}
And then in your component you can import the style as a class onto your component. Here is an example of a component consuming the previous CSS file.
// src/components/container.js
import React from "react"
import containerStyles from "./container.module.css"

export default ({ children }) => (
  <div className={containerStyles.container}>{children}</div>
)
I tried to use inline styles where ever I could, but CSS modules are nice when you have to add media queries to make you components responsive. Here is a module I used on one of my headers so it would work on a desktop, tablet or smartphone.

h1.about {
    padding: 200px 0px 200px 0px;
    text-align: center;
    font-size: 4rem;
    font-weight: 1000;
    text-shadow: 2px 2px 5px black;
    margin: 0px 200px 0px 200px;
    color: #fff;
}

@media (max-width: 768px) {
    h1.about {
        padding: 150px 0px 150px 0px;
        text-align: center;
        font-size: 2rem;
        font-weight: 1000;
        text-shadow: 2px 2px 5px black;
        margin: 0px 100px 0px 100px;
        color: #fff;
    }
}

Pages
Creating pages in Gatsby is fairly easy. All you have to do is create a functional component in the src/pages directory in your project. If you name your page about.js, Gatsby will automatically create a route to that page as /about/. Here is what my about page looks like in React syntax;
import React from "react"
import Layout from "../components/layout"
import Navbar from "../components/navbar.js"
import Header from "../components/aboutheader.js"
import Footer from "../components/footer.js"
import Article from "../components/article.js"
import MainHelmet from "../components/mainhelmet.js"

export default () => {
    return (
        <Layout>
            <MainHelmet title="Fek.io" />
            <Navbar />
            <Header headline="About FEK.IO" />
            <Article>
                <div>
                    <h2>Need a iOS, Android or Node.js application</h2>
                    ...
                    <p>This Web site is built using Gatsby JS. </p>
                </div>
            </Article>
            <Footer />
        </Layout>
    )
}

Linking to other pages
Gatsby does not require the use of the React router. If you want to link to another page, they have a component you can use to create hyperlinks to other pages. This is the <Link /> component. If you want to use it in your page or component, all you have to do is import it from the gatsby module.
import React from "react"
import { Link } from "gatsby"

export default ({props}) => {
    return (
        <div>
            <Link to={props.page}>{props.name}<Link>
        </div>
    )
}
Conclusion
I have not finished making changes to my site yet, but I should be making some more changes soon. I will have some posts on how to add a blog to your site, how to use markdown and how to use the image manipulation features in Gatsby plugins.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 8th, 2018Coffee Breaks is what one of my flight instructors referred to my breaks of a couple months or a couple of years from flying.
I recently started flying again after a 20 year absence from the cockpit. A recent experience I had with the Transportation Security Administration encouraged me that there might be a better way to travel.
When I was a child I became fascinated with airplanes, helicopters and anything else that might fly. I was fortunate enough to have a parent who was also a pilot, so I was able to learn some basics prior to actually learning how to fly an actual aircraft. So when it became time to decide on my education, I decided I wanted to become a professional pilot. There are a number colleges where students can learn how to fly, but I wanted one to go to one that focused on aviation and aerospace. The university I wound up attending was Embry-Riddle in Daytona Beach, Fl.
After graduating I had a degree and a commercial pilot's license. At that time there were two tracks a student with my degree could take as a pilot. One where you could get a Multi-engine rating, and one where you could become a Certified Flight Instructor. I chose to get my Multi-engine rating because that was the quickest and least expensive way to complete my training.
After graduating I was broke and looking for work, so I chose to get a job doing what I had been doing in college, and save my money and train to become a flight instructor. I did eventually go on and become a CFI. At the time I had a day job working in IT, but either in the mornings before work, or on the weekends I would fly and instruct.
Life has a funny way of finding different vectors in life you take on your career. With my day job I eventually became a Software Engineer, and I have been extremely content in that profession. Along the way I let my CFI certificate expire, and stopped flying altogether in the 90s.
In my current job I travel fairly frequently. Over the last year I traveled to the San Francisco Bay area three different times, as well as many other locations across North America. Like many of the people probably reading this post, I enjoy all the same indignities as you trying to get from point A to point B. It was on one of my recent trips that I decided to get back into the cockpit after a 20 year absence.
A lot of people think that a pilot‚Äôs license has an expiration date, but in fact it does not. Once you receive an airman‚Äôs certification, it is good forever. But in order to fly legally, there are a number of things a pilot must do to stay current. These include proof of sound health and recurrency training.
Unless you are a sport pilot, you have to have what is called an aviation medical exam (AME). There are doctors that are certified to give airmen medical exams by the FAA. They can give three different types of medical certificates that have different classes. The FAA recently added a new type of medical called a basic aero that can be used by private and recreational pilots. Basic aero medicals can be performed by any licensed doctor.
I decided to get a 1st class medical last month, which is the highest class medical a pilot can receive. One of the things I noticed from my most recent medical exam is that the FAA has relaxed this exam. They used to be pretty strenuous, but you will find that TSA is more thorough now on their inspections than the flight surgeon. The reasoning is that flying an airplane is not that different from driving a car. I don‚Äôt know if I agree, but this did used to scare a lot of people away from learning how to fly.
Every 24 months, a pilot has to do recurrency training if they want to fly legally. This requires that the pilot find an instructor and they get at least an hour of ground and an hour of flight instruction. Pilots do not have to do this training if they have completed another rating in the proceeding 24 months.

      
    
  
  
    

British registered Cessna 152 two person trainer

Some Observations on 20 Years of Changes
I was worried that all of the regulations would have changed since I was flying in the 90s, but to my surprise not much has changed. There are some new regulations in our post 9/11 world, but they are what you would expect. One of the big regulatory changes was the establishment of the ‚ÄúSpecial Awareness Training for the Washington, DC Metropolitan Area‚Äù. There is special training that pilots must undergo if they plan on flying into a 60 nautical mile radius of the DC metro area. There is even a course you can take online by the FAA on how to fly within this area.
The other thing that has not changed is the aircraft I was flying 20 years ago are the same ones I am flying today. In fact it is very common to find Cessna and Piper aircraft from the 60s, 70s and 80s on the ramp today. What has changed a lot is the Avionics. These are the radios and instruments that pilots use to navigate aircraft around in flight.

      
    
  
  
    

A Garmin G1000 EFIS display

When I was flying in the 90s, we had one airplane on the flightline that had a GPS receiver. That receiver did not have a graphical display, and it could only tell you if you were on or off course.
One of the most significant changes in avionics has been the introduction of ADS-B. Automatic Dependent Surveillance-Broadcast (ADS-B) allows aircraft to broadcast their positions to ground stations. In turn the ground stations send traffic and weather information back out to the aircraft. This is an amazing tool we did not have when I started flying, and helps pilots avoid other aircraft and bad weather.
Resources and Inspirations
One of the things we did not have when I began and ended my early career as a pilot was the internet. We did have the internet in the 90s, but there were not a lot of resources online for pilots. You generally had to find an aviation bookstore to find current copies of the FAR/AIM or charts used in flying. A lot of these are online now. FAA.gov has most of the publications that pilots require in PDF form.
There are also great weather resources for pilots online as well. We used to have to call a Flight Service Station (FSS) to get weather and file flight plans. Today the government has contracted Lockheed-Martin to offer these same service through a website called 1800wxbrief.com.
iPad

      
    
  
  
    

Two pilots looking at airport diagrams on their iPads

The days of carrying around 40 lbs of charts are gone. Nowadays pilots are using some sort of ‚Äúelectronic flight bag‚Äù, or an iPad. As someone who earns their living writing iOS software, this is one of my favorite changes for the better.
The folks at ForeFlight have an amazing product. I remember when they launched, they were just an aviation weather app. Now you can do flight planning, view approach plates, get up to date weather and even file flight plans all in ForeFlight on your iPad.
YouTube Channels
There are a ton of YouTube channels from pilots showing everything from instruction to just showing GoPro footage taken from their flights. It is important to remember that these videos should not be considered a substitute for real instruction, but it helped me remember things from my training.
My favorite channel right now is FlightChops from Canadian pilot Steve Thorne. Steve is a professional filmmaker and a private pilot. He does a really good job of showing context in the things he is learning, and he consults with and uses real flight instructors in his videos.

    

YouTube user Steveo1Kinevo is a professional pilot based in South Florida. He makes great videos of his flights and experiences as a commercial pilot.



Friendly Skies Films is another great YouTube channel by Nicholas Cyganski. Nicholas makes great videos about his experiences as a licensed pilot. He also goes into great detail explaining different aviation subjects. One of my favorite videos he did was how the news media never gets anything right when it comes to aviation.



Another YouTube user I enjoy quite a bit is Matt Guthmiller. Matt set a world record when he was 19 to be the youngest pilot ever to fly around the world. Matt makes great videos of him flying the same plane he flew around the world, making regular general aviation flights. Check out this video he made of flying to the Bahamas.



There are also two ground instruction companies online that produce great short videos on short subjects on learning how to fly. One of these companies is MzeroA.com. Jason Schappert is a CFII and owner of MzeroA.com. Check out him demoing how to do slow light.



Another one of these companies is FLY8MA. They have some great videos online demonstrating different things a pilot needs to know when flying an airplane. Check out this video from Jon Kotwicki doing an introductory flight lesson.



I would not use these videos as a substitute for training, but they are good refreshers on things you might have leaned in the past. I would still consult a CFI or CFII in person before attempting to do anything in these videos.
Bucket List
There are a number of things I was never able to accomplish as a pilot that I would like to do now that I am flying again. I have never flown to the Bahamas. I hope to do that this year.
I am also planning on getting my seaplane rating. I plan on writing about my aviation experiences with these blog posts to help other pilots like myself who have taken long coffee breaks from flying.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeMarch 9th, 2017I started a Node.js User Group here in Jacksonville back in 2013, and I wanted to share my experiences about starting a Node.js User Group‚Ä¶
I started a Node.js User Group here in Jacksonville back in 2013, and I wanted to share my experiences about starting a Node.js User Group for anyone who has ever wanted to get one started in their community! FYI, the user group that was started is called JaxNode. Come join us next time you are in the area!
A Little Bit of My Background
Back in the summer of 2013, I became interested in learning more about Node.js. I had a side business where I was building native mobile applications for iOS and Android smartphones. My day job had been building ASP.NET web applications and web services. I was looking for a way I could build restful services for my mobile apps without having to run a Windows emulator since I was doing my mobile development on a Mac. This was pre¬†.NET Core.
So I looked at the alternatives for doing backend service development that could be done on a Mac. I looked at Java, PHP, Python, Ruby and Node.js. I had some server experience with Java, but I was looking for something that did not require the overhead of using a compiler.
Node.js turned out to be a perfect fit for my needs. With Node‚Äôs evented IO, it had very quick startup times. My http requests took a few milliseconds to process as opposed to several hundred milliseconds with ASP.NET. There was also a huge open source community with tools and frameworks for building the applications and an amazing module ecosystem through npm (Node Package Manager).
Jacksonville has a great community of software engineers, and many programming User Groups, but none that were dedicated to Node.js or JavaScript. I had seen a few presentations on Node.js in Jacksonville, but no one had started a User Group just for Node.js.
The people were there, now we just needed to come together to learn more from each other around Node.js and JavaScript. If you find yourself in my same predicament and there is not a Node.js user group or JavaScript User Group in your community, then you should consider starting one. Here‚Äôs why and some suggestions on the how!
Why Start a Node.js User¬†Group?
User Groups are great not just for learning about new subjects and trends in software, but they are also a great place to network with other developers and companies with similar interests.
Node.js has a non-profit organization that supports, i.e.. The Node.js Foundation and companies that support it, but almost everything in Node.js is driven by the community. User Groups are a great way to help foster and support that community.
Organizing your Node.js User¬†Group
const startNodejsGroup = () => {
    findPlaceToMeet();
    findSpeakers();
    reachOutToCommunity();
    scheduleMeeting();
    learnMoreAboutNodejs();
};
Ok, so now you have started your Node.js group, now what? How do you let the local community know about it, find a place to meet, and provide food and drinks for those meetings? The best suggestion is to use a site like Meetup or Eventbrite to organize your meetings and invite people to those meetings. Meetup does have a subscription cost, but if that is an issue, there are free alternatives like Facebook.
I used Meetup to start and advertise JaxNode. You also might want to create a website for your user group. It can be as simple as creating a GitHub pages site. GitHub provides free web hosting. I created an open source web application based on express that ties into Meetup‚Äôs API. It can also use the Twitter API. This site automatically displays the next meeting.
Once I started our Meetup group, a few companies here in town offered to provide a meeting room for free. Other companies also offered to provide food and refreshments at those meetings. Everything started to fall into place very quickly. If you cannot find a company or organization that will host your meetings, take a look at your local public library. Many libraries have meeting spaces that can be reserved.
Try to communicate with your users on a regular basis. Let them know about upcoming meetings, but don‚Äôt spam them. I try have future meetings topics posted at least a month out. I will send an email to my members the week of the meeting, and the day before the meeting as a reminder. Posting on you social media accounts is also important for getting the word out.
It is also important to meet on a regular basis, during the same time of the month, each month. JaxNode meets the third Thursday of the month.
Try to find volunteers to help run the group. Sharing responsibilities will help prevent you from burning out. Managing a User Group usually involves booking speakers, finding meeting locations and emceeing the meetings.
One of the challenges in running a user group is finding speakers and topics that can be discussed that will draw users to your meetup. Fortunately for us in the JavaScript community, there is no shortage of topics that can be discussed. npm now holds over 250,000 modules. That is a source of 250,000 topics that can be discussed. We have many speakers who have volunteered to speak at JaxNode, but I try to actively encourage members who have not spoken before to create presentations for our group.
Try to have some variety in your presentations as well. At JaxNode we have presentations on server-side web application frameworks, such as Express and Hapi; client-side frameworks like Angular and Ember. But, we have also have presentations on quirkier subjects like robots, and even how to write plugins to Photoshop using Node.js.
Soft skills are increasingly mentioned as an important skill for developers to have, and presenting a subject to a user group is a great way to develop those soft skills.
Marketing your User¬†Group
Besides getting setup on Meetup or creating a website, it is a good idea to create social media accounts on Facebook, Twitter and Linkedin. We also use our @jaxnode Twitter account to repost interesting articles and posts around the web on Node.js.

If you need a Logo, there is a great repository created by Chris Williams featuring the ‚ÄòJS‚Äô against a yellow background. We took that original Logo, and created our own version with the JaxNode logo. There is a company called Sticker Mule that makes stickers of your Logos. Those can be given away as swag at user group meetings. They help drive buzz about your group when people see your sticker emblazoned upon someone‚Äôs Laptop.
I also created a GitHub group just for our group so the members could fork their repos on presentations they have done at the group. I also put the source for our site https://github.com/Jaxnode-UG/jaxnode on our GitHub site as well.
The Node.js github site also has a repo for evangelism. You can list your group in the Current Initiatives by making a pull request to this repo for adding your group to the list of meetups. They have a good article on this site explaining the format of the submission.
Make friends with the other User Group managers in your area. It is a great way to market your group and possibly find new members and speakers for your group.
Planting the¬†Seed
Just in the last month here in Jacksonville, a React](https://www.meetup.com/React-JAX) and React Native user group was started by members who have attended our meetings. This is one of the things that I have been happiest about in starting JaxNode. We had several meetings on React, and now we have two new user groups in Jacksonville dedicated to React.
I have to admit, the main reason I started a Node.js User Group was a selfish reason. I wanted to see other companies here in Jacksonville start to adopt Node and other JavaScript technologies. I knew that creating new opportunities for Node.js in Jacksonville would also help me in my career. The side benefit is that it has also helped other people get the opportunities that they wanted as well.
So what are you waiting for? Start that Node.js and JavaScript user group in your area. And if you need any help on the way, feel free to contact me at @jaxnode or @davidfekke on Twitter.Tags: node.js,   javascript community   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeSeptember 6th, 2016This article is reprinted from a post I made to Hashnode.
I have been writing software for iOS since before it was the iOS, back when it was still called iPhone OS 2.0. Navigating the App Store approval process can be tricky, specifically when dealing with a rejected app.
Apple can reject an App for a lot of different reasons. After having gone through this process dozens of times, I thought I would share some insights about what to do when your app is rejected by Apple. I had an app I was working on rejected a couple of days ago, and I was able to get the App approved through Apple's "Appeal Board".
The app I was trying to submit was rejected because Apple said it did not work on IPv6 WiFi networks. Apple began requiring that apps submitted to Apple back in July should run on IPv6 networks because a lot of cellular networks are switching IPv6 only. This makes sense because ICANN ran out of IPv4 IP addresses some time ago. If your app does not run on a IPv6 network, Apple will reject the app.
Our app did work on IPv6 networks, but Apple still rejected our app. How did this happen? It is because their is a flaw in Apple's WiFi testing network. You can read about it in this link https://forums.developer.apple.com/thread/48314. There is reference to an article on Apple's dev site on how to turn your Mac into a IPv6 WiFi router with NAT64 support. I used this to prove that our app ran on IPv6 networks.
How to win an Appeal
Don't just re-submit your app! Apple provides a "resolution center" on iTunes Connect. In the resolution center you can reply to messages from Apple. Provide as much information to Apple as you can in your reply. You can even upload attachments. Apple also provides a link to "Appeal" the rejection for your app to Apple's review board. That sounds pretty bureaucratic, but Apple usually repsonds to your appeal within 24 hours.
In our case, they requested that we add some additional information to the notes section in the metadata, which included a link to a video of our app working on an IPv6 network, and that we push the "Submit for Review" button in iTunes Connect.
The Basics of Submitting an App
The first thing I would recommend any developer do before submitting an App to Apple's App Store is read their App Store review guidelines. Apple even released a comic book explaining the rules for Apple excepting an app. After reviewing our video, they accepted our app.
There are many different ways to create an App now. You can even pick your favorite programming language in a lot of cases. Some of these frameworks include PhoneGap, Cordova, Xamarin, Unity 3D, React Native, NativeScript and of course Apple's CocoaTouch framework. Apple used to be restrictive on anything outside of their own tools, but they have opened up the App Store to most of these different frameworks. That being said, make sure that if you do use one of these non-Apple frameworks that you still follow their guidelines. Apple does not want anyone running compilers on the iPhone or iPad. Even if you do build your application with CocoaTouch, that does not guarantee that Apple will not reject your app.
App Completeness
Another reason Apple may reject your app is because of something they call "Completeness". This means they do not want you publishing an app that is buggy or crashes on startup. Other things you may also want to consider is if your app requires a login, make sure your provide Apple with a login and password they can use when they are reviewing your app. If you app requires a backend service, make sure that service is turned on. Most of this is common sense, but this a common gotcha that catches some developers.
Content
Apple is sensitive to content you put on your app. Make sure you respect the copyright and IP laws of the country you plan on releasing your app. It is also important to make sure that your app is age appropriate for the age group your are targeting for your app. They want to make sure that parental controls will work correctly. It is also important that you select the correct category for your app. If your app targets business, make sure you select that as your category.
Privacy
Respect your users privacy. Don't send data back about the users personal information without getting consent from that user. The scrutiny is amplified here if you are dealing with medical information or with children. There are also general privacy and HIPAA laws to take into account.
Location
Using the GPS and other location based APIs on the phone can be expensive as far as battery use goes. I have had Apple reject an app update I made because they did not like the way I was using location in the background. In my situation, Apple recommended that we use geo-fencing, which is part of their location API.
Metadata
This may sound trivial, but this is a common reason why Apple rejects a lot of apps, and that is because of incomplete or erroneous information supplied in the app's metadata. I had an update rejected because we mentioned a companion app in our description that ran on a competitor's operating system. I won't say which OS that is now, but I can tell you it is the most common mobile operating system in the world, and it is put out by a company whose name rhymes with "foogle".
To Summarize
The app submission process to Apple can seem onerous at times, but Apple has gotten a lot better at this now. Phil Schiller took over the part of Apple that runs the App Stores, and the review times have dropped dramatically since he took over. It used to take two weeks for Apple to approve an app. That time is now down to about a day.
Apple is about to release iOS 10 soon, so I am sure that these review times will go up again as developers race to get their apps ready for iOS 10, but the overall process seems to be a lot less painful now.
I love developing for iOS despite some of the hurdles that you have to jump through in dealing with the App Store. This should not prevent anyone who wants to develop an app for iOS from publishing on the App Store.Tags: iOS,   Apple App Submission   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 13th, 2016After programming in an object oriented way for 15 years, I am started to make the transition of programming in a more functional way
with languages like Javascript and Swift. Javascript has always treated functions as first class citizens, and their is a movement in
the Javascript community from developers such as Eric Elliot to never use the new keyword again.
I recently upgraded an express site from 3 to version 4. As part of that process I decided to refactor the code that called external
services so they would be more testable and more loosely coupled. In languages such as Java and C# this can be achieved by using
dependency injection.
In express it is actually very easy to inject functionality into a route. This can be done by either using middleware or
injecting another function into a route.
const routes = require('./routes/index');

const exposeService = function(req, resp, next){
    req.service = require('./myservice');
    next();
};

app.use('/', exposeService, routes);
For one of the routes I needed to be able to inject two services that could be used by the route. In an earlier version of the
combined service I created an object that had two properties that held references to other objects that had functions for
returning the data I needed in my route. Here is how I intially wrote the service as an object.
"use strict";

// Creating function object
const Service = function Service(meetupdata, twitterdata) {
	this.Meetup = meetupdata;
	this.Twitter = twitterdata;
}

// Prototype function for getting the next meeting
Service.prototype.getNextMeetup = function getNextMeetup(cb) {
	this.Meetup.getNextMeetup(cb);
};

// Prototype function for getting the tweets
Service.prototype.getTweets = function getTweets(cb) {
	this.Twitter.getFeed(cb);
};

// factory function for creating a new version of the object
function create(meetupdata, twitterdata) {
	return new Service(meetupdata, twitterdata); 
}

module.exports = create;
While this worked, it turns out there is a much simpler and more elegant way of creating this service.
"use strict";

function Service(meetupDataFN, twitterDataFN) {
	return {
        getNextMeetup: meetupDataFN,
        getTweets: twitterDataFN
    }
}

module.exports = Service;
Summary
In the current version of my service I am returning an object with two functions. Not only is this approach cleaner,
it is also more functional. I am also just passing in functions instead of whole objects.Tags: expressjs,   Javascript,   node,   node.js,   DI,   Dependency,   Injection   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeApril 12th, 2015I have decided to move my web site off of the Orchard CMS, and to Jekyll.

      
    
  
  
    
If you are not familiar with Jekyll, it is a static site generator written in Ruby. I initially decided a couple of years ago that I would move my site and blog over to Orchard because it is based on ASP.NET MVC, and I am a C# ASP.NET developer. I also write web based software using Node.js, and there are a coupld of CMSs based on Node that are pretty good.
In the process of researching some of the Node based systems, I am came across a number of Node based static site generators. Most of them do essentially the same thing as Jekyll. They use Markdown for posts and pages, which I like.
I am also a fervent user of GitHub. GitHub has a very cool feature called GitHub pages. GitHub pages uses Jekyll in combination with their CI to automatically generate static content.
There are a number of advantages of using static content and GitHub pages. There is no backend database that is required to host the site. GitHub pages as hosted solution will automatically distribute the content over their servers so you get the benefit of having their infrastructure with your site. They have excellent documentation on hosting your website with GitHub pages.Tags: Jekyll   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeFebruary 7th, 2013I am going to be doing the presentation this month at the JaxArcSig. The topic will be on TypeScript, which is a language based on Javascript. TypeScript essentially adds a type system to Javascript. It also allows developers create classes and modules in Javascript.
The language is being developed at Microsoft. Anders Hejlsberg is the primary designer. They have added a project type in Visual Studio 2012 where you can write TypeScript, and VS will compile TypeScript down into Javascript. You can also use the Node Package Manager in Node JS to download the compiler. The compiler is written in TypeScript.
The meeting will start at 6:00 PM at Building 500 at the Bank of America campus on February 26th. Here is a map to the location.
View Larger MapTags: JaxARCSIG,   TypeScript,   Javascript,   JQuery   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeNovember 28th, 2012I will be speaking tomorrow at the Jax-js group on leveraging JQuery with ASP.NET MVC. The meeting will be at the Hash Rocket offices down at the beach starting at 7:00 PM.
There is also an upcoming meeting for the JaxMUG next week.
From Ovi at JaxMUG;
Dec 4th, Last meeting for 2012 - Introduction to MonoTouch by Irv Adams
We will develop a single-screen iPhone app from scratch that does tip (gratuity) calculations. This is an app I wrote and published in the Apple App store. I will show the code that comprises the business logic, which is C# but is compiled on a Mac using MonoTouch. This process converts it to Objective-C. I will also demonstrate Apple's Xcode and Interface Builder and how they interact with MonoTouch. I will talk about some of the steps necessary to get your apps into the app store.
BIO:
Irv Adams holds a BA degree in Mathematics. He has twenty-seven years in the IT field, ten as a self-employed consultant and the rest as a client support and internal systems specialist. He has coded in various environments BASIC, C, C++, VB, dBase, Clipper, FoxPro, ASP, WPF, and in the last seven years in .NET/SQL. Most recently he has taken an interest in Mobile apps for phone and tablets. He enjoys writing iPhone apps using MonoTouch by Xamarin
RSVP @ www.jaxmug.comTags: Javascript,   Jax-js,   JaxMUG,   MonoTouch   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeOctober 29th, 2012I wanted to send a reminder about tomorrow's JaxMUG meeting. Mike Glass of Pocket Sevens will be giving a presentation on new features for developers. Here is the write up for tomorrows meeting;
New Features in iOS 6
A brief overview of some of the new features available to developers in iOS 6, including Passbook, Transit routing and the new Maps API, and Facebook sharing. Also, some perspective on being a member of the community of iOS and Mac developers, including WWDC experiences from the last few years. Bring any questions you may have!
BIO:
Mike Glass is the President of Pocket Sevens, Inc., a Jacksonville based mobile development consultancy focused on iPhone and iPad apps. He has been developing for Mac OS since 2006, and iOS since day one of the iPhone SDK in 2008. His passion is building awesome, creative and easy to use apps. He also speaks on simplicity and usability in the iOS development world. Outside of work, he loves cooking, airplanes, boats and the New York Yankees. He is originally from Connecticut, and now lives in Jacksonville with his wife Nicole and daughter Madison.
The meeting will start at 6:00 PM at Co WorkJax.
View Larger MapTags: iOS,   iOS 6,   JaxMUG,   iPhone,   iPad,   iPod Touch   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeOctober 24th, 2012I wanted to put a reminder out that the next JaxMUG meeting will be this Tuesday, October 30th at CoWorkJax. The meeting will start at 6:00 PM.
Here is the write up on the presentation;
A brief overview of some of the new features available to developers in iOS 6, including Passbook, Transit routing and the new Maps API, and Facebook sharing. Also, some perspective on being a member of the community of iOS and Mac developers, including WWDC experiences from the last few years. Bring any questions you may have!
Mike Glass is the President of Pocket Sevens, Inc., a Jacksonville based mobile development consultancy focused on iPhone and iPad apps. He has been developing for Mac OS since 2006, and iOS since day one of the iPhone SDK in 2008. His passion is building awesome, creative and easy to use apps. He also speaks on simplicity and usability in the iOS development world. Outside of work, he loves cooking, airplanes, boats and the New York Yankees. He is originally from Connecticut, and now lives in Jacksonville with his wife Nicole and daughter Madison.Tags: iOS,   JaxMUG,   Objective-C,   Obj-C   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeOctober 6th, 2012Thanks to everyone who came out to my presentation at Code Camp on Objective-C for .NET developers. I have added that presentation to my powerpoint page on this site. All of my powerpoint slides can be found at http://fekke.com/powerpoint. I hope to see everyone who came out today at this months JaxMUG meeting.Tags: JaxMUG,   JaxCodeCamp,   Objective-C,   .NET,   C#,   Java   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeOctober 1st, 2012It is only five days until this years Jacksonville Code Camp. I am going to be giving a presentation on Objective-C for C# and Java developers.
If you have not signed up yet for the Jacksonville Code Camp, it is not too late to sign up. The registration for code camp can be filled out at eventbrite.
The schedule for the different presentations is now up on the JaxDUG web site. The first presentation will start at 9:00 AM at the College of Computing and Engineering (building 50) this Saturday. Here is a map of the location.Tags: jaxcodecamp2012,   Objective-C,   iOS,   iPhone,   iPad,   iPod Touch,   .NET,   C#,   Java   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeSeptember 26th, 2012I am going to be doing a presentation on developing for iOS devices at the Jacksonville Code Camp on October 6th. The schedule has not been posted yet on the web site, but I just got notification that my presentation was selected.
This presentation will be similiar to one I did in 2009. Objective-C is the primary language used for developing apps on the iOS and the Mac. There have been a lot of changes to the iOS SDK since I did that last presentation in 2009.
The point of the presentation will be to familiarize Objective-C to C# and Java developers. There are a lot of similarities between C# and Objective-C. I will explore these so that C# or Java developer can walk away with better understanding using their existing knowledge.
I hope we get a good turn out for the JaxCodeCamp this year. Please tell your developer friends to come out a week from Saturday.Tags: JaxCodeCamp,   jaxcodecamp2012,   C#,   Objective-C,   Java,   iOS,   iPhone,   iPad,   iPod Touch   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeSeptember 20th, 2012Scott Guthrie's last blog post had details on Microsoft's new Azure websites. Some of the big improvements are a new shared tier hosting, A-Record support and Fast-CGI support.
One of the features I like is GitHub and CodePlex continuous integration support. He has some demonstrations on how you can push changes into your repository and they automatically get loaded onto the website.
I have avoided using Azure in the past because of price and a-record support, but now with the new pricing structure I will probably use Azure going forward for small sites.
Azure also supports PHP and Node.js applications. They even host Linux VMs if you need a Linux VM.Tags: Azure,   ASP.NET,   .NET,   ASP.NET MVC,   PHP,   Node.js   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeSeptember 12th, 2012From Ovi over at the Jacksonville Mobile Developers User Group:
September 24th, Monthly meeting - Intro to Unity3D by Joel Hegeman

What is Unity3D
What kind of games can be written in Unity3D?
IDE Basics
Creating a Scene
Moving around the Character
Time Permitting......Blowing Stuff up!!!

Joel Hegeman is the Vice President of application development for New Age Solution. Joel was born and mostly raised right here in Jacksonville. He has been writing enterprise web and mobile applications for 14 years in various languages and platforms. Joel specializes in .Net, jQuery, Windows Phone, and Android development projects. Joel is the author of several WP7 apps including Simply Solitaire which generates over a million ad impressions a month.
Rsvp at http://jaxmug.eventbrite.com/ . See you there!‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeSeptember 11th, 2012From JaxCodeCamp 2012;
JaxCodeCamp 2012 - Mark your calendars for Saturday, October 6th, 2012!!
It is that time of year again and JaxDUG is excited to announce that JaxCodeCamp 2012 is rapidly approaching and we are looking forward to another great event this year!
With a variety of sessions and speakers, this event is a great way to expand your knowledge and your network with other professionals in the IT industry. If you or anyone you know is currently working with Microsoft Technologies, .Net development, and other areas of web development, mobile applications or similar technologies this is the event to attend! Whether you are junior, mid or senior level in IT field, this event is a great way to network and gain additional knowledge about various technologies.
Attendees:
If you have not yet registered for JaxCodeCamp 2012 please sign up  here as soon as possible! 
Speakers:
If you are interested in submitting a speaker session, please visit:  https://jaxcodecamp.uservoice.com/ to submit your topic.
The last day to submit a session is September 24, 2012.
Please feel free to pass this information along to anyone you know who would be interested in this event!
_TEKsystems will be sponsoring breakfast and we look forward to seeing you there!!
_‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeAugust 29th, 2012Michael Gidron will be speaking tomorrow on developing for Android at the JaxMUG meeting. This is part of a series of presentations on going from zero experience to getting your applications onto the app store for that platform. Michael is a former colleague of mine from LPS, and a great engineer. Michael has been developing for mobile since the Palm, and has great insight into developing for mobile platforms.
Android has an interesting SDK. You can build apps for android using the Java language. I am certain Michael will go into detail on the developer experience using the Android SDK.
The JaxMUG meets the forth thursday each month. We are currently meeting at the Jacksonville Southside public library. The meeting will start tomorrow at 6:00 PM. I look forward to seeing everyone there tomorrow.
View Larger Map
Update;
You can checkout the details at jaxmug.eventbrite.com and register if 
you'd like to attend.
On a separate note, for those who don't know yet, Jax CodeCamp 2012 
organized by JaxDUG is taking place @ UNF, Oct 6th. You can see current 
talk submissions, vote or propose your own talk at 
jaxcodecamp.uservoice.com ... Also, volunteers are always in demand :) 
You can use jaxcodecamp2012-eorg.eventbrite.com to get in touch with the 
organizers. Feel free to ping me as well with any questions ...
Cheers,
OviTags: JaxMUG,   Android,   Zero to AppStore   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeAugust 16th, 2012Microsoft has released new versions of Visual Studio and .NET 4.5. There are a lot of cool new features like better HTML and CSS editors. The Javascript editor now has full intellisence support.
Scott Hanselman has a great post on the new features, plus videos on some of those new features. The videos average about 6 minutes in length, and give a great overview of those features.
Microsoft also released a new version of ASP.NET MVC, MVC4. This version has the new Web API and mobile features. Scott shows these features on his post as well.Tags: .NET,   Visual Studio 2012,   MVC4,   ASP.NET MVC,   ASP.NET MVC4   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJune 21st, 2012Thanks to everyone that came out for my presentation tonight on "From Zero to App Store". Here are my slides from tonights presentation. I also have a PDF version of my slides. All of my presentations are available at the following link.
If you liked or hated my presentation, I would like your feedback. Let me know what you think. See you at the next meeting.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJune 12th, 2012The first meeting of the Jacksonville Mobile User Group will be next Thursday, June 21st. The first meeting will be held at the Southside library. The first presentation will be on going from zero to the app store. Here is the note from the group manager;
Your local Mobile User Group is scheduled to have its first meeting on June 21st. If you have an interest in mobile apps and webapps you can find out more about the group at www.jaxmug.com
-Ovi
I hope to see you there.Tags: JaxMUG,   iOS,   iPhone,   iPad,   Android,   Mobile   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeApril 25th, 2012I posted a video that explains how to use the Web API with the iPhone SDK onto Youtube last night. Click on the following link, and you can watch the demo. You can also see it below;


Tags: Screencast,   iOS,   Web API,   WebAPI,   ASP.NET MVC   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeApril 24th, 2012I have posted the slides and the sample code from tonights presentation at the Jax ARCSIG presentation on this site.Tags: WebAPI,   JaxARCSIG,   ASP.NET,   ASP.NET MVC,   iOS   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeApril 22nd, 2012I am speaking at the Jacksonville Software Architecture Group this Tuesday, April 24th on how to leverage the new Web API for building services that can be consumed on mobile devices. Microsoft's new Web API makes it very easy to develop light weight rest based web services that can be consumed on any platform.
My presentation on Tuesday will demo how to develop services very quickly using the Web API. I will also be demoing how to consume those services in an iPhone app.
The meeting starts at 6:00 PM, April 24th at building 500 on the Bank of America campus off Southside Blvd.Tags: ASP.NET,   MVC,   WebAPI,   iOS,   iPhone,   iPad   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeMarch 7th, 2012I wanted to thank everyone for coming out tonight and supporting the JaxDUG group. I just posted my presentation on using ASP.NET MVC with JQuery 1.7.1. All of my powerpoint presentations are up on this site at the fekke.com/powerpoint. The presentation I did tonight can be found at the following link.
I plan on publishing the source code up in segments when I get the time. Please let me know what you thought of the presentation if you attended tonight.Tags: ASP.NET MVC,   JQuery,   MVC3   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeMarch 2nd, 2012I am going to be giving a presentation on Wednesday on using JQuery with ASP.NET MVC 3 at the JaxDUG. JaxDUG is moving their meeting space to a different building on the LPS campus. The meetings will now be held at the Penn building in the auditorium.
The meeting starts at 6:00 PM this Wednesday, March 7th.
I am going to covering four areas in this presentation. Those areas are as follows;

Validation
Interactivity
AJAX
Widgets and UI

I am going to have lots of examples on how to use JQuery with ASP.NET MVC3\. The MVC Framework was designed with JQuery in mind. Microsoft has taken full advantage of the JQuery framework in MVC, and they are actively making additions to JQuery as part of their open source initiatives.I will post my slides after the presentation on Wednesday. I look forward to seeing you there at the meeting.Tags: ASP.NET,   ASP.NET MVC,   MVC3,   JQuery,   JAXDUG   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 27th, 2012I do not know if I will be speaking this year at SQL Saturday. SQL Saturday #130 is coming to Jacksonville, Fl on April 28th. Here is the statement from SQL Saturday.
SQLSaturday #130 is coming to you on Apr 28, 2012 at 1 UNF Drive, Building 50, Jacksonville, FL 32224.Tags: SQLSaturday,   Microsoft,   SQL Server   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeNovember 9th, 2011I was reading some of the ColdFusion blogs, and I saw that Steve Bryant had suggested about writing a post on how developers got started in ColdFusion development. I decided to write a blog post on how I got started doing ColdFusion development, and how it changed my life for the better.
I after I finished college in 1992, I got a job working for a company called Impact Publishing. I was hired initially to typeset black copy in a program called Aldus Pagemaker. That job eventually led to me to running a pre-press department for that company. Part of that job was making sure all of the Apple Macintosh computers ran properly on the network, and writing AppleScripts for automation. I also was starting to do web design using HTML.
By the end of the 90's I had moved into the IT department. While working for the technology group I heard that the company was sending group of our web developers to a three day training class on how to use ColdFusion 4.5. I convinced my boss to let me tag along with the developers since it would only cost an extra $200.00. During the class I fell in love with the language because it was built with the web in mind. I did not realize at the time, but ColdFusion is a DSL (domain specific language). Since it was based on , similar to HTML tags, the code mixed with the other tags in a very natural way.
<cfquery name="myQuery" datasource="database">SELECT username FROM tblusers WHERE clue > 0</cfquery>
<cfoutput query="myQuery">#username#</cfoutput>
I did ColdFusion development for nearly six years exclusively. As ColdFusion grew and improved with new versions, I grew and improved with the language. When ColdFusion MX/6 came out, I started using ColdFusion Components to do object oriented programming. Then when ColdFusion 7 was released, I started using the new gateway features for integration. ColdFusion led me into SQL Server development, which led me into .NET development, which led me into iOS development.
One of the nice things about the ColdFusion community is that they are pretty progressive about adopting good practices and new technologies. In a lot of ways they are more advanced than the ASP.NET community. A lot of the good practices and frameworks have been adopted in the ASP.NET community, such as the JQuery library and the ASP.NET MVC framework.
I really enjoy doing ASP.NET MVC development. It is about the closest experience I have had to doing ColdFusion developmentTags: ColdFusion,   ASP.NET MVC   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeAugust 27th, 2011I have uploaded a copy of all my presentations from my MVC 3 presentation today at the Jacksonville Code Camp.
Here are the links for from the presentation;

ASP.NET MVC site
MVC e-book
MVC Music store
Orchard Project

If you liked the presentation, or hated it, please leave comments.Tags: ASP.NET MVC,   JaxCodeCamp   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeAugust 26th, 2011The session times for tomorrow's Jacksonville Code Camp have been posted. It is still not too late to register for Jacksonville's 7th annual Code Camp.
A code camp is essentially a day of free software development training. I have been going to and presenting at the Jacksonville Code Camp for the last six years.
I am giving a presentation on ASP.NET MVC 3 and code first database prototyping. My presentation is also going to touch on the next version of MVC, and how you can start using those features today.
I look forward to seeing you there tomorrow.Tags: .NET,   JaxCodeCamp   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeAugust 21st, 2011I will be giving my presentation on ASP.NET MVC 3 and 4 at this Saturday's Jacksonville Code Camp. My presentation will cover the MVC framework, code first databases and scaffolding. MVC is getting much broader adoption in the enterprise, and it is certainly worth learning more about this framework.
The MVC team is working on version 4 of the framework that will be coming out at the beginning of next year. Part of my presentation will be on some of the new features that are coming out in this version. Some of these features include better mobile support and the web api.
I look forward to seeing you there on Saturday.Tags: ASP.NET MVC,   JaxCodeCamp   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeAugust 1st, 2011We will be releasing new versions of all of our applications for iOS 5 when it is released. All of our apps are being optimized so they will run natively on the iPad.
Currently all of applications run on the iPad, but in iPhone mode. The new versions will be able to take full advantage of the screen size of the iPad.Tags: iOS,   iPad,   iPhone   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJune 26th, 2011I just made the upgrade to from Orchard version 1.0 to Orchard 1.1 for the Fekke.com site. The upgrade was relatively easy following the instructions in the orchard documentation.
Orchard 1.1 was demoed at the MIX11 keynote a few months back. You can watch a video of the new features and modules at the following link.
I will be giving a demo of how to create and add modules to an Orchard site at the Jacksonville Code Camp this summer.Tags: orchard,   MVC,   .NET   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJune 9th, 2011The Jacksonville Code Camp site for 2011 is now open for registration. The Code Camp is a free software conference on the last Saturday of August every year. I will be presenting this year in the web track. I hope to see you all there again.
Here is the writeup from the home page;
What: All day geek fest focusing on code and not marketing fluff.
When: Saturday, August 27, 2011 All day (registration opens at 7:00am)
Where: Univeristy of North Florida - 1 UNF Drive, Jacksonville FL 32246
Cost: Free!
Sessions will range from informal "chalk talks", hands on labs, to presentations. All are welcome to attend and speak. We will have a mix of speakers ranging from MVPs, Regional Directors, Authors, and most importantly, local developers like you! Thanks to the generosity of our contributors we will be able to provide breakfast, snacks, lunch, and LOTS and LOTS of SWAG.
**Hotel Information:**Hampton Inn--Jacksonville 9A & Baymeadows
8127 Point Meadows Drive
Jacksonville, Florida, 32256‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJune 1st, 2011John McFetridge will be presenting tonight at the JaxDUG meeting. The meeting will start at 6:00 PM at the Fidelity/LPS Riverside campus in downtown Jacksonville. Here is the description of tonights meeting;
I have done a few Code Camp talks on why Silverlight is a great platform for developing business applications. This talk is a case study on the actual delivery of a such a product, IXReveal‚Äôs uReveal Pro that uses Silverlight for the delivery of a stunning UX to empower its very sophisticated advanced analytics engine. IXReveal‚Äôs unique and patented approach enables users to simultaneously fuse, manage, and analyze 100% of e-data. See a real product example of why Silverlight is such a great platform for Line of Business Apps. This will be demod on a Windows 7 Tablet, the Asus by Jeramiah Nazuruk of IxReveal.
Here are directions to our campus;
601 Riverside Ave, Jacksonville, FL 32204
Room: Building 1 (Tower) - Room G01Tags: .NET,   SilverLight,   JAXDUG   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeApril 23rd, 2011SQL Saturday 74 will be in Jacksonville, Fl next weekend on April 30th. From their website;
SQLSaturday is a training event for SQL Server professionals and those wanting to learn about SQL Server. This event will be held Apr 30 2011 at Jacksonville, FL. Admittance to this event is free, all costs are covered by donations and sponsorships. Please register soon as seating is limited, and let friends and colleages know about the event.
I will be giving a presentation on the new version of SQL Server Compact Edition 4.0 for the desktop. This presentation will show how you can use SQL Server CE for prototyping and code first development.
Tags: SQLSaturday,   SQLSaturday74,   SQLSERVERCE,   SQLSERVERCE4   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeApril 15th, 2011I just made the upgrade to from Orchard version 1.0 to Orchard 1.1 for the Fekke.com site. The upgrade was relatively easy following the instructions in the orchard documentation.
Orchard 1.1 was demoed at the MIX11 keynote this week. You can watch a video of the new features and modules at the following link.Tags: orchard,   MVC,   .NET   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeApril 11th, 2011The Orchard CMS project is now at version 1.1. There are upgrade instructions at the Orchard documentation site. Future versions of Orchard will be able to take advantage of the new import/export feature that was added to 1.1.
I am currently using version 1.0 for this site, but I plan on upgrading to version 1.1 soon.Tags: orchard,   MVC,   .NET   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeApril 7th, 2011I will be giving a presentation at the next Jaxdug meeting on March 2nd at LPS. Here is the writeup below;

Microsoft recently released new bits for Visual Studio 2010, ASP.NET MVC 3.0, SQL CE 4.0, the Razor view engine, WebMatrix, and the new NuGet package installer. They also released the Orchard CMS. This presentation will cover some of the new features that were part of this release.

The meeting will be held the Tower at the LPS campus in riverside.
View Larger MapTags: JAXDUG,   .NET,   NuGet,   MVC   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeApril 7th, 2011Phil Japikse will be giving a presentation tonight at the JAXDUG meeting at the LPS campus at 6:00 PM tonight. Here is the writeup from the JAXDUG site;
Implementing M-V-VM (Model-View-View Model) for WPF
Now you are writing WPF applications, and wondering ‚Äì what is all this code in the code behind? Shouldn‚Äôt we be doing something different? Our cousins working with ASP.NET MVC don‚Äôt even have a code behind! The answer is YES ‚Äì you should indeed be doing it differently. The M-V-VM pattern is the WPF adaptation of the Presentation Model pattern (first documented by Martin Fowler). I will show how the M-V-VM pattern is utilized for building SOLID WPF applications that are also testable.
About The Speaker
Philip Japikse | 1 Meeting
Phil Japikse has been working with .Net since the first betas, and developing software for over 20 years. Phil is a Microsoft MVP and also holds MCSD, MCDBA, CSM, and CSP certifications. Phil is an international speaker and a passionate member of the developer community, speaking at events all around the world as well as serving as the Lead Director for the Cincinnati .Net User‚Äôs Group.
Phil works as the Patterns and Practices Evangelist for Telerik (http://www.telerik.com/), is a Firefighter/Paramedic, and a volunteer for the Ski Patrol. You can follow Phil on twitter viawww.twitter.com/skimedic and read his blog atwww.skimedic.com/blog.Tags: DOT NET,   JAXDUG,   MVVM   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeFebruary 14th, 2011I recently uploaded a new Orchard module to the Orchard CMS Gallery for adding a Facebook Like widget. I also created an associated codeplex project for the widget.Tags: orchard,   Widget,   Facebook   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeFebruary 3rd, 2011I uploaded a new module to the Orchard Gallery today. The module is called Wunder Weather. It uses Wunderground's REST API to display the current weather.
You can install the the Widget by going to the admin section of your Orchard site, and clicking the Gallery > Modules menu item.

On the Module page find the WunderWeather Widget, and select the install link as pictured below.

Once the module has been installed, you will need to click on the Configuration > Features, and scroll down to the Widgets section. Then enable the WunderWeather Widget.

Now that the widget has been enabled, you can add the widget to one of your layers by clicking on the Widgets. First you will need to select a layer you want to add the widget too.

Once you have selected the layer, you will need to select the WeatherWidget.

Orchard will present you with a Widget form to fill out. Simply put in your airport location or zip code, and choose witch zone you want to display the widget.

Once you click save, browse to the layer you placed the widget, and it should look like as follows.
Tags: Widget,   orchard,   Weather,   WunderWeather   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeFebruary 1st, 2011JQuery 1.5 was released yesterday. I have not had a chance to review all of the new features, but it looks like it has all of the performance improvements like in previous releases. One of the cool new features is the .sub() function. The new Sub function actually creates a copy of the JQuery object that can be modified.
  (function(){
    var sub$ = jQuery.sub();

    sub$.fn.myCustomMethod = function(){
      return 'just for me';
    };

    sub$(document).ready(function() {
      sub$('body').myCustomMethod() // 'just for me'
    });
  })();

  typeof jQuery('body').myCustomMethod // undefined

There also many improvements to the Ajax functions. Read up on it at JQuery.com.Tags: JQuery   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 21st, 2011I am working on project now where we are creating reports and saving them to a document library in Sharepoint 3. I am automating this by using .NET code to create the subdirectories and files in the document library. I have not seen a lot of good code examples on how to do this on the internet, but this is how I am doing it in C#.
When I add a folder to the document library I used the following code;
SPSite mySite = new SPSite("http://sitename/");
SPWeb myWeb = mySite.AllWebs["mywebname"];

SPFolderCollection myFolderCollection = myWeb.GetFolder("http://sitename/sites/mywebname/PDF Reports").SubFolders;
myFolderCollection.Add("FolderName");
To add a file from a filestream, I used the following code;
FileStream stream = File.Create("report.pdf", result.Length);

SPSite mySite = new SPSite("http://sitename/");
SPWeb myWeb = mySite.AllWebs["mywebname"];

SPFileCollection destFiles = myWeb.GetFolder("http://sitename/sites/mywebname/PDF Reports/FolderName").Files;
destFiles.Add("report.pdf", stream, true);

stream.Close();‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 19th, 2011I have not had a Privacy Policy on my web site until today. I recently decided to turn on web logging for my web site, and decided to add a privacy policy.
My privacy policy can be read at the this url. I am also using P3P on this site now as well. I encourage any web developers who are not familiar with P3P to read about it at the W3C site.Tags: terms,   privacy   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 19th, 2011Scott Guthrie in his latest blog post explains one of the cool new features in ASP.NET MVC 2: Model Validation. MVC already had a way of validating that worked pretty well, but with MVC 2 has improved on this with new DataAnnotation Validation attributes.
using System;
using System.ComponentModel.DataAnnotations;

namespace fekkedotcomMVC.Models
{
    public class Person
    {        
        //Example of required attributes.        
        [Required(ErrorMessage="First Name is required")]
        public string FirstName { get; set; }

        [Required(ErrorMessage = "Last Name is required")]
        public string LastName { get; set; }

        [Required(ErrorMessage = "Email is required")]
        public string Email { get; set; }
    }
}
There are also attributes for length and regular expressions. You can also add your own by extending one of the annotation classes.Tags: ASP.NET MVC   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 19th, 2011I moved my site over to Orchard 1.0 today. If you are not familiar with Orchard, it is a new open source content management system based on ASP.NET MVC 3.0.
I used Nick Mayne's BlogML importer to bring over my old blog. I will have a post up soon on the challenges I had with my conversion.
Here is the writeup on The Orchard web site about their mission;
Orchard is a free, open source, community-focused project aimed at delivering applications and reusable components on the ASP.NET platform.
Orchard will create shared components for building ASP.NET applications and extensions, and specific applications that leverage these components to meet the needs of end-users, designers, developers, and Web professionals. Additionally, we seek to create partnerships with existing application authors to help them achieve their goals. Orchard is delivered as part of the ASP.NET Open Source Gallery under the Outercurve Foundation. It is licensed under a New BSD license, which is approved by the OSI.
The intended output of the Orchard project is three-fold:

Individual .NET-based applications that appeal to end-users, designers, developers, and Web professionals
A set of re-usable components that makes it easy to build such applications
A vibrant community to help define these applications and extensions

In the near term, the Orchard project is focused on delivering a .NET-based CMS application that will allow users to rapidly create content-driven Websites, and an extensibility framework that will allow developers and customizers to provide additional functionality through module extensions and themes.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I finished creating my presentation on XML yesterday. One of the things that became obvious was that there is a lot more than an hours worth of content on XML.
Even with all of the XML features in ColdFusion, there are still some shortcomings in the way that ColdFusion handles XML. One of the key parts of the presentation will be StAX, the new Java API for dealing with XML. One of the key features of StAX is that it uses a pull parser when dealing with large XML files.
One of the issues I have run into with using large XML files in ColdFusion is you have to load the whole file into memory in order for the DOM parser to work.
Using a stream based parser is much more effecient when dealing with large XML files because it does not have to load the whole file into memory.
I am plugging the JaxFusion meeting this Tuesday for the JaxFusion user group because this will be covered at the meeting.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011This article has already been posted on DIGG, but I thought I would blog about this since we just discussed this at the JaxFusion user group meeting last night.
Ajax can solve and add security problems to your web app. This article goes over some of the different security problems that can arise from using Ajax.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I live in Jacksonville, and AOL has a large Call Center down the street from my home. Well AOL lost 875,000 subscribers last quarter, so they are closing that call center. I was once an AOL user back in the day, but I got an actual internet ISP account in 1994. So I have not used AOL in 12 years. I remember when they were a Mac only service as well.
I certainly feel bad for the employees who lost their jobs today, but I think the writting has been on the wall for AOL for a long time.
They had an extremely nice facilty here in Jax. AOL is having Job fairs to try to place the 1200 workers who lost their jobs today.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Last week I posted qustion if anyone knows what K.I.S.S. stood for? This weeks question is what does R.T.F.M. stand for? R.T.F.M. stands for Read the *%$#@& manual. I forgot what the middle word was, but please do post any profanity to my comments section.
I have a project that I have been working on that provides a standard interface into one of my companies applications. We created a document that provides information about the methods and parameters that are exposed through our SOAP web services.
For the last month I have been answering questions that could be found in our API document. I hope I do not seem anti-social, but I am spending half of my week answering questions that could be answered by reading the manual.
Yesterday I wrote an example of how our software could be used by writing an example in C#. I am not paid or trained to write C#, but I found myself doing it to show the developers how to do it.
R.T.F.M. Please!‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I will be giving a presentation at May's JAXDUG meeting on the ASP .NET MVC framework. The MVC framework is modern web application framework for .NET that shares many popular features with other popular frameworks such as Ruby on Rails, DJango, Grails and ColdBox.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Microsoft has released a preview of the next version of ASP.NET MVC, version 3.0. This new release includes the following new feature;

View improvements
New View Engines (Spark, Razor, NHaml)
Global Filters for cross-cutting
New action types like HttpNotFound
Javascript and Ajax improvements
Model validation improvements
Dependency Injection improvements

Check out Scott Guthrie's blog entry on this release.Tags: Unity   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I was reading Scott Guthrie's blog post about the just released ASP.NET MVC 3 Beta. So I decided to download the bits, and get MVC running on my Windows XP box only to find out that it will not run due to a dependency on the ASP.NET Web Pages. MVC 3 preview did run on Windows XP.
I know Microsoft no longer wants to support OSs older than Vista, but unfortuneatly the version of an OS that a developer uses is determined by their IT department. I spoke to a Microsoft Developer evangelist about not supporting Windows XP for upcoming developer tools, and he told me I should take that up with my IT department.
Many large companies skipped Windows Vista, opting to continue to use XP. Even though Windows 7 has been more widely accepted, it has been out for less than a year. Many companies will not deploy a new version of Windows until Service Pack 1 has been released. This has left many developers in a black hole, where they cannot upgrade their tools due to policies set by their companies.Tags: Visual-Studio   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I am giving a presentation tonight on the ASP.NET MVC web application framework at the Jaxdug. If you have not come out to a Jaxdug meeting before, you should. They do a good job of covering new development technology.
I will post the slides up on this website tonight after the presentation.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I added my ASP.NET MVC presentation to my presentations page on Fekke.com. I have not posted my code from the presentation on my site yet, but you download samples from asp.net/mvc.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Sayed Hashimi is presenting on view helper methods tomorrow at the Jacksonville Developers User Group. The meetings are held at building 500 at the Bank of America Campus.
Sayed currently is an engineer at LPS, and the author of several books on MSBuild. The meetings start at 6:00 PM.Tags: NET   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I read in DSL Reports that AT&T is launching U-Verse in Jacksonville.
The AT&T U-Verse website has a form that will allow you to check and see if their service is available in your neighborhood. As usual, this broadband service is not in my neighborhood.
U-Verse is AT&T's Fiber to the Curb or Fiber to the Premises service.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Yes, I listen to podcasts. I was listening to Diggnation this weekend, the companion podcast for the Digg.com web site. For those not familiar with this site, it was started by Kevin Rose of Tech TV fame as a way for users to vote for which stories get promoted to the front page of the site. On this weeks episode, Kevin mentioned that the sponsor of the show this week was Adobe Apollo. He even went into the detail of how Apollo uses web technologies to create cross platform desktop applications.
Kevin also mentioned that Digg was looking into using Apollo for future applications.
I think it is great that Adobe is using this type of marketing because it directly targets the audience they need to reach which is technophiles.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Adobe released Air today, the Rich Internet Application runtime that lets run web application technology on the desktop.
I have written some flex apps that I am planning to release as Air apps. Adobe has lowered the price for Flex Builder to $249. You can upgrade for as low $99 if you have a license for Flex Builder 2.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Tomorrow marks the end of an era, and the beginning of a new one. Adobe and Macromedia officially merge tomorrow. As a ColdFusion developer, this will be my second one.
I remember different developers I knew freaking out about Macromedia buying Allaire. In the end, ColdFusion propably would not have survived if Macromedia had not bought Allaire. There have been three whole versions released since that merger.
I look forward to see what Adobe does with Macromedia's server products.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011It is official. Adobe has shipped ColdFusion 8. I am really exciting about this release. The next JaxFusion meeting will be going over some of the new features in ColdFusion 8.
I am still trying to secure a room for the next JaxFusion meeting. I hope to have another update shortly this week.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Adobe has been up to trouble for the last three days. They have launched a new developer site, new updates to the AIR and Flex 3 betas.
I hope to have several presentations coming out based on these technologies future JaxFusion meetings.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Adobe announced that they are going to be open sourcing the code for the Flash avm2 to the Mozilla. Avm2 is the compiler used in Flash 9 for running ActionScript 3. AS3 is based on the ECMAScript 4, and is the same as what the next version of JavaScript.
Avm2 is extremely fast because it is very similar to how the Java VM and the .NET CLR work. Right now in most browsers JavaScript is interpreted. When Mozilla switches over to the avm2 compiler, their browser will be able to take advantage of this technology for executing JavaScript code on the page.
With more and more web sites using advanced JavaScript for things like AJAX applications, this will a positive impact on the overall performace of these applications.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I have been at the managers conference in San Jose this week that Adobe holds for user group managers. This is the first managers conference I have been to in about four years.
If you have ever thought about becoming a user group manager, I highly suggest becoming one. Macromedia, now Adobe, requires that managers sign a NDA. The managers do get to learn about technology that Adobe has not made available to the general public.
This week Adobe has given us presentations from Kevin Lynch, Ben Forta and Mike Downey. Some of the presentations have covered existing versions of products that Adobe is working on, but they have also covered Apollo.
Adobe has published an F.A.Q.  on Apollo. You will see a lot on this from Adobe over the next months. They plan on doing a big presentation on Apollo at MAX this year. If you are going to be at MAX, you defineatly want to check it out.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Adobe and Macromedia websites have had some outages recently. I have been trying to get to MXNA all morning, and I have been presented with a ColdFusion error. From what I hear, they will have their web infastructure merged within the next few weeks. I guess I will have to be patient.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011The aerospace system in this county is not getting any better, it is getting worse. I am currently waiting on standby for another flight, because the connection was too late to the airport. And it does not look like I will get on this flight either.
It has become almost impossible to fly across the country from regoinal airports, like the one in my current home city of Jacksonville.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Apple showed off a new laptop today called the MacBook Pro. All I can say is I want one. It is four times faster than the current PowerBook, and features a dual core intel processor.
It will not ship for another six to eight weeks, but Apple is taking orders today. I wish Apple had done this two years ago when I bought my last laptop.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I have been playing around with BlueDragon.NET with one of the older applications I have that uses Web Services. If you have not looked at the Amazon Web Service, you really should because it is a good example of how Web Services should work.
Unlike the Google web Services, you only pass one parameter into the web method, and only one parameter is passed back. Both are actually simple SOAP objects that are defined in the WSDL file. The chief difference I am finding with ColdFusion MX and Blue Dragon is that ColdFusion treats the object returned as a Java Object, and BD treats the object as a series of structures and arrays. Here is an example of some test code I wrote. Try running it in both ColdFusion and BD, and see the results.
"attributes.pagenumber" default="1" />  
 "devtag" default="DYXI4669H65EH" />  
 "tag" default="davidfekkeshomep" />  
 "sims" default="false" />  

aDirectorRequest=StructNew();
aDirectorRequest.keyword = "Forta";
aDirectorRequest.page = 1;
aDirectorRequest.mode = "books";
aDirectorRequest.tag = tag;
aDirectorRequest.type = "lite";
aDirectorRequest.devtag = devtag;
aDirectorRequest.locale = 'US';

<cfinvoke
webservice="http://soap.amazon.com/schemas3/AmazonWebServices.wsdl"
method="KeywordSearchRequest"
returnvariable="aProductInfo">
<cfinvokeargument name="KeywordSearchRequest" value="#aDirectorRequest#"/>

<cfdump var="#aProductInfo#" />‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Saw this article on Digg today. This Wired article talks about how Apple is adding a new Animation API to Leopard (Mac OS X 10.5). The important part of this article is that animation is starting to become a more important of the user experience. You can start to see this in the way Ajax and Flash are being used in web sites now. With Ajax and Flash coming to the desktop with Apollo, I think Apple and Microsoft are trying to differentiate themselves.
Of course Leopard has been delayed until this Fall. Microsoft just released an alpha of Silverlight, but I think we will start seeing more applications with these types of user interfaces.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011We are happy to announce the newest version of iDogYears. This is a simple program that converts dog years into human years. It uses the canines actual weight plus the actual age to determine the age. You can install this app by going to this link at the iTunes App store.Tags: COCOA   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011We are pleased to announce version 1.0.1 of iLottoNumber. This program randomly picks a number from the starting value to the end value. It is written as way for groups to quickly pick a number for giveaways at meetings. This is the Ad supported version of this application. You can download this app by going to the following link.Tags: Apple   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011A couple of little hangups when I tried to install ColdFusion MX 7.0.1 on my Mac. I set it up for Apache. I embarrased to say that I have never used Jrun or ColdFusion with Apache on Mac OS X. I always use the built in web server that comes with CF, but I wanted to use Apache this time.
When installing ColdFusion, the installer will ask where the web root for your web server is located. It needs this to know where to install the cfide directory. On Mac OS X 10.4 the web root is located in /Library/Webserver/Documents/ folder. You can also install it in the sites folder in the User directory for your user.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Adobe has put a pre-release version of Apollo on Adobe Labs. The Labs page for the pre-release has links for the runtime and the Apollo SDK. Apollo is the codename for Adobe's new cross platform runtime that lets developers use web technologies (i.e. html, Flash, Flex) to build cross platform desktop applications.
I hope to put some sample apps that I have been working on up on my site soon.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011This did not get a lot of attention yesterday, but Apple changed their name from Apple Computer, Inc. to Apple, Inc. Having worked at a Company that has changed their name, this can be a pretty big deal. For Apple it is not a total re-branding, but it reflects what they are doing now, consumer electronics.
That being said, when Apple introduced the iPod, they may not of counted on most of their money coming from iPod sales within five years.
The Apple iPhone and Apple TV are both products geared for consumer market. Microsoft is also headed in this direction as well with the XBox 360 and the Zune.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011With Apple's announcements yesterday of the new iPhone, I did not hear anything about Flash. Mr. Jobs did say that the iPhone uses a version of Mac OS X. I do not know how similar this is to the desktop version of Mac OS X, but I am curious if it will use Flash or Flash Lite.
I have been building some Flex based applications lately, and it would be nice if there was a way to run these applications on the iPhone.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Yet another open source site!. Apple announced to developers that they have created a site called macosforge.org. The site contains the source to their iCal server, Darwin streaming server, Bonjour as well as to their WebKit.
Here is some text from their site: "Mac OS Forge is dedicated to supporting the developer community surrounding open source components specific to Mac OS X. Here you will find resources for working with the source code to popular Apple-original projects, as well as third party projects that are closely related to the Macintosh operating system."‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011One of the features I like most about ColdFusion 8 is the cfdbinfo tag. The cfdbinfo tag allows developers to view database meta information such as tables, columns and data types. Another nice thing about the cfdbinfo tag is that it will work with most RDBMS servers.
Each database server, whether it is Oracle, MySql or MS SQL Server, all have different ways of getting this meta information. CFDBINFO gives ColdFusion developers a nice level of abstraction from these different ways of accessing meta information. I am currently trying to document all of the stored procedures I wrote for a project I just finished. I decided I wanted to try to automate this task, so I wrote ColdFusion script to list my stored procedures. The following code shows how you can use the cfdbinfo tag to list all of your stored procedures.
This may be enough information for some users, but I also wanted to display all of the input and output parameters as well as the code in the procedure as well.
I work with SQL Server 2005 as my primary database engine. All of the database meta information can be accessed through system views known as INFORMATION_SCHEMAs. There are two views that I used to get the information about my procedures that I wanted. They are the INFORMATION_SCHEMA.ROUTINES and INFORMATION_SCHEMA.PARAMETERS views.
I used the following query to get the meta information that I needed for my documentation;

SELECT r.SPECIFIC_SCHEMA, r.SPECIFIC_NAME, r.ROUTINE_DEFINITION,

p.ORDINAL_POSITION, p.PARAMETER_MODE, p.PARAMETER_NAME, p.DATA_TYPE

FROM INFORMATION_SCHEMA.ROUTINES r

JOIN INFORMATION_SCHEMA.PARAMETERS p

ON r.SPECIFIC_SCHEMA = p.SPECIFIC_SCHEMA

AND r.SPECIFIC_NAME = p.SPECIFIC_NAME

WHERE r.ROUTINE_TYPE = 'PROCEDURE'

ORDER BY r.SPECIFIC_SCHEMA, r.SPECIFIC_NAME, p.ORDINAL_POSITION

I then used the following code to display the stored procedures in my database;

## #SPECIFIC_SCHEMA#.#SPECIFIC_NAME#

The parameters and data types for the #SPECIFIC_SCHEMA#.#SPECIFIC_NAME# procedure are as follows;

4.  #PARAMETER_MODE#, #PARAMETER_NAME#, #DATA_TYPE#

Here is the transact-sql for the #SPECIFIC_SCHEMA#.#SPECIFIC_NAME# procedure.

<div class="solid"><pre>#ROUTINE_DEFINITION#</pre>  

</div>‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011About five months back I started working as consultant for a company called Idea Integration based here in Jacksonville. I have been doing SQL Server consulting since I arrived. The group I work in specializes in Microsoft technologies, including SQL Server, ASP .NET, BizTalk and Sharepoint. We also do consulting in legacy systems, network infrastructure and Java.
I just finished up a project, and I am available for consulting work. If you would like to contact me for consulting work, you can reach me be going to this link.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Ben Forta has a post on his blog asking for anyone interested in beta testing ColdFusion 8.
I participated in the ColdFusion 7 beta. It is a great opportunity to look at the new features and help find bugs before the product is released to the masses. I highly recommend becoming a ColdFusion beta tester.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I got the following message from the manager of the Tampa Adobe User Group;
[code:c#]
The second meeting of the Tampa Flash, Flex and AIR Developers Group
will be held on Wednesday, March 4th, 2009 at 6pm in the Atrium of
the Art Institutes of Tampa. The Art Institutes of Tampa is located
at 4401 N. Himes Avenue, Tampa, Florida.
Event Details: http://www.tffadg.com/blog/?p=31
Google Map: http://tinyurl.com/aitampamap
From Greg Wilson, Adobe Evangelist:
Speakers:
I am happy to announce that Ben Forta, Director of Platform
Evangelism (and my boss!) will be speaking at this event. Anyone
that has traveled with Ben quickly discovers that he is practically a
celebrity, especially in the ColdFusion world... so... we've also invited
the local Tampa ColdFusion User Group to join us!
Also joining us will be Kevin Hoyt, Adobe technical evangelist
extraordinaire. Kevin is a very frequent speaker on multiple topics
including AJAX, Flex, AIR and many other topics. You're guaranteed
to see something cool from Kevin.
Between the three of us, we plan to cover a lot of topics, including
the following:
Flash 10 - what's new, what's cool
ColdFusion Future Sneak Peek
Flex 3.2
Flex 4 preview
Catalyst (formerly Thermo) preview
AIR 1.5
Connecting your Flex/AIR applications to the backend
LiveCycle Data Services
BlazeDS
BlazeDS and Spring Integration
Much much more
We plan to start promptly at 6pm, so be there! There is no cost to
attend, but an RSVP is requested to rsvp@tffadg.com. For more
information, please visit www.tffadg.com.
[/code]>‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I received the following message from Brian LeGros;
Hello everyone,
The Adobe Developers of Greater Orlando (Adogo) user group has been selected as a stop on Adobe's Flex 3 Pre-release Tour. We're fortunate enough to have Ben Forta, Adobe's Senior Technical Evangelist, speaking to the group for this leg of the tour. The meeting will be held on January 21st, 2008 @ 7:00 PM in the Oleander Room at Westgate Lakes Resort and Spa (located at 10000 Turkey Lake Road, Orlando , FL 32819, parking at The Smokehouse). We'll be giving away a copy of Flex 3 and CS3 Web Premium, a pass to CFUnited 2008, as well as lots of branded schwag from Adobe and CFUnited. Food and drink will be provided to all in attendance while it lasts. Registration for this event is available at http://adogo200801.eventbrite.com/. Additionally, more information can also be found on our website at http://adogo.us.
Since this will be the only stop on the tour in the state, we would like to extend an invitation to all of the Adobe User Groups in Florida to join us for our meeting. We are attempting to promote this event as much as possible, but our channels outside of the Orlando area are somewhat limited. If anyone is open to helping, we are definitely grateful for any cross promotions you and your groups can provide for this event.
I apologize if this email has reached you in error; I took these emails addresses from your user group's websites as well as the contact information from Adobe. If there are any questions we can answer for you, please don't hesitate to contact myself, Adam, or Max (see CC). Thanks for your time and we hope to see you all at the meeting.
-Brian LeGros‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Ben Forta has responded to the Mary Brandel piece on ColdFusion being dead.
In his response, he mentions that Computerworld has refused to hear from Adobe or listen to their side. All in all, sounds like Shoddy journalism from Computerworld. ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I am watching Ben Forta's keynote, and it if very heavy on Flex. Adobe annouced today the availablity of CFMX 7.0.2 nad Flex 2 today. Flex Builder 2 is selling for $499, and they have a free version Flex Data Services.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I was not able to attend Ben Forta's keynote or CFUnited this year. Part of the keynote this morning was on the new features in ColdFusion 8, but they also went over performance gains in ColdFusion 8.
Ben Forta has posted numbers on his blog. Looks like the performance increases will be worth the price upgrade alone.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I volunteer my time to maintain the website for my rowing club. I would list the domain for the site, but the site is down right now. I am in the process of trying to have the domain transfered.
The hosting business uses a Linux server with LAMP installed to host all of their websites. When I first took over the club site, I was actually encouraged by the fact that they had options for PHP and MySQL. On Wednesday, I received an email from the hosting company that the club was past due by a month on the site, and that we owed them $115.00 for the year. The main problem with this is that they have never ever charged for the site before. The club is a non-profit organization, and can not afford to pay the hosting fee.
So I sent them an email after the invoice, and told them to transfer the domain to me, and I would find another host.
I never heard back.
Then on Friday afternoon I decided to check the email for the site, and I could not authenticate with the IMAP server. So I decided to check the site, and was presented with a "PAST DUE! login here, and pay us" screen.
At this point, I decided to call the hosting company. I was not able to reach the nice person who turned the site off, but I did get a lower level employee. That employee told me that an automated bot had turned the site off. He also informed me that they did not have an Linux administrator to manage the site, and that they were having service issues related to that fact.
To compound matters, the administrative contact for the site is a board member of the club, but the hosting company listed their email address as the contact information for the administrative contact. So the entire process of transfering the domain has to go through a company that thinks we owe them money.
So by the end of the day Friday, they finally responded to the first request from my registrar to begin the process of transfering the domain to my account. Since the site is a .org, it requires an authorization code from the original registrar. It was too late on Friday to get that code from original registrar, so the site has been down all weekend, an well into today.
When the club set up the web site originally, they did not realize the importance of owning the domain name. In the mean time, the site has been down for four days.
The moral of the story is to make sure you own the domain name. You can check and make sure the domain contact information is correct in the whois database.
In the mean time, I have the code loaded to the new site. I am planning on using Raymond Camden's BlogCFC for the site blog. I am hosting the new site at www.pridedata.com, and they offer ColdFusion MX and PHP support.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I purchased the Flex Builder upgrade today from the Adobe Online Store. When I went to find the serial number for my download, I was presented by a 'Contact Customer Service'.
So I contacted Adobe's Customer Service, and they said it would take 24 hours to provide me with a serial number. You may not want to purchase this from Adobe until this gets worked out in their online store.
Update
According to Matt Chotin, all of the serial number issues have been resolved with the online store, so it should be safe to buy online.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I was watching some of the interview with Steve Jobs and Bill Gates interview yesterday from the D5 conference. Bill and Steve got a question if Mac OS X and Windows applications are dinosaurs compared to new browser based applications.
Steve Jobs made a point that he thought there is room for these applications that are made to run on the desktop, but can use Internet base services. He gave an example of a Google Maps application that runs on the iPhone. He said it works better than any browser based application. They showed vision about the idea that there is room for hybrid rich client applications that use web services.
At the same time Google has released a browser plugin called 'Gears'. Gears is still in pre-release, but it has a local server, a database and messaging components. This allows developers to write disconnected applications. It is my understanding that some of these components are being included in Adobe Apollo. The database component is based on SQLite, which is the same engine used by Mac OS X for searching. It is an extremely lite weight database engine, and can be accessed with JavaScript.

resultSet = db.execute (

'INSERT INTO MYTABLE VALUES (?, ?, ?) WHERE id=?',

[1, 2, 'three four', 5]

);

Apollo, Silverlight and Gears all important parts of building these types of applications that use Internet based web services.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I was lucky enough to get a BlackBerry for XMas this year. It is a 7100, and is part of a plan with Cingular. I have had a Nokia 3650 for the last three years. My first complaint is the BB did not come with a camera. I have made good use of my camera in my Nokia.
I was able to sync all of my old contacts over to the BlackBerry, but it seems to chock on the calendar for some reason.
I am excited by the email features, and I will have playing with the other features.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Good news. I fixed the SES problem with my comments. I have sacked my QA department. Please do not feel bad for them. They now work as Windows Vista QA testers.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Ray Camden just released version 5 of his BlogCFC blog software. Ray had some new contributors this time around, and one of them is a co-worker of mine, Charlie Griefer.
I just wanted say thank you to all of the BlogCFC contributors. I use this software for my blog, and I will be upgrading my site to this version ASAP.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I have never been on a flight with WiFi before. I am currently at 34000 feet over Kansas flying at 457 miles per hour. I think I paid around $10 for the access.
I have heard that this was coming, but this is my first flight with WiFi. 6n this Delta flight, they use a service called GoGoInflight.Tags: Airlines   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011The folks over at New Atlanta hae released a beta of the next version of their Blue Dragon server. You can download it by going to the page. Blue Dragon is a CFML server that works in Java and .NET.
Vince Bonfanti demoed one of the new features at CFUnited this year. The feature was the inclusion of a CFThread tag and a CFJoin tag for doing multi-threaded processing.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I have recently started evaluating BlueDragon.NET from New Atlanta. I heard that MySpaces will be switching to BlueDragon.NET soon, and I was curious to see if I can leverage .NET and ADO.NET with my CFML code.
My first impressions so far have been mixed. I have used the Java version of BlueDragon before, but this is my first attempt with the .NET version. Before you can install, please use this check list to make sure you have the following running on your development box;


A PC with Windows 2000 or XP Pro


IIS installed and running


.NET installed, either 1.1 or 2.0


The ASP.NET configured to run with IIS


The J# language pack addon for .NET


The BlueDragon.NET installer


If you need to run Multiple versions of ColdFusion, then I would suggest reading Charlie Arehart has written an article in the CFDJ on how to run multiple versions of CF and BD on the same box. New Atlanta has a copy of the article on their website.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I just finished reading iWoz, Steve "Woz" Wozniak's autobiography. The book was co-written by Gina Smith, but is written in the first person.
I have been a fan of a lot of the work that Steve and Apple did in the early 70's and 80's. I owned, or I should say that my parents owned an Apple II. Steve designed the Apple II, according to the book, all by himself. He says he wanted to set the record about a lot of misconceptions about him and Apple. He designed the Apple I and the Apple II by himself. Steve Jobs did not design the Apple computers. He says that he never quit working at Apple. He still is an employee for Apple to this day.
The first half of the book covers what he did as an engineer before he and Jobs started Apple. He talks a lot about his parents and the influence they had on him as a child, teaching him about electronics, ethics and education. His father was an engineer, and his mother was a teacher.
I don't want to talk about too much of what is in the book, because I think everyone should read the book. With that said, I think one of the interesting things about the book is the lack of a forward. Steve Jobs was supposed to write the forward, but backed out right before the book was published. After reading the book, I can understand why he didn't. The book does not make Jobs look very good.
In the book Woz says that Steve screwed him out of several thousand dollars on the hardware design he did for breakout at Atari. He says that he did not mind because he wound up making millions on Apple. Later on in the book, he talks about the remote control he designed at Cloud Nine. Frog design did the case design, which was the same company that did designs for Apple at the time. Woz was told that Jobs saw the remote control, and threw it against the wall, and put it in a box, and told Frog to send that design to Woz.
One of the things I found interesting was that Woz created the BASIC interpreter for the Apple I and the Apple II. He knew that Bill Gates had done the BASIC for the Altair, and he wanted to do a BASIC. My understanding was that Bill Gates copied the basic he used from DEC, and made it work on the Altair with help from Paul Allen and another engineer. Woz did it all by himself. I learned how to program using that BASIC interpreter in the Apple II.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011When Apple first announced the MacBook Pro earlier this year, I thought about ordering one then, but decided against buying one for several reasons. One is that I just bought a PowerMac last year before the announcement. Another reason is I use my current laptop for my DBA work, and SQL Server is my primary database. A couple of weeks ago someone came out with a way to dual boot a Mac with Windows. Then yesterday Apple announced the beta of Boot Camp which essentially does the same thing.
This is all good news, but What I really need to be able to do is use the Mac OS for my development, and run my SQL code on Windows at the same time on the same machine. Ideally having an Windows image on a Mac so I can have Windows sandboxed as much as possible.
Today Parellels announced the beta of Parallels Workstation 2.1. I am going to try to scrape together funds now to buy one of the MacBook Pros. This is what I have been waiting for. Now I just need to find someone to buy my old PowerPC based Macs.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I saw this error in the CF_talk list yesterday. I have had this error in ColdFusion before. As far as I can tell this happens when there is a lot of repetitive code in your CFCs.
I was using a meta code generator to create CFCs for a gateway I was writting. There were SQL tables with over 100 columns and structures with over 100 keys. Since ColdFusion MX came out, ColdFusion actually compiles your .cfc and .cfm files into java bytecode. When my CFCs were being executed for the first time, ColdFusion would get this error on the compile.
I was able to fix this by breaking my CFC apart into smaller pieces using the cfinclude tag. Once I broke the code into included sections, ColdFusion was able to compile these files without a problem.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I read on Brian Knight's blog about a new tool that converts DTS packages to SSIS packages on SQL Server 2005. Brian says that the built in migration wizard that comes with SQL Server 2005 is only 40% successful, and that it does not follow the best practices for building SSIS packages.
The tool is called DTS xChange, and is a couple of weeks away from release.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I was reading Jen deHaan's blog about the second day keynote. I was happy to read about Adobe CEO Bruce Chizen's comments.
Adobe wants to leverage the Macromedia relationship with developers, and enhance the great work that has already gone on. And not mess it up.
I found this encouraging to hear. It is clear to me now that it wasn't just the Flash that Adobe wanted, they wanted Macromedia's developer community. 
Apollo is a technology that shows a broad vision. I feel that Adobe will be able to do what Apple, Sun and Microsoft have not been able to do, which is build a desktop environment that will be trully cross platform.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011One of the mistakes I have seen developers make is not using bulk transaformations in SQL. It does not matter if you use MS SQL Server, Oracle, DB2 or MySQL, all of the RDBMS's provide developers a way to perform bulk transformations of data.
One of the powerful things about SQL is that you can update or insert thousands or millions of records with one SQl Statement. Here is a simple example. Lets say I have a thousand records in a table that have a bit column to determine if a record is active. I can set every record of that table to inactive with two lines of SQL.
UPDATE myTable  
SET Active = 0;
GO

If I only want to set records in my table that have a certain value in another column to inactive, I can do that as well with a few lines of SQL.
UPDATE myTable  
SET active = 0
WHERE State = 'CA';
GO

If I need to populate all of the records of one table from another table, I can do that with one SQL statement as well;
INSERT INTO myTable (firstName, Lastname, addressLine, City, State, Zip)  
SELECT fName, lName, Address1, City, StateProvince, ZipCode
FROM impTempTable;
GO
‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I just read on Ryan Stewarts blog that Adobe's CEO Bruce Chizen is stepping down as CEO. I always liked the cut of Bruce's jib.
I think his tenure will be most remembered for the merger between Adobe and Macromedia. I think the merger was a win win for developers and Adobe and Macromedia. Bruce also managed not to be kidnaped while CEO.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Here is a list of CDs infected with the Sony-BMG RootKit. Trey Anastasio, Shine (Columbia)
Celine Dion, On ne Change Pas (Epic)
Neil Diamond, 12 Songs (Columbia)
Our Lady Peace, Healthy in Paranoid Times (Columbia)
Chris Botti, To Love Again (Columbia)
Van Zant, Get Right with the Man (Columbia)
Switchfoot, Nothing is Sound (Columbia)
The Coral, The Invisible Invasion (Columbia)
Acceptance, Phantoms (Columbia)
Susie Suh, Susie Suh (Epic)
Amerie, Touch (Columbia)
Life of Agony, Broken Valley (Epic)
Horace Silver Quintet, Silver's Blue (Epic Legacy)
Gerry Mulligan, Jeru (Columbia Legacy)
Dexter Gordon, Manhattan Symphonie (Columbia Legacy)
The Bad Plus, Suspicious Activity (Columbia)
The Dead 60s, The Dead 60s (Epic)
Dion, The Essential Dion (Columbia Legacy)
Natasha Bedingfield, Unwritten (Epic)
Ricky Martin, Life (Columbia)
The EFF has an  about the problem with the copy protection.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Ben Forta, Raymond Camden and Charlie Arehart have released the first volume of the WACK for ColdFusion 9. According to Ben Forta's blog, they waited to release the book until ColdFusion Builder was released.
I do not do much ColdFusion programming anymore, but these books are the defacto standard books for ColdFusion programming. Sometimes referred to as the "Forta" books, they are a must have if you use ColdFusion.Tags: ColdFusion   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I try to write as little code as I can get away with. Because of this, I make functions calls like this in my cfoutput tags.
  
#myObj.getString()#

This is a lot easier to write than the following;
  

#myString#

The problem I ran into is I was putting quotes around my function call, and it was adding a space inbetween the quotes and the beginning of the string.
  
"#myString#"

" Actual String value"
What happens is if the function does not have output="no" it defaults to true. So just like in a regular cfm page, the white space is added to the function. If you set the output="no", no white space will appear. The result will look like this;
"Actual String value"‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I was saddened when I heard that the CFWeekly podcast was being retired. I thought Matt and Pete did an excellent job with that podcast. One of my favorite podcasts was when they had a round table of different CF developers. One of those developers was Brian Meloche.
Brian is now hosting a new podcast called CF Conversations. The first podcast has a round table with Rick Mason, Adam Haskell, Jeff Coughlin and Aaron West. I listened it this morning, and I really like the format. Keep up the good work Brian.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I have finished up some projects recently developing C# windows form based applications. When .NET was first released in beta, I took a look at it and joined a C# User Group, but I never developed any applications. About that same time, Macromedia released a beta of ColdFusion MX with these new things called components. I looked at the syntax and observed that they were really class based objects. That was enough to keep me busy for the next couple of years.
My next job was working at a company that needed to rearchitect a web application where the business logic needed to be reused throughout several front ends web sites. They were looking at using Custom Tags. I evangilized using CFCs instead because that seemed to be a much better way to implement backend reuse. They also worked better as a BlackBox. Custom Tags can arbitralily pull values from any scope and place values back into those scopes or the caller scope. Custom Tags do not offer true encapsulation.
I have had a lot of religous arguments with other developers about whether ColdFusion is truly Object Oriented language now. It is true that CFCs do not offer method overloading and a true way of implementing interfaces, but you can still do most of what you would be able to do with Java or other Object Oriented languages.
The end result was I learned a lot about writing Object Oriented code and Object Oriented design patterns.
When I started writing these new programs in C# I had not looked at the language or .NET in about three years. I was able to write these programs with little or no effort mainly to do with the fact that I was familiar with the concepts of Object Oriented development from working with CFCs.
My biggest learning curve came from learning the .NET API. I had some experience working with ADO from ASP 3.0. Microsoft has made some nice enhancements to ADO for .NET 2.0.
I am usually the first person to criticize Microsoft, but they have some very nice development tools and a very nice framework now. I am still not sold on ASP.NET.
At my current job we use a lot of different tools including a hardware router for integrations. I am a firm believer in using the right tool for the right job. Dot NET will make a nice complement to the tools that we already use.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011CNBC must have good sources because they are reporting that Apple is coming out with an iPhone next year. They are also reporting that Apple has another iPhone in the works that will come out the first generation phone.
Once again, I am screwed because I just bought a new phone. It is an LG CU500. The coolest thing about it is that it supports 3G networks. According to my provider, it offers faster internet access than the wireless PC card they provide.
I think I will wait to get an iPhone until after the second generation phone comes out.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Microsoft released a free IDE to build .NET applications when they released .NET 2.0 a while back. I have been using it to rewrite some utilities at work. I have to say I am pretty impressed so far. The IDE does not offer all of the features that the full Visual Studio 2005 does, but it still has a lot of power.
It will work with SQL Server express edition and it has a feature for connecting to web services.
Apple already offers a free IDE, and there are several in the Java world. This is a first for Microsoft, and I think ther will be a lot of new .NET application written because they released this IDE. Kudos to Microsoft.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I have been developing almost exclusively in C# .net for about a year now. In that time, I have wished for some of the language functionality in ColdFusion to find its way into C#. I have been using Visual Studio 2008 since it came out, and I found a project that is used to test Linq called ObjectDumper. It compiles a class called ObjectDumper that can be used for dumping the value of just about any object into a command line. Here is some sample syntax;
using System; 
using System.Collections.Generic;  
using System.Linq;   
using System.Text; 

namespace DumperTest { 

	class Program 
	{ 
		static void Main(string[] args) 
		{ 
			var myObject = new[]  
			{ 
				new { Name = "Chris Smith", 
				PhoneNumbers = new[] { "206-555-0101", "425-882-8080" } 
				}, 
					new { Name = "Bob Harris", 
					PhoneNumbers = new[] { "650-555-0199" } 
				}	 
			}; 
			var myPets = new[] 
			{ 
				new { name = "Spike", number=9 }, 
				new { name = "Snoopy", number=7 } 
			}; 
				ObjectDumper.Write(myObject); 
				ObjectDumper.Write(myPets); 
			} 
		} 
	} 
}‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Adobe started shipping Creative Suite 3 today. This is the first version that supports Intel based Macintosh systems. So all of the people who have been whining that Photoshop had to run in emulation on Intel Macs can stop now.
I have not purchased a Intel Mac, but I have no excuses now to not purchase one.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I went to Embry-Riddle Aeronautical University from 1988 to 1992. While there I had the opportunity to meet Carlos Costa. Carlos was in the same program I was in which is the Aeronautical Science program where students learn how to become professional pilots.
Carlos went on to fly with Brothers to the Rescue. Brothers to the Rescue flew over the Florida straights in Cessna Skymasters between Florida and Cuban airspace looking for Cuban refugees trying to escape from Cuba. On February 24th, 1996 the Cuban government sent Migs to shoot down Brothers to the Rescue. Carlos and another Embry-Riddle student, Mario De La Pe√±a, where killed while flying in international airspace.
A documentary film has been made about them called "The Shoot Down". The movie opened this weekend in select theaters. It is playing in Miami and Tampa, but not in Jacksonville where I live.
I did not know Carlos well, but I used to see him all the time at the flight line at Embry-Riddle. I did not meet Mario while he went to Embry-Riddle. I look forward to seeing this movie when it either comes to a theater near me or it comes out on DVD.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Next week I start training on the Cast Iron Application Router. This is a hardware device designed for streamlining enterprise application integrations. It can connect to applications through a range of methods including smtp, http, ftp, SOAP and MQ Series.
It uses a graphically based studio to design integrations between amplications. It is very similiar to DTS Packages and SSIS if you are familiar with SQL Server. As I learn more about this product, I will blog my experiences.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I finished my training yesterday on the Cast Iron Application router. It is composed of two pieces of software, one is a Java based Studio application for creating orchestrations. The other is a web based management console. The studio application lets you graphically create an integration. You simply set up endpoints to HTTP posts, web services, databases or even email. Then you can design your transformations. Once you finish the design, you can push them to a router for testing.
Most of the actual debuging occurs on the Web based console. You can schedule integrations on the web console as well as generate WSDL files for hosted web services, and change parameters for your integrations.
The router does allow for different levels of security, and will log every single aspect of an integration taking care of most Sarbanes Oxley issues.
The Router does have some limitations. They do not have any support for encryption. While they do support MQ series messaging, there is no support for JMS messaging.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Brian Simmons, the president of CentraSoft, the makers of the CFMX Exam Buster, is donating all of CentraSoft's proceeds to help the victims of hurricane Katrina. Here are the details:
CentraSoft is donating all proceeds from the sale of CFMX Exam Buster from 12:01am Friday September 2nd, 2005 through 11:59pm Friday September 9th, 2005 to the American Red Cross (for Hurricane Katrina victims). That's right, you can purchase CFMX Exam Buster to help you study for the Macromedia ColdFusion MX 7.0 certification exam, and know that your purchase is being donated to a fantastic charity and helping people that are in dire need.
100% of the proceeds from sales during the above mentioned time period will be donated to the American Red Cross. After September 9th, He will post the amount which has been donated to help the Hurricane Katrina victims.
I know a lot of people are studying to take the CFMX 7 test. This would be a great oppurtunity to prepare for the test, and help those in need.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011One of the developers I work with ran into a problem yesterday with the cffile tag that seems to be too common with ColdFusion MX 6.1. The tag threw an error saying that the source attribute did not have a valid path. We double checked the source, and it actually had a valid path.
We then checked the destination attribute, and it did have an incorrect path assigned. We fixed the path for the destination, and the page is working fine again. The is one of my main beefs with ColdFusion MX. As descriptive as the errors usually are, many times the wrong kind of error is displayed, or the wrong template is listed as the source of the error along with the wrong line number.
I love ColdFusion MX, but I wish Adobe would fix these problems because these were not problems in ColdFusion 5 and earlier.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Last week Vince Bonfanti and Josh Adams came out to the JaxFusion user group to present on the next version of BlueDragon. The presentation was excellent, and I hope we can have back again. As good as the presentation was, we had a much lower turnout than I would have liked. Because of the turnout, I sent out a list of questions to the members of the user group who work internally at Vurv to get feedback. Not every member of the JaxFusion user group works at Vurv, so I decided to post these questions to my blog.
Please feel free to leave comments on this blog post with answers to these questions;
What do you want to see at future meetings?
Is there a better meeting time that would be more convenient for most members?
Would you prefer a different day of the week for the meetings?
Would you like to have lunchtime meetings?
Are there subjects you would like to see covered which are not being covered by the group?
One idea has been to do Study Groups. Would anybody be interested in Study Groups for Flash, Flex, Apollo or ColdFusion 8?‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011John Lyons wanted me to post about a problem he encountered with a version of Civilization 4 he recently purchased.
Here is an example of the error;
Civilization 4 Error   
Feature: DefaultFeature
Component:
File:
Error: Catastrophic Failure
This error is the result of corrupt installation disks from Take2. You have to return to your retailer the two cd's , box contents and exchange it for a valid non corrupt cd set. To determine what CD set is valid or not open the box at the store after purchase and compare the inner serial codes on the clear section of the cd agianst the following.
Bad Disks: #1 - 7787511 R2N 01 IFPIL250 , #2 - 7787512 RERIR 01 IFPIL241
Good Disks:#1 - 77875-1.1V3 , #2 - 77875-1.2V3‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011The Jacksonville Code Camp final
[ "http://www.jaxcodecamp.com/Schedule.aspx" target="_blank">schedule](</p) has been posted. I am giving all of my presentations in the morning in room 203.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Adobe has released the ColdFusion 8 updater 1. This contains some hot-fixes, but the real news is that Adobe has released 64 bit version for Windows, Linux and Mac OS 10.5.
Previously the only 64 bit version of ColdFusion ran on Solaris only. If you have been running any server software on 64 bit hardware, you have probably seen improvements in permormance and memory usage.
For Mac OS X users, the installer will now work with 10.5. All of my Macs are now using 64 bit hardware with Mac OS X 10.5. 10.5 also comes pre-installed with Apache 2.2‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011The ColdFusion 8 beta is now up on Adobe Labs. If you have not an opportunity to get on the earlier betas, now is your chance before the final product is released.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I did not go MAX this year, but I have enjoyed reading the coverage this year. Ray Camden reports on his blog that ColdFusion 8 is getting image support. Here are some of thedetails listed on his blog.
Resizing (in various ways)  
 Pasting images over each other  
 Adding text to an image  
 CAPTHA (of various levels of difficulty)  
 base64 encoding images  
 Works with Blogs (lets you store images in databases)  
 Read Exif/IPTC metadata  
 Basic drawing functions (line, rectangle, curves)‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Adobe has released public beta's now of ColdFusion 9 and Bolt (ColdFusion Builder) on Adobe Labs. A lot of attention has been payed to the new IDE, probably overshadowing the new server features.
Adobe has been receiving feedback from a language group about new language features that the community would like to have added to CF9. Some of these new features include CFFinally, CFContinue and CFIMAP.
CFScript now has full language features. You can write CFCs completely in CFScript. I am really excited about this release of ColdFusion.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011The new version of ColdFusion 9 has been released today. This will be he subject of tonight's JaxFusion meeting. The meeting will be at Andromedia Systems in Orange Park at 7:00 PM.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Seann T. Mulligan of K-Force in Tampa is looking for a ColdFusion Application Architect. There is a job description and contact information below; Application Architect Job Summary:
The software architect leads the definition and implementation of the product software architectures. Product software consisting of user interface software and real time embedded software. In order to further improve the software engineering process a shift to the Unified Process is being made. In this environment we are looking for a software architect whose main tasks are to:


Participate in the complete software development cycle from requirements analysis to deployment of the product


Responsible for the software architecture of complex systems and/or services provided to the customer


Responsible for further development of the software architecture process


Enforce the compliancy with architectural processes for projects


Coach teams of software design engineers for planning, tracking and completion of the work within the agreed plan, using agreed methods and processes


Advise on and lead the implementation of new methods, tools or processes


Must Have:


Understand software development approaches e.g., object-oriented (OO), component-based


Experience with modern, iterative software design processes like the Unified Process


Excellent understanding of fundamental technologies;


¬ß operating system/networking
¬ß middleware
¬ß security
¬ß databases
¬ß graphical user interface (GUI) toolkits


Demonstrated expertise in system modeling and tying architectural solutions to business requirements


10 years of IT experience with 3 to 5 years experience in an architectural role


Advanced knowledge of Cold fusion, SQL, Java, UML, XML, Search Techniques


Nice to Have:


Has demonstrated leadership skills


Good oral and written communication skills


Demonstrates strong time management skills


Stay current on newest technology and industry trends


Is capable to transfer knowledge to various audiences


Education

Bachelors in Computing Science

Seann T. Mulligan
Response Manager
National Recruiting Center
Kforce Professional Staffing
813-552-2986 office
813-786-6755 cell
www.kforce.com‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I was reading Ben Forta's blog and saw that Jason Delmore, the ColdFusion product manager has been let go from Adobe. He was one of the many people who have been laid off from Adobe.
I had the opportunity to meet Jason not too long after he was hired at Adobe. At the time he was hired, I was happy that Adobe hired him because he had been working at a competitor of mine. I found Jason to be good steward for ColdFusion.
While Jason was at Adobe, ColdFusion 8 was released, and ColdFusion 9 has been announced. I have been extremely happy with the new features that have included in 8, and the features announced for 9.
I am sorry that Jason is gone from the ColdFusion team. The product really improved under his tenure. That is not a bad CV. Hey Microsoft, you might want to hire this guy.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Adobe released ColdFusion Builder 1.0 today. This is the first ColdFusion IDE since ColdFusion Studio back in the 90's.
This new IDE will cost $299.00, and includes the Flash Builder 4. You will be able to build Air apps with this IDE as well.
ColdFusion Builder is based on the Eclipse IDE, which has already been popular as a Java and ColdFusion editor already. You can install CF Builder as a stand alone IDE, or as a plugin to an existing version of Eclipse.Tags: ColdFusion   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Matt Woodward and Peter J. Farrell over at the ColdFusion Weekly podcast covered in great detail some of the more popular design patterns. If you are a ColdFusion programmer interested in Object Oriented design patterns, this episode is must listen. Keep up the good work Matt and Peter.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Vurv Technology, my employer, needs to hire another ColdFusion developer. Here is the job posting below;
Cold Fusion Developer - Senior
Vurv Technologies Inc. is an award-winning global provider of workforce management solutions. We provide software and services that allow companies to attract, hire, retain, and manage their workforces more efficiently. Headquartered in Jacksonville, Florida, Vurv provides solutions that are used by more than 40,000 users at over 500 client companies, ranging from small recruiting firms to multinational Fortune 100 companies.
The preferred candidate will be a self-starter who works well in a team environment. He/She should possess the discipline and stress management of meeting challenging deadlines. Strong communication skills are a must as client and internal interaction is an essential component of the position. The candidate must possess the ability and experience to jump in and make a difference immediately.
Responsibilities:


Maintain, design, and develop enterprise components and database architecture used for data integration, data conversion, localization, and reporting.


Implement new technologies that will increase software and middleware efficiencies.


Code / Develop / Architect new and existing products and enhancements.


Maintain and upgrade existing installed products.


Debug and test all work.


Strong Development Qualifications Include:

Cold Fusion, ColdFusion, CFML

Preferred Skills:


ColdFusion MX


HR-XML


SQL Statements, T-SQL, DTS


Stored procedures, triggers, arrays, regular expressions


JavaScript, Java Script


SQL Server


Oracle


Globalization, Translation, Localization, Internationalization


Ability to travel up to 10%


Must have outstanding customer service skills, both written and verbal


Excellent attention to detail and organizational skills required


Ability to work in a team environment


Vurv hires only top talent, and offers excellent benefits and has a fun, casual work environment, but employees must be able to work in a fast-paced, production atmosphere. Good communication skills and teamwork required.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011If you are a ColdFusion developer living in or around Palm Coast, Fl, and you are looking for work, please let me know. A couple of positions have opened up, and I know someone looking to hire right away.Tags: ColdFusion   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011A member of the JaxFusion user group is available for ColdFusion and or Flash development. I used to work with this guy, and he is hands down one of the best Flash developers I have ever worked with in my web development career.
He is based out of the Jacksonville area, and is also available for remote work. Please contact me if you are interested at davidfekke at gmail dot com.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011A developer where I work experienced a problem with two ColdFusion MX servers trying to make web service calls to each server. One of the CFMX servers was running version 6.1, and the other was running 7.0.1. The code for calling the web service on both servers was identical. The web service call looked like this;
myWSObj = createObject("webservice","[http://myserver.com/com/myserver/soapconnector.cfc?wsdl](http://myserver.com/com/myserver/soapconnector.cfc?wsdl)");
When he went to run the call, ColdFusion MX 6.1 threw an error, but 7.0.1 did not throw an error at all.
[]coldfusion.jsp.CompilationFailedException: Errors reported by Java compiler: Found 1 semantic error compiling "E:/JRun4/servers/Instance19a/cfusion-ear/cfusion-war/WEB-INF/cfusion/stubs/WS-14748293807/com/myserver/SoapconnectorCfcSoapBindingStub.java": 10\. public class SoapconnectorCfcSoapBindingStub extends org.apache.axis.client.Stub implements com.myserver.Soapconnector { <-------------> *** Error: Type com/myserver/Soapconnector was not found.
The problem was being caused from the fact that CFC 'soapConnector.cfc' was camel cased in the file system. In CFMX 6.1 the path of the wsdl being passed in your code IS CASE SENSITIVE.
The fix if you are using CFMX 6.1 is to make sure the path you are using is correctly cased as it is on the file server.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I am a firm believer in not re-inventing the wheel. My company has a text parser that was written in ColdFusion. It typically processes one document. I just finished a project where I had to process 200,000 documents. The kicker was almost all of these documents where Microsoft Word files. I needed to write an application that could read Word files and convert them to text files. I used the COM interop features built into .NET 2.0 to accomplish this task.
I also wanted to have a way to monitor the progress of this conversion. I used Windows forms and the progress bar component to do this part.
I kept the parsing functions in ColdFusion, and passed the text to a ColdFusion SOAP web service.
The end result was able to come up with a solution in a day without having to rewrite all of the functionality in C# or Java.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011As many of you have been reading, Macromedia released an update to ColdFusion MX 7. You can download the updater for version 7.0.1 from macromedia's website. What got me exited was Macromedia finally has a Mac OS X installer for ColdFusion MX 7.0.1.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Does anyone know if there is a ColdFusion Podcast? There is one for .net.
If anyone knows of one, please let me know.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Raymond Camden has released a new web site called coldfusionportal.org. It is based on the idea behind the Flex.org site. It has links to ColdFusion resources, popular blogs, pod casts as well as user groups. Cudos to Raymond Camden!‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I have received numerous emails from people today about my comments popup not working correctly. I am still researching this problem. Some people seem to be able to post, and others do not. It may be related to a DNS issue. The IP address for my site is ??.??.?.??. This was a recent change in the last month, and for some reason it has not propegated to all DNS servers.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Lets analyze the facts. Is ColdFusion Dead? Full disclosure. I just switched jobs a couple of months ago, and I am no longer a full time ColdFusion developer. When I switched jobs, I was asked the same question by a co-worker at my new job, "I thought ColdFusion was dead?" after I told him about my previous experience. I could see where someone would get that impression if you were to base it solely on Adobe's marketing of CF.
In Mary Brandel's "opinion piece", she states the following;
This once-popular Web programming language -- released in the mid-1990s by Allaire Corp. (which was later purchased by Macromedia Inc., which itself was acquired by Adobe Systems Inc.) -- has since been superseded by other development platforms, including Microsoft Corp.'s Active Server Pages and .Net, as well as Java, Ruby on Rails, Python, PHP and other open-source languages.

Debates continue over whether ColdFusion is as robust and scalable as its competitors, but nevertheless, premiums paid for ColdFusion programmers have dropped way off, according to Foote. "It was really popular at one time, but the market is now crowded with other products," he says.
So lets analyze this sentence by sentence. Brandel states that ColdFusion was once-popular. It is "once-popular" when you consider it has always been a popular web application language since it was released in 1995. Back then you could write CGI applications in C++, or use ColdFusion and ASP. ColdFusion quickly became popular because it was easier to develop for then ASP or C++. Later on in the 90s PHP and JSP became popular options, but neither are as easy to use as CF.
Brandel goes on to mention that ColdFusion has been superseded by .NET, Java, Ruby on Rails, Python, PHP and other open-source languages. She kind of lumps application servers with languages. .NET and Java are both application runtime environments that can be run on desktops, phones and servers. They can also run multiple languages. ColdFusion currently runs on top of Java, and can be used in conjuction with Java. The two products actually compliment each other. New Atlanta makes a CFML engine that runs on .NET called BlueDragon.NET.
I have done some PHP programming, and I like PHP as a scripting language, but not as much as CFML. You can still write web apps quicker in CFML than in PHP. Unlike Ruby on Rails and Python, CFML and PHP are made from the ground up to be a web scripting language. Python requires that the code be indented, which makes it next to impossible to combine inline HTML with your code. Ruby on Rails is not a language, it is a web application framework. 37 signals has automated a lot of things in Rails, including scaffolding and AJAX, but the underlying language is Ruby. Ruby is probably easier to learn than Perl, but it is still just a system scripting language.
Brandel goes on to write that "Debates continue over whether ColdFusion is as robust and scalable as its competitors". .NET and Java both scale extremely well. Since ColdFusion runs on top of Java, it also scales very well. I just came from a company that had a hosted solution the ran on a web farm of clustered servers. Their customers included Fortune 100 companies. There is no debate, ColdFusion does scale. The same can not be said about other technologies like Ruby on Rails. Two of my favorite sites are running on Rails. They are Twitter and Basecamp. Both of these sites are down constantly, or at least run extremely slow because Rails does not scale well.
She also said that premiums for ColdFusion developers have fallen. I am not sure what time frame she is writing about because my phone was ringing off the hook when I was in my last job transition a couple of months ago. There was a period around 2002 after the Dot Com bust where there was a drop off in salaries, but I found that to be the case for all development. Saleries are actually higher now for ColdFusion than I have ever seen them in the past.
Brandel goes on to quote David Foote who says "It was really popular at one time, but the market is now crowded with other products." Lets analyze this bit of brilliance from Mr. Foote. If anything there are fewer competing products then there were in the late 90s. Many of the smaller products have died or have withered on the vine. If you look at Python and Ruby, they are actually older than ColdFusion. If you also look at the number of development jobs out in the marketplace, ColdFusion outnumbers Rails jobs by a factor of two.
In the Computerworld article, Brandel compares ColdFusion to non-relational databases, COBOL, and OS/2. ColdFusion is still being sold, supported and developed into new versions by one of the largest software companies on the planet, unlike OS/2. Brandel mentions that ColdFusion was acquired from Allaire by Macromedia, and Macromedia by Adobe. I think the fact that a software product is being purchased by an even larger software company is a good thing, not bad.
There are no less than five different application servers that run CFML applications. Some of these are open source projects. Plenty of options from multiple vendors.
Op-Ed pieces like this are typical of pubs like Computerworld and Wired nowadays. I guess it is to be considered when you realize that Adobe has completely mishandled the marketing of ColdFusion. One has to ask how Ruby on Rails has garnered such positive press with no advertising budget, and ColdFusion gets an "It is dead" article every three months.
Tim Buntel, Where are you when we need you?‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I remember when Mitch Williams blew the 93' World Series for the Phillies. This occured 5 years before the 'Devil Rays' threw there first Pitch.
I was at the Rays game 2 of the 98 season when the Rays had their first win. They did not have many more wins for the next nine years.
I am just happy that the Rays made it as far as they did this season. Conratulations to both teams.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I was just thinking back to my earliest experiences with Apple computers. When I was child, my elementary school has a lab of Apple II's. I started programming with the Apple Basic that WOZ had added to the ROMs on the Apple II. From that point on I was hooked to personal computing. Since 1986 I have owned six different Apple computers, five of them were Macintosh's including the G5 I use as my home computer now.
In the 90s when I was working in the print publishing industry, I really started to cut my teeth scripting with AppleScript.
In the 30 year history of Apple Computer, I have watched the company go from a media loved company, to a media hated company, back to a media loved company.
My attitude towards the company has not changed. I am a loyal customer, I love their products, yet they still piss me off from time to time. I look forward to seeing the products they produce over the next 30 years.
Congratulations to Apple for making it this far.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Congratulations to the Tampa Bay Rays on their ALCS pennant win yesterday. I have been a fan of the Rays since their inaugural season in 1998. After nine seasons of being in the baseball basement, all I have to say is this feels good.
I have a number of friends who live in Boston who I know are not feeling well this morning about their Red Sox. The first baseball game I ever saw was in Fenway Park, and I rooted for Boston over the Yankees in 2004 when Boston came back from being three games down to beat the Yanks. The Red Sox are a great team, but this was not to be their year, it is Tampa's.
At the beginning of the season, the Tampa Bay Rays were 200/1 to win the World Series. It has been one wild ride this year. Joe Maddon deserves a ton of credit for turning the Rays around, along with the new ownership.
After listening to the Bob Costas' of the world bad mouth my home team for the last ten years, it is nice to see them host the 2008 World Series in my home town of Tampa.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I have been developing a lot of windows workflows and web services in .NET recently. I came across a need to convert a WMF file (Windows Meta File) into a gif file. SQL Server Reporting Services can not display WMF files.
.NET 2.0 can convert and resize images natively. Here is how I converted the WMF files. First I added the following using statements;

using System.Drawing;

using System.Drawing.Imaging;

InfoPath saves images as Base64 strings, and .NET treats this as a byte array. So I had to convert the WMF byte array to a gif byte array.

byte[] imageByteArray = DiagramImage;

MemoryStream inStream = new MemoryStream(imageByteArray);

StreamReader myStreamReader = new StreamReader(inStream);

Image myImage = Image.FromStream(inStream);

Bitmap myBitmap = new Bitmap(myImage);

Graphics myGraphics = Graphics.FromImage(myBitmap);

//Keep background white.

myGraphics.Clear(Color.White);

myGraphics.DrawImage(myImage, 0, 0, myImage.Width, myImage.Height);

MemoryStream outStream = new MemoryStream();

myBitmap.Save(outStream, ImageFormat.Gif);

byte[] gifByteArray = outStream.GetBuffer();
‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I have been using Microsoft Office InfoPath in some recent projects. One of the nice features of InfoPath is the ability to consume SOAP based web services. This can be used to pre-populate fields in the InfoPath form, or to submit the form to a web service once the user has finished filling out the form.
I decided to test some different web services with InfoPath, and I received the following error when I tried to use InfoPath with a ColdFusion based web service;
InfoPath cannot work with this Web service because it uses RPC encoding. Only document literal encoding is supported.
There is actually a very easy way to fix this if you are using ColdFusion 7 or greater, and that is to use the style attribute in the cfcomponent tag.
There are four different ways a SOAP based web service can be encoded, but the two most popular are rpc encoded and document literal. ColdFusion by default uses rpc encoded and .NET by default uses document literal.
If you are trying to use an existing rpc encoded web service that is used by other applications, do not change the component style because this will break the existing applications that are consuming this web service. Write a proxy service that that uses document literal to talk to the InfoPath form.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Todd over at cfsilence.com had a a question about one of my recent blog posts on converting WMF files to GIF files. I gave an example of how to do this in .NET, but how do you leverage ColdFusion's .NET integration to do the same thing in ColdFusion.
The first thing you have to do is create a class project in .NET. Add a reference to the System.Drawing library. Here is the class I built for this example;

using System;

using System.Collections.Generic;

using System.Drawing;

using System.Drawing.Imaging;

using System.IO;

using System.Text;

namespace ImageConvertLibrary

{

public class GifItUtility

{

public static void saveGifToPath(string wmfFilePath, string gifFilePath)

{

Image myImage = Image.FromFile(wmfFilePath, true);

int myWidth = (int)myImage.HorizontalResolution;

int myHeight = (int)myImage.VerticalResolution;

Bitmap myBitmap = new Bitmap(myImage, (int)myImage.HorizontalResolution, (int)myImage.VerticalResolution); 

Graphics myGraphics = Graphics.FromImage(myBitmap);

myGraphics.Clear(Color.White);

myGraphics.DrawImage(myImage, 0, 0, myWidth, myHeight);

myBitmap.Save(gifFilePath, ImageFormat.Gif);

}

}

}

Build the project into a dll file that can be added to the Windows assembly. Visual Studio will place this file either in the project bin/debug or bin/release folder.
The saveGifToPath method excepts two string parameters, one for the input WMF file path, and the second for the path to GIF file.
Here is an example of a ColdFusion file using this class and method to create a GIF file from a WMF file;
I did some googling for a Java library that will do the same thing as this .NET code, and I found some propriatery libraries that will do converting of images from the WMF format. If you are running ColdFusion on Windows, or you have a Windows server you can proxy too, this is a free way to convert this files.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I was in San Jose last week for the managers summit. While I was out there I noticed that a lot of the developers use Macs.
I have been a Mac user since 1990, and I have a G5 for my home machine. I am trying to convince my company that I should get a MacBook Pro to replace my Dell laptop. Sean Corfield brought up some good points to me about how to convince your boss to get you a Mac for development.
The new MacBook Pro is an Intel based machine. Because it uses an x86 based processor, you can run multiple operating systems on it now. If you use parallels, you can even run multiple OSes at the same time, and test your web apps in each browser.
If you host your applications on Unix servers, you can run your apps on the same OS that the server is running since Mac OS X is Unix based.
I do not know if I will be able to convince my boss to get me a Mac, but if he does not, I will probably get one to replace my home machine. I just bought my G5 about a year and a half ago, so it will probably be awhile before I replace that machine.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Thanks to Buck Woody for pasing along link to me. There are some goodies in that post.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I was recently told by a co-worker that you should never use DOM based XML parsers to load XML data into a application or database.
DOM is extremely bad in JAVA for processing large XML documents, mainly because it has to load the entire document into memory. We use JRun which by default has a maximum of 512 megabytes of memory. If you have a XML file that is several hundred megabytes in size, JRun will not be able to load the whole document into memory. SAX or the Simple API for XML processing does a much better job at processing large XML files. The reason for this is you can load portions of the XML file into a buffer, extract the information you need, and process the rest of the file. Since you are you are only loading a portion of the file at a time, it does not require as much memory.
So why would anyone ever use DOM based parsers for processing XML. While it is true that DOM does poor job at handling large XML documents, it is much easier to develop for DOM than SAX. DOM based parsers are more elegant and have an easier learning curve than SAX. Most XML files that developers run into are small enough that they can be handled with a DOM based parser.
SAX is based on an event model that raises events when tags are recognized in the buffer. It is nowhere as elegant as a real XML API.
ColdFusion MX uses a DOM based parser for processing XML. It allows the developer to treat the XML as tree structure and to use xpath for searching for specific nodes.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011My former employer, Jagged Peak is looking for a couple of ColdFusion developers in the Tampa Bay area. Here is their post;
Immediate opening for full time, permanent Web Application programmer in Tampa, FL. Telecommuting is not an option.
You should be comfortable designing and maintaining complex, enterprise-level web applications inside an existing development team.
Each candidate will be tested for proficiency and should be prepared to provide code samples.
Must be proficient in:
ColdFusion (5,6,7)
Fusebox (all versions)
HTML / DHTML
JavaScript
CSS
XML
T-SQL
Must have working knowledge of or desire to learn:
Webservices
Java
PL/SQL
Knowledge of one or more of the following is a plus:
Flash / ActionScript
AJAX
.NET
ASP 3
Send Applications to: rcrutchfield at jaggedpeak dot com.
EOE‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I recently read that Microsoft is thinking about porting .NET to Mac OS X. As a developer, I think this would be awesome if they did. I use .NET at work now when I can not use ColdFusion. James Gosling, the inventor of Java, recently criticized .net and some other non-java technologies in a speech he gave. One of his criticisms about .NET is that Microsoft missed an opportunity by not being trully cross-platform.
The Mono project has already crossed some these cross platform issues by supporting Linux and the Mac OS.
Microsoft would have some technical hurdles to overcome to port .NET to the Mac. One of those would be their reliance on parts of the framework that use COM still. Much of that has been fixed now in .NET 2.0. Another issue would be porting Windows Forms so that it maintains the Mac look and feel. But I think it can be done.
As a Mac developer and a .NET developer, I hope Microsofts does port .NET to the Mac. This is the one area where Java has shined over .NET is cross platform development.
Now if we could convince Microsoft to port .NET to Linux. I am not holding my breath for that one.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011DVD Format war gauntlet thrown. Toshiba has thrown down the gauntlet. Sony and Toshiba will have two different formats for High Def video. Consumers be damned.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Macromedia has a good overview of the new features in CFMX 7.0.1. This article covers many of the new features, including CFC Proxy, RTF output and updated web services. I can not wait to start playing with these new features.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I went to Dave Ross's presentation on ColdSpring at CFUNITED. It was an extremely informative presentation on the ColdSpring frame work that Dave developed. ColdSpring is based on the Java Spring framework. It makes it much easier to create service factories for creating objects. It also includes a framework for Aspect Oriented Programming.
Dave mentioned that the examples that are always given of AOP are logging and security, but it can also be used for managing transactions as well as caching.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Damon Cooper has posted new versions of the CFThread and CFJoin tags developed by Rupesh Kumar. These tags are proof of concept tags, so not for production use yet. I hope they add this into ColdFusion. Very cool guys.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I just discovered a really neat tool for debugging web services. There is a sniffer application that will reroute TCP requests that come with every version of ColdFusion MX. In the JRun_Root\bin directory or ColdFusionMX_Root\runtime\bin their is a Java application called sniffer.exe. This will allow you to monitor all tcp requests in an unused port, such as 8600 or 8800, and reroute the request to a legitimate port such as 80.
I used this to look at a http post request that someone was using to call a SOAP based web service.
I do not know if a lot of ColdFusion developers know that you can use cfhttp to make web service calls. This tool can also be used to see how the soap message needs to be formatted if you are using ajax to make a call to a web service.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I recently heard about a company that because they deleted what they thought was lookup data in a table ran into all kinds of relational issues with data in other tables that referenced that lookup table. On top of that it was a production database.
With very few exceptions, don't delete data from databases. SQL makes it very easy, maybe too easy to delete data from tables;
DELETE FROM myTable;  
 GO There are some applications that collect tons of transactional data that fill up hard drives pretty quickly. That being said, hard drive space is cheap now, and this data can be offloaded to another system if it needs to be moved to clear up disk space. This is a fairly common task used in database warehousing.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I saw a CNET article today that Dell was selling some individual AMD processors, as if Dell was testing the waters. They still do not sell PCs with AMD processors, but they may be looking to change that now. My company only bought Dell computers for the longest time. Recently, we have started breaking away from that practice. Some of people at my company use Macs. We also have some higher end laptops and servers using AMD processors.
I think since Dell is seeing a slowdown in their business, they are taking a second look at AMD processors. AMD always seems to win the speed tests in the desktop and x86 based servers. Even Sun is using AMD processors in their x86 servers.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Does ColdFusion need 64 bit support? The short answer to this question is yes, but it really depends on the ROI if Adobe charges more for the 64 bit version. My company is currently in the process of upgrading to 64 bit servers, but only where it makes sense.
SQL Server 2005 has a 32 bit and a 64 bit version. The 64 bit version takes advantage of the 64 bit chips, but it also costs a lot more. Factor in the cost of the 64 bit version of Windows 2003 Server OS, and it gets pricey.
From my tests with SSIS on this new hardware, ETLs that used to take hours now take minutes to run. Granted a lot of the speed improvements have come from code optimizations in SQL Server, but there is still a huge improvement from using the 64 bit hardware.
It would be nice to see 64 bit version of ColdFusion. I know it would require having a 64 bit OS and JVM, but it would be nice to see ColdFusion take advantage of this new hardware.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Right now I only have one application on the Apple App Store, but I am planning on releasing more applications. According to Apple, iPhone applications will run unmodified on the iPad. Apple released a new SDK for the iPhone and iPad today.
The new iPhone/iPad SDK is version 3.2. Many speculated it would be version 4.0, but they may be saving those features for this Summer. The iPad will cost $499, $599 and $799 for the WiFi only versions, and $629, $729 and $829 for the WiFi/3G versions. Flash memory sizes will range from 16 GB to 64 GB.Tags: COCOA   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Years and years ago, when I was still using ColdFusion 5, I decided to contribute an UDF to the cflib.org web site. The function I wrote converts actual years to dog years.
/**  
 * This UDF translates a dogs age to a humans age.  
 *   
 * @param age The age of the dog.   
 * @author David Fekke ([david@fekke.com](mailto:david@fekke.com))   
 * @version 1, February 14, 2002   
 */  
 function DogYearsToHumanYears(DogAge) {  
 return ((DogAge - 1)* 7) + 9;  
 } When I first submitted it, it was rejected because I used the wrong algorithm. I thought the corect way to determine dog years was to multiply actual years time seven. Raymond Camden corrected me, and when and found the correct calculation.
We were going through the source code for an application we just purchased from another company, and we found my function with the entire common function library.
An important warning that comes with the library is as follows;
Warning:
You may not need all the functions in this library. If speed
is extremely important, you may want to consider deleting
functions you do not plan on using.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I am a big fan of the show Breaking Bad on AMC. This is my favorate scene from the season 3 finale. Don't mess with Mike.


‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011A firend of mine is a graphics professional, and he asked me if he should get a Intel based iMac for his job. I told him absolutely not!
Alright, I know what you are saying. "David, you are a mac guy, how can you tell a graphic professional not to buy a mac." Here is why, Adobe. Adobe is not planning on leasing any of their CS apps as dual binary until CS3. Typically, new versions of Adobe apps are released every 18-24 months. CS2 was just released about 6 months ago, so it will propably be late 2007 before Adobe has CS3 ready.
This means that Photoshop, Illustrator and InDesign would have to run in emulation on an Intel based Mac. It is certainly faster than running 68K code in emulation on a PowerPC, but the experience would suck.
So with that all being said, you can buy a mac for these apps as long as it is a PowerPC based Mac. I would suggest buying a PowerMac G5 if you need to run CS2.
If you are using Motion graphics such as Apple Motion or Final Cut Pro, Apple is supposed to be coming out with dual binaries for these apps in March. The wait will not be as long for Apple's apps. Quark Inc. supposedly has a beta of Xpress for the Intel Mac.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I was looking at some more information on Dreamweaver 8, and it looks like they are adding support for xslt. From there website, they state that you can drag and drop XML objects into your template, and Dreamweaver will write the xsl for you.
So far most of the new features look very cool. Macromedia has also added numerous changes to their code editor.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I was just checking out the new Studio 8 on macromedia's web site. I checked out a video presentation on Dreamweaver 8. The coolest features I saw had to do with css and different views including the screen reader. There is even a section 508 checker for accesibility concerns.
I have not looked at Flash 8 features yet, but it looks like there are some nice features related to mobile apps.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I just learned today from a friend of mine that a Tampa based Drummer Jeff Wood passed away. I had the pleasure of knowing Jeff when he was the drummer in Barely Pink. Jeff was diagnosed with brain cancer and been fighting it for many years.
Jeff was in a lot of different bands in the Tampa Bay area. On top of being an amazing drummer, Jeff was also a great vocalist.
Here is note I got from Mark Warren this morning;
The Tampa Bay music scene lost one of its own and it hurts bad. Following a long struggle with brain cancer, Jeff Wood passed away yesterday. Beloved by all who knew him, Jeff was a constant on the scene for more than 20 years, playing drums with an intensity and passion you'd rarely see even amongst his drumming heroes. The guy was the real deal, a good friend to have and any band privileged to count him as a member was better for it. And he played with a lot of them over the years -- odds are, if you've been a musician for any length of time in Tampa Bay, either you've been in a band with Jeff or you know someone who has. The Vodkanauts are no exception -- guitarist Mark Warren played with Jeff while a member of power-poppers Barely Pink and V'nauts drummer Stan Arthur was Jeff's successor in Barely Pink. Notice the avoidance of the word "replacement" as Jeff Wood is, was and always will be irreplaceable, truly a one-of-a-kind both as a musician and a human being. Our thoughts go out to Jeff's incredible family, girlfriend Vicki and everyone who's feeling this loss as deeply as we are. It's not gonna be easy but we will get through this.
Whenever tragedies like this occur, it serves as a reminder of just how brief our stay on the big blue marble can be and how abruptly it can come to a halt. With that in mind, we urge you to tell your loved ones just how much you care about them on a regular and frequent basis. If there's amends to make, do it now. And if you've got dreams, don't hesitate another moment to realize them.
Peace.
Update;
Here is a list of bands that Jeff played in as drummer;


The Moon Calves


Fugitive Kind


Forgotten Apostles


Monday Mornings


Smashmouth


Joe Popp


Barely Pink


Spiller


Nutrajet


and many, many more.


There was a mention of this yesterday on the Seminole Heights Blog‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Sean Corfield has made some good observations on his blog about duct typing. You should not duct type solely for performance.
One of the things that makes ColdFusion a rapid language for development is you are not required to specify a type for your parameters or return types.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011John Lyons had a post about whether to encapsulate your business logic in CFCs vs. Stored Procedures. The answer to this question is "it depends". I used to work at a company that used SQL Server stored procedures for all of the business logic in our applications. One of the reasons we did this was because we had some applications that were written in VB, and others that were written in ColdFusion that accessed the same databases. Using stored procedures allowed us to have a single point of entry and one set of code that we had to maintain for that business logic.
If all of your applications were written in ColdFusion, I would use CFCs to encapsulate that business logic. It is easier for most developers to maintain CFCs than it is to maintain T-SQL. Stored Procedures are an database object, and they may be difficult to promote to your QA and production servers depending on how your security is set up.
There is also no speed advantage to using MS SQL Server stored procedures over inline SQL statements. If you are using an Oracle database server, there may be a speed advantage to writing your PL-SQL as stored procedures. If I was using Oracle, I would probably use stored procedures with my most of my business logic in my CFCs.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I have not seen a lot of discussion on open source projects that move to commercial products. I have noticed a couple of open source projects lately that have been abandoned, and the authors have since released commercial versions of the same project. I am guessing the reasoning is that they could actually sell the applications, and make money with the project. I am not a legal expert, but this seems to be a violation of the GPL.
One of the problems I see with open source is that if someone does violate the GPL, there is no real way to enforce this. Who is going to sue?‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I have been using the DAAB part of the Enterprise Library at my current job. One of the advantages of using this library is that you can write ANSI standard SQL, and it should work with any Relational Database.
The problem with this is that if you want to use parametrized queries, T-SQL and PL-SQL use different prefixes in front of the parameters. SQL Server uses '@' symbols in front of the parameter names, and Oracle uses ':' in front of their parameters. So how can you write Ad hoc queries that will run on both SQL Server and Oracle. I have written a class that will set the parameter tokens automatically based on your database context.

using System;

using System.Collections.Generic;

using System.Linq;

using System.Text;

using Microsoft.Practices.EnterpriseLibrary.Data; 

namespace MyDataAccessNamespace

{

public class DAABDbTokenSetter

{

public static string CreateParam(Database db, string parameterName)

{

string TokenPrefix = "";

string DatabaseType = db.DbProviderFactory.ToString();

if (DatabaseType == "System.Data.SqlClient.SqlClientFactory")

{

TokenPrefix = "@";

}

else if (DatabaseType == "System.Data.OracleClient.OracleClientFactory")

{

TokenPrefix = ":";

}

else

{

TokenPrefix = "";

}

return TokenPrefix + parameterName;

}

}

}

This class can be used in your ad hoc queries in the following way to set the tokens;

string myquery = "select firstname, lastname " +

"from customertable " + 

"where customerid = " + DAABDbTokenSetter.CreateParam(db,"customerid")
‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011A friend of mine is having problems trying to shutdown ColdFusion MX 7 on fedora core 4. He logs in to root and gets the following error when he uses the stop command;
/opt/coldfusionmx7/bin/coldfusion stop  
 Stopping ColdFusion MX 7, please wait  
 Stopping coldfusion server..could not stop server, either it's not running, you don't have permission to stop the server or it needs to be killed manually The ColdFusion MX 7 server seems to be hanging, will stop non-gracefully ColdFusion MX 7 has been stopped
Since he is logged in as root, he is curious why CFMX is not stopping gracefully? If you have any ideas, please feel free to post them in my comments.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011My web site is running on SQL Server 2005! I wish I could take credit for it, but my service provider, Mercury New Media, just upgraded to SQL Server 2005 for most of their customers.
I have been running 2005 locally for about a year now, so it is nice to have my personal site running on 2005 as well.
No one should really notice this change because it is on the backend, but it will be nice future development.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I upgraded to the new version of CFEclipse this morning to 1.3.1.1. The changes that have been made since 1.3 have been changes to the File Explorer. I am not using the regular version of Eclipse, I am using Flex Builder 3.0.1. I think this is probably why I might be having problems with the File Explorer in CFEclipse.
When I upgraded to CFEclipse 1.3.1.1, the File Explorer will not come up in either the Flex perspective or the CFEclipse perspective.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I have been lite on my blogging lately. I have been training for the First Coast Head Race here in Jacksonville. It is a 5K crew regatta.
The last race I went to was the World Masters Championships in New Jersey, which was a 1K event. It has been fun transitioning to the 5K event.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I gave a presentation last year on the Event Gateway for ColdFusion MX 7. John Lyons asked me to post the code for the CFC I used in my presentation to my blog.
The way this code works is that it uses a File watcher event gateway to see if any files of type jpg are written to a folder specified in the Event Gateway. Here is the code for the CFC.
"imageWatcher">  
<cffunction name="onAdd" access="public" returntype="void">
<cfargument name="CFEvent" type="struct" required="true">

<cflog file="MydirWatcher" application="No" text="ACTION: #data.type#; FILE: #data.filename#; TIME: #timeFormat(data.lastmodified)#">

<cfset createThumbImage(data.filename) />
<cfcatch type="any">
<cfwddx action="cfml2wddx" input="#cfcatch#" output="myWDDX" />
<cflog file="MydirWatcher" application="No" text="#myWDDX#">



<cffunction name="createThumbImage" access="public" returntype="void">
<cfargument name="filepath" type="string" required="yes" />
<cfset var imageName = "Thumb" & getFileFromPath(arguments.filepath) />
<cfset var ImageIOObj = CreateObject("Java", "javax.imageio.ImageIO") />
<cfset var FileInputStream = CreateObject("Java", "java.io.FileInputStream") />
<cfset var FileOutputStream = CreateObject("Java", "java.io.FileOutputStream") />
<cfset var newImage = createObject("java", "java.awt.image.BufferedImage") />
<cfset var AffineTransform = CreateObject("Java", "java.awt.geom.AffineTransform") />
<cfset var AffineTransformOp = CreateObject("Java", "java.awt.image.AffineTransformOp") />



<!--- Ideal ratio is 128 pixels by 128 pixels --->
<cfset FileInputStream.init(arguments.filepath) />




<!--- Set the new dimensions for the thumbnail based on the image ratio. --->
<cfif imageRatio GT 1>

<cfset newWidth = 128 * (width/height) />

<cfset newHeight = 128 * (height/width) />


<cfset pWidth = newWidth / Width />
<cfset pHeight = newHeight / Height />
<cfset jwidth = javaCast("int", newWidth) />
<cfset jheight = javaCast("int", newHeight) />

<cfset newImage.init(jwidth, jheight, imageType) />
<cfset AffineTransform.scale(pWidth, pHeight) />
<cfset AffineTransformOp.init(AffineTransform, AffineTransformOp.TYPE_BILINEAR) />
<cfset AffineTransformOp.filter(Image, newImage) />
<cfset FileOutputStream.init("c:\thumbnails#imageName#") />
<cfset ImageIOObj.write(newImage, "jpg", FileOutputStream) />
<cfset Image.flush() />
<cfset FileOutputStream.close() />


This code uses the underlying Java libraries that are included with ColdFusion to resize the images.
Doug Hughes has written an Image component that takes advantage of these underlying java libraries. I highly recommend that if you need to do image processing in your web app, that you take a look at some of the components that Doug sells at his company Alagad. He also sells a component for doing Capchas.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I work with an application that can update the database schema of on Oracle database. Sometimes when the application updates the database with a DDL script I will get an unstable indexes error.
Rebuilding indexes in Oracle can be done by using a PL-SQL script like the following;

ALTER INDEX SCHEMA_NAME.INDEX_NAME REBUILD;

If you need to rebuild every index at the same time, that can be accomplished by using a cursor such as the following

DECLARE sql_str varchar2(1000);

cursor c1 is

select index_name

from user_indexes

WHERE index_name NOT LIKE 'SYS%';

BEGIN

FOR index_rec in c1

LOOP

sql_str := 'ALTER INDEX ' || index_rec.index_name || ' REBUILD';

EXECUTE IMMEDIATE sql_str;

END LOOP;

COMMIT;

END;
‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I just finished watching the second day keynote at MAX. There was a lot of focus on Flash video, Flash lite, the next generation of Flash as well as Breeze.
Adobe and Macromedia shared a demo on how to export video from After Effects into Flash 8. They showed how you can share an alpha channel, and line up the video in Flash.
Jeremy Allaire gave a presentation on his video distribution network, BrightCove. You can even distribute video onto an iPod Video. The application front end for BrightCove is built in Flex.
I have been through a couple of presentations on Actionscript 3.0 and Flex. Flex 2.0 is supposed to include a CF Adapter for providing AMF like functionality without having to use Flash remoting.
The language improvements and VM changes for Actionscript 3.0 look very nice. The language will be type safe, and you will be able to register ColdFusion components in Flex as value objects.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011www.pryoritytraining.com is looking for two Flash developers who are familiar with Flash 8 and AS 2. Here ae a list of requirements;


function to retrieve data from an XML file.


modify (customize) a Quiz component: add option to play a sound and display a graphic for feedback


some customized quiz exercises (not using components).


function for bookmarking


Please contact Julia at her email address, julia@pryoritytraining.com, or by phone, 904-491-5007.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I just got back from California last week where I was receiving training at the Adobe campus on Flex 2. I am by no means an expert yet, but I figured this would be a good opportunity to present on how to build a simple app in Flex 2. This presentation will also give an overview of MXML and ActionScript 3.
The JaxFusion User group meets the first Tuesday of the month at Vurv Technology in Jacksonville. The meetings start at 6:30 PM.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011The 30 day trial for Flex Builder 2 just ended on my laptop. I am still in the process of trying to convince my company to buy me a license.
If you have the standalone version of Flex Builder 2, and were curious what happen when the trial ends, here is what I have observed. Flex Builder 2 is built on the Eclipse IDE platform. I was using Eclipse before I started using Flex 2, but I decided to download the standalone version because of some behaviors that are different between the plugin and the standalone version. The differences were mainly how Eclipse builds and launches apps and some keyboard shortcuts.
When my trial ended, I went to the Manage Flex licenses... menu option under the help menu. Before the trial ended it gave the option of entering in the key or continuing on. Now it lets you enter in the license key or you can just quit.
If you try to open a Flex MXML file, you have the same option of entering the key or quiting the application.
You can use Flex Builder for more than just working with Flex. You can also use Flex Builder with CFEclipse and Java development. After the trial license ends, you can still use Flex Builder with these other plugins, but as soon as you try to work with Flex specific files, the IDE quits.
In the mean time, I am going to reinstall Eclipse until I can get the license key for Flex.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Adobe has put a beta of the Flex Builder 2 IDE on their labs website. I have been waiting for this for a long time.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Flex Camp Miami is this March 6th. I have not been to a Flex camp yet, but I am thinking about going to this Flex camp.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Ben Forta has a blog posting about the next version of Flex. He says that Adobe is trying to form a advisory panel of ColdFusion developers to help provide feedback.
If you are interested, click this link, and fill out the online application.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I this link on Ben Forta's blog about a new project called Ajax Data Services on Adobe Labs.
This Library lets you embed an invisible SWF file in your web page, and then use Flex Data Services to push data to your HTML content. It is extremely difficult to push to AJAX clients without a technology like this for developers.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I read about this on Ben Forta's blog. Adobe is renaming Flex Data Services to LiveCycle Data Services. Data Services is an important part of the Flex/Apollo products because of the ability Data Services gives you to push data to the client using modern messaging.
Adobe is currently looking for feedback from developers. Data Services runs as a J2EE app.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I have seen about four sessions on Flex so far at MAX. The new features coming out in Flex 2.0 do two new things, messaging and data services. The messaging allows for real time updates of multiple Flex clients, so you can write a chat client if you wanted. You will be able to connect to a JMS server.
The data services allow for flagless updates to a database server. You can use DAO objects to update an Array of objects.
You can also use these two features together, so one user can add a row to a recordset, and the change is reflected in real time in all clients.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I have been playing around with some of the Flex 2.0 examples for ColdFusion. I am trying to get the cfcontact example working and I get the following error when I try to edit the flex-data-service.xml file.
error Could not pre-load servlet: MessageBrokerServlet I made the following two changes to this file;  
 "actionscript" class="flex.data.adapters.ASObjectAdapter" default="true"/>  
 "java-dao" class="flex.data.adapters.JavaAdapter"/>  
 "hibernate" class="flex.data.adapters.HibernateAdapter"/>  
 __  
 "coldfusion-dao" class="coldfusion.flex.CFDataServicesAdapter"/>  

I also added the destination for the cfcontact;
"cfcontact">   
 "coldfusion-dao"/>   
    
 "cf-dataservice-rtmp" />   
    
    
    
 "contactId"/>   
    
    
 0   
 "false" size="10"/>   
 "ERROR" max-frequency="500"/>   
 "REPLACE" max-frequency="500"/>   
    
    
    
samples.contact.ContactAssembler
localhost

remote


false
false
false



fill


sync

    
 get   
    
    
 count   
    
    
    
 
The only thing I can think of that might be causing a problem is that I am running CF mystic under IIS and Jrun. I have standalone version of jrun Flex data services running on port 8700.
Has anyone found a fix for this yet?‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Adobe is Open Sourcing Flex and the Flex SDK. This includes the Java source code for the ActionScript and MXML compilers. It also includes the ActionScript debugger and the core ActionScript Libraries from the SDK.
Here is the link to the Labs page.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011It has been awhile since the last JaxFusion meeting. We are meeting at Southwest Signal next Wednesday. I will be giving a presentation on integrating ColdFusion with Flex and Air applications.
There have been a lot of changes in the ColdFusion community in the last couple of months and I am looking forward to meeting up with the developers in the group.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011My blog was recently added to the MXNA list of feeds. The great thing so far is the feedback that I am getting from other developers.
While trying to research a problem lately, I used Google and some other search engines to try to find the solution. After having no luck, I tried searching MXNA, and found the solutions I was looking for right on MXNA.
One of the flaws in Search Engines is that they index everything. If you are using common words, you will get more search results that a human can possibly dig through. The nice thing about MXNA, I can just search the feeds that would normallly have the answer I was looking for.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I will be giving three presentations at the Jacksonville Code Camp this Saturday. Two of the presentations will be on Flex, and the other will be on Linq.
This years code camp will have multiple tracks covering development methodologies, .NET 3.5, Flex/Air, Java, Ruby, SQL Server. The event is free, and all you half to do sign up to attend. Tuesday is the last day to register. Here is a list of the presentations I will be giving at the code camp;
Intro to Flex/Air
This presentation is a introduction to the Flex and Air technologies from Adobe.
Integrating Flex/Air with ColdFusion
This is the same presentation I gave at the last JaxFusion meeting. It covers how to use server technologies with Flex/Air applications.
Linq for SQL
This is the same presentation I gave at SQL Saturday earlier this year. It covers the basics on querying at database using Linq.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I uploaded the powerpoint presentation is used for last night's presentation on Fusebox 5 and Model-Glue onto my web site. I will have code examples on my downloads section next week.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Partha Puskar, A co-worker of mine, showed me a really neat Free SOAP Client tool for looking at SOAP messages. I find tools like this to be handy to show the full XML sent back from a Web Service call.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I have a site that I run that is on a Linux server. I just finished writting an application in fusebox 5, and I noticed the following problems.
Since Fusebox 4, the framework actually compiles code into a "parsed" directory. I tried to reparse my app using the fusebox.cleanbuild=true url parameter, and I got the following error;
An Error during write of Parsed File or Parsing Directory not found.  
Attempting to write the parsed file 'circuit.filename.cfm' threw an error. This can also occur if the parsed file directory cannot be found.
I changed the "parse" directory to have permissions set at "777" so that the public group had permission to write. I am pretty sure that Fusebox 4 has the same issue, but I have not been able to verify.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I don't know how I missed this, but Fusebox 5 general release is available at fusebox.org.
Congratulations to Sean Corfield and the rest of the Fusebox group for getting this release out. I have been beta testing the framework for a new application I have been working on for last couple of weeks.
This is the first release of the Fusebox framework that has not required a rewrite of your application to upgrade the framework. All fusebox.xml and circuit.xml files will run as they did in version 4.0 and 4.1.
The core files are now CFCs for the most part. There is also a new fusebox.loadclean keyword that can be used to recompile the app from the xml files.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I am preparing a presentation on both Fusebox and Model-Glue. The most current version of Model-Glue is called Unity. In this version Joe Rinehart has added ColdSpring and Reactor into the Model-Glue framework.
One of the neat features of fusebox is the notion of lexicons. Lexicons let you add your own tags or verbs to the framework.
I was reading on MXNA that Dope Fly has some downloads that will let you add ColdSpring and Reactor Lexicons to Fusebox. Pretty Cool.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Sean Corfield had a posting on his blog about the Fusebox conference for 2005. Here is some additional information.
The 6th Annual Fusebox Conference is being held from September 29th to September 30th, 2005 at the Marriott Bethesda North Hotel in Rockville, MD.
There are more details at http://www.cfconf.org/fusebox2005/‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I got a question yesterday about how to just get the XML being returned from a web service call. SOAP Based web services use a XML standard syntax when the client communicates with a service. ColdFusion does a pretty good job of translating the return value into either a simple object, or a Java like serialized object.
I believe CF7 included some new functions for returning the XML used in the request and the response. Here is an example below;

ws = CreateObject("webservice",

"http://localhost/soapheaders/headerservice.cfc?WSDL");

ws.echo_me("hello world");

resp = getSOAPResponse(ws);
‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011This year I decided to run in the Gate River Run here in Jacksonville. The race is a 15k (9.4 miles) race with some 11000 runners. I have never run a race like this before, but I would up finishing in 1:36. I was pretty happy with my 11 minute mile, but I saw that some of the runners averaged 4 minute miles. Frankly, I was just happy to finish.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Here is a simple way of getting rid of duplicate records in a SQL Server table. This comes up frequently when a customer gives you bad data. You can clean this up in temp tables before adding it to the actual database.
DELETE temp_Table  
WHERE SOME_UNIQUE_CODE IN (SELECT SOME_UNIQUE_CODE
FROM temp_Table
GROUP BY SOME_UNIQUE_CODE
HAVING COUNT(SOME_UNIQUE_CODE) > 1)
AND tempPrimaryKeyID NOT IN (SELECT MIN(tempPrimaryKeyID)
FROM temp_Table
GROUP BY SOME_UNIQUE_CODE
HAVING COUNT(SOME_UNIQUE_CODE) > 1);
GO

So by using the HAVING clause, you can check for a count greater than one on the column that has been duplicated using the COUNT() aggregate function. You can then filter out the records you want to keep by using the MIN() aggregate function on the column that is truly unique.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011The big Google news today is that they released a spreadsheet program that runs on web browsers. The Outer-court has a nice over view of the new Google spreadsheet program. It does not do everything that Excel does, but it does allow multi-user editing.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011There is a giant Spider bot net based SQL Injection attack going on right now. This has personally affected some friends of mine, and I have been reading about it on the CF-Talk list.
Unfortunately, there does not seem much that can be done about it other than to try to ride the storm out. I have not seen anything in the Tech press about this yet, but they seem to be a day late and dollar short anyways.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I just learned that a good friend of mine, Darren Bunn, has passed away.
It has been a reminder to me about how precious life is and how important it is to live life to its fullest. I believe Darren was only about 36 or 37 years old.
He will be deeply missed by his friends and family.
Update:
There is an Obit now on the Blount & Curry web site.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I have had a lot of fun playing around with some of the Google APIs lately. My favorite so far is the Google Map API. If you have seen the Google Maps maps.google.com.
Google Maps uses an AJAX javascript object to display Interactive map within a div tag. AJAX stands for Asynchronous Javascript and XML. The Javascript object can call back to the Google server to pull updated information without having to reload the whole page. Google requires that the page use pure xhtml code and that you have a Google Map key. You can get a key by going to this page at Google. Place the following script call in the head section of your html page.
"[http://maps.google.com/maps?file=api&v=1&key=YOURKEYHERE](http://maps.google.com/maps?file=api&v=1&key=YOURKEYHERE)"</font> type=<font color="BLUE">"text/javascript"</font>></font></font><font color="NAVY"><font color="MAROON">
Inside the body of the html page, place a div tag with the ID set to MAP. 
"map" style="width: 900px; height: 600px">
The next thing that needs to be done is to create a Javascript object based on the div tag.
var map = new GMap(document.getElementById("map"));
There are several different controls that can be placed on the map. For the control with the zoom slider, you will need the large control.
map.addControl(new GLargeMapControl());
The map is centered using a what is called a gpoint and the zoom level. The code looks like this;
map.centerAndZoom(new GPoint(-81.48125, 30.30912), 2);
The Gpoint is based on Geocodes, which is a decimal version of Latitude and longitude.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Google just opened their calendar application to public beta. I have been playing around with it this morning, and once again Google is making good use of Ajax on this site. There is a link to it here at Google's beta site.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I have been reading a lot of negative comments today about the new Google Finance site that Google added today. I guess Google is starting to loose some of their mind share.
I like Google Finance so far, but mostly because of the technologies that they are using to implement this new site. Google Finance makes heavy use of Flash widgets and AJAX. The Stock chart is linked to the headlines, so if you select a sudden drop in the share price, the headlines change to correspond to the dates of the drop. Very cool!
I have been giving Google a hard time about some of their business decisions, but I think they deserve credit for their engineering. It is nice to see that Google is using Flash.
On that note, I am giving a presentation on AJAX at the next JaxFusion user group meeting.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I try to avoid making statements if I can get away with it, but I am making an exception in this case. I have been using Google Adsense since last year.
Google just made a "Business Decision" to launch the chinese version of their search service, google.cn. One of the things that they had to do was to censor their search results in order operate in China. I do not oppose any person or business who wants to do business in China. I just bought a racing shell that was partially manufactured in China. I do oppose censorship and hypocrisy.
Google's moto is "Do no evil". Censoring information because it contains words like "Freedom" or "Democracy" is evil.
This is why I made a "Business Decision" to no longer use Google Adsense. I am not sure if I will replace the advertising with something else.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Google has really got itself in a mess over the news.com lockout. There is another article in wired.com about what a poor decision this was by Google.
When your moto is "Do No Evil", then it really looks bad to pull this kind of stunt.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Google Talk was released today. This is HUGE! AOL, YAHOO and MSN have dominated the IM space for years. I have heard from users that if Google released an IM client, they would use it over AIM or MSN messenger.
That being said, what is really important about this is that Google Talk uses Jabber. Jabber is an open standard for Instant Messaging. If Google Talk takes off, it will acheive something that corporate IT departments have wished for for years, a standard IM protocol. Linux and Mac users can use this service with their IM clients because it is uses Jabber. I was able to sign up last night using my iChat AV client because Jabber is a supported protocol.
ColdFusion Event Gateways also supports the Jabber protocol. Expect to see a lot of application using this Google Client. I know I will be writting some in the near future.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Just read were Google Talk works with Gizmo, the voice over IP client.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Guy Kawasaki recently started a business blog. He had a really interesting post on the Art of Firing. I have been in the unpleasant position of having to let someone go, and it is never easy. Guy has some great tips on how to fire properly.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Google has added the abilty to search blogs. They are going to actual blog ping sites to gather their rss feeds. In their FAQ, they said they will add a form to submit your rss feed manually.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I am a big fan of open standards. One of the things that has prevented me from upgrading to a HDTV and a new high def player is that lack of a high def format standard.
There have been two camps for the last couple of years for high def video players, Toshiba's HD-DVD and Sony's Blu-Ray. This past weekend Warner Brothers anounced that they were going drop support for HD-DVD and go with Blu-Ray exclusively. I read today on engadget that Paramount was switching to Blu-Ray. That leaves only one major studio behind HD-DVD, that being Universal, and I am sure Universal will drop support as well.
I have not purchased one of these players yet because I did not want to get Betamaxed. I will probably buy a Blu-Ray player now, I am even thinking about getting a Play Station 3.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 20112007 has been an exiting year for me because of many changes in my life. The ColdFusion 8 launch was very exiting and has been successful for Adobe. I wish I had more time to devote to the JaxFusion user group this year to cover all of the new features.
I also started a new job working as a technical consultant. I did that to get more hands on experience using the BI features in SQL Server 2005. I also have had the opportunity to work with Microsoft Sharepoint and .NET this year. It has been great to learn new things related to these other products.
I just wanted to wish everyone a happy and safe new year.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011With the New Year fast approaching, I wish everyone a Happy Holidays and Happy New Year.
I have not bloged this much do to my schedule, but one of my New Year resolutions will be to blog more.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Andrew Fryer uses a neat technique to create a Heat Map in SSRS 2005. Read more about it at his blog. Thanks to Buck Woody for passing this along.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011A while back I asked if there was anybody doing a ColdFusion podcast. Hal Helms and Jeff Peters have a podcast covering FLiP, the Fusebox Lifecycle Process. I have seen Hal and Jeff speak at several different user group meetings and software conferences. They are both great speakers.
You can find there podcast at www.helmsandpeters.com.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I recently came across the following error testing a web service call using ColdFusion MX.
Error Could not generate stub objects for web service invocation.
It was followed by a name and the following message; java.net.ConnectException: Connection timed out: connect It is recommended that you use a web browser to retrieve and examine the requested WSDL document for correctness. If the requested WSDL document can't be retrieved or it is dynamically generated, it is likely that the target web service has programming errors.
Basically what this means is that the application server can not connect to the server hosting the web service or the wsdl file.
The reason for this error was caused by a host header file that caused a conflict on the application server and the DNS server. Swapping out the domain name with the actual IP address can fix this sometimes.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Adobe is starting their marketing push for Apollo. From what I have read, Apollo is a combination of different technologies, including the new Flash player 9, PDF, Flex, HTML and disconnected as well as connected services. The last four years I have worked at companies that are Application Hosting Providers. In simple terms they have created web applications, and they lease the application to customers. Salesforce.com is a perfect example of an ASP. Not just because of their success as an ASP, but also because of the problems they have had as well. Since they provide a web based application, the customer depends on a maintained internet connection between their browser and the hosted application, not to mention that Salesforce.com's servers are up and running. Salesforce has had some service interruptions the have been widely reported in the news.
Most ASPs have service license agreements with their customers that guarantee 98% or better uptime. The problem is if you try to access the application during the 2% downtime.
One of the great things about Macromedia Central was the concept of a "Disconnected Application". This is an application that makes use of an internet or network connection, but if the connection is broken, the application will still run. The application can take advantage of cached data, and once the connection is restored, the data can be synced between the server and the client.
Since Central used Flash as the basis for the content, it is lightweight and easily deployable over the internet. Apollo is similar to Central since it does not depend on a live connection in order for application to run, but uses additional technologies such as PDF and HTML.
One of the criticisms of Java is that it never really made it as a desktop environment for running applications, but it has become very popular as a portable server environment. Improvements have been made to Java on the desktop, but there are competing frameworks for GUI development, and incorrect perception (IMHO) that it is slow. James Gosling recently wrote on his blog about this, and admitted that one of the areas that SUN was working on was improving load times for J2SE.
One of the things I like about Flex is that you can build components in ColdFusion or Java that can be used as remote objects or web services inside of a Flex application. You can leverage your company's current Service Oriented Architecture (SOA) as the backend for Flex.
I believe since Apollo already uses technologies that are popular and universal on the desktop (Flash, PDF and HTML), and that run in all of the popular OSes (Linux, Windows, Mac OS X), it can become the front-end technology for Java. I would not be quick to dismiss Apollo. It deserves a good look as a solution for thin client based disconnected applications that can connect to your enterprise. I look forward to seeing examples from Adobe on their lab web site soon.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Last week in Califiornia, and in other parts of the country students protested tuition hikes and budget cuts in their colleges and universities. In California where the state has a $20 billion budget shortfall, the students there protested by holding up traffic.
I am a firm believer in the First amendment, and for the rights of Americans to peaceably assemble. One of the goals of a protest is to sway people to your point of view. Holding up traffic does not achieve this goal. It turns people against you and your argument.
Traffic in California is already pretty bad. Running out into traffic on Interstate 80 just makes it much worse, and will turn the public against you and your argument. There are much more affective ways of protesting. Holding up traffic just makes the public think you are a narcissistic brat.
I would suggest actually looking at the state and school budgets, and making suggestions to you local state representives on how your tax dollars should be spent.Tags: Legal   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I found a really good post on how to set up Sharepoint Server to host the 'My Site' function on CHris Johnson's blog.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Charlie Arehart suggested to me over a year ago that I put a sound up on my web site so people can hear how my last name "Fekke" is pronounced.
I decided to create a small Flex application to play back the audio of how to pronounce my last name. Here is the link to the page on my web site where I keep the audio of my last name. This is actually the first Flex application I have put on my web site. I hope to put more up there soon.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I am working on project to migrate some existing DTS Packages that were created in SQL Server 2000 over to SQL Server 2005. I have been trying to use SQL SMO, which is the prefered Microsoft way to script and program SQL Server. SMO does have a way to import SSIS packages to SQL Server 2005, but it will not work with the older DTS packages.
Buck Woody at Microsoft pointed me in the right direction on how to get this working. SQL DMO is the old COM library for scripting and programming SQL Server. The SQL DMO library still works with SQL Server 2005. I created a C# app to import a SQL Server 2000 structured storage file into the 2005 server.
The first thing I did was add a reference for the Microsoft DTSPackage Object Library in the list of COM objects.
I then used the following code to import the DTS file into the SQL Server;

string package = @"C:\DTSTest\ImportSample.dts";
object pVarPersistStgOfHost = null;
DTS.Package myPackage = new DTS.Package();

myPackage.LoadFromStorageFile(package, "", null, null, null, ref pVarPersistStgOfHost);
myPackage.SaveToSQLServer("10.25.15.0", null, null, 
DTSSQLServerStorageFlags.DTSSQLStgFlag_UseTrustedConnection, 
null, null, null, ref pVarPersistStgOfHost, false);

You will need to add some additional code to unmarshall DTS.Package object.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Thanks to James Ahrens for sending this to me;
You Might Be a Redneck Pilot If:
1. Your stall warning plays DIXIE.
2. Your cross-country flight plan uses flea markets as checkpoints.
3. You think sectionals should show trailer parks.
4. You've ever used moonshine as AV-Gas.
5. Your 172's wheel pants have mud flaps with a chrome silhouette of a reclining
nude.
6. Your toothpick keeps poking your mike.
7. You've ever taxied around the airport just drinking beer.
8. You wouldn't be caught dead in a Grumman Yankee.
9. You use an old sweet mix sack as a windsock.
10. You constantly confuse "Beechcraft" with "Beechnut."
11. You've never flown a nose-wheel airplane.
12. You refer to formation flying as "We got us a convoy."
13. Your matched set of lightweight flying luggage is three grocery bags from Piggly
Wiggly.
14. You have a gun rack in the rear window.
15. You have more than one roll of duct tape holding your cowling on.
16. You figure mud and manure in your weight and balance calculations.
17. You siphon gas from your tractor to go flying.
18. You've never landed at an actual airport even though you've been flying
for over 20 years.
19. You've ever ground looped to avoid hitting a cow.
20. You consider anything over 500-ft AGL as High Altitude Flying.
21. There are parts on your aircraft labeled "John Deere."
22. You don't own a current sectional, but have all the Texaco road maps for
your area.
23. There's a brown streak down each side of your airplane; exhaust on the
right side and tobacco on the left.
24. You have to buzz the strip to chase off the livestock before landing.
25. You use an old parachute for a portable hanger.
26. You've ever landed on Main Street for a cup of coffee.
27. The tread pattern, if any, on all three of your tires is different.
28. You have a pair of fuzzy dice and some small copper shoes hanging from the
Magnetic Compass.
29. You put straw in the baggage compartment so your dogs don't get cold.
30. You've got matching bumper stickers on each side of the vertical stabilizer.
31. There are grass stains on the tips of your propeller.
32. Somewhere on your plane, there's a bumper sticker that reads "I'd
rather be fishing."
33. You navigate with your ADF tuned to only AM country stations.
34. You think an ultra light is a new sissy beer from Budweiser.
35. Just before the crash, everybody on the UNICOM heard you say, "Hey Y'all-Watch
This!"
36. You use your airplane for camping.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Leif Wells asked if I would edit my previous blog post on how to invoke the ImageWatcher CFC. The CFC is actually invoked by the Event Gateway. A new Gateway instance needs to be created in the ColdFusion Administrator. To create a new instance, click on the "Event Gateways" link, then on the "Gateway Instances". This will the ability to add or edit a new Gateway Instance. A new Instance requires a Gateway ID, Gateway type (DirectoryWatcher), CFC path (path to my ImageWatcher CFC), and a reference to the Configuration File.
The configuration file tells ColdFusion which folder to watch, the interval, and which functions to call for the directory watcher. Here is an example of a config file;
directory=c:[\\images](\\images)  
 interval=10000  
 extensions=jpg,jpeg  
 addFunction=onAdd
You can also use functions for onChange and onDelete.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I am going to the Darkside, well sort of.
Today is my last day at Vurv Technology, the company I have worked at for the last two and half years. It was extremely tough to make the decision to leave, and it has been adventure working here at Vurv.
I have decided to take a job with a company that specializes in Microsoft technologies. My new role will be working with Business Intelligence technologies in SQL Server 2005. I will also be doing some .NET development as well. The work I have been doing for the last three years has been related to business to business integration. A lot of my experience has been using ColdFusion to build these integrations, but we have also used SQL Server DTS as well as SSIS to accomplish these tasks.
I will be posting more details about my new job in the next couple of weeks. Part of my new job will be doing consulting. I look forward to continuing to support the ColdFusion community as well as the SQL Server/.NET community.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Calvin Ward, the manager of my local ColdFusion User Group, put a very elegant page onto our User Group website about the disaster in the Gulf States with Hurricane Katrinna.
He has links on that page that will allow people to donate to the different NGO that are aiding in the relief effort.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I was walking through San Marco towards 1st Place Sports Friday afternoon, and I got stopped by a reporter. He asked me what I thought about a state proposal to add advertising to license plates to lower the cost of tag renewals. Here is my response;
http://www.news4jax.com/video/22759848/index.html
Here is a link to the story on the News4Jax web site;
http://www.news4jax.com/news/22759976/detail.htmlTags: Misc   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I ordered the Apollo Flex Developers pocket guide from O'Reilly books when I read about it on Mike Chambers' blog. It finally arrived yesterday in my Mailbox.
I have not had a chance to read the whole yet, but it is a pocket guide, so it should not take long to read. Thanks to Mike Chambers, Robert Dixon and Jeff Swartz for writing the book.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I just picked up my new MacBook Pro this morning. This is my first Mac based laptop, even though I have owned and worked with Macs since the 1980's. This is also my first Intel based Mac, so I look forward to start playing with the multiple operating system support.
I purchased Flex builder earlier this year, and I plan on moving that over from my desktop to my MacBook. I plan on installing ColdFusion and MySQL on it as well.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I have been writting HTML before Netscape released their first browser. I was very exited when the first Netscape browsers came out because the used the table tag.
This marks the tenth aniversary of the first Internet Explorer browser. Microsoft was late to the game, but they worked very hard to make it a better browser than the netscape browser. Many of the web developers I worked with gave up writting their code so it would work with both browsers. IE quickly surpassed Netscape as the most common browser.
I certainly started to write my code so that it would correctly on IE first, and I would check that it worked on other browsers and operating systems.
I jumped on the IE bandwagon for a couple of reasons. That was because they made it easy for developers to write for their browsers, and they supported open standards.
With that, I would like to say, "What have you done for me lately?" It is almost like Microsoft has droped the ball. I still write my code so it will run on IE browsers, but I also make sure it runs in Mozila and Safari. I also test my HTML on Windows, Linux and Mac OS X computers. I believe that IE still holds around 90 percent market share.
Hopefully Microsoft will catch up and embrace open standards again, but I am not holding my breath.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I guess I am not cool enough for a Pownce invite. If anyone has an extra Pownce invite, I would like one.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I upgraded my PC to IE7 today. One of the sites I like going to is Digg.com. It seems to take a really long time to display this site, and sometimes it fails to display the site with the CSS. I guess I will continue using Firefox as my primary browser for my PC for the time being.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I think the Anti-phishing support that has been added to IE is a good thing. There is a noticeable lag in pages loading over slower connections. This is a feature I will turn on my Mom's computer. I did a test pulling up a web site that was in one of the numerous phishing emails I get everyday, and it prompted me with a phishing warning.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Greg at point and pay is in need of two ColdFusion developers ASAP. Here is his messsage to the Tampa CF Jobs list.
"We are in dire need of at least some temporary
help for the next few weeks. Anyone with some free time the next 2-3 weeks, give us a shout at jobs@pointandpay.com. We'll make it worth your while."‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011If you are curious about some of the new features in CFMX8, Ian Smith posted some of the new features that Ben Forta presented on last night in Seattle.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011My current employer, Idea Integration, is looking for candidates with
Microsoft SQL Server Integration Services (SSIS) ETL and Database Developer experience. Here is a description below; Job Description
Under minimal supervision, the ETL developer will be responsible for interpreting and creating mapping documentation and translating it into detailed design specifications and ETL code via SQL Server Integration Services (formerly known as DTS). This person will be responsible for all ETL aspects of data warehousing/data mart applications, and data quality. They will be responsible for a mix of new development, production support, and managing data quality. In support of ETL development they will analyze, develop, test, and implement database as well as perform data modeling and logical and physical database design. They also will assist customers in researching data issues and problem solving.
Essential Functions
Design, develop, code, test and maintain SQL Server Integration Services (SSIS) packages that perform Extract Transform & Load (ETL) processes. Design and code the ETL logic to enable initial load and incremental processing, error and exception handling, restartability and recovery, data cleansing, validation and monitoring. Create documentation of ETL process flows, ETL technical designs, and specifications. Create, expand, and optimize ETL jobs based on ETL specifications driven by changing business requirements. Write database procedures, functions and views to optimize ETL processes. Coordinate source data feeds to ETL targets. Develop, document, and execute test plans. Plan and implementing data integration processes for multiple source systems. Identify and resolve problems encountered during both development and release of ETL systems. Analyze and implement enhancements to ETL and database systems.
Desired Skills
Extensive experience with Microsoft Data Transformation Services (DTS - SQL Server 2000) and/or experience with SQL Server Integration Services (SSIS - SQL Server 2005) are required. Minimum 3 plus years of SQL Server development skills including creation of tables, views, stored procedures, and user defined functions is required. Experience documenting ETL requirements and designs required. Must have experience tuning and optimizing queries. Candidates must have excellent interpersonal and communication skills, professional appearance, and a stable work history. Previous experience working as a consultant preferred. Experience with data warehousing preferred.
Please contact joe dot salvatore at idea dot com.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I was interviewed today for the webdevdesign Podcast. I do not know if I will make into the final broadcast, but listen in just in case.
Their show covers a host of different issues relating to web development.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I am in San Jose, CA for the Adobe Managers Summit. This is my first time in Silicon Valley. The last time I was in this area of california was about 16 years ago.
The first and last days of the summit include Flex training. I am looking forward to using Flex in my future applications. I already have several planned that could benefit from rich internet front ends.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011John Lyons, a friend and co-worker of mine has figured out how to install CFMX 7 on the fedora core. He will be posting to this blog soon with instructions on how to configure CFMX and Apache 2.0.
It is tricky, but you can get it to work by manually configuring the connector to Apache. Macromedia does support CFMX with Red Hat, but not the Fedora core. Fedora is meant to be more expiramental than the standard Red Hat distro.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Apple just announced its "Professional" image editing program, Aperture. It is designed for professional image editing. So how does it compare to PhotoShop? The answer is it is very lame compared to PhotoShop.
Aperture does not allow you to do any actual retouching, even though Apple says you can in their marketing. There are no cloning or paint tools. The only editing that Aperture lets you do is make tonal and color changes in a nondestructive way. Photoshop has allowed for this for over seven years now.
The one thing that Aperture lets you do that is pretty cool is that it uses Apple's Core Image API. The Core Image API is Apple's underlying image processing using the Quartz imaging engine. Adobe has always used their own engine for image processing. This may give Apple some speed advantages.
The price tag is steep at $499.00 US. For 100 bucks more, I would just buy a copy of PhotoShop.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Thanks to everyone who came out to Jax Code Camp this last Saturday. Attendees from my presentation on jQuery and .NET asked if I would post my slides and code on this website. The slides can be downloaded from this link. I have also posted a copy of the example code I used during my presentation. I also used Phil Haack's example of using jqGrid and MVC together.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I will be giving a presentation on jQuery 1.4 this Saturday at the Jax Code Camp. This is the sixth annual code camp here in Jacksonville. This years camp will be held at the UNF campus. There are seven tracks this year. I hope to see my blog readers there.Tags: Microsoft   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Google's moto is 'Do no Evil'. I was reading an article today in the San Francisco Gate about how Google employee's are banned from talking to News.com reporters for a year.
I am not a big fan of the term 'Evil Corporation', but I think that Google does some things that can be considered unethical. The News.com piece showed how you can look up personal information using Google. For the example in the article, they used Google's CEO. I guess he did not like his just desert.
As you have propably noticed I run Google ads on my web site. Just so people do not think I am trying to bite the hand that feeds me, Google does a lot of things I like. I use their Search engine everyday. I also use some of their APIs as well. On that note, I think Eric E. Schmidt is great guy!‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I ran into an issue this morning using a JQuery selector filter. One of the things I like about JQuery is that they have some pretty cool filters that you can use to specify different parts of your DOM.

jQuery("table tr:first"); // This will select the first row.

jQuery("table tr:last"); // this will select the last row.

I was trying to select all cells that were blank or empty so I used the following;

$("#myIDName td:blank"); //Find all in table.

This worked fine in Firefox, but created all kinds of Havoc. I do not believe this is officially supported by the JQuery group.
I was able to solve the problem using the following change to my selector.

$("#myIDName td:empty");

I am assuming that blank has been deprecated or was never fully supported, either way you should just use the :empty filter.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011The Jacksonville Code Camp location has been moved to the East Pointe Church on Kernan Blvd. just north of Atlantic Blvd. The Venue change is due to Tropical Storm Fay.
The address for the East Pointe Church, 270 North Kernan Boulvard, Jacksonville, FL 32225. Please spread the word.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011The JRC Weather app has just been updated to version 1.0.2. We have added iAd advertisments, as well as a new load screen and a map to our rowing site.
Click this link to download the application. If you have already downloaded the application to your iPhone, you should get a notice to upgrade your application automatically.Tags: Web Services (SOAP)   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I am involved with the Jacksonville Developers User Group, and I am helping plan the upcoming jaxcodecamp. I have herd from some of the members planning the Code Camp that there is some interest in a COCOA Special Interest Group. COCOA makes up the set of APIs that are used to program the Mac OS X and the iPhone.
Let me know if you are interested in the a COCOA SIG if you live in the Jacksonville area.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011The Jacksonville Code Camp needs sponsors. The Code Camp is a free event for developers now in its forth year.
Sponsorships can be as low as $25.00. The code camp needs to raise $10,000 for the entire event.
This years camp should be very good, because there will be tracks for .NET, Java, Ruby, Flex and ColdFusion.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011The Jacksonville Code Camp website has updated the Sessions that will be available. If you have not registered to attend, go ahead and do so before the event fills up.
Also, if you would like to see more Flex/Air/ColdFusion presentations, let the organizers know. The Code Camp will be held August 23rd, and it is free to anyone.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011The Jacksonville CodeCamp is this Saturday at the FCCJ Advanced Technology Center campus in downtown Jacksonville. I am going to be giving a presentation on Excel Services, and how to integrate them into your applications.
I went to the Code Camp in Tampa last month. These are great events because they cover a broad range of different Microsoft technologies. This year their are a lot of sessions on SQL Server 2005 and Rich Client Apps.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I went to the annual Jacksonville codecamp here in Jax this past weekend. This was a free Microsoft event. There were several presentations on SQL Server 2005 and N-tiered Architecture that I attended.
Microsoft recently had a codecamp in the Tampa Bay area as well. If Microsoft is having one in your area, this well worth the day. We use .NET for some internal applications at my present job. Even if you do not use .NET, there were many other compelling technologies that Microsoft was showing off. Some of these were SSIS, analysis services, the Atlas Ajax library and Biztalk server.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011The Jacksonville - North East Florida CFUG is having a meeting this Tuesday, October 5th. The meeting will start at 6:30 PM. Mike Collins is presenting on processing PDF forms using ColdFusion. He will also be reviewing the new CF Wack, and giving away a new copy signed by Ben Forta. Here is a rundown of the meeting agenda;

Introductions
Go around and get everyone's input on how to make group valuable
ColdFusion, Flex and AIR in Jacksonville - who is using it? Hosting Companies, Training facilities, Companies, Colleges etc
Mike Collins 30 minutes - Using CF and PDF Forms. I will walk thru how to create form based PDFs and then have them submit to CF for server side processiong.
Book review - ColdFusion Web Application Construction Kit (Ben Forta and RayCamden)
Raffle signed copy of CF Wack to attendees (Signed by Ben)
Plan Next 2 meetings
After the meeting meetup - someone suggest a spot for a beer

Here is a map to the meeting. I hope to see you there on Tuesday. The location is the Venture Plex.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011From Brian Knight:
The Jacksonville SQL Server Users Group will begin meeting again on June 27th (4th Wednesday of the month) at 6pm. We'll be meeting at the Modis building downtown in the auditorium on the second floor. As always, the meetings are free so please pass this around to your crew. Please RSVP Brian Knight if you haven't already if you're interested in coming so we can buy enough food and below you'll find all the details: Time: 6/27 at 6pm-about 8pm
Giveaway: Full copy of Vista Ultimate to a lucky winner. 38 people will receive a copy of SQL Server 2005 Management Studio book ($30 value).
Topics:


Performance Tuning SQL server Integration Services This 400-level session will dive deep into some techniques for performance tuning SSIS. This session was a session given at TechEd 2007.


There will also be a informal session on career development and lots of time for networking with others in the community. Pizza and drinks are provided and the event is free as always.


Plenty of time for networking and meeting other database pros in the community.


Location:
Modis Building (Downtown Jacksonville)
1 Independent Dr. , Main Auditorium (2nd Floor)
Jacksonville, FL 32202
Phone: 904-360-2700
Parking is located directly across the street at the Landing or a much larger 9 story garage is available on Bay Street. Street metered parking is also free after 6pm also. It's important to note that some parking lots downtown may not take credit or debit cards (cash only).
Directions:
http://local.live.com/?v=2&sp=Point.p1mscz85vmtt_1%20E%20Independent%20Dr%2C%20Jacksonville%2C%20FL%2032202%2C%20United%20States___&encType=1
Please RSVP at bknight@sqlservercentral.com so I can order enough pizza.
Jacksonville SQL Server User Group new website is at http://www.jssug.com!‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011This Friday will be Microsoft's SQL Server 2008 coming out event in Jacksonville. The Jacksonvile SQL Server Users Group is promoting the introduction of SQL Server 2008 this Friday, September 12th at the Modus building in downtown Jacksonville.
Here are the details;
Join us next week on Friday, September 12, 2008, for a one day deep look at the new features of SQL Server 2008 as we celebrate the launch of the latest version. This free event will be located at the Modis Building, 1 Independent Dr, Jacksonville, FL. We'll have 15 sessions across two tracks on SQL Server 2008 and other supporting technology. Downtown, there is a fee for parking that ranges from $5-10 depending on the parking location you select. Breakfast and lunch will be provided by our event sponsors. This event is being coordinated by members of the Jacksonville SQL Server Users Group ( http://www.jssug.com ), Idea Integration, Modis and Pragmatic Works.
There are only about 250 seats total and we already have 200 registered so please get your seat quickly by registering at http://www.sqlsaturday.com/eventhome.aspx?eventid=10 . Below, you can find some of the sessions that will be at the event. Thanks and we look forward to seeing you there!‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Jason Delmore, the new product manager for ColdFusion showed off some of the new features that will be in next version of ColdFusion mX, code named Scorpio. Jason showed off some of the features that integrate with other Adobe technologies. One of these features was a new CFPDF tag that integrates with Adobe LiveCycle.
He also showed off a feature that dynamically generate breeze presentations from ColdFusion. This will use a CFPresentation tag. Some of the features include the ability to add mp3 audio files to your presentation.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I have been listening to the Java Posse podcast recently. They cover general Java news and Java information. They also have some excellent interviews with industry VIPs.
If you are using iTunes, you can use the following link to add them to your list of podcasts.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Tim Buntel stepped down recently from the senior product manager role at Adobe. Tim came and spoke at my user group in Tampa when ColdFusion MX was first released. He is defineatly leaving some big shoes to fill at Adobe.
Adobe announced yesterday that Jason Delmore is the new senior product manager for ColdFusion. Jason previously worked for a company that is a competitor of the company I work for now, so needless to say, I am glad he is working at Adobe now.
Good luck Jason!‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011The planning has begun for the next Jacksonville Code Camp. The next code camp will be this August at the UNF campus. If you are not familiar with the Code Camp, it is a free one day development conference put on by the local development community.
One of the things we tried to do last year was to have differing development technologies presented on at the camp. We had a presentation from the Ruby Jax group, as well as several presentations on Adobe Air and Flex.
The conference is still looking for speakers and volunteers. If there is a subject you would like to present on, please submit your presentation subject at the web site.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011My software update feature on my older Mac showed that I had downloaded Java release 6 for Mac OS X 10.4. I got really exited until I read the release notes;
This release of Java for Mac OS X includes improvements for Java 2 Platform, Standard Edition 5.0 (J2SE 5.0) and Java 2 Platform, Standard Edition 1.4.2 (Java 1.4.2) on Mac OS X. It features Apple's implementation of Sun's J2SE Versions 1.5.0_13 and 1.4.2_16.
It looks like this is a series of security updates. Before Leopard was released Apple had a prerelease version of Java SE 6 on their developer site, which they took down earlier in the year. I had hoped that Apple would release Java SE 6 with Mac OS 10.5, but I was let down when it was released to find it only had Java SE 5.
Apple is known for its secrecy when it comes to releasing new products. I can understand that when it comes to certain products and software. The problem comes when you are trying to develop for a platform. Developers have to have SDKs, APIs and the other tools so they can start to develop for the platform before it is released.
Right now the silence coming from Cupertino is deafening. Apple should come out and say if they are going to continue to develop Java on the Mac so developers can start planning what technology they need to use in their future products.
I have liked Java because I could write applications that can run on any platform, whether it was Linux, Mac or Windows. If Apple is not going to develop Java on the Mac anymore, Sun needs to start developing future versions for the Mac like they do for Windows.
In the mean time I am going to start taking a harder look at Adobe Air and Microsoft Silverlight as alternatives.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011From the Jacksonville SQL Server Users Group;
April JSSUG Meeting Wednesday 16th at 6pm (From jssug.com)
JSSUG will be meeting Wednesday at 6PM at the BOA campus.
Where: "Driftwood" room (2nd floor) in Building 500, Bank of America, 9000 Southside Blvd: Map and Directions
Topic: SQL Server 2008 T-SQL Enhancements
This intermediate session by Plamen Ratchev, will focus on some of the T-SQL enhancements in SQL Server 2008 like the new MERGE functionality. These enhancements can cut your coding significantly and can run much faster than SQL Server 2005. Those that came to Plamen's last session requested to see him again.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I attended the JaxFusion meeting last night. We had it at the Deerwood library. We discussed what topic CF developers would like to have presentations on at future meetings. Are next meeting will be next month, but I think we may try to find a new location. The library closes right at 8:00 PM.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I attended a Microsoft sponsored codecamp in Jacksonville, FL today. If you have one of these in your local area, I highly suggest attending. They covered all of the .NET 2.0 stuff as well as VS.net 2005 and SQL Server 2005.
We use SQL Server at my present job, and I am a big fan of DTS Packages for performing data tranformations for exporting and importing data. Microsoft has completely rewritten this tool as a Visual Studio tool called SSIS (SQL Server 2005 Integration
Services).
You can use conditional logic to handle failures and loop through transformations. This can all be done from a Drag and Drop GUI interface. It does support scripting with VB.NET.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011The JaxFusion user group meeting is today at 6:30 PM. The meeting will be on the new release of ColdFusion 8. I have a lot of giveaways for this meeting.
The meetings are held downtown in the Modis building on the second floor in conference room B. The address is on the website.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011The JaxFusion user group is having its next meeting this Monday. Here is a description of the meeting;
This meeting we will be discussing JaxFusion and how it can best meet the needs of the Jacksonville ColdFusion User Community going foward. JaxFusion has been in place for a year and a half now and has had some great speakers and events, and the coming years can even be greater!
This will be an open forum to express what you'd like to see JaxFusion provide for the community as well as how you might be willing to assist in improving and developing JaxFusion into a top notch User Group Community. We look forward to seeing everyone visit with some creative and fun ways to improve JaxFusion.
For details, click on the this link.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011The next JaxFusion User Group meeting will be held on April 4th at Vurv Technology in Jacksonville.
The presentation for this meeting will focus on using Ajax with ColdFusion. Here is a map to the new meeting location.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011The next JaxFusion User Group meeting is this Tuesday at Vurv Technology. We will have a small recap of the CFUNITED conference as well as a presentation on the Spry framework.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011The JaxFusion user group meeting will be having their next meeting on May 2nd at 6:30 PM at Vurv Technology in Jacksonville. The presentation will cover new features in Flex 2.0, and how to integrate ColdFusion MX 7 with Flex.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Mark you calendars for the next JaxFusion meeting. Tuesday's meeting will be covering how CSS can be used for re-skinning Flex content. We will also be going over the topics that were covered at the Miami Flex Camp.
We will still me meeting at the same location, but the company, Southwest Signal, has changed their name to Xorail.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011The JaxFusion User group will be meeting November 7th at Vurv Technology in Jacksonville. The topic will be on Web Services and new web service features in ColdFusion 7.
The meeting will start at 6:30 PM. It will be the last meeting of the year where there is a presentation.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Tomorrow will be the first meeting of the year. John Lyons will be presenting on FlashMX sprite sheet animation. The JaxFusion user group will have a large number of meetings this year on Flex and Flash based topics.
The meeting will start tomorrow at 6:30 PM at Vurv Technology.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I will be doing a presentation tonight for the JaxFusion User Group tonight at Vurv Technology. The meeting starts at 6:30 PM ET.
The presentation will have a comparison of the Fusebox 5 framework and the Model-Glue framework. This presentation will also have a discussion on how these Frameworks compare to some of the other popular web application frameworks such as Ruby on Rails, Struts, and Django.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011John Lyons will be presenting tomorrow on the ColdFusion MX 7 reporting features for the JaxFusion user group. As always, there will be free pizza and giveaways at the meeting.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011The JaxFusion User Group will be meeting tonight at 6:30 PM at Vurv Technology. There will be two short presentations tonight on the CFUNITED conference and on the Spry framework.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011The JaxFusion user group is meeting tonight at 6:30 PM at Vurv Technology in Jacksonville.
I will be giving a presentation on XML features in ColdFusion MX as well as the StAX Java API. StAX allows ColdFusion and Java to process very large XML files.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011The JaxFusion user group is meeting tonight at Southwest Signal at 6:30 pm. The meeting tonight will cover Drag and Drop in Flex as well as Adobe AIR desktop Drag and Drop capabilities.
We will also be discussing some of the changes in Adobe, and the ColdFusion community.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011The JaxFusion user group is meeting tonight on ColdFusion and .NET interoperability.
The meeting will be held tonight at 6:30 PM at South West Signal.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011The Jaxfusion user group is having a presentation tonight on the Ext Javascript framework. The meeting starts at 6:30 PM at SouhWest Signal.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011This is a reminder that the JaxFusion user group will be meeting at Vurv Technology tonight at 6:30.
Tonight‚Äôs meeting will have a presentation on Flex 2. This presentation will have an overview of how to use Flex Builder 2, MXML and ActionScript 3.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Tonight we are having the first JaxFusion meeting at the new location at the Modis building in downtown Jacksonville. The meeting will be on the second floor in conference room A.
Tonights meeting will be on how to use ColdFusion with .NET and other Microsoft technologies including Exchange server. Some of these features are new to ColdFusion 8, but others can be used in the current versions of ColdFusion. I have a lot of swag to giveaway at tonights meeting as well.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Tonight is the night of the JaxFusion meeting. The presentation for tonight's meeting will be on how to integration of Flex/Air applications with ColdFusion.
Thanks to the folks at Southwest Signal for hosting the meetings. Here is a map to their office. See you tonight.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011The JaxFusion user group meeting is at 6:30 PM tonight at Vurv Technology. The presentation tonight will be on Ajax and CFAjax. This is the first meeting in several months, and we are expected a large turnout.
There will be free pizza and other giveaways available at the meeting.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I had the pleasure to watch a presentation that Raymond Camden gave at MAX this week on the ColdFusion application.cfc component framework.
Raymond amoung many other things is the creater of BlogCFC. BlogCFC is by far the most popular Blog software for ColdFusion and BlueDragon. My blog is running on this software, and as I told Ray at MAX the software I wrote for my blog before "sucked". Ray's is much better than mine, hence why I am using his code. Ray also told me he is trying keep tract of all of the sites that are using BlogCFC so he can list links to them on his site.
Ray's regular blog is a very good source for ColdFusion related information.
You can download the BlogCFC zip file here.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011The JaxFusion user group will be moving to downtown Jacksonville. I do not have the next meeting scheduled yet, but the meetings will be held at the Modis building in downtown Jacksonville. The meetings have been held at Vurv in the Deerwood parkway area, but we have decided to move to a more central location.
I want to thank Vurv for letting me have the meetings there for the last two years. I will have more details on the new location on the JaxFusion website soon.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011John Lyons will be presenting on FlashMX sprites at next JaxFusion meeting. This is the first in his <cf_gamer> series on Jan 9th, 2007.</cf_gamer>
John Lyons will be covering spritesheet animation and basic keyboard navigation in flashMX.
Future Topics will include Ismoetric views, Collision , Path finding and AI.
John is still trying to convince Adobe to add OpenGL to flash!‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011John Lyons will be presenting on Game development using Mono, Unity3d and Blender at the next JaxDug meeting.
Unity is an integrated authoring tool for creating 3D video games and interactive presentatons on Windows, Mac, Wii and iPhone platforms.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I was listening to the ColdFusion Weekly podcast a while back, and Matt Woodward mentioned that he worked on the Dean campaign. The Dean campaign was very innovative when it came to using the internet for their campaign.
Now all presidential and other national candidates use the internet for their campaigns. Nancy Pelosi has even posted videos onto YouTube. Unfortunately, local politicians and Judges do not use the internet. Local politicians and judges have a much greater affect on our lives than national politicians. Only two judicial candidates had websites. How hard is it for a city councilman to get a blogger account or post a video onto YouTube explaining their positions on issues.
Every local politician needs to have a website at a minimum. There is no excuse not to with sites like blogger and MySpace.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I just added a podcast pod to my blog last week. Right now I just have four that are related to ColdFusion and Java.
Java Posse
ColdFusion Weekly
Helms and Peters
ColdFusion Podcast
If there are any others, I would like to know if I am missing any?‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Kforce in Tampa is looking for a senior ColdFusion architect. If you are interested, please contact Nicole Stephenson ‚Äì nstephenson@kforce.com. The job description can be found below. Application Architect Job Summary:
The software architect leads the definition and implementation of the product software architectures. Product software consisting of user interface software and real time embedded software. In order to further improve the software engineering process a shift to the Unified Process is being made. In this environment we are looking for a software architect whose main tasks are to:


Participate in the complete software development cycle from requirements analysis to deployment of the product


Responsible for the software architecture of complex systems and/or services provided to the customer


Responsible for further development of the software architecture process


Enforce the compliancy with architectural processes for projects


Coach teams of software design engineers for planning, tracking and completion of the work within the agreed plan, using agreed methods and processes


Advise on and lead the implementation of new methods, tools or processes



Must Have:


Understand software development approaches e.g., object-oriented (OO), component-based


Experience with modern, iterative software design processes like the Unified Process


Excellent understanding of fundamental technologies;


o operating system/networking
o middleware
o security
o databases
o graphical user interface (GUI) toolkits


Demonstrated expertise in system modeling and tying architectural solutions to business requirements


10 years of IT experience with 3 to 5 years experience in an architectural role


Advanced knowledge of Cold fusion, SQL, Java, UML, XML, Search Techniques


Nice to Have:


Has demonstrated leadership skills


Good oral and written communication skills


Demonstrates strong time management skills


Stay current on newest technology and industry trends


Is capable to transfer knowledge to various audiences


Education

Bachelors in Computing Science
‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011The presentation I gave today on LINQ for SQL at SQL Saturday is up on my parent web site, Fekke.com.
This is a powerpoint file, but I originally did it as a keynote presentation. Most of the cool animation does not look as cool as it did in Keynote, but the information is all there.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Today is the last day to register for Jax Code Camp. The code camp is free, and will be this Saturday. Be there or be square.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I will be giving my Linq presentation tomorrow at the JAXDUG meeting. This presentation covers the basics of Linq for SQL. The meetings are held at building 500 at the Bank of America campus in Jacksonville. The meeting starts at 6:00 PM.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011When I lived in Daytona Beach about 17 years ago, there were some pretty famous murders. Konstantin Fotopoulos was tried and sent to Death Row for the murder of a hit-man he hired to kill his wife, and for planning the murder of a vagrant.
Fotopoulos just won a new penalty phase, and is off of Florida's Death Row.
I normally do not blog about this stuff, but it is not often I can scoop major news outlets.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Most of the blogs I subscribe to are from MXNA. It is a great source of information about server side programming and Flash rich client programming. I hope that my blog will become one of the blogs that people want to subscibe to on a regular basis.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I am expecting a lot of news today at the conference. I hop to post peridodically throughout the day.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I have never seen Joe Rinehart speak before, so I was curious to see his MVC presentation.
Some of his points from his presentation were that MVC is actually multiple design patterns, not just one. It combines three patterns, the Observer, Strategy and Compsite patterns.
The Strategy pattern allows developers to loosely couple their applications. The Observer pattern acts like a listener. The Composition pattern refers to a has-a pattern where an object can be built with smaller objects. The controller works as the observer pattern.
He then went into his Unity presentation. He did a demonstration with Reactor. Reactor uses the scaffold tag.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Steve Gustafsen has added the ability to subscribe and subscribe from his MXNA bot. This will work with Trillian or the Google Talk client. When updates to MXNA occur, a IM message will pop up with the lastest Macromedia developer articles.
Steve has instructions on how to do this on his blog.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I have been reading a couple of articles about Mac OS X running on x86 processors as a vmware disk image. If you have been living hole in the ground for the last couple of months, you might have heard that Apple is switching to Intel processors.
The development machines that shipped have the installer disk, and so people have managed to install Mac OS X without the machine level copy protection. My personal opinion about the move to Intel is that is about time.
As far as Apple selling the Mac OS for any pc, I think that is a bad idea. Apple is a hardware company, and besides that it is a lot easier to develope an operating system if you also make the hardware, rather than trying to make the Mac OS compatible with every piece of hardware out there.
I own a Mac, and do most of my development on the Mac. Mainly because I am fed up with viruses and spyware, but I have always owned a Mac since 1993.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Macromedia officially announced Macromedia Labs today. From what I can tell, this will be a web site much like Google Labs where developers can try out the latest stuff from Macromedia.
Macromedia is allowing developers to download ALPHA trials of the Flash 8.5 player and Flex Builder 2. FB2 is based on Zorn, and eclipse based IDE.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I am going to my first Macromedia MAX this year. I am looking forward to seeing all of the other developers there, who I have talked to, but never met in person.
I am hopinh to do a fair amount of blogging over what I see and hear at the conference.
If you see me there, look me up.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I asked a couple of days ago if anyone knew of a ColdFusion podcast. Macromedia actually has a podcast already for all Macromedia developers.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I decided to try to use Spry to make a SOAP based web service call using a ColdFusion CFC for the web service.
Spry 1.1 allows developers to make GET and POST method calls for DataSets. Here is an example I wrote that calls one of my quote web services;
"_-//W3C//DTD XHTML 1.0 Transitional//EN"__ "[http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd](http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd)">_ "[http://www.w3.org/1999/xhtml](http://www.w3.org/1999/xhtml)" xmlns:spry="[http://ns.adobe.com/spry](http://ns.adobe.com/spry)">  
   
 "Content-Type" content="text/html; charset=iso-8859-1" />  
 </font>Call Webservice<font color="NAVY">  
 "JavaScript"</font> type=<font color="BLUE">"text/javascript"</font> src=<font color="BLUE">"spry/includes/xpath.js"</font>></font></font><font color="NAVY"><font color="MAROON">  
 "JavaScript"</font> type=<font color="BLUE">"text/javascript"</font> src=<font color="BLUE">"spry/includes/SpryData.js"</font>></font></font><font color="NAVY"><font color="MAROON">  
   

</font></font><br>
var dsData = new Spry.Data.XMLDataSet(<font color="BLUE">"<a href="http://www.fekke.com/com/SpockWS.cfc">http://www.fekke.com/com/SpockWS.cfc</a>"</font>, <font color="BLUE">"/soapenv:Envelope/soapenv:Body/ns1:getQuoteResponse/getQuoteReturn"</font>, { method: <font color="BLUE">"POST"</font>, postData: '<?xml version=<font color="BLUE">"1.0"</font> encoding=<font color="BLUE">"UTF-8"</font> standalone=<font color="BLUE">"no"</font>?><font color="NAVY">&#x3C;SOAP-ENV:Envelope xmlns:SOAP-ENV=<font color="BLUE">"<a href="http://schemas.xmlsoap.org/soap/envelope/">http://schemas.xmlsoap.org/soap/envelope/</a>"</font> xmlns:apachesoap=<font color="BLUE">"<a href="http://xml.apache.org/xml-soap">http://xml.apache.org/xml-soap</a>"</font> xmlns:impl=<font color="BLUE">"<a href="http://com">http://com</a>"</font> xmlns:intf=<font color="BLUE">"<a href="http://com">http://com</a>"</font> xmlns:soapenc=<font color="BLUE">"<a href="http://schemas.xmlsoap.org/soap/encoding/">http://schemas.xmlsoap.org/soap/encoding/</a>"</font> xmlns:tns1=<font color="BLUE">"<a href="http://rpc.xml.coldfusion">http://rpc.xml.coldfusion</a>"</font> xmlns:wsdl=<font color="BLUE">"<a href="http://schemas.xmlsoap.org/wsdl/">http://schemas.xmlsoap.org/wsdl/</a>"</font> xmlns:wsdlsoap=<font color="BLUE">"<a href="http://schemas.xmlsoap.org/wsdl/soap/">http://schemas.xmlsoap.org/wsdl/soap/</a>"</font> xmlns:xsd=<font color="BLUE">"<a href="http://www.w3.org/2001/XMLSchema">http://www.w3.org/2001/XMLSchema</a>"</font> xmlns:xsi=<font color="BLUE">"<a href="http://www.w3.org/2001/XMLSchema-instance">http://www.w3.org/2001/XMLSchema-instance</a>"</font> ></font><font color="NAVY"><a href="SOAP-ENV:Body">SOAP-ENV:Body</a></font><font color="NAVY">&#x3C;mns:getQuote xmlns:mns=<font color="BLUE">"<a href="http://com">http://com</a>"</font> SOAP-ENV:encodingStyle=<font color="BLUE">"<a href="http://schemas.xmlsoap.org/soap/encoding/">http://schemas.xmlsoap.org/soap/encoding/</a>"</font>></font><font color="NAVY">&#x3C;/mns:getQuote></font><font color="NAVY">&#x3C;/SOAP-ENV:Body></font><font color="NAVY">&#x3C;/SOAP-ENV:Envelope></font>', headers: { <font color="BLUE">"Content-Type"</font>: <font color="BLUE">"text/xml; charset=utf-8"</font>, <font color="BLUE">"SOAPAction"</font>: <font color="BLUE">"<a href="http://localhost:8300/com/SpockWS/getQuote">http://localhost:8300/com/SpockWS/getQuote</a>"</font> } , useCache: false });<br>
dsData.startLoadInterval(<font color="BLUE">10000</font>);<br>
<font color="NAVY"><font color="MAROON">
<div id="Specials_DIV" spry:region="dsData">
Episode: {episode} 
{quote}
Stardate: {stardate}

<input type="button" name="Do something" value="Get Quote" onclick="dsData.loadData();" />


The trick to getting this to work is setting the header attribute for the XMLDataSet method with a SOAPAction method.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Ben Forta posted on his blog about how the Macromedia is supporting the CFEclipse project. Damon Cooper is leading an effort to support RDS in the Eclipse IDE.
If you have not tried Eclipse yet, I highly recommend downloading it from eclipse.org. It is a open source and free IDE with a plugin system that allows anyone to add additional funtionality to it.
It looks like Macromedia is trying to point designers back at Dreamweaver, and point coders to Eclipse.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I have been preparing a presentation for my local user group on Ajax. Part of my presentation will be on REST vs. SOAP based RPC calls. One of the arguments against using SOAP based web service calls is that it is too hard to make SOAP calls using the XMLHTTPRequest object. I have not found this to be the case. The trick to making SOAP calls with XMLHTTPRequest object is setting the right request headers before making the call. SOAP calls should also be made as a post rather than a get. Here is an example below;
xmlhttp.open("POST",url,true);  
_ // set header for valid XML document_
xmlhttp.setRequestHeader('Content-Type', 'text/xml; charset=utf-8');
_ // Set the SOAPAction header, ColdFusion will look for the SOAPAction header._
xmlhttp.setRequestHeader('SOAPAction','http://www.fekke.com/com/Wright/getQuote');

I am going to be redoing portions of my main site using Ajax. Here is a [preview](http://www.fekke.com/index.cfm?fuseaction=home.wrightajax) of my Quote from Steven Wright as an Ajax app. IBM also has a [javascript framework](http://www.ibm.com/developerworks/webservices/library/ws-wsajax/) for making SOAP based web service calls.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Doug Hughes has a great port on his blog about managing asynchronis threads in ColdFusion MX 7 with out having to create event gateways. He just uses a some Java code to manage multiple threads. Here is a link to his post.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I was reading Rey Bango's Blog today, and he had some interesting observations about how Adobe is marketing ColdFusion.
I posted the following comment to his blog post; It is going to take more than marketing money. If you look at Ruby On Rails, 37 Signals has been able to effectively market Ruby without spending hardly any money. Most of the marketing has been viral for RoR.
Tim and Ben are both preparing trips to user groups right now to start promoting ColdFusion 8. I think that will help, but Adobe really needs to look at how some of these other scripting languages have been marketed. Python and Ruby, both scripting languages, have been gaining popularity over Java and C#. ColdFusion is a scripting language, and I would argue easier to use than Python or RoR. Adobe should be able to leverage that increase interest in developing web applications using scripting languages.
Right now ColdFusion has about a 6% market share. That should be higher when you look at the other languages that compete with ColdFusion.
Keep in mind that Ruby, Perl and Python are all open source products. These are community projects without a company like Adobe to market it as a product.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Mercury New Media in Tampa is hiring;
Mercury New Media is looking for candidates to fill a ColdFusion developer position. Depending on applicant qualifications this could be a mid- or senior-level developer position. Mercury New Media is a comprehensive web consultancy specializing in strategic guidance, design and development of websites and business process automation. We are largely a ColdFusion, .NET and SQL Server shop and are looking for strong contributors to our team.
To learn more about Mercury New Media, please visit
www.mercurynewmedia.com. Forward your resume to
dbickel@mercurynewmedia.com.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Mercury New Media is hiring another ColdFusion developer in the Tampa Bay Area. Mercury New Media also hosts this website. Check out the Ad below.
Mercury New Media is a Tampa-based web development shop and we are currently hiring for a ColdFusion Developer position. A mid- to high-level ColdFusion developer would fit well with the team and experience with Fusebox is a must. In addition to working with the ColdFusion 8 platform and Flex applications we are also actively integrating ColdFusion with .NET applications. This would be an excellent position for any ColdFusion developer looking to also expand into .NET development.
If you are interested or know anyone that would fit this position, please email Donald Bickel at dbickel@mercurynewmedia.com.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Mercury New Media is hiring two ColdFusion developers in the Tampa Bay area. The Positions are for junior and senior developers.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I recently read that Microsoft has agreed to pay Universal music a portion of all Zune sales. I can't believe that Microsoft would make a business deal this bad. This is the same company that bought an unlimited license for DOS at $50,000. That was the Alaska purchase deal in the software business.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Thanks to Buck Woody at Microsoft for giving me a heads up on this new tool. The tool lets you publish a script for creating both database structure and data. Here is the note from Buck;
Need to send both the structure AND data from a database as a script? We have a free tool for that:
http://www.microsoft.com/downloads/details.aspx?FamilyID=29b4ffd8-ac3a-4481-b352-9b185619a901&DisplayLang=en.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I bought one of the new MacBook Pros last week. I absolutely love it. I have used a couple of different database engines on the Mac in the past such as MySQL, Sybase, Oracle and more recently Derby. Because the processors in my Mac where based on PowerPC processors, I was never able to run SQL Server with out some type of emulation. Anyone who ever ran Virtual PC on the Mac knows what I am talking about. I installed boot camp on the Mac initially with Windows XP. I downloaded the trial of Parallels Desktop 3.0 for the Mac and and it will use the boot camp partition.
I then installed the developer edition of SQL Server 2005 on XP. I have the beta of ColdFusion 8 running on my Mac, and I wanted to be able to access the database I was running on Parallels. Initially I could not get this to work. The default setup of Parallels does not allow the Mac to access servers running on Parallels. I was able to get this to work by changing the networking on Parallels to "Bridged Ethernet". I can now access SQL Server through JDBC on my Mac through parallels.
I am getting ready to work on a project using Oracle 10g. I will most likely run it the same way I am running SQL Server, just with a different operation system.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011jQuery has been popular in the ColdFusion community, but it is also popular in the .NET community. It is popular enough that Microsoft is including the jQuery library with Visual Studio going forward.
Microsoft already includes AJAX .NET libraries with Visual Studio 2008 as part of the IDE. The 15k jQuery library will be included now as well. jQuery is an open source library, so it is nice to see Microsoft carrying an open source library with one of their products.
Scott Guthrie has a blog entry about this along with some jQuery examples.
I am thinking about having a presentation on jQuery at the next JaxFusion meeting in October.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Yahoo's board of directors rejected Microsoft's offer to buy Yahoo this weekend. I have been thinking about the Microsoft Yahoo takeover proposition. It reminds me of Time Warner AOL merger. There are a lot of reasons why the AOL Time Warner merger failed. The one reason that sticks in mind was the cultural differences between AOL and Time Warner. The cultures of the two companies clashed. Never mind the fact that AOL's business model was based on dialup internet access and a walled garden of content.
Microsoft and Yahoo would have similar culture problems if they merged. Microsoft eats its own dog food when it comes to consuming technology. Microsoft, for the most part, uses Windows Server, SQL Server, .NET and IIS. Yahoo uses a lot of open source technology including Apache, Linux and PHP. They also use a lot of Adobe software as well. The developers who develop for open source technologies, don't like Microsoft, and they do not want to work with Microsoft.
If Microsoft were to buy Yahoo, they would not keep any of Yahoo's infrastructure. They would rip it out in favor of Microsoft technology. All of Yahoo's PHP apps would be rewritten in .NET, Linux would be replaced with Windows, and Apache would be replaced with IIS.
Microsoft's attraction to Yahoo has to largely with Ad revenue. Ironically, this is one of the things that attracted Time Warner to AOL.
For full disclosure, my current employer is a Gold Partner with Microsoft. I am also a stockholder in a company that does business with Yahoo. At my current company, we have a pretty good working relationship with Microsoft. I think Microsoft should consider partnering in certain areas with Yahoo, but a full merger is a bad idea.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I recently downloaded the Sharepoint 2007 SDK from Microsoft's web site. This article is available as part of the version 1.2 SDK that was recently released for Sharepoint 2007. This article includes code samples that do not work, and references an IDE, Visual Studio .NET, that is not used with SDK. If you read the community comments at the bottom of the article, they describe about how the article is "outdated". It looks like the examples were written for Sharepoint 2.0, and never got updated to 3.0.
Currently with the WSS 3.0 SDK, you do not have have to add all of the references at the top of the article. In Visual Studio 2005 with the 3.0 SDK, it creates the references to Sharepoint automatically, and it will automatically install the web part on the Sharepoint server if it is on the same machine with Visual Studio. Part of my job now as a consultant is too advise my clients on how to leverage certain Microsoft development technologies. Good documentation and books on Sharepoint are few and far between. Many of the books on Sharepoint 2007 were rushed to press while it was still in beta, and content of the books reflect that they are referring to the betas.
At the very least, Microsoft should keep their online documentation up to date.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011There are a number of dynamic languages that are already supported by .NET, such as Iron Python and JavaScript, but according to this article at eWeek, Microsoft has made this easier to do with a dynamic language runtime. The article inteviews Jim Hugunin and John Lam of Microsoft about the language support. Their work was done primarily for Iron Python, but it seems to me that it should make that much easier to support other dynamic scripting languages such as CFML.
It is becoming clear that dynamic languages are becoming more popular than statically typed languages such as Java, C# and C++. There are currently a number of dynamic languages that have been gaining interest such as Ruby, JRuby, Perl, Python, Groovy and Scala. CFML is a dynamic scripting language that should see some benefit from this renewed interest in scripting languages.
New Atlanta currently supports .NET, but without the DLR.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011The next version of Microsoft SQL Server has been anounced.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Brad Abrams of Microsoft gave a great presentation on the Atlas framework. Atlas is a javascript library for performing Ajax like functionality in web abblications.
At the end of the presentation they showed off a library that Microsoft wrote that translates ColdFusion objects into JSON (Javascript Notation).
Brad mentioned that Atlas is platform agnostic, and will work on IE as well as Firefox and Safari.
He also said that asmx pages have the ability to output in JSON by adding a /JS to the end of you asmx url.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I am a big fan of all of the major ColdFusion frameworks. They all support Model View Controller. Joe Reinhart has done some great work with his Model Glue Framework.
The only real beef I have with I with Model Glue is that it is much slower than Fusebox 4. While it is not a 1.0 release yet, it has to reproduce an event model in the framework.
On my development machine, which is a fairly modern Dell laptop with One gig of RAM, most requests take 500 to 1400 miliseconds to process.
I have just started running the framework in the BlueDragon.NET server with much better results. My request times are only taking 40 to 70 miliseconds. This is more than adequate for production use.
I highly suggest trying this framework on BlueDragon.NET. I am planning on testing some Mach-II and Fusebox 4 apps in the framework as well.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Thanks to Buck Woody for bringing this to my attention, Microsoft has announced Visual Studio Shell. Much like Eclipse, this shell can be the basis of building tools for development. It will be interesting to see how this tool compares to Eclipse when it is released.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I have been recently approached by two different companies in the Jacksonville, Fl area that are trying to hire ColdFusion developers. If you live in Jacksonville or are willing to relocate, these are good opportunities.
There are three open positions at Taleo. If you follow this link and do a search for "Software Engineer" it will show the open positions. They are also trying to hire Java, C# and Flex developers.
Another company that is trying find ColdFusion developers is called Andromeda Systems.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Brian Merrill, the lead singer for the band Barely Pink sent me a song that he recorded with drummer/singer Jeff Wood. The song is called Rosalee.
Jeff passed away this week after a long battle with cancer. If you have not heard his music before, I suggest giving this song a listen.
Listen to Rosalee‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I upgraded my blog to BlogCFC 5.6. I have been using BlogCFC 3 before this, and I wanted to get up to speed with the latest version. If you have been thinking about getting some blogging software, I would highly recommend downloading Blog CFC.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I have been pretty good to sticking to my New Year's resolutions in the past. This is not because I have some great resolve, but because I pick easy goals. For instance, "I am going to buy a new laptop this year". The tough ones are like quiting smoking or losing 15 pounds.
Since I like to pick easy ones, I have picked one that I think will be attainable to me. My New Year's resolution is to become more proficient at Flex.
This will be a big year for Flex. A lot of this has to do with Apollo being released soon. Apollo will make it easy to take existing Flex/Flash content, and turn it into double click-able applications.
I am also planning on having more Flex and Flash presentations being made at the JaxFusion User Group this year as well.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Ok, I know I had a blog before, but it was really lame. I do not plan on copying over any of my old posts. I do plan on starting to add lots of new content to this website.
My primary focus of this blog is Web application development, with a focus on CFML and SOAP. I also plan on adding an articles section very soon as well. I will also be focusing more on other subjects like BlueDragon, ASP.net, AJAX, Flash MX, Java, Design Patterns as well as ColdFusion MX. I am also planning on adding a code section where people can download copies of applications I have written.
This application was written by Raymond Camden. It is called BlogCFC. It will work with ColdFusion or BlueDragon. His blog and downloads can be found here.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I was reading Scott Guthrie's blog yesterday, where he said that Microsoft was releasing the the source code for the core .NET libraries for .NET 3.5 in 2008. So does this mean that .NET will be Open Source? The answer to that question is no.
Microsoft is releasing the libraries under a reference library so that the code can be used for debugging in the VS 2008 debugger. Read the post for more information.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I recently received a software update for my MyGig audio navigation system in my Dodge. I am still getting used to the idea of giving my car software updates.
This was for version 3.0 of the MyGig system software. The update took about 10 minutes to install. Harmon Becker cleaned up the interface with prettier icons. There is an icon on the bottom right hand corner of the map for tracking your path.
My MyGig system has a 20 gigabyte hard drive. After the update it reset all of my phone numbers, and my paired phones. Chrysler does warn that stored numbers will be lost. I re-paired my iPhone 3G with the MyGig's bluetooth. Other than the issues with the phone, the upgrade was flawless.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Nate Nelson gave a presentation on undocumented features in CFMX. I have never seen Nate speak before, but he was a good presenter.
He covered making changes to the XML config files, how to reset the admin password if you lose the admin password.
He also showed how you can add code to the CFAdministrator. Some of the cooler features he showed off had to do with the cfQuery object, and the methods you can use on that object.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I am looking for a ColdFusion developer with C# .NET experience here in the Jacksonville, Fl area. If you are available, and have experience with both ColdFusion and C#, please contact me at davidfekke at gmail dot com.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I was researching the Spry:state="loading" feature in Spry 1.2, and I came across this site. This site will create a Ajax loader animated gif file that you can use while your ajax call is being returned. Pretty cool!‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I have seen a lot of blogging this morning about the final merger of Adobe and Macromedia's web sites this morning. The biggest change I have seen is that Adobe now lists ColdFusion on their homepage.
I have been blogging about problems I have seen since the conversion of the two sites started, but I wanted to add I know this has been a ton of work for Adobe. My kudos to Adobe.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I purchased one of the new Apple Airport Extreme wireless routers this weekend. I have been using one of the older D-Link routers that is a 802.11G router. The D-Link has worked alright, but I would have problems with losing my connections. A couple of years ago I purchased an Apple Airport Express router as a backup when I traveled, and it worked better than my regular wireless router. This new extreme router has a USB port so I can connect external hard drives and printers. It also has three Ethernet ports for any computers that do not have wireless cards.
It is also is based on the new 802.11N standard. I am planning on upgrading my home to 802.11N, so this is the first step.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Not sure how I missed this one, but there is a new ColdFusion web site for answering ColdFusion questions called cfanswers.org. Thanks to Matt Woodward and Pete Farrell at the ColdFusion Weekly podcast for letting me know about this site. This works like Google Answers, where you can ask a question, and someone will answer the question. Unlike Google Answers, it is free and has not been shut down.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I switched to a new web host yesterday. My previous site was written in ColdFusion. This site is written in ASP.NET MVC. I really like this new framework from Microsoft. I have not abandoned ColdFusion, but for the last few years I have been developing for .NET. I felt that it made since to switch my site over to .NET since that what I have been using for most of my development.
I am using BlogEngine.NET for my blogging software. I looked at Oxite, but it was still in beta when I looked at it.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Calvin Ward asked me if I would become the new JaxFusion User Group manager this week, and I accepted.
I used to manage the Macromedia User Group in Tampa and really enjoyed my work with that group. I am looking forward to managing the group in Jacksonville. There is a terrific community of developers and engineers in this area. I also wanted to thank Calvin Ward, Steve "Gus" Gustafson and James Ahrens for doing such a great job of starting and running the club.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I decided to redesign my blog last night. I am using Aura from Leorex and the Aura skin that Joe Rinehart created for Aura. The nice thing about Aura is that they provide a Photoshop template to redesign the skin very easily. I personally feel it looks better than my last design, and it uses CSS positioning for the layout.
I did run into some problems initially with the Javascript popup window functionality for the blog editor. I think it has to do with the version of BlogCFC I am using and the version of the Aura skin that Joe provided. I am using BlogCFC 3.5.
Joe javascript command looked like this;
"javaScript:launchBlogEditor('#id#')">#application.resourceBundle.getResource("edit")#
I changed it to look like this;
"javaScript:launchEditor('#id#')">#application.resourceBundle.getResource("edit")#
That seems to have done the trick.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Sorry about the last minute confusion, but the next JaxFusion meeting will be held next Tuesday on the 22nd. I apologize for the last minute change.
The meeting will cover some of the different ways you can integrate Flex/Air applications with ColdFusion 8.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Pablo Varando from EasyCFM.com has announced that he is launching a free ColdFusion 8 hosting service at the beginning of next year. The hosting service will be based on ColdFusion 8 and have either a MS Access or MS SQL Server 2005 database.
Pablo made this announcement on his blog. He says he will have more details about this service soon, so check back soon.
Pablo has done this before successfully, so I look forward to this new service.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011The next JaxFusion meeting will be Tuesday January 20th at SouthWest Signal at 6:30 PM.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011The next JaxFusion meeting will be this coming Tuesday, August 7th at 6:30 pm. The meeting will be at Modis building in downtown Jacksonville. We will be going over some of the newest features of ColdFusion 8 which you may or may not heard about. I have a lot of giveaway items for this meeting.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011The next JaxFusion User Group meeting should be held on August 7th at the Modis building in downtown Jacksonville. I am still trying to schedule a conference room, but we should still be meeting around August 7th.
We will be covering some of the new features in Adobe ColdFusion 8. I found out at the Tampa Code Camp last week that my service provider, Mercury New Media, will be upgrading to ColdFusion 8 once it is released.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011The next JaxFusion user group meeting will be at Dave & Buster's. The next official presentation will be next year. For December we will just be having a get together.
The meeting will be held at Dave & Buster's just off I-95 and J. Turner Butler in Jacksonville. The get together will start at 7:00 PM on Thursday, December 7th.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011The next JaxFusion user group meeting will be at Dave & Buster's. The next official presentation will be next year. For December we will just be having a get together.
The meeting will be held at Dave & Buster's just off I-95 and J. Turner Butler in Jacksonville. The get together will start at 7:00 PM on Thursday, December 7th.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011The fine folks at SouthWest Signal will be hosting the next JaxFusion meeting. July's meeting will be covering how to integrate ColdFusion with Flex/Air applications.
We will be giving away a lot of goodies from Adobe. We hope to make this a regular occurrence again. We are also going to have a presence this year at the Jacksonville Code Camp.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Adobe is making the rounds of different user groups presenting the next version of ColdFusion. The next version of ColdFusion, codenamed 'Scorpio', should be released sometime this year.
Adam Lehman from Adobe will be presenting on this version of ColdFusion at the next JaxFusion user group on April 23rd at 6:30 PM. I have not had a chance to update the JaxFusion web site, but I should have more information about this meeting shortly.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011The next JaxFusion will be on October 5th at 7PM. The meeting will be held at ASI in Orange Park. ASI is located at 330 Crossing Blvd Orange Park, FL 32073.
There will be two presentations. One will cover the new features in ColdFusion 9. The other will cover hybrid iPhone ColdFusion apps.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Lasts nights JaxFusion meeting on Flex went fairly smoothly. We will having a presentation on ColdFusion MX 7's reporting tool on June the 6th at Vurv Technology.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011The next JaxFusion meeting will be on Tuesday, September 16th at 6:30. The presentation for the next meting will be on integrating ColdFusion and .NET hybrid applications.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011The next JaxFusion meeting will be on Tuesday, September 5th at Vurv. I will be doing a presentation on Fusebox 5 vs. Model-Glue framework.
This presentation will be more of a side by side comparison of the two frameworks. It seems like there is no shortage of web application frameworks nowadays. I am also a fan of Mach-II, but I have not taken a look at any of the other frameworks for ColdFusion. There is a new framework called CF on wheels, kind of a spin on Ruby on Rails.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011The next JaxFusion meeting has been announced. The meeting will be held at the new location at the Modis building in downtown Jacksonville.
The topic this time will be covering integrating .NET with ColdFusion. There are a lot of new features coming in ColdFusion 8, but it is possible to integrate older versions of ColdFusion and .NET. The presentation will cover the differences between the different versions of ColdFusion and BlueDragon.NET.
If you live in the Jacksonville area, come on out.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011The next JaxFusion User Group meeting will be on October 3rd, 6:30 PM at Vurv Technology in Jacksonville. The presentation will be on XML in ColdFusion MX, as well as how to use StAX API to handle large XML files.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I purchased a new car this weekend. It is an 08' Dodge Charger.
The thing that really blew me away about this car was that it has a lot more electronic wizardry than any car I have ever had before. It came with Bluetooth, a voice activated audio and nav system, 20 gigabyte hard drive for pictures and MP3s, GPS system with live traffic updates. It even has an USB port for transferring MP3s and pictures.
It will probably take me couple months to figure out how to work all of this stuff. I am still trying to figure out how to connect my iPhone so I can use the hands free features in the car. Overall, I am very impressed.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011The Florida Times-Union has a nice article on a Game and Mobile development program at the University of North Florida. The article talks about a game that a friend of mine is developing called "Ascension War: Triumvirate".
I am glad to see that UNF and other colleges are focusing on mobile applications. If you look at the number of people around the world who have mobile phones vs. a personal computers, many more have mobile phones. The future of client app development will be on mobile phones.Tags: Misc   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Just read this on Slashdot. I guess Flash will not be coming to the iPhone.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011So I went to buy a new iPhone 3G on friday. After standing in line for two hours I was not able to buy an iPhone 3G. After getting to the front of the line I was told there was an error in my AT&T account that would prevent me from upgrading. Apparently some AT&T accounts were preventing users from upgrading to the new phone because of family account or business reference. In my case it was a business reference. Apple would not let me walk out of the store with one of the new phones. So I called AT&T on Saturday and tried to speak to a customer service representative who could help. After being transferred and hung up on about six times, I was able to speak to someone who handles business accounts, even though I do not have a business account. I was told I needed to speak to someone in premier support, the business account department was able help me figure out what was wrong.
It turns out that AT&T had thousands of customers who had errors in their database accounts that prevented them from upgrading. In the Apple stores, the account would show up with an "IRU not supported" error. If you got this error, you could not buy an iPhone.
So after I went back to the Apple store after the error had been fixed on AT&Ts side, I still got the "IRU not supported" error when I tried to buy the iPhone. I spoke to an AT&T representative again, and was told that it takes 24 hours for the records to get sent down to Apple's system.
So I went back to Apple store on Sunday, and all iPhones are sold out now. No Apple or AT&T store in Jacksonville has iPhones in stock anymore.
So now I am on waiting list for an iPhone 3G. All of this because Apple and AT&T require in store activations. If they did not have this requirement, I could have walked out of the store with an iPhone 3G on Friday.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I have received a couple of comments recently about a Blog post I made about the death of JRun. Adobe is not the only vendor who has been slow to update JRun to the latest Java EE spec. Almost every major Java vendor is taking their time upgrading their respective app servers.
This Dr. Dobbs article reports on what the different vendors are doing when it comes to Java EE 5. Right now ColdFusion is only supported on J2EE 1.4.2. So there is no reason for anyone who is doing dual development on the same server to upgrade to 5.
IBM's WebSphere will not be upgraded again until 2008, and I believe JBoss is on a similiar time frame for their upgrade.
At my company we use JRun, and it has done an excelent job in our enterprise environment. We do most of our development in CFML, so this has not been a major issue. If we did more Java development, we would probably use another vendor.
I am not a big fan of WebSphere because the complexity configuring the server. I have been playing around with WebLogic and JBoss recently. Redhat, Sun and BEA seem to be more focused on pushing Java EE platform forward‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Congratulations to Barack Obama and Mike Huckabee for winning the Iowa Caucus last night. I was looking at their respective web sites last night. I am not sure which web framework Obama is using, but Mike Huckabee is using Fusebox.
As a long time Fusebox developer I wish all candidates would use Fusebox. It will not affect my vote, but it is still nice to see.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011The first meeting for the North East Florida CFUG is tonight at 6:30 PM. The meeting will be held at Ventureplex. See the previous post for directions. I hope to see you there tonight.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I bought an iPhone. I said I was not going to do it. The selling factor for has been the browser. The browser is Safari which is based on webkit, the same HTML rendering engine Adobe is using for Air. I browsed an Ajax application I built, and it worked perfectly on the iPhone.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I have been on the road a lot lately, so my blogging has been lite lately. I just got back from competing in the South East Regional rowing regatta. Jacksonville came in third overall if you follow rowing.
I found out late last week that I will be attending CFUNITED this week. I look forward to meeting all those people I only see at ColdFusion and Adobe conferences. Then I will be off to the Pepsi 400 to see the race in Daytona this weekend.
I hope to blog on CFUNITED while I am there, but I do not know what the Wi-Fi access will be like.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I am taking a class on Microsoft SharePoint architecture this week. I learned today in the class that the next version of SharePoint will be 64 bit only. If you are going to be buying new server hardware, get 64 bit hardware.
Not only does SharePoint run better on 64 bit hardware, so does MS SQL Server and ColdFusion. You can also take advantage of much more RAM. I believe that 32 bit hardware is limited to a maximum of 2-4 GBs. 64 bit hardware can go up to 256 Terabytes in theory.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Just found this out that Michael Crichton has passed away unexpectedly. Crichton was one of my favorite fiction authors, and he was also dabbled as film director as well.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I have run into this error recently "OCIEnvCreate failed with return code -1 " trying to make a database connection to Oracle from a .NET 2.0 application. It took me a couple of days to resolve the error, but it stems from having to have ODP.NET and another Oracle client installed on the same machine as my application. Running into this error really made me appreciate JDBC for making connections to Oracle, which has always been relatively simple.
The mistake I made was just trying to install just ODP.NET for Oracle 10.2.0.21 on the client machine. The OCIEnvCreate failed message went away after I installed the Oracle production client 10.2.0.3 on my client machine. The end result is that you have to have two different sets of client software installed in order to be able to make a connection to Oracle 10g.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Oracle has released a free version of their database server software. It is called Oracle Express. It looks like a competitor to the SQL Server express and MySQL products.
It will work with Redhat and Windows. No Mac installer yet.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011The Orchard CMS version 0.8 has been released. This release has a new theme engine written using the new Razor rendering views. Orchard is based on ASP.NET MVC. Here is the write up from announcement on the release;
The Orchard Project team is pleased to announce the availability of the Orchard 0.8 release, which provides essential features that designers need to tailor the look-and-feel of Orchard sites. The release can be downloaded from http://www.orchardproject.net/download The Orchard 0.8 release includes a theme engine based on the new Razor syntax in ASP.NET MVC, which is an extensible object model for defining ‚Äúshapes‚Äù, as well as a flexible template system for rendering those shapes. The theme engine includes support for multiple layouts and zones, a script and style sheet registration API, and more. It also includes a new default theme, ‚ÄúThe Theme Machine‚Äù, which leverages these features and can be adapted to fit the needs of different site designs.
As if a Theme Machine isn‚Äôt cool enough, the 0.8 release also includes support for widgets - in this case, configurable UI elements, such as a tag cloud or search input, which can be easily mapped to different regions in the site (for example, a sidebar). The configuration of individual widgets and the rules about where they appear in the site are configurable from the Orchard admin panel.
For designers, this offers the flexibility to either brand individual sites or create reusable themes to be shared with others. Orchard 0.8 also includes support for packaging themes and publishing them to an online gallery feed where other users can discover and download them.
I will be giving a presentation on Orchard at the JaxDUG next Wednesday.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I saw this story over on DIGG today. There was a study done that shows that Oracle's database has more security flaws then SQL Server.
I will point out that I am biased. I have used both SQL Server and Oracle, and I prefer MS SQL Server. I have found it much easier to develop on SQL Server because of the client and integration tools.
The article also points out that there are many zero day exploits that Oracle has not fixed.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I will be giving a presentation in November at the Jacksonville Developers User Group on the Orchard CMS. I am going to use part of this presentation to demonstrate Microsoft WebMatrix. WebMatrix is a simple webserver and deployment tool. You can very quickly prototype a web site using one of many blogs or content management systems, and then deploy that site to a hosting provider.
Most of the presentation will cover the Orchard CMS project. Orchard is a open source community focused content management system based on the ASP.NET MVC framework. Microsoft is sponsoring the project, and they are looking for collaborators. Orchard is currently at a 0.5 release. The Orchard team is currently implementing the new Razor engine to be the default view engine.
I will have a lot more on this subject coming soon.Tags: Visual-Studio   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I will be giving a presentation at the Jacksonville Developers User Group on the Orchard CMS tomorrow at 6:00 PM. I am going to use part of this presentation to demonstrate Microsoft WebMatrix. WebMatrix is a simple webserver and deployment tool. You can very quickly prototype a web site using one of many blogs or content management systems, and then deploy that site to a hosting provider.
Most of the presentation will cover the Orchard CMS project. Orchard is a open source community focused content management system based on the ASP.NET MVC framework. Microsoft is sponsoring the project, and they are looking for collaborators. Orchard is currently at a 0.8 release. The Orchard team just implemented the new Razor engine as the default view engine.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011The Oscars are this weekend, and I thought I would make my Oscar picks for this year and give my explanation as to why the academy will pick a nominee. Best Motion Picture of the Year:
Brokeback Mountain will when best picture. The academy will not be able to resist giving an Oscar to a movie about gay cowboys. I have not seen this one yet, but I doubt I will since that South Park episode about the independant film festival. In that episode, all independant films were about gay cowboys.
Best Performance by an Actor in a Leading Role:
Philip Seymour Hoffman will win for Capote. Hoffman is an Oscar fav, but I hope it goes to Terrence Howard for Hustle in Flow. His performances in Crash and Hustle and Flow and Crash were incredible.
Best Performance by an Actress in a Leading Role:
Dame Judi Dench will win for Mrs. Henderson Presents. She is always an Oscar fav.
Best Performance by an Actor in a Supporting Role:
Matt Dillon will win for Crash. The Academy always loves a bad cop. Plus it is Matt Dillon, and he has been around for long time.
Best Performance by an Actress in a Supporting Role:
Frances McDormand will win for North Country. McDormand is always a Oscar fav, plus she is married toa Coen brother, and that does not hurt.
Best Achievement in Directing:
Ang Lee will win for Brokeback Mountain. And Lee will be redeimed for making The Incedible Hulk, even though I liked that movie.
Best Writing, Screenplay Written Directly for the Screen:
Crash by Paul Haggis will win this one. Crash has themes that the Academy and I for that matter love. Paul is a great writter and I hope he wins this one.
Best Writing, Screenplay Based on Material Previously Produced or Published:
Larry McMurtry and Diana Ossana will win for Brokeback Mountain. Larry McMurtry has penned many of the great screenplay for the last 40 years. The Academy loves him. I am personally partial to Lonesome Dove and Hud.
Best Achievement in Cinematography:
Rodrigo Prieto will win for Brokeback Mountain. This movie was shot in Canada, and it is impossible to make Canada look bad on film.
Best Achievement in Editing:
Michael Kahn will win for Munich. Plus he is the only nominee that still edits movies by splicing film together on a moviola. All the rest use computers now.
I will the the rest of my picks this afternoon.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Here are the rest of my Oscar picks.
Best Achievement in Art Direction:
Grant Major, Dan Hennah, and Simon Bright will win for King Kong. Anyone who can turn New Zealand into New York city deserves an Oscar. Best Achievement in Costume Design:
Colleen Atwood will win for Memoirs of a Geisha.
Best Achievement in Music Written for Motion Pictures, Original Score:
John Williams will win for Munich. John is my favorate score composer anyway.
Best Achievement in Music Written for Motion Pictures, Original Song:
Jordan Houston, Cedric Coleman, Paul Beauregard will win for "It's Hard Out Here For a Pimp" in the movie Hustle and Flow.
Best Achievement in Makeup:
Howard Berger and Tami Lane will win for Narnia.
Best Achievement in Sound:
Terry Porter, Dean A. Zupancic and Tony Johnson will win for Narnia. They will win because it is not a Peter Jackson film.
Best Achievement in Sound Editing:
Mike Hopkins, Ethan Van der Ryn will win for King Kong.
Best Achievement in Visual Effects:
Dean Wright, Bill Westenhofer, Jim Berney, Scott Farrar will win for Narnia because it is not a Peter Jackson film.
Best Animated Feature Film of the Year:
Steve Box and Nick Park will win for Wallace and Grommit.
Best Foreign Language Film of the Year:
Tsotsi will win this one. It has already won a lot of other awards.
Best Documentary, Features:
Alex Gibney and Jason Kliot will win for Enron: The Smartest Guys in the Room. The Academy hates corporations.
Best Documentary, Short Subjects:
Kimberlee Acquaro and Stacy Sherman will win for God Sleeps in Rwanda. The academy will be able to say they care about genocide.
Best Short Film, Animated:
Shane Acker will win for 9.
Best Short Film, Live Action:
Rob Pearlstein will win for Our Time Is Up. Too many academy members have therapists for this one not to win.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011The results from my Flash poll showed that Crash would win the Oscar for Best Picture. I picked Brokeback Mountain.
You were right, I was wrong. There I said it. I am just glad that the 36 Mafia won an Oscar.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I have not been blogging much over the last month. I have had a few funerals and weddings that I have been attending. I have recently switched jobs. I was working for Idea Integration as a Microsoft Consultant, mainly around SharePoint and SQL Server consulting, but I left them at the end of last month. By the way, if you are looking for SQL Server or SharePoint consulting, go with Idea Integration.
I am now working as a .NET developer for HCR Software in Jacksonville. We build web based software for Human Resources.
I hope to blog more about .NET, but I am still active in the ColdFusion and Flex space. I plan on having meetings next month for JaxFusion user group on Flex and ColdFusion.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I had a conversation with someone today about the cost of Photoshop CS2. The current price listed on the website is $649.00. This is the full version. Photoshop elements 5.0, the lost cost alternative, goes for about 89.00.
My dad refers to Photoshop Elements as "Photshop for Dummies". It can't even do channels, and it is only for Windows. The full version of photoshop is one of the most pirated pieces of software out there on the web. Adobe knows this, and this is why they so many levels of copy protection.
There is a economic term refered to Elasticity of price. The idea here is that the demand for a product will increase if the price lowers, and it will decrease as the price increases.
The theory here is that Adobe would sell more copies of Photoshop if they lowered the price, and would have less piracy.
I used to do photo retouching for a living. When I did, my company purchased the full version for me to use. I no longer do any kind of graphic arts for a living. I do have a digital camera, but I no longer have a copy of Photoshop. I can't justify spending 649 dollars on software that I would only use as a hobby.
I think the solution for Adobe is to have three different price points for Photoshop. They could have the full version and elements at the current prices, but have a version of Photoshop that had most of the features of the full version for around $299. The inbetween version of Photoshop would have features like layers, history, channels and paths.
I personally feel that this would cut down on the piracy, and Adobe would make a lot more money.
I know some people will say I should download and use GIMP. I have tried using GIMP, and I have to say, GIMP sucks.
I am a huge fan of John and Thomas Knoll. John Knoll gave me the encouragement to become a Software Engineer, so for the record I am biased towards Photoshop.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I just got back from a trip to New Jersey to participate in the FISA World Rowing championships. While I was there I had a chance to go into New York City for the day on Friday the 8th.
Here is a link to the pictures I took while I was in Manhattan. I have been to Ground Zero before. I was there about a two and half years ago. From what I understand, it has not changed at all since the last time I was there, so I decided to go to other places in the city this time.
One of the feelings I got walking around the city was a strong sense of freedom and optimism. You almost would not know that there was an attack there five years ago. It was warm day with lots of sunshine. It felt a little more like Florida then the North East.
If you have not had a chance to visit New York, I would highly recommend visiting. I plan on going back soon.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I updated the Podcast pod on my blog today. I removed the ColdFusion podcast from that pod, and added one for the Flex show. I am sorry to hear that the ColdFusion podcast is going on hiatus. Those guys plugged my blog a few times.
Jeffry Houser and Ryan Stewart are hosting the Flex show. It is good to hear the community building behind Flex.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Bryan Kaiser and Michael Haynie plugged my website again on the last episode of the Coldfusionpodcast. This last episode covered the Fusion debug tool for eclipse. If have thought about using a more traditional debugger with ColdFusion, Michael and Bryan give an overview of this new tool. They even managed to pronounce my last name correctly. Thank Guys.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Point and Pay has an immediate need for one or two Coldfusion programmers to work onsite in sunny Winter Haven Florida.
Please submit your resume to jobs@pointandpay.com.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I recently purchased Adobe Creative Suite 3 for my Mac G5 tower. When I bought the suite I did not realize that it required a minimum of 1 Gigabyte of RAM to install. I only had 512 MB that came with the Mac when I bought it, so I decided to buy some more RAM.
This is where my nightmare started. When I came home with my i Gig RAM stick, I installed it, and turned my computer on to find out that it did see the stick of RAM.
Then I seated the stick in all the way, restarted the computer, and the computer flashed the status light twice.
This is when I decided to break out the manual. I have a T-shirt that says 'RTFM', but I did not follow my own ethos.
The manual for the G5 says that two flashes means that it can not see the RAM in the computer. It also says that the RAM sticks have to be in opposing RAM bays.
Since I only had one stick, I had to go back to the Computer store and buy a second stick that was identical to the one I purchased. This is when the computer store guy says to me, "oh, you have a dual processor machine."
So I put the other RAM stick in the opposing RAM bay, and the computer started up without a problem. This is why I should not be allowed back in a computer for the foreseeable future.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I use subversion at work, but I have been wanting to run a subversion server at home. On Windows I use Visual SVN server, but at home I am running Mac OS X on all of my home computers. I use one of my Macs as a server.
Here is the good news. Mac OS X 10.5 comes with Apache 2.2 and SVN pre-installed.
Here is the bad news. An older version of SVN exists on Mac OS X. I believe it is version 1.4.4 of subversion.
I found some good resources on how to set up Subversion with Apache 2.2. This Sonzea article does a good job of the nuts and bolts of setting up a SVN repository. I did have to change the chmod to "www" instead of "_www". I was not able to get trac working. I think it was because I am using an older Mac with a PowerPC processor.
I also was able to install a newer version of subversion software from the Collab.net site. After the newer version of subversion is installed, I had to change my subversion.conf file so that it pointed to the newer shared objects.
By default you point your subversion.conf file to the following location;

LoadModule dav_svn_module libexec/apache2/mod_dav_svn.so

LoadModule authz_svn_module libexec/apache2/mod_authz_svn.so

After I installed the newer version of SVN, I changed this file to point to the new location of the mod_dav_svn.so and mod_authz_svn.so files.

LoadModule dav_svn_module /opt/subversion/lib/svn-apache/mod_dav_svn.so

LoadModule authz_svn_module /opt/subversion/lib/svn-apache/mod_authz_svn.so

I also installed project tracker after I ran into problems trying to install Trac. I am really liking this web application for doing my bug tracking. It also integrates with subversion and will send SMS messages.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I will be presenting on jQuery at the Jaxdug tonight at 6:00 PM. jQuery is a lightweight JavaScript library that helps add interactivity to web pages and manipulated the DOM more easily.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011A co-worker of mine, John Lyons, showed me a really cool tool for editing and auto-formatting XML. The tool is called Butterfly XML. It is built in Java and uses the tiny XML api to load your XML into DOM. It shows the DOM tree in a real time as you edit the XML, and will tell you if the document is well formed.
Oh, and did I metion it is Free!‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011We have a partner who is using SAP and ABAP to consume web services. We are trying to provide a ColdFusion Web Service that they can call with ABAP.
They get the following error when they try to generate the proxy;
System response  
ABAP proxy generation expects that all directly and indirectly referenced
objects are in the WSDL document. Therefore, no proxy can be generated for
this WSDL and the system displays an error message.
Procedure
This situation can have different causes:
Object "" not been defined
Object "" saved in the wrong namespace
In the reference to object "", the wrong name was specified
In the reference to object "", the wrong namespace "" was specified

If anyone knows how to fix this, or could point me in the right direction, please comment.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I was reading on Engadget that they believe HD DVD is on a Death Watch. It seems to me that HD DVD has been on a Death Watch since Warner Bros dropped all support at the beginning of the year.
In the post at Engadget, Ryan Block also mentions that Blockbuster and Netflix have dropped HD DVD as well. There have also been stories that Toshiba, the creator of HD DVD, is looking at developing a Blu-Ray player.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I have a SOAP based web service that I wrote when ColdFusion MX 6 first came out, and it does not work in BlueDragon.NET.
The web service is called a quote from Mr. Spock. (Yes, I am a GEEK.) It has a one method called getQuote which returns a coldFusion structure or a HashMap object if you are using Java. When I test my client for the web service in BlueDragon, it retuned an empty object. So I decided to rewrite my web service code to return a simple object instead. My current cfc for the web service looks like this;
"spock">  
<cffunction access="private" name="getRand" returntype="numeric">
<cfset randNum = randrange(1,85)>


<cffunction access="Remote" name="getQuote" returntype="struct" hint="Get Quote from Mr. Spock">
<cfquery name="myQuoteQuery" datasource="#application.davidsDSN#">
Select * From SpockQuotes
WHere QuoteNum = #getRand()#;









ColdFusion MX has a built in way to describe simple objects in the WSDL file. If you create another cfc using the cfproperty tag, you can return that type in the web service.
My structure has three name/value pairs for the quote, stardate and episode. The values are all of type string. So the following cfc that describes the simple object looks like this;
"SpockQuoteModel">  
<cfproperty name="quote" type="string" />
<cfproperty name="episode" type="string" />
<cfproperty name="stardate" type="string" />

Then I wrote a new web service code that uses this cfc;
"SpockWS">  
<cffunction access="private" name="getRand" returntype="numeric">
<cfset randNum = randrange(1,85)>


<cffunction access="Remote" name="getQuote" returntype="SpockQuoteModel" hint="Get Quote from Mr. Spock">
<cfquery name="myQuoteQuery" datasource="#application.davidsDSN#">
SELECT quote, episode, stardate
FROM SpockQuotes
WHERE QuoteNum = <cfqueryparam cfsqltype="cf_sql_integer" value="#getRand()#" />;

<cfset spock = createObject("component","SpockQuoteModel") />






I tested this in BlueDragon.NET with the following client code;
"[http://www.fekke.com/com/SpockWS.cfc?wsdl](http://www.fekke.com/com/SpockWS.cfc?wsdl)"  
 method="getQuote"  
 returnvariable="aHashMap">  
   

Quote: "#aHashMap.quote#"
Episode Name: #aHashMap.episode#
Stardate: #aHashMap.stardate#

It Worked!!! I will copy this sample code to my web site with instructions soon.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011The final schedule for the SQL Saturday Schedule has been posted on the SQL Saturday site.
I will be giving two presentations at the conference on the Business Data Catalog and Linq for SQL. These mini conferences are very good and they are free.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I am going to be giving a presentation on Linq for SQL at the SQL Saturday at the University of North Florida on Saturday May 2nd. This presentation covers the basics on how to use the Language integrated query syntax inside of .NET 3.5.
There a lot of other good presentations that will be given on the SQL Server 2008 platform. SQL Saturday is a free event. Sign up now before registration for the event fills up.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I will be giving two presentations tomorrow at SQL Saturday in Jacksonville. There will be a lot of info on SQL Server 2008 at the conference. The conference is being held at the University of North Florida campus.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011SQL Saturday is coming to Jacksonville on Saturday May 3rd, 2008. The conference will be held at the UNF campus.
The SQL Saturday conferences encompass one hour sessions on SQL Server and technologies used in conjunction with SQL Server.
I will be giving a couple of presentations this year at this conference. You can go and register now, and the registration is free.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Thanks to Buck Woody for pointing me to this tool. It analyzes your database and advises based on best practices.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011The registration for SQL Saturday is almost capped for this coming weekend. Go to www.sqlsaturday.com, and click on the registration link for Jacksonville. I am presenting on Linq this year first thing in the morning.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011If you ever run into a problem trying to find out what the equivalent data type for a SQL Server 2005 data type is in .NET, This chart has all of the data types mapped out.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I have been at SQL Server 2005 Integration Services training for the last two days, and I have to say it has been an eye opener. The class is being taught by Brian Knight
of Idea Integration. Brian runs the local SQL Server users group, and has co-authored a book on SSIS. Integration Services is the replacement for Sql Server‚Äôs DTS (Data Transformation Services) packages. It provides a graphical tool for programming data integrations into and out of SQL Server. DTS was already fast before SSIS for importing and exporting data, but it was limited in what you could do without doing a lot of activex scripting. At my current job, we use ColdFusion to do our file moving, ftp and encryption. We presently reserve DTS for bulk transformations on the database server.
All of the things that we could not do in DTS can be done now with Integration Services. SSIS can also iterate through files in a directory though containers. XML support in SQL Server 2000 was non-existent, but the support is much better in SSIS. If you do not have an XSD file for your XML file, SSIS will generate one for you.
SSIS also has improved scripting capability, and comes with a new expression language for evaluating system and user variables.
@[User::varConfigString] == @[System::PackageName]
If you use SQL Server 2005 and have to integrate with different data sources, SSIS is comes included with SQL Server. It is a cheap alternative to other ETL solutions such as CastIron, WebMethods and EAI.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011A buddy sent me a link to this web site for SQL on Rails. I found this hysterical. Watch the screencast. If you have ever watched a Ruby on Rails screencast, you will get the joke.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Steve Jobs at WWDC 2007 has just announced that Apple is releasing a version of Safari for Windows.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I read on Scott Guthrie's blog today about how Microsoft will be showing off a version of IronRuby at the next Mix. There is already a version of Python that runs on .NET through their DLR implementation. He has code samples of IronRuby in his post.
One of the exciting things to see is that Microsoft is embracing dynamic scripting languages like Ruby and Python. They are also adding Lambda expressions and dynamic features to C# and VB.NET. There is already an implementation of Ruby running on Java called jRuby. Sun has also been promoting a new scripting language called Scala.
It is nice to see these language features being embraced by Microsoft and Sun. Dynamic scripting languages like ColdFusion are becoming more and more popular. It will be interesting to see if New Atlanta will use this new technology in the next version of BlueDragon.NET.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Adam Lehman from Adobe will be giving a presentation today at the JaxFusion User Group. The presentation will cover the next version of ColdFusion.
The meeting will be held at Vurv in Jacksonville at 6:30. The directions are on the web site. Be there or be square.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Sean Corfield has a great post at his blog in responce to my post about ColdFusion as a true OO language. Yesterday I tried to avoid the arguments for or against ColdFusion as a Object Oriented language. Sean points out some of the differences between C++ and Smalltalk as it pertains to method overloading.
You can get into a real religous argument about one language over another. I personally consider ColdFusion to be an Object Oriented language since the release of ColdFusion MX. You can do most of the things you can do in other Object Oriented languages i.e. Encapsulation, Persistence, Composition, Inheritance and Polymorphism.
One of the points I was trying to make is that by learning CFCs, you can springboard into other languages with very little effort. All of the same concepts you learn with CFCs can be applied to languages such as Java, C#, ActionScript, C++ and Smalltalk.
Alan Kay is credited with coining the term "Object Oriented" and for authoring SmallTalk. I read an interview with him recently, and he said that if he had it all to do over again he would not have used the term "Object Oriented", he would have used "Message Oriented". One of the real powerful features of Object Oriented development is the ability of objects to talk to each other.
I look forward to reading Sean's posts on double-dispatch.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Sean gave the first presentation I went too on creating factories for CFC based objects. As always, Sean is a great presenter and covered the topic well. He ended the presentation with a discussion of the ColdSpring framework.
ColdSpring simplifies the creation of factories by using a configurable XML file. I am going to see another presentation while I am here at CFUNITED on ColdSpring.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I watched Sean Corfield's presentation on duck-typing this morning, and he brought up very valid points on why we should not type parameters and returntypes.
The bigest advantage that I saw was performace. Sean said he was able to improve performance of the fusebox XML compile by 2-3 times. Joe Rinehart was in the audience and said he witnessed the same imrovement in speed for Model-Glue.
Since ColdFusion does not require types like Java does, we should take advantage of that ability. You still have to use typing when writting SOAP based Web Services and Flex marshalling.
Duck-Typing also makes unit testing easier because you can reuse your tests for multiple objects.
He mentioned that Michael and Judith Dinowitz, and Hal Helms have written articles on duck typing.
I will try to post links later in my comments.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I wrote a gateway service that allowed an Oracle database server to talk to a SQL Server database server about two years ago in ColdFusion MX 6.1. Back then I was able to use a centralized auditing table to store all of the inserts and update values. At my current job I am writing a lot of stored procedures, and I wanted to do the same thing just in Transact SQL. In ColdFusion it is fairly easy to serialize complex data into a string using WDDX.
You can do something similar to this to serialize name value pairs in SQL.

DECLARE @myTable TABLE (myString NVARCHAR(128) NULL, myInt INT NULL, myBool BIT)

DECLARE @myXML XML

INSERT INTO @myTable

SELECT 'My string' AS myString, 12 AS myInt, 0 AS myBool

SET @myXML = (SELECT *

FROM @myTable AS myTable

FOR XML AUTO)

If you are using SQL Server 2005, you can store the XML value into a XML column or cast it into a NVARCHAR(MAX) or NTEXT column.
The result will look like the following;‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I recently came across a nasty bug in Sharepoint 2007. When a custom workflow uses an intiation form to collect data for the start of a workflow, it will only collect this form when the workflow is run manually.
Workflow intiation forms can be created using InfoPath or aspx pages to collect data that can be used in the workflowProperties.InitiationData property. This form is only presented to the user when the workflow is run manualy in Sharepoint 2007. If you set the workflow to start automatically when an item is created or changed, Sharepoint will not present this form to collect the InitiationData.
There are a couple of work arounds you can use to get around this bug. One is you can set the InitiationData using an Association form when the workflow is first added to the Sharepoint list. You can also just make sure not to select the 'Start this workflow when a new item is created' or the 'Start this workflow when a new item is changed' check boxes.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I have been building Sharepoint Custom workflows this year and came across a nasty problem when I tried to reference the workflowProperties field in the onWorkflowActivated activity. I kept on getting a System.ArgumentNullException. The problem was actually a simple one to fix. I had not set the onWorkflowActivated property correctly to use the workflowProperties field. By the default when you replace this activity, it does not highlight that the workflowProperties need to be set to a field or property in your workflow.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I have been working on a lot of data coversions lately. One of the problems I run into is parsing dates from one RDBMS to SQL Server. 2000 has several different date formats. The one I have been running into problems with is the SMALLDATETIME data type.
I was able to parse out the different parts of the date using the datepart() function. The next problem I ran into was the date range. The date range for the SMALLDATETIME is from January 1, 1900 through June 6, 2079. I found a date that had a year set to 3003.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011This definitely will follow my own personal opinion on technology. If you have been living on another planet for the last year, you might have heard that there is a format war ala VHS vs. Betamax.
The two competing standards are a high def format from Toshiba and Sony's Blue Ray DVD. Toshiba's format, HD DVD, can store 15 gigabyte's on a layer while Sony's Blue Ray will store 25 gigabytes on a layer. Blue Ray also allows your DVD interactive content to be programmed with Java. Blue Ray also has better content protection that will allow consumers to copy Blue Ray content to other types of players. The only negative I have seen so far is that the media for Blue Ray is easier to scratch, but a solution has been found for that already.
With all of that being said, Sony will lose. Every new format that Sony has come out with has been a Sony only format. Betamax was a Sony format, and it failed. Betamax is still used at television studios because the quality is much higher than VHS.
I hope I am wrong. Sony has gotten a few studios to come to their side along with a few prominent Computer companies. Unfortunately, consumers usually buy the cheaper technology. As a developer, it would be nice to see a format that uses Java win.
Good Luck Sony.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I heard this weekend that Sony hired a company to develop a rootKit to be installed on the computer of the person listening to its CDs. If you are not familiar with rootKits, they alter the default functionality of an users operating system. This is very common behavior in spyware and malware. Apparently, they have been selling these CDs from the beginning of the year.
This is not the type of behavior I would expect from a major corporation like Sony, more like from a black hat hacker. I own a lot of sony products, but I do think I will be buying any of their music CDs any time soon.
The CDs should be labeled with some sort of label advertising that they have copy protection.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011SouthWest Signal has been trying to place a ColdFusion developer at their offices in Jacksonville, Fl.
Here is the job description;
Southwest Signal Engineering is expanding and we are looking for aColdFusion Web Developer for our Jacksonville, Florida office. Theindividual will work with a team & independently on web developmentand function in multiple roles to include: business analyst, developerand tester. They will design and develop new forms, reports and otherweb applications, support modification requests, identify and solveissues within several web applications.
Specific experience/knowledge requirements include:
A minimum of three years of web-based software development & hands-on experience on ColdFusion web development efforts.
Experience developing object-oriented ColdFusion web-basedapplications using CFCs and standard frameworks (e.g., Mach-ii,ModelGlue).
Familiarity with all areas of software developmentincluding object-oriented software design and how to transform modelsinto software code; user interface/front-end development (HTML, CSS);and business object/component development.
Database programming experience using SQL: hands-onexperience with Microsoft SQLServer and/or MySQL plus experience withdatabase design and modeling preferred.
Broad software-development experience preferred. BeyondColdFusion, Additional experience in other developmentenvironments/languages such as PHP/Python/Ruby/.Net also preferred..
Recognition and observance of industry-standardarchitectural and coding standards, an understanding of best-practicesin software development, and familiarity with different SDLC processesand agile methodologies.
The ideal candidate will have good verbal and written communication skills
Bachelors degree in Computer Science or closely related area, or equivalent experience preferred.
Contact a_daveline@swsignal.com‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Adobe released a new prerelease of the Spry Ajax framework today. One of the things included in this release is a DataSet Explorer. Spry uses the xpath to flatten XML into JSON array structures that are used by the framework to display the data in a HTML format, such as tables.
This Explorer tool makes it easier to introspect the XML, and how nodes are named by the framework. It is like having a CFDUMP tag for Ajax. The DataSetExplorer file is in the "samples/DataSetExplorer.html" path in the zip file.
Here is an example of a XML file I passed into the tool;
  
   
   
   
   
 Obsession  
   
   
 ...hesitation ... is an hereditary trait of your species, and suddenly faced by the unknown, or imminent danger, a human will invariably experience a split second of indecision. He hesitates.  
   
   
 3620.7.  
   
   
   
 
It will show the structure of the XML in a format like this;
wddxPacket  
@version
header
data
struct
@type
var (REPEATING NODE)
@name
string

You can click on any of the nodes and it will show you the data in that structure.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I have seen two blog postings by Matt Woodward and Dave Carabetta about the ending of the JRun 4.5 Beta (Cheeta). Let me speculate about what Adobe might be doing about JRun. Currently the standalone version of ColdFusion runs on a JRun runtime. When Macromedia merged with Adobe, Adobe was already providing enterprise solution running on J2EE.
I know a lot of the engineers are developing these solution on top of JBOSS. JBOSS is an open source J2EE server. The company that develops and supports this server was recently purchased by Red Hat.
It is extremely dificult right now to deploy ColdFusion for JBOSS, but it is possible. Adobe might be planning to use JBOSS for their future J2EE development, and just deploy ColdFusion on top of JBOSS for their Standalone version.
I am curious to see what Adobe is up to none the less.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I was speaking to one of my user group members, Luis Casillas, about Spry at our last meeting. I told him I had been thinking about writing a Spry example that searches YouTube tags, displays results, and even loaded the and played the Flash video.
Last night I sat down and took a look at the YouTube API. They use REST and XML-RPC interfaces to expose their api. They have good documentation on their dev site. I used the REST interface to call their tag search method in COldFusion. It returns an XML file that then consumes the XML through an ColdFusion proxy. This solves cross domain security issues, and allows the XMLHttpObj to call without security warnings. There is an example below.
  
<cfprocessingdirective pageencoding="utf-8" />
<cfsetting showdebugoutput="false" />
<cfparam name="url.tag" default="cat">
<cfset youTubeKey = "mykey" />
<cfset UTubeName = "myusername" />
<cfset methodName = "youtube.videos.list_by_tag" />
<cfset uTubeURL = "http://www.youtube.com/api2_rest?method=#methodName#&dev_id=#youTubeKey#&tag=#url.tag#" />
<cfhttp url="#uTubeURL#" charset="utf-8">

<cfcontent type="text/xml; charset=utf-8" />#resultXML#

I ran into problems with the XML feed losing the utf-8 encoding coming through COldFusion's CFHTTP tag. I specified utf-8 encoding with the cfprocessingdirective tag as well as the cfhttp tag and the cfcontent tag.
All the rest was done in JavaScript, so the page only has to load once. All of the real functionality are Spry Ajax calls using the Spry.Data.XMLDataSet object.
I use one DataSet object to perform my searches with, and I wrote two functions to use a form perform the search, and another to display the YouTube Video. The JavaScript code is listed below;
var UTubeURL = "youtubesearch.cfm?tag=";  
var UTubeXPath = "/ut_response/video_list/video";
var dsYouTube = new Spry.Data.XMLDataSet(UTubeURL, UTubeXPath, { method: "GET", useCache: false });
function isdefined( variable)
{
return (typeof(window[variable]) == "undefined")? false: true;
}
function searchUTube() {
var myTag = document.myForm.tag.value;
UTubeURL = "youtubesearch.cfm?tag=" + myTag;
dsYouTube.setURL(UTubeURL);
dsYouTube.loadData();
if (isdefined("so")) {
YouTubeVideoDiv = document.getElementById("YouTubeVideo");
YouTubeVideoDiv.innerHTML = "";
}
}
function showVideo(myid) {
var swfFileName = 'http://www.youtube.com/v/' + myid;
so = new SWFObject(swfFileName, "mymovie", "425", "350", "7", "#336699");
so.write("YouTubeVideo");
}

I used the following form code to perform searches on new tags.
"myForm" onsubmit="">  
<input type="text" name="tag" value="" />
<input onClick="searchUTube();" type="button" value="Search" />


I then used the following div tags and Spry regoins to display the movie and the search results;
"YouTubeVideo">  
<div id="mContainer" spry:region="dsYouTube">
<tr spry:repeat="dsYouTube"><td valign="top">

Image
Title


<a href="{url}"><img src="{thumbnail_url}" />



<a href="#" id="{id}" onclick="showVideo(this.id);return false;">{title}


{description}







The next problem I ran into was trying to load the SWF movies dynamically. Khary Mallea turned me on to the SWFObject library. Like Spry, this library dynamically takes care of the browser differences to make sure the movie will always display. Internet Explorer would not load the movies until I added this library.
You can view a working example at this url.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I have put the PowerPoint presentation and the sample code from my JaxFusion presentation on my site. The powerpoint and the sample code from my presentation last night can be located on these links.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Steve Jobs does not have a blog, but he does have a website called Apple.com. He has posted his thoughts on Flash at the following URL:
http://www.apple.com/hotnews/thoughts-on-flash/
There has been some controversy on Apple not having a way of playing back Flash content on their mobile devices. I think the main reason is that the mobile devices have slower processors, and Flash would slow the device down. Other than JavaScript, Apple does not allow interpreted environments to run on top of their hardware. Flash like Java has a VM that it runs on top of, and Apple does not allow emulation.
I have written Flex/Flash based applications, and one of the things I like about Flash is that you can write applications that look and act the same on any platform. This does not necessary translate well to mobile devices. I think you are better off writting software for the platform for mobile devices. I have written iPhone applications using Objective-C. I know a lot of Actionscript developers are probably weary of learning a new language, but Objective-C is not that big of a transition.
Jobs mentioned that he thought that HTML5 makes Flash obsolete, but HTML5 even though it is an open standard, the MP4 video format is a proprietary. HTML5 is still an unfinished spec. I think it shows great promise, but the browser vendors will interpret the spec different ways. The nice thing about Flas is that it always looks and acts the same on different platforms.Tags: W3C Standards   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011This story is already on Digg and Slashdot, but I thought I would throw my two cents on as well. Steve Gibson at GRC.comalleges that Microsoft intentionally left in a backdoor in Windows, and they did it recently in the 2000 period. If Steve's claim is true, it is really damning. If Microsoft is serious about Security, why would they put a hole into the OS. This was either a rouge microsoft programmer or something more sinister.
I currently use Windows and a Mac. My home computer is a Mac, and my work computer is a Windows laptop that my company gave me to use. Outside of work, I no longer use Windows. It is bad enough with all the spyware and malware written for Windows, but nobody needs Microsoft leaving intentional holes into their OS.
I really hope the Justice Department takes a look at this right away. Microsoft needs to open their source to developers outside of Microsoft to make sure that there are not any more holes like this in the OS.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Steve Robinson and Brian Merrill now have a podcast called the Sunshine Drenchy Podcast. If you like pop music, I think you will like this podcast from these St. Pete musicians.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Steve, one of the founders of my local CF user group has had some very interesting posts on his blog about Google Talk. He has written some applications that use Google's Jabber IM service for viewingthe mxna feed. If you click Here, you can read his posts, and get instructions on how to use the apps.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Macromedia is now shipping Studio 8. This edition has a lot of features made for designers. I am anxious to try out the new XSLT features in Dreamweaver.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I read this article about how Sun is going to open source Java. They just don't know how they are going to do it yet.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011This is not so much on the technical side, but it is pretty damn funny.
Check out this Flash Movie. It is a great time killer.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I listen to the Java Posse each week, and one of their hosts works at Sun Microsystems. Tor Norbye gave a presentation at JavaOne on something Sun has under wraps for a while, Visual Basic for the Java Platform.
I have never been a big fan of VB, but I know a lot of VB developers who felt they were left high and dry by Microsoft moving to .NET with all of the changes they made to make VB object oriented.
VB for the Java platform is taking advantage of the multi-language features in Mustang, the next major release of Java. As most ColdFusion developers know, you can run multiple different programming languages on Java already.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011The inaugural meeting of the newly reformed Tampa Bay Adobe User Group (TBAUG) will be held this week at the International Academy of Design and Technology. The meeting time is on Thursday, November 17th at 6:30pm.
My former boss and good friend, Donald Bickel, is heading up this new group. If you live in the Tampa Bay area, please come out and help him get the group started with a bang. The evening will include a presentation of Macromedia's latest product offerings, along with a Macromedia prize raffle. Refreshments will be served.
You can read more about it at http://www.iadtampa.com‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011One of the nice new features in SQL Server 2005 is the inclusion of an XML data type. Microsoft added the ability to use XQuery searches to pull values from this type.

DECLARE @filterData xml;

DECLARE @PersonID int;

SET @filterData = '';

SET @PersonID = @filterData.value('(/XMLDATA/REC/@PersonID)[1]','int');

--This will show the XQuery value in the PersonID

PRINT @PersonID

One of the problems I am seeing with developers using this code is that because Transact SQL is case insensitive, they forget that XQuery is not case insensive. The following example will return a NULL value

DECLARE @filterData xml;

DECLARE @PersonID int;

SET @filterData = '';

SET @PersonID = @filterData.value('(/XMLDATA/REC/@PersonID)[1]','int');

--This will show the XQuery value in the PersonID

SELECT @PersonID AS PersonID

Make sure you use the proper casing when using XQuery in your Transact SQL.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011If you use the following statement to empty our your transaction log, beware.
BACKUP LOG dbname WITH TRUNCATE_ONLY
When I am doing bulk loads for data conversions, it is not uncommon for me to fill up my transaction log. SQL Server 2000 will allow you to shrink your log file throught enterprise manager or the use of one of the DBCC commands, but you can still use code.
This option has been deprecated, and Microsoft is not planning on having the TRUNCATE_ONLY option in SQL Server 2007.
Another option is detaching the database, and then reattaching without the log file. SQL Server will recreate the LOG file from scratch.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I received an email from a friend of mine I used to work with in Tampa. He is reforming our old user group as the Tampa Bay Adobe User Group. They are going to be meeting at the International Academy of Design and Technology in Tampa. They will be covering a whole slew of products from Macromedia and Adobe.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I attended the Tampa Code Camp on Saturday. If you have an opportunity to go to one of these conferences in the area you live, you should.
Microsoft used to host the Tampa Code Camp, but now the code camp is run by Visual Gov. These conferences are essentially one day conferences that are free for developers.
The Tampa Code Camp had sessions on SQL Server, which were the sessions I attended, but also on AJAX, .NET, Silverlight, Sharepoint, XNA Gaming and a session on a Robotic API.
Check and see if if there is one in your area.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I wanted to thank every family member and friend who came out to watch the First Coast Head Race this past weekend. It was nice having cheering sections on different parts of the river.
Even though I had the lowest time for the masters class, I came in second place. The rower who came in with the next lowest time got first place with his handicapped time. In rowing, we shave seconds off the time based on your age. Since he was older than I was, he got the first place medal.
Several members of the club also won medals, and I wanted congratulate them as well. Everyone trained hard this year and it showed.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I made a blog post over the weekend that Engadget said that they were putting HD DVD on a Death Watch. Today Engadget says that Toshiba will announce tomorrow that they are officially killing HD DVD.
Most likely Toshiba will start manufacturing Blu-ray players. There has been speculation in the tech press that Microsoft pressured Toshiba to create a competing format with Sony to screw up sales of the Playstation 3. I am skeptical about Microsoft pressuring Toshiba, but there is another post on Engadget today saying that Microsoft will not add Blu-Ray support for the Xbox 360.
In the mean time I am going to see if I can find a playstation 3.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I have been trying to find a Podcasts on ColdFusion, and I just found out about one called the ColdFusion Podcast by Bryan Kaiser and Michael Haynie. These guys do a great job covering the latest news, blogs and theory surrounding ColdFusion. This is a definite must listen if you listen to Podcasts.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011The JaxFusion meeting for tomorrow has been canceled. We are going to try to do a make meeting in April.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I have to give thanks to getting home to Jacksonville from CFUNITED to an airline pilot named "Rusty". As my airline experiences have been lately, my flight out of Dulles was delayed. When I finally did get on the plane to fly to Charlotte, I was bemoaning the fact that my connection flight had already left before we took off. The passenger who was in the standby seat behind me was a pilot for the same airline. He told me he was going down to the races in Daytona. I told him I was supposed to go, but I missed my connection.
At this point, "Rusty", offered to give me a ride to Jacksonville once we landed. I accepted his offer, and we drove to Jacksonville from Charlotte. I would not have made it back last night if it had not been for Rusty.
How is that for service. If you are reading this Rusty, you are the coolest airline pilot on the planet!‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Damon Cooper posted a note on my Blog that JRun is not dead and will be around for awhile. Thanks for the update Damon.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011This article says that Toshiba and Sony are playing nice and will come out with dual format players. If it is true, it would be great news.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I try not to talk about my job on this blog, but I heard a rumor that I was no longer working at the job I actually work at, if that makes any since. I am currently employed at a company called Recruitmax Software. I have no intention of leaving any time soon.
Just wanted to report that the rumors of my demise have been greatly exaggerated.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I read on Ben Forta's blog that Tim Buntel is leaving Adobe. Ben says he is going to follow his true passion as an educator.
I used to run a user group in Tampa, and Tim came out to give a presentation on ColdFusion MX when it was first released. It was one of our biggest meeting the group had ever had. I was grateful that he came out. My parents are both teachers and I used to work as a Flight Instructor back in the 90s. I would still be Flight Instructing if my students did not keep on trying to kill me, but that should be left for another blog post. Teaching can be extremely satisfying and frustrating as the same time. I wish Tim good luck in his new career.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011At the end of the keynote, Tim Buntel was brought onto the stage in a very dramatic fashion, as if he was being kidnapped.
Tim annonuced that he was back at Adobe as the Sr. Marketing Manager for ColdFusion. He aslo told the audience that Adobe was going to spend some money advertising and promoting ColdFusion.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Buck Woody at Microsoft pointed me to this article at MSDN. There are actually some handy tips in there relating to scaling and security. Thanks for the cool tip Buck.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I am a big fan of public APIs that are provided by web sites such as Google, Microsoft and Facebook. I think one of the reasons that twitter has been successful is that their service can be accessed through their API's.
One of the jokes I heard at the Miami Flex Camp was that Adobe Air was a framework for building twitter applications. The truth is that Air is simply taking advantage of the public API's.
Here is a Shell script that I wrote to send twitter updates from the BASH shell in Mac OS X 10.5;

#!/bin/bash

curl -u username:password -d status="$1" http://twitter.com/statuses/update.xml

echo "Sent twitter a status update"

You will need to replace the username and password with your own username and password. I named my script "twitter". Once you create the script, you will need to change the permissions on the file to execute using a command like the following;

sudo chmod +x twitter

Once you have set the permissions on the file, you can use it in the following way;

./twitter "I am updating my twitter status"
‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Two of my co-workers, Henry Adam and Sai Kolla, turned me on to some new tools for testing Web Services. The first tools is called soapUI. It is an opensource project for testing SOAP calls and generating SOAP envelopes. They also have plugins for Eclipse, IntelliJ and NetBeans.
They also showed me a full blown testing tool called Lisa. This is not an open source tool, but is free to the first 50,000 registered users to download the tool. Lisa will allow to do assertions.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I just added two new powerpoint presentations to my main site. I try to make it a habit of posting the powerpoint presentations I use at the JaxFusion User Group right after the meetings, but I have been lazy.
Over the last two months I did a presentation on Flex 2 and the Spry framework. These and my other presentations can be found here on my site.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011If you are looking to hire experienced ColdFusion developers, I know two ColdFusion developers who have been working at NASA. Their contracts are up at the end of this month. They are currently based in the Cape/Orlando area of Florida.
If you know of any opportunities in Orlando area, or remote ones, please contact me, and I can put you in touch with these developers.
My contact email is davidfekke@gmail.com.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I have been watching some of the presentations at Charlie Arehart's UGTV web site. Charlie has added this site were people can place the links to their breeze presentations. There are some excellent presentations there to watch. Breeze presentations are a great way to learn about new subjects if you are unable to attend these presentations in person.
Keep up the good work Charlie.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I try to avoid getting political on this blog, but I started noticing something alarming a couple of weeks ago with my inbox. I am receiving a couple of extra hundred emails a day that are undeliverable emails being returned to my inbox because my email address is listed as the sender. I did a little research on the interweb, only to find this is nothing new. Spam is a reality for anyone who has had an email account for any length of time. I use filters and anti-spam software, but I still get more and more spam to the point now my personal email address is almost unusable.
I have a lot of friends who are against the death penalty, and want to see it done away with for good. I am taking the opposing view as of today.
Not only do I believe we should keep the death penalty, but it should be extended to cover spammers. I also believe the death penalty should be extended to people who complain about airport noise after they build a house next to an airport, but that is a whole other blog entry.
CAN-SPAM was supposed to fix this, but the problem has only gotten worse since the law was passed. The only real solution is a technological one. The fear of incarceration, or even death will not stop spammers.
This system would need to have some sort of authentication similar to the one used for SSL certificates. All client and server software will need to be upgraded to use this system, but this is the only was I see the spam problem being fixed.
In the mean time we should start executing spammers.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Microsoft dropped the Office Sharepoint Server 1.2 SDK last month which included a tool for generating Application LobSystem files for creating Business Data Catalog (BDC) applications. The BDC can connect to database resources or Web Services.
The BDC tool allows you to specify a connection string or a WSDL document for creating the LobSystem xml files. Their is a tutorial on MSDN explaining how to use the Web Services to create BDC methods and entities.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011One of the developers I work with recently had a problem trying to make Web Service calls to a SOAP based Web method that requires Request Headers. I ran into the same problem about a year ago using CFMX 6.1. Request and response headers for web services are now built into CFMX 7. It is possible to get CFMX 6.1 to send request headers. Here is how you can do it with CFMX 6.1. The first thing you will have to do is make sure CFMX is patched to at least the 6.1 updater (6,1,0,83762) or the hf53566_61.jar hot fix. This patch will cause problems with trying to use cfdump to output the cfcatch variable, but there is also a patch for that as well.
You will need to use the createObject function to create a web service object instead of using cfinvoke to be able to use the request header.
"webservice","[https://www.somecompany.com/services/somews.asmx?wsdl](https://www.somecompany.com/services/somews.asmx?wsdl)") />
Request headers are usually in the form of a XML object. You can use the CFMX's built features to create the xml object.
   
<cfset doc.Authentication = XmlElemNew(doc, "https://www.somecompany.com/services/ ", "Authentication") />
<cfset doc.Authentication.username = XmlElemNew(doc, "username") />
<cfset doc.Authentication.username.XmlText = "myUsername" />
<cfset doc.Authentication.password = XmlElemNew(doc, "password") />
<cfset doc.Authentication.password.XmlText = "myPassword" />

The resulting XML looks like this when serialized;
  
myUsername
myPassword


The object that is passed to to the request header method requires the use of some java, but it is very simple. The first thing that needs to happen is to turn the ColdFusion XML Object into something that Java will understand. There is a function built into every ColdFusion XML object that returns a Java based XML object.

Once you have the java based XML object, you will need to create a SOAPHeaderElement java object that will be passed into the web service object.
"java","org.apache.axis.message.SOAPHeaderElement") />  
<cfset headerElement.init(jXMLdoc) />
<cfset WSObj.setHeader(headerElement) />

Now that the request header has been set in the web service object, it is safe to call the methods that require that request header.

I plan on creating a web service on my web site that use request and responce headers. Thanks to Tom Jordahl and Damon Cooper who showed me how to get this to work in ColdFusion 6.1.
ColdFusion MX 7 handles this now quite well by using addSOAPRequestHeader() function. There is no longer a need to call the underlying java to make these calls.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I went to a presentation last night at the Jacksonville SQL Server user group on using .NET CLR code in SQL Server 2005. One of the neat features in SQL Server 2005 is the ability to write user defined functions, aggregate functions and stored procedures in .NET code. The examples they used included doing triple DES encryption and spherical trigonometry to calculate distances between latitude and longitude in SQL queries.
They accomplised this by writting functions in C# assemblies, and adding those assemblies to the SQL Server.
The bottom line is there are some things that are faster to do in the CLR than in T-SQL, and some things that are faster to do in T-SQL than in the CLR.
Complex math and string functions would most likely be faster in the CLR, but set based computing would be faster in transact.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I am pleased to annouce that Vince Bonfanti is coming to present the next version of BlueDragon at the March meeting for the JaxFusion user group. Vince Bonfanti is president and co-founder of New Atlanta Communications. We look forward to seeing him at the March meeting.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Vince Bonfanti of New Atlanta will be presenting the next version of BlueDragon tonight at 6:30. The meeting will be held at Vurv Technology in Jacksonville. You can find meeting details here.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Vince Bonfanti will be presenting the next version of BlueDragon at the JaxFusion user group. The next meeting will be at Vurv Technology in Jacksonville at 6:30 PM on Tuesday March 6th. Here is the write up for the next meeting;
BlueDragon 7.0: New Capabilities for CFML Applications
In this presentation, Vince Bonfanti will demonstrate some of the new and powerful language features of BlueDragon 7.0 including:


CFTHREAD and its associated tags


CFC interfaces and abstract CFCs


NULL value and the IsNull() function


CACHEDUNTILCHANGE attribute of the CFQUERY tag


Vince Bonfanti is president and co-founder of New Atlanta Communications,and has successfully brought three generations of web-scripting languages to market since 1995:


Lasso - A cgi-based web-scripting language and runtime for publishing FileMaker Pro databases. Lasso was sold to Claris (now FileMaker, Inc.), a wholly owned subsidiary of Apple, in March of 1997 - becoming the FileMaker Pro 4.0 Web Companion. Over ten million licenses of FileMaker Pro have been sold since its initial release.


ServletExec - A server-side Java based web-scripting language and runtime that implements the Java Servlet and JavaServer Pages (JSP) APIs.


BlueDragon - A ColdFusion Markup Language (CFML) runtime with native deployment and integration capabilities on both the Microsoft .NET and Java 2 Enterprise Edition (J2EE) platforms.


Vince also authored "blueprints", a regular column featured in the ColdFusion Developer's Journal (CFDJ). A charter member of Sun's Java Servlet and JSP Expert Groups, Vince has been a JavaOne speaker and a contributor to Java trade magazines and online publications. Vince has also been a featured speaker at CFML-based conferences as well as at local ColdFusion User Groups throughout the country.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I recently purchased a MacBook Pro a couple of months ago. I installed Boot Camp and purchased Parallels so I could run Windows in VM on a Mac. I have been running XP, but my company was interested in how well Vista would run on the Mac. Vista actually screams on the MacBook Pro. We rated Vista on my Mac, and it got 5.9 on some tests and as low as 4.5 on another. Overall it rates very high. My Mac has 2 GB of RAM and a slower hard drive.
I was reading that the next service pack for Vista will include support for EFI, Intel's replacement for BIOS. Currently to install and run Windows as the startup OS for the Mac, you have to use Boot Camp to handle the EFI BIOS differences in the hardware.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Like many other web developers on the Mac, I use Parallels desktop 3.0 on the Mac. I go back and forth between Boot Camp and Parallels depending on what I am testing.
I ran the most recent Windows update on my version of Vista while I was in Boot Camp. Now when I try to start Vista in Boot Camp, I get a Genuine Advantage error, and Vista will not continue to start. I have to restart in Boot Camp, and re-enter the serial number. I am running Vista Enterprise which allows virtualization.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011A client of mine ran into an interesting problem trying to debug a Sharepoint 2007 workflow. Whenever they try to attach the debugger to the w3wp.exe process that is running the workflow, they get a dialog that says "Access is Denied".
What is weird about this is they are logged in as administrator, and this is on the same box as the Sharepoint Server. The only thing that I see that is different is that the box has a x64 processor. I am curius if anyone else has run into this problem with Visual Studio 2005?‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I tried to install the Visual Studio 2008 SP1 update, and the install failed. I did some searching, but I was not able to find anyone else who is having this problem.
I have been running the SP1 beta for Visual Studio 2008. When I went to run the actual SP1 installer yesterday, I got prompted to run the Visual Studio 2008 Service Pack Preparation Tool.
I tried running the tool, and was prompted to locate "x64/Setup/vs_shell.msi" file on the Visual Studio installer disks. No such file exists on my original installer. The Visual Studio uninstaller does completely remove the IDE, so I am dead in the water until Microsoft Fixes this issue.
Update:
I uninstalled the Visual Studio 2008 shell, and I was able to run the visual studio patch tool.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I have added a poll to my site for who should win the Oscar for best picture.
This Flash Poll is using the old Pollster application. I will be interesting to see if the winner is the same as what the Academy chooses.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Many of you know that I work at Recruitmax Software. We just changed our name today to Vurv Technology, Inc.. This is an important change for our company as we continue to expand our business. Here is a link to a press release.
It is a lot of work to get your brand established, so to avoid confusion we will go by Vurv Technology, formerly Recruitmax Software.
I would like to say congratulations to our Marketing team, they have worked very hard to make this happen.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I just purchased a book on the Windows Communication Foundation. I had a discussion with a Co-worker about why someone would write a SOAP based web service in WCF over traditional ASMX. One of the advantages of WCF is that you take a service written in WCF, and also use it as a MSMQ messaging service or a windows service. I think there is a perception that if you write your services in WCF, they will not be compatible with Java, ColdFusion and other technologies. WCF is completely backwards compatible with the SOAP specification.
Microsoft suggests that if you are writing new web services in .NET, you should write them using in WCF.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Beware of installing the Microsoft SQL Server 2000 DTS Designer Components for SQL Server 2005. For a long time, I have been using both SQL Server 2005 and 2000 client tools on the same machine. When I installed the DTS 2000 components, it corrupted my SQL Server 2000 clients tools. I can use the 2005 tools for both 2000 and 2005, but the 2005 tools are definitely slower than the 2000 tools when working with DTS packages. Hopefully Microsoft will address this issue with SP2 for SQL Server 2005.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Many of you have probably heard about the WMF exploit that Microsoft still does not have a fix for yet. Steve Gibson over at GRC is hosting a fix and a vulnerablity checker on his web site.
The fix and the vulnerability checker were developed by Ilfak Guilfanov and tested by Steve Gibson.
I consider Steve Gibson the best resource on Computer Security. He hosts a podcast with Leo Leporte called Security Now that is a must listen.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I have been getting a lot of questions about which libraries need to be installed in order for the Stax sample code to work. All of the Stax libraries are available from the Codehaus.org site.
Here is a list of the Jar files I have installed in my web-inf/lib directory;
jsr173_1.0_api.jar  
jsr173_1.0_examples.jar
jsr173_1.0_javadoc.jar
jsr173_1.0_ri.jar
jsr173_1.0_src.jar
wstx-asl-3.0.1.jar
stax2.jar
‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011When I finished college, I read an autobiography by the famed Aeronautical engineer, Clarence "Kelly" Johnson. He started the Skunk Works at Lockheed during WWII. The Skunk Works developed the P-80, America‚Äôs first jet fighter, as well as the U2 spy plane, the SR-71, and most recently the F-117 stealth fighter. Johnson believed when you are engineering, you should always subscribe to the K.I.S.S. principle. That stands for Keep It Simple Stupid!
This is a motto I have always tried to subscribe too whenever it is possible. Sometimes it is not possible. A perfect example of that was the SR-71. There was nothing simple about the SR-71 to do as an engineer. Johnson told his engineers at the Skunk Works that he would give them $20 if they could find something simple to do on the SR-71. He retired with that same $20 bill. But if it was possible to something simply, he would do it that way.
A better example of over-engineering recently was the Apple dual button mouse. Like many Mac users, I purchased a third party mouse with a right mouse button when I bought my Mac. When Apple released their own two-button mouse, I ran out and purchased it thinking that it would be way better than my third party USB mouse. Well I was wrong. The Apple mouse sucks! It used pressure sensitivity instead of an actual button to tell if you have clicked. Even worse, the software has a difficult time of telling where you clicked on the mouse. So sometimes when you click on the right side of the mouse, it thinks you clicked on the left side. It also has side squeeze buttons, so if you grip the mouse the wrong way, it open up exposure for Mac OS X 10.3+. Long story short, I am now using a Microsoft mouse.
I recently ran into a situation where someone was trying to engineer a solution that was exceedingly complex, and did not necessarily solve the problem. I have found that sometimes it is a good idea to step back and take a look at your solution, and make sure it is accomplishing your goals without being exceedingly complex. Having peer reviews of you project is also a good idea. Sometimes a second set of eyes will point things that you did not take into account.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011One of the problems in the past with ColdFusion has been that you could not load CFCs into the session scope of your server in clustered environments, and have those CFCs replicate to the memory of the other app servers in your cluster. The issue was that session scope memory stayed resident in the memory of the application server. You could replicate simple data such as strings, but complex objects would not. In the Java world you can serialize java objects across servers. There have been workarounds such as maintaining sessions onto a single server through sticky sessions or using the request scope. The problems with these approaches is that you either had to keep your CFCs for a session on a single server, so if the app server died, you lost all of the session data. If you use the request scope, you have to reload the CFCs for every request, which is an expensive operation. Neither one of these approaches is ideal for scalable web applications.
With the release of ColdFusion 8 you now have the same ability to serialize CFCs in the session scope over multiple servers. This is not perfect either because there is some latency in replicating session data over multiple servers. Given the latency issues, you still gain in the redundancy of having session data replicated over a cluster of servers.
So why is this so important? The answer is that you can use persisted objects in a clustered environment. A perfect scenario for this new functionality is a shopping cart. Shopping cart data is typically transactional, but still need to be persisted. After the shopping cart goes to a checkout is usually when that data needs to be placed into a database. Before that the shopping cart can stay in session memory.
The Session.shoppingCart can now be persisted across page requests and application servers. If the server I am requesting crashes, my object will still be alive on the other application servers on the cluster.
If you are planning on using this new feature in ColdFusion 8, I would suggest doing research on session clustering. There are some good articles on how to configure app servers for clustering and replication session data. It is worthwhile to do research on how to set up NIC cards for replicating session data, and how many application servers you can cluster together without losing performance to latency.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I am going to watch a movie this afternoon with a bunch of friends. You might have heard of it, "The Godfather". Steven Spielberg says that "The Godfather" is the greatest movie ever made. I have added a flash poll that asks the question.
If you disagree with Mr. Spielberg, please let me know. You can vote here.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I use a RSS news reader to subscribe to several tech sources. One of those sources is Wired.
I used to be huge fan of Wired when the magazine first came out. They were incredibly inovative with there design and their editorial content. Granted a lot of it was unreadable because of the pink type on top of gold foil background from the latest eight color press. Even with the radical design, the editorial content was great. Here are the headlines that came into my reader today.
Sony in Bad Need of Recharging  
Christians Should Have Great Sex
Record Pot Busts in 2005
Plug-In Hybrid to Power Grid
Playlisting Web 2.0

I use to work as a journalist, and I realize that the same people who write headlines do not necessary write the articles. Maybe two of those are actually tech related.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Was it Sir Tim? I have always been curious who the developer was who misspelled referrer. The 'Referer' in the http cgi is the variable that represents the site or page you came from originally. In ColdFusion you can access this variable with cgi.HTTP_Referer.
Spelling has never been one of my strong points, and anyone who reads this blog on a regular basis knows this already. I was always curious who the developer was who misspelled referrer. And is it actually misspelled if he developer was from a country where referer is the correct spelling?‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011The biggest reason I will not be buying an Apple iPhone is they are not on sell yet, but that is not the only reason.
Now that I have left the Steve Jobs reality distortion field, there are a lot of features that I do like about the iPhone. I think the interface for the iPhone is truly revolutionary. From the demo I saw at the MacWorld keynote, the touch screen makes since for the best user input device for a smart phone. I had a Blackberry last year as my primary phone, but I was never really liked it that much.
The iPhone is also missing a number of things that I have in my current phone. My current phone is a Cingular 3G phone. The iPhone is only an EDGE phone. It looks like Apple is compensating for that with WiFi built into the phone.
It also looks like you will have to be a Cingular customer to get the phone. I hope that you will still be able to buy the phone unlocked. I think it is good that it is a GSM phone. In the US, there are only two GSM providers I know about, but this is the standard used outside the United States by most providers.
Right now my next Apple purchase will most likely be a Mac Book Pro.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Full disclosure here, I own an iPhone 4. I also develop software for the iPhone, so I have a vested interest in the iPhone succeeding as a platform. I have seen where you can drop the radio reception of the phone when you press on the lower left hand corner. Any phone you where you hold your hand on the antenna will reduce the reception. Between my previous iPhone 3Gs and my new iPhone 4 I have not been able to see a difference in call quality or data performance. If anything, the iPhone 4 seems like it may be a little better.
The office where I work is in downtown Jacksonville, FL. The AT&T coverage is horrible here, but my iPhone seems to have a better time making phone calls than my 3Gs.
Steve Jobs had a press conference today to discuss the iPhone 4 reception issues. A lot of blame has been placed on Apple for their antenna design, but the iPhone in the United States has always had reception issues and dropped calls. In the past much of the blame has been put on AT&T, but even then there are only certain areas that have bad reception. San Francisco and New York are always mentioned.
So whose fault are the reception issues. The Answer is the Government. In particular, local and state governments. One of the key take aways from that press conference was the amount of time it takes to add a cell tower. Here is an excerpt from the press conference today;
When AT&T wants to add a cell tower in Texas, it takes about three weeks... when they want to add one in San Francisco, it takes three years. That's the single biggest problem they're having. They're spending a lot expanding their networks, and our data rates are way better on the iPhone 4, but AT&T has to expand its network, and that's a long process. I know because we're constantly asking about it. They're trying really hard, and sometimes I think they should enlist the support of the users in the community.
_-_Steve Jobs
The reason it takes three years to add a new cell tower in San Francisco is the amount of government required red tape you have to go through to add a new tower. Steve Jobs is hardly an anti-government Tea Party Republican. I don't believe he would have brought it up at the press conference unless the government red tape was really creating problems resolving network issues.
AT&T should enlist their customers to call and right their local representatives to remove the red tape for adding new cell towers.Tags: ATampT   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I am starting my last day at MAX. I have to say the WiFI access at the conference is really good. I have had better access to the internet here than I do on my home WiFi network.
All in all, this is one of the best organizied conferences I have been too. Kudos to Macromedia.
I am looking forward to my next couple of Flex sessions. More posts soon.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011There have been a lot of posts on the interwebs this Summer on supporting Internet Explorer 6 (IE6). Recently on the Digg blog there was a post from one of the engineers that they have very low usage from IE6 at this point, so they are dropping support.
Ina Fried also had a post on how Microsoft is having a hard time getting companies to upgrade to newer version of IE. I am currently building web applications for business users, and as much as I would like to stop supporting IE6 it still has a 40 percent market share in the financial sector.
A lot of the problem stems from the fact that most companies are deploying desktops with Windows XP and IE6. IE6 was released in 2001, and has really started to show its age. Some of the problems have been that it does not support W3C standards fully, poor CSS support, security bugs as well as Javascript interpreter bugs.
Even though IE7 and IE8 have improved on the standards and security, there are still major problems with the Javascript bugs.
Hopefully with Windows 7 coming out soon, more companies will start to upgrade their PCs with this new operating system.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Having been a resident of the Tampa Bay area for a long time, 22 years, one of the things I was proud of was that Wikipedia was based out of St. Petersburg, FL. I read recently that the foundation is moving its office's from St. Pete to San Francisco.
I am sorry to see Jimbo and the gang moving out of state, but I can certainly understand why they are moving. According to the article, they are "moving to San Francisco in an attempt to create a larger brand, attract more talent and make better inroads in developing countries, particularly in Asia".
As for me, I am happy staying here in the Sunshine state.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I just went through the process of making sure my site is XHTML 1.1 and CSS compliant. The W3C.org site has several validators that will inspect your code to make sure it is compliant. They will show line by line where there are problems in your code.
Bottom line is that my site had a lot of compliance issues. I got them fixed, but here are some of the gotchas I ran into cleaning up my design.

Since XHTML is a subset of XML, it follows all of the rules of having proper XML formating. I had a lot of breaking returns. Single tags require that you have a slash at the end, or a closing tag. Breaking returns should look like this;

It is also common to have paragraph returns in a single tag, but this is not proper either. Your paragraphs should be enclosed in beginning and end tags.
  
 Your paragraph here.  
 
For the 1.1 compliance you need to adhere to strict XHTML. Targets attributes are not allowed in href anchor tags. I have used target="_blank" to open up new windows, but I have had to replace them with the following syntax;
"javascript:window.open('[http://www.JaxFusion.org/](http://www.JaxFusion.org/)','JaxFusion');" title="Home of the Jacksonville, FL ColdFusion User Group">JaxFusion‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I am a huge sports fan. I wanted to say that before anyone got the wrong idea. I used to play Soccer, or Association Football as my brother-in-law likes to call it, when I was kid and later as an adult. My brother-in-law played professionally in the U.K. I also have played baseball, basketball and I currently crew competitively.
Soccer is the most popular sport in the world, or so I have been told. If this is true, I really feel sorry for the world. The last two world cup finals I have watched have been decided by kickoff competition.
One of the things I like about baseball is that there is no tying, or crying for that matter. Both teams play until someone wins. A baseball game usually lasts for nine innings, but it may go 14 or 15 innings before a winner is decided.
I think FIFA should change the rules, especially for the final rounds, so that Both teams play until someone scores a goal.
Another change that should be adopted is the idea of a penalty box like in Hockey. That way if your captain headbuts another player, instead of getting a red card, he could sit out ten minutes in the box.
There are also a lot of dramatics on the field with players falling down like they are hurt, especially when the other team is trying to score a goal. I heard on the news that the doctors for the world cup said that half of the players who do this have no injury at all. They should not stop play if a player falls down.
I think FIFA should adopt these changes if they want to remain the "most popular sport in the world".‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011The next Jaxfusion user group meeting will be hosted by me and I will be covering XML features in ColdFusion, and features that have been added since 7. This presentation will also cover how to leverage Java to overcome the shortcomings of XML DOM. The meeting will be held at Vurv Technology in Jacksonville, FL on October third at 6:30 PM.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Sean Corfield had a terrific presentation today on Enterprise integration using ColdFusion. I found this very interesting
because this is the kind of development I do everyday. He talked a lot about about messaging based systems for integrating enterprise data. The Two big ones are JMS and SOAP.
Other were also mentioned like of the microsoft variety. The importance of making sure your integration code is "loosely coupled" was also brought up in the presentation.
He also mentioned how security is becoming a bigger factor, like adding the ability to use SOAP headers in the request and responce to a Web Service.
Some of the other ways organizations exange data is by ftping or httping flat files and xml files. Occasionally some use a shared database, but this is uncommon because of differences of database schemas.
There is a function on cflib called listFix() for fixing inproperly formated csv files.
After watching this presentation, I definately want to start looking at using JMS more for integration. Sean also mentioned that there are many different providers for this type of software including open source.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I heard about this today on the CF-Talk list. There is a survey about what ColdFusion developers would like to see in a IDE if one were to be developed by Adobe. Here is your chance to let Adobe know what you want in an IDE for ColdFusion.
I personally use CFEclipse and enjoy using that more than DreamWeaver or Homesite.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Macromedia has posted mine and Steven Erat's comments onto livedocs for xmlsearch about the NoNameSpace issue.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I got tired of waiting for Macromedia to fix the bug in XMLSearch, so I wrote this User Defined Function that will bypass the problem with xpath searching when the xmlns attribute is set in the XMLDoc.
The code below uses a regular expression to strip the xmlns attribute out of the XMLDoc before performing the xpath search.
<cffunction name="fixedXMLSearchOld" access="public" returntype="array">  
 <cfargument name="XMLString" type="Any" />  
 <cfargument name="xPathString" type="string"  
 <cfset var myRegEx = 'xmlns[ ]*=[ ]*"[[:graph:]]+"' />  
 <cfset var currentXMLString = "" />  
 <cfset var currentXMLDoc = xmlNew() />  
 <cfset var myArray = arrayNew(1) />  
 <cfif isXMLDoc(arguments.XMLString)>  
 <cfset currentXMLString = rereplaceNoCase(toString(arguments.XMLString),myRegEx,"","all") />  
 <cfelse> 
 <cfset currentXMLString = rereplaceNoCase(arguments.XMLString,myRegEx,"","all") />  
 </cfif>
 <cfset currentXMLDoc = XMLParse(currentXMLString) />  
 <cfset myArray = XMLSearch(currentXMLDoc,xPathString) />  
 <cfreturn myArray />
</cffunction>
I also wrote a version in cfscript.
 function fixedXMLSearch(XMLString, xPathString) {  
 var myRegEx = 'xmlns[ ]*=[ ]*<font color="BLUE">"[[:graph:]]+"</font>';  
 var currentXMLString = <font color="BLUE">""</font>;  
 var currentXMLDoc = xmlNew();  
 var myArray = arrayNew(<font color="BLUE">1</font>);  
 if (isXMLDoc(arguments.XMLString)) {  
 currentXMLString = rereplaceNoCase(toString(arguments.XMLString),myRegEx,<font color="BLUE">""</font>,<font color="BLUE">"all"</font>);  
 } else {  
 currentXMLString = rereplaceNoCase(arguments.XMLString,myRegEx,<font color="BLUE">""</font>,<font color="BLUE">"all"</font>);  
 }  
 currentXMLDoc = XMLParse(currentXMLString);  
 myArray = XMLSearch(currentXMLDoc,xPathString);  
 return myArray;  
 }  ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I was wrong. XMLSearch is not broken. Steven Erat at Talking Tree made a post about this issue on his blog.
The issue has to do with setting a namespace without using a prefix qualifier. Here is an example from Steven's blog;
"[http://ns.r-xml.org/2004-08-02](http://ns.r-xml.org/2004-08-02)" ....>
Since the xml sets a namespace without the qualifier, no namespace gets set at all. Because of this, the xPath has to be explicit;
/:BackgroundReports/:ProviderReferenceId/:IdValue
By placing the colons after the forward slashes, you are telling the search that the elements are in a no-name namespace. This should return the results you are looking for in your xml.
Thank you Steven Erat for pointing out what was actually happening.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I really wish Macromedia and the ColdFusion team would fix their bugs! I was a beta tester for Blackstone, and I hoped that Macromedia would have fixed the XMLSearch() before CFMX 7 was released.
I just tested CFMX 7.0.1 to see if this was fixed, and it is still broken. I am happy that there is a Macintosh installer now, but this has been an issue all the way back in CFMX 6.
XMLSearch() works fine until you set a XmlNsURI anywhere in the XML document. You can test this by adding a xmlns="anyURLHere" name attribute in any tag in your XML file. Once this is set, XMLSearch() breaks.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I have been doing a lot of work with XML validation lately. I have the Visual Studio tool that comes with SQL Server 2005, and it actually has very nice tools for creating xml schemas.
A lot of applications that except applications require that the xml be validated against and xml schema file, or an xsd. ColdFusion MX actually has parameter now in xml parse that will validate your xml.

If you are still using ColdFusion MX 6, you can still validate your xml against your schema using UDF function from [cflib](http://www.cflib.org/) that uses the built java functionality in ColdFusion.
The function is called validateXMLFile. It will validate xsd and dtd files as well.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011CFMX 7 has builtin xsd validation using the xmlParse function. What about CFMX 6.1. There is a very neat udf on cflib.org site called xsdValidate.
Here is an example using this udf in cfmx 6.1.
  
<cfset xmlUri = "file:///c:/test/bad.xml">
<cfset xsdUri = "file:///c:/test/test.xsd">

Valid: #xsdValidate(xmlUri, xsdUri, "", err)#

<cfdump var="#err#" label="Information about the error, if any">
This udf requires the Xerces XML parser. It works by calling the underlying Java classes to validate the xml against the xsd file.
Kudos to Sameul Neff who wrote this udf.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Apple Insider has a nice preview of the next version of Apple's Xcode IDE. Xcode 4 was previewed at WWDC, Apple's developer conference earlier this month. I have been developing applications in Xcode for a little over year, and it looks like it fixes a lot of the complaints that I and other developers have had about xcode 3 who have used Visual Studio.
One of the biggest changes is that Interface Builder is no longer a separate application, it is built into Xcode. Another one of that changes is that there is a single window for the whole IDE. You can open up your header file and implementation file at the same time.
I know this will make the Ruby developers happy, Xcode 4 supports git. Apple is also adding a timeline viewer so you can use a time machine like slider to look at you code changes as well as side by side comparisons of the different versions of the file.
I am very excited about this release of Xcode.Tags: Subversion   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011You know you are at CFUNITED when you walk into the hotel and you see Ben Forta, Sean Corfield, Charlie Arehart and Raymond Camden in the first five minutes of being at the hotel. I wish I could say the weather here in Washington was great, but I would be lying. It has been raining non-stop since we arrived. It does not inspire confidence when the cab driver screams in terror several times on the way to the hotel because of the wet driving conditions.
The hotel is actually quite nice, and we have a nice room to watch the rain from.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I am a board member of my local rowing club here in Jacksonville. When they found out I was a web developer, they asked me if I would work on their web site.
Our hosting provider uses LAMP to host their web sites, so everything is Apache, PHP and MySQL. I have worked with MySQL and Apache before, but not so much with PHP. Since I know enough to be dangerous with PHP, I decided to try using one of the open source packages for blogging, so we could use blog software on the web site.
I decided to use bBlog for our blog. One of the things I noticed was how easy it was to install the different php projects that I came across. Most of these packages make it very easy to install on a LAMP site just using FTP and an HTML based wizard.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I guess Vince from New Atlanta made a statement on the cf-talk list that Sean Corfield was a liar.
Vince says:
Sean's statement that MySpace is "not (running) BlueDragon" is blatantly, factually false.
Ok, here is my two cents. I think Vince overstated his claim that BlueDragon.NET was powering MySpace.com. I have met Sean before, and he is an honest guy. Marketing is just that, Marketing. Vince should chill.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I recently ran into a situation where someone needed to call one of my web services, but they could only generate a proxy class if my wsdl file and service were rpc encoded. It turns out that there several different wsdl and SOAP message styles. The most common are rpc/encoded and document/literal. There is a very good IBM article about the differences between the different styles.
ColdFusion MX 7.0.1 supports the two most common styles now. Macromedia's livedocs has examples of how to change styles using the style attribute.
If you need to change the style to document/literal, all you have to do is change the style attribute in the cfcomponent tag to document.
"document" >‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I saw on Ben Forta's blog today that cfeclipse was released recently. More details can be found at www.cfeclipse.org.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011One of the slogans for Java is write once, run everywhere. What that really means is write once, test everywhere. I have been writting some web service based API examples in a couple of different environments including java. I just downloaded the NetBeans 5.0 IDE from Netbeans.org. I wrote a application that calls and displays the results of the web service.
I did have to add an additional library for the web service call on my Mac for the application to run on both Windows and the Mac. I also set the look and feel so it would look like a Windows application on the PC, and like a Mac app on the Mac.
UIManager.setLookAndFeel(  
 UIManager.getSystemLookAndFeelClassName());‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Just finished watching a presentation on cfform by Mike Nimer of Macromedia. He showed how you can create you own XML skins for forms using CFML.
One of the examples he gave used the fckeditor. He also said that you can use qForms in your skin if you do not like the JavaScript generated with cfform. I am a huge fan of qForms, so I will probably start creating my own skins now to take advantage of this feature.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I have been lite blogging lately. I have been preparing for FISA world rowing championships in Princeton, NJ.
I read today on Sean Corfield's blog that Fuseboxframework.org website is up now as well as a SVN and bugtrak site.
The Mach-II 1.1.1 beta has also been released as well, so I will have to check that out.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I got home last night and installed the latest iPhone update, version 1.1.3. This update includes a new version of the Google Maps with a location aware feature. This uses triangulation from Cell towers to find your position on the map. This works well enough that I am planning using this instead of getting hand held GPS.
One of the other cool features is the ability to reorganize icons on the home screen and even create additional screens.
On the downside, the Uconnect feature still does not work with the bluetooth in the iPhone. I was hoping Apple would fix this, but it still fails to complete the calls.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I just upgraded my iPhone to the 2.2 update. Updating the software on my iPhone broke my bluetooth connection to my MyGig audio system in my Dodge.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I moved my site to ASP.NET MVC 2.0 last year. I was disappointed that there was not a blogging software that was not written for the MVC framework. When I started doing research on MVC based blogging engines, there were not any that used a relational database as the content repository for the blog. There was one that was a work of progress, and that was Oxite. Oxite went on to become the Orchard Project.
Orchard is a content management system. It is based on ASP.NET MVC 3.0, and allows you to add your own modules as well. The requirements for my site were pretty simple. I needed to have individual pages such as ‚ÄòAbout‚Äô and ‚ÄòContact Us‚Äô, but I also needed to be able to bring over my blog.
Here are my experiences with installing orchard cms with the Microsoft webmatrix tool. I decided to port my home site using the new orchard since it is based on ASP.NET MVC 3.0.
Setting up the dev site
I used WebMatrix to created new orchard site on my Windows 7 box. When you create a new Orchard site if prompts you for a site name, admin username and password, as well the choice of a SQL CE or SQL Server database.
Porting my blog
My previous blog was hosted using blogengine.net. That blogging software can export the contents of the blog in the BlogML XML format. So I exported my blog, and used Nick Mayne‚Äôs BlogML module to import my blogml XML file.Tags: orchard,   ASP.NET MVC   ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I recently started developing some iPhone applications and registered in the iPhone SDK program at Apple. As Apple typically does, they have sworn me to secrecy about their new iPhone APIs. It has been fun planing around with Apple's development tools. If you use a Mac, the development tools are are free. On the Mac there are already a lot of options for developing application. I have used the Mac for years for doing my ColdFusion, Flex/Air and Java server development. Up until a couple of months ago I have never bothered to actually use Apple's tools such as xcode and Interface builder. Xcode will allow you to build applications using many different languages including AppleScript, Ruby, Python, Java and C++. The iPhone is a different animal. You can only develop using Objective C or C++. By default Objective C is Apple's language of choice. One of the key reasons Apple has given for this limited choice are the limited resources of the iPhone. As advanced as the iPhone is, it is using an Arm processor with 128 MB of RAM. On the Mac you can use a garbage collector when developing Obj-C applications, but this is not an option on the iPhone. You are required to do your own memory management. Obj-C uses pointers for non-primitive objects, but Apple has actually implemented a nice framework that helps you manage your memory. Obj-C, like C++ uses header files. Your header files typically contain your interface, while you code file contains the implementation. This is one of the things that has kept me from ever doing any C++ development. I always have felt writing a header file is like having to write the same code twice. So far I am finding Objective C to be a language that is somewhere in between C++ and Java in its ease of use. Another thing that C developers will find weird is the SmallTalk like syntax. A typical call to create a new object might look like the following example;

NSObject *myObject = [[NSObject alloc] init];

The same call in Java would look like this;

NSObject myObject = new NSObject();

I intend on blogging about my experiences with the Cocoa Framework. I am also trying to start a Cocoa user group here in Jacksonville. I am giving a presentation on iPhone development at this years Jacksonville Code Camp. If you are interested in joining this group, please send me a buzz.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I have posted my presentations from the annual Jacksonville code camp on this site. Thanks to everybody who came out to code camp this weekend.
The iPhone development presentation and the ASP.NET MVC presentation are both in Microsoft Powerpoint format.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011The annual Jacksonville code camp is tomorrow. I will be giving a presentation on iPhone and COCOA development. There will be a lot of presentations on SQL Server and .NET as well. I am looking forward to seeing some of the .NET 4 presentations.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I have posted on this before, but the iPhone is coming out tomorrow. I am still not getting an iPhone.
The biggest criticism I have seen for the iPhone is that Edge network is slow. My current Cingular phone is a 3G phone, and I get pretty good reception here in Jacksonville. Here are the other reasons why I am not getting one; No Mobile Java, No mobile Flash and no GPS. That being said, it is also a closed platform. My current cell phone, which is not a Smart phone can still run third party applications.
YouTube is re-encoding all their videos for H264. Apple could have just supported Flash FLV, and YouTube would not have to re-encode all of their video.
I guess AT&T and Apple are afraid that Skype are going to kill off AT&T's long distance business.
I also think that some of the arguments against the iPhone are bogus. The complaint I have heard is battery life. Most cell phones turn the screen off when they are not in use. I have also read a lot of complaints about the touch screen. I think the virtual keyboard make a lot more sense than the current qwerty keyboards that ship with some smart phones. The keyboard on my Blackberry really sucked.
If Apple where to offer 3G and GPS, I would buy an iPhone. Hopefully Apple will fix this with the next rev of the iPhone.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011The Apple iPhone is not a true smart phone. Like the iPod, the iPhone is a closed platform. You can buy content such as music and TV shows, but not third party applications.
Apple will be the only party to provide applications for the iPhone according to CEO Steve Jobs. The only real way to provide third party applications will be through the safari web browser.
I have owned several smart phones, and the feature I like most is the ability to buy and download applications. I really hope Apple opens this up in the future.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Well I bought one. I got an iPod Nano today. I have always been a fan of Apple's hardware, and this is the third one I have owned.
A couple of things blew me away about this iPod. It has flash based memory, so it has much longer battery life. It also has a color screen, and synced all of my photos the first time I plugged it in.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011The iPod Nano is not compatiple with Firewire. When I plaugged mine in to my Mac at home, I was presented with an error message that I could charge the iPod, but I could not transfer data. It took a lot loinger to upload my music using USB.
Other than that, I must admit, I realy love the color screen. It syncs all of my contacts and photos very nicely. This is also very good integration with the enhanced podcast. It is like having chapters that you can page through using the next song buttons. It will also display the different artwork for those chapters.
The battery life is phenominal. I used my iPod Nano all weekend long with out recharging. According to Apple it has a 14 hour battery life. It only takes one and half hours to get an 80 percent charge. So far I am extremely impressed.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011Apple released a whole bunch of new software and hardware today. Part of that is Motorola is releasing a phone that will work with the iTunes Music store. The service will be provided by Cingular.
They also released iTunes 5.0 today as well. You can create multi-level playlists, and overall, it seems a lot faster on Windows. They also included Outlook integration. Hoorah!!!
They came out with a new Mini replacement. The iPod nano replaces the harddrive with Flash memory. It also has a color screen. Very cool. I am thinking about picking one up.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011I do a lot of data conversions with my current job. I use a lot string and date function that are provided in Microsoft SQL Server 2000 in order to validate column when doing my bulk inserts and updates. I came across one today that is in the books online, but I did not realize it was there.
I use ColdFusion functions all the time like isDate and isNumeric to check variables for proper type. Here is an example of where these functions can be used in bulk inserts.
USE myFakeDB;  
 GO  
INSERT INTO myTable (oldCustomerID)
SELECT CASE isNumeric(CustomerNumber)
WHEN 1 THEN CustomerNumber
ELSE 0
END
FROM myTempTable
LEFT JOIN myTable
ON myTempTable.CustomerNumber = myTable.oldCustomerID
WHERE myTable.myPrimaryKey IS NULL;
GO
This will also work on bulk updates as well.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011January 14 ‚Äì28th are the 14 days of jQuery. If you are not familiar with jQuery, it is a highly popular open source Javascript framework. Microsoft is now including jQuery with new editions of Visual Studio. John Resig and other developers are giving presentations on new features that are being included with version 1.4 at the 14 days of jQuery site.
One of the changes in this coming release is a new API documentation site for jQuery. This site has a listing of the new and changed functions in jQuery.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2011jQuery will be the focus of the next JaxFusion meeting this coming Tuesday. jQuery has been popular with the ColdFusion community for awhile, but Microsoft will be including it with their ASP.NET products going forward.
There are millions of javascript frameworks for developers to use, but there is a lot of momentum behind jQuery. I am using it with my current job, and have found it to be very powerful.
The next JaxFusion meeting will be on October 21st at 6:30 PM at Southwest Signal.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJune 22nd, 2008Bye Bye George :-(

    

My favorite three comedians are George Carlin, Dennis Miller and Stephen Wright. I was saddened to learn this morning that Comedian George Carlin passed away.
I saw Carlin the first time I was out in Vegas. At the end of his routine he did his famous bit on "the" Seven dirty words you can't say on radio or TV. He said when he originally did the bit, it was not "the" seven words, it was "here are seven words you can't say".
A radio station played the bit late at night in 1978, and they were fined by the FCC. They took their case all the the way to the Supreme Court until the court said that you cannot actually say those seven words.
Carlin said that he was proud because his name was mentioned in the annals of the Supreme Court for all eternity.

      
    
  
  
    ‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeJanuary 17th, 2008It was ten years ago when Michael Dell answered a question about what Apple should do at an expo in Orlando with this comment;
"What would I do? I'd shut it down and give the money back to the shareholders,"
This Fortune CNN Money article shows the difference in stock valuations between Apple and Dell. Apple is now worth more than twice then what Dell is worth as a company. To be fair, I think Michael regreted making that comment, but in the end it doesn not matter. Apple was able to inovate their way out of a crisis with good solid design.
Dell on the other hand does not inovate, they rely on Microsoft and Linux to do the inovating. Dell is not a technology company, they are a logitics company. Apple has applied a lot of those principles to their business, but they did not forget about design in the process.
I recently purchased a new laptop. I bought a MacBook Pro. I use it to run Vista and Mac OS X. I doubt I will ever buy a Dell.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeAugust 17th, 2007I have been developing custom Sharepoint workflows in Visual Studio 2005 over the past year. It can be fustrating developing for Sharepoint 2007 because Microsoft has done a lousy job documenting the Sharepoint API.
The SendMail activity in the workflow tools does not allow for email attachments. I found a good work around is to use the .NET email API in a custom code activity. In the following example I send an email with an attachment.

SmtpClient client = new SmtpClient();

client.Host = smtpServer;

client.Port = 25;

client.DeliveryMethod = SmtpDeliveryMethod.Network;

MailMessage myMailMessage = new MailMessage();

myMailMessage.From = new MailAddress(this.fromEmail);

myMailMessage.Subject = "Test email subject";

myMailMessage.Body = "This is a test email message.";

myMailMessage.To.Add(new MailAddress(toEmail));

MemoryStream myMemoryStream = new MemoryStream(this.attachmentByteArray);

myMailMessage.Attachments.Add(new Attachment(myMemoryStream, this.attachmentFileName));

client.Send(myMailMessage);
If you need to dynamically get the name of the Smtp server, you can get this throught the parent web application. Here is an example of how to call it through the Workflow Properties.

SPSite site = this.workflowProperties.Site;

SPWebApplication webapp = site.WebApplication;

//Get the SMTP server 

string smtpServer = webapp.OutboundMailServiceInstance.Server.Address;

I found the previous example in this
Blog post.
Update
There is a question on how I got the Byte[] array. I used a InfoPath form to collect the attachment. The InfoPath form stores this attachment in a XML node as base64 encoded string. When .NET pulls the value from the XML node, it turns the value into a byte array. I then use the following code to extract the filename and the document data;

byte[] myAttachment = myInfoPathForm.Attachment;

if (myAttachment != null)

{

int namebufferlen = myAttachment[20] * 2;

byte[] filenameBuffer = new byte[namebufferlen];

for (int i = 0; i < filenameBuffer.Length; i++)

{

filenameBuffer[i] = myAttachment[24 + i];

}

char[] asciiChars = UnicodeEncoding.Unicode.GetChars(filenameBuffer);

string filename = new string(asciiChars);

filename = filename.Substring(0, filename.Length - 1);

byte[] filecontent = new byte[myAttachment.Length - (24 + namebufferlen)];

for (int i = 0; i < filecontent.Length; i++)

{

filecontent[i] = myAttachment[24 + namebufferlen + i];

}

this.attachmentByte = filecontent;

this.attachmentFileName = filename;

}

This code only works if you are pulling the data from an InfoPath form.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeMay 24th, 2007This paragraph is taken from a Computerworld article today that I saw on DIGG.

This once-popular Web programming language -- released in the mid-1990s by Allaire Corp. (which was later purchased by Macromedia Inc., which itself was acquired by Adobe Systems Inc.) -- has since been superseded by other development platforms, including Microsoft Corp.'s Active Server Pages and .Net, as well as Java, Ruby on Rails, Python, PHP and other open-source languages. Debates continue over whether ColdFusion is as robust and scalable as its competitors, but nevertheless, premiums paid for ColdFusion programmers have dropped way off, according to Foote. "It was really popular at one time, but the market is now crowded with other products," he says.

Apple ran throught this about ten years ago with the Apple is dead, and Mac is Dead. Of course now Apple is stronger than they have ever been. As far as I am concerned this is another example of tech journalism going down hill.
It is also an example of Adobe not doing its job in marketing ColdFusion.
Look for more about this on my blog.‚Üê Previous Page ¬†Next Page ‚Üí



Twitter/XLinkedInReddit   Listen to Post By David FekkeMarch 17th, 2007Ok, I am on the bandwagon now. I just started a twitter account. I have also added a twitter widget to my blog.
The widget I added to my blog is a Flash widget. Twitter also has HTML Javascript widgets that can be added to your homepage. The best feature I like about twitter is the ability to update my accout over my cell phone using SMS messages.¬†Next Page ‚Üí



